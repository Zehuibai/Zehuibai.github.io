<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title> Safety Signal Detection and Evaluation</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Zehui Bai</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="02-Clinical_Experience.html">
    <span class="fa fa-user"></span>
     
    Clinical Experience
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-sliders"></span>
     
    Sample Size
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="03-SSC-Everything-to-Know-About-Sample-Size-Determination.html">Everything to Know About Sample Size Determination</a>
    </li>
    <li>
      <a href="03-SSC-Choosing-the-Effect-Size-for-Sample-Size-Calculations.html">Choosing the Effect Size</a>
    </li>
    <li>
      <a href="03-SSC-Biosimilar-Trials.html">Statistical Considerations for the Design and Analysis of Biosimilar Trials</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-and-Power-for-Non-Parametric-Analysis.html">Sample Size and Power for Non-Parametric Analysis</a>
    </li>
    <li>
      <a href="03-SSC-Power-for-Complex-Hypotheses.html">Power for Complex Hypotheses</a>
    </li>
    <li>
      <a href="03-SSC-Alternatives-to-Power.html">Bayesian methods - Alternatives to Power</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-for-Pilot-Studies.html">Sample Size for Pilot Studies</a>
    </li>
    <li>
      <a href="03-SSC-Case-Continuous-Endpoint.html">Sample Size Determination for Continuous Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Categorical-Endpoint.html">Sample Size Determination for Categorical Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-Determination-for-Counts-and-Rates.html">Sample Size Determination for Counts and Rates</a>
    </li>
    <li>
      <a href="03-SSC-Case-Survival-Endpoint.html">Sample Size Determination for Survival Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Repeated-Measures.html">Sample Size Determination for Repeated Measures</a>
    </li>
    <li>
      <a href="03-SSC-IA-Sequential-Design.html">Statistical Considerations for Group Sequential Design</a>
    </li>
    <li>
      <a href="03-SSC-IA-Adaptive-Design.html">Statistical Considerations for Adaptive Design</a>
    </li>
    <li>
      <a href="03-SSC-Multiple-Test.html">Sample Size for Multiple Test</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-pencil-square-o"></span>
     
    Study Design
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="04-Design-Estimands-Framework.html">Estimands Framework</a>
    </li>
    <li>
      <a href="04-Design-Estimands-Practice.html">Estimands and Sensitivity Analyses</a>
    </li>
    <li>
      <a href="04-Design-Phase-I-Trials---Design-Considerations.html">Phase I Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-II-Trials---Design-Considerations.html">Phase II Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-III-Trials---Design-Considerations.html">Phase III Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-IV-Trials---Design-Considerations.html">Phase IV Trials - Design Considerations for Post Marketing Surveillance</a>
    </li>
    <li>
      <a href="04-Design-Complex-Sequential-Trials.html">Complex Sequential Analysis Trials</a>
    </li>
    <li>
      <a href="04-Design-Adaptive-Clinical-Trials.html">Adaptive Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Bayesian-Clinical-Trials.html">Bayesian Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Dose-Escalation-and-Stratification-Designs.html">Dose Escalation and Stratification Designs in Early Oncology Development</a>
    </li>
    <li>
      <a href="04-Design-Single-Arm-Clinical-Trials.html">Single Arm Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Diagnostic-Study-Design-and-Evaluation.html">Diagnostic Study-Design and Evaluation</a>
    </li>
    <li>
      <a href="04-Design-Diagnostic-Study-MRMC.html">Diagnostic Study-Multireader Multicase (MRMC)</a>
    </li>
    <li>
      <a href="04-Design-Hierarchical-composite-endpoints.html">Hierarchical Composite Endpoints</a>
    </li>
    <li>
      <a href="04-Design-Externally-Controlled-Trials.html">Considerations for the Design and Conduct of Externally Controlled Trials</a>
    </li>
    <li>
      <a href="04-Design-Noninferiority-Trials.html">Noninferiority Trials</a>
    </li>
    <li>
      <a href="04-Design-Bioequivalence-and-Biosimilar-Trials.html">Bioequivalence and Biosimilar Trials</a>
    </li>
    <li>
      <a href="04-Design-Exploring-Survival-Analysis-Designs-for-Clinical-Trials.html">Exploring Survival Analysis Designs for Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Projecting-How-Long-Your-Trial-Will-Take.html">Projecting How Long Your Trial Will Take</a>
    </li>
    <li>
      <a href="04-Design-Regulatory-Submission.html">Regulatory Submission from Stats Perspective</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-line-chart"></span>
     
    Data Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="05-Plot-Adverse-Event.html">Adverse Event Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Laboratory-Data.html">Laboratory Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Time-To-Event.html">Time to Event Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-PRO-Data.html">Patient Reported Outcome Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-SSC-and-Power-Calculation.html">Sample Size and Power Calculations Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Correlation.html">Correlation Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Model-Table.html">Clinical Data and Model visualization</a>
    </li>
    <li>
      <a href="05-Plot-ScatterPlot.html">Scatter and Line Plot</a>
    </li>
    <li>
      <a href="05-Plot-BarPlot.html">Bar Chart</a>
    </li>
    <li>
      <a href="05-Plot-PieChart.html">Pie Chart</a>
    </li>
    <li>
      <a href="05-Plot-BoxPlot.html">Box Plot</a>
    </li>
    <li>
      <a href="05-Plot-Histogram.html">Histogram</a>
    </li>
    <li>
      <a href="05-Plot-Forest-Plot.html">Forest Plot</a>
    </li>
    <li>
      <a href="05-Plot-Flow-Chart.html">Flow Chart</a>
    </li>
    <li>
      <a href="05-Plot-Some-Interesting.html">Some Interesting Plots</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-calculator"></span>
     
    Statistical Analysis
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06-Analysis-Linear-Regression.html">Linear Regression</a>
    </li>
    <li>
      <a href="06-Analysis-Logistic-Regression.html">Logistic Regression</a>
    </li>
    <li>
      <a href="06-Analysis-Mixed-Model.html">Mixed Model</a>
    </li>
    <li>
      <a href="06-Analysis-MMRM.html">Mixed Model Repeated Measures</a>
    </li>
    <li>
      <a href="06-Analysis-GEE.html">Generalized Estimating Equation</a>
    </li>
    <li>
      <a href="06-Analysis-ANOVA.html">Analysis of Variance</a>
    </li>
    <li>
      <a href="06-Analysis-Survival-Analysis.html">Survival Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Survival-Competing-Risk.html">Survival Analysis - Competing Risk</a>
    </li>
    <li>
      <a href="06-Analysis-Missing-Data.html">Missing Data Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-MI-Implementation.html">Multiple Imputation Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-SSD.html">Safety Signal Detection and Evaluation</a>
    </li>
    <li>
      <a href="06-Analysis-Meta-Analysis.html">Meta Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-PK-and-PD.html">PK and PD Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Time-Series-Analysis.html">Time Series Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-SEM.html">Structural Equation Modeling</a>
    </li>
    <li>
      <a href="06-Analysis-Factor-Analysis.html">Factor Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="07-ML-Bayesian-Theory.html">Bayesian Theory</a>
    </li>
    <li>
      <a href="07-ML-Bayesian-Analysis.html">Bayesian Analysis</a>
    </li>
    <li>
      <a href="07-ML-Regularization-Penalized-Regression.html">Regularization Penalized Regression</a>
    </li>
    <li>
      <a href="07-ML-Loss-Regression.html">Loss Functions in Machine Learning</a>
    </li>
    <li>
      <a href="07-ML-PCA.html">Principal Component Analysis</a>
    </li>
    <li>
      <a href="07-ML-KNN.html">K-Nearest Neighbors</a>
    </li>
    <li>
      <a href="07-ML-SVM.html">Support Vector Machine</a>
    </li>
    <li>
      <a href="07-ML-Tree-Models.html">Tree Models</a>
    </li>
    <li>
      <a href="07-ML-LDA.html">Linear Discriminant Analysis</a>
    </li>
    <li>
      <a href="07-ML-Cluster-Analysis.html">Cluster Analysis</a>
    </li>
    <li>
      <a href="07-ML-Neural-Networks.html">Neural Network</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="08-CV.html">
    <span class="fa fa-file-pdf-o"></span>
     
    CV
  </a>
</li>
<li>
  <a href="mailto:zehuibai@outlook.com">
    <span class="fa fa-envelope-o"></span>
     
    Contact me
  </a>
</li>
<li>
  <a href="https://github.com/Zehuibai">
    <span class="fa fa-github"></span>
     
    GitHub
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore"><p><img src="logo.png"
style="width:3in" /><br />
Safety Signal Detection and Evaluation</p></h1>

</div>


<div id="safety-signal-detection" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Safety Signal
Detection</h1>
<div id="introduction" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Introduction</h2>
<p>Safety Signal Detection (SSD) is a critical component of
pharmacovigilance and drug safety monitoring. Its primary aim is to
detect, assess, and manage potential safety risks associated with
pharmaceutical products, ensuring patient safety and supporting public
health.</p>
<p><strong>What is Safety Signal Detection?</strong></p>
<p>SSD involves the routine evaluation of safety signals through
periodic reviews of aggregated data from various sources, including
clinical trials, post-marketing surveillance, and real-world data. A
safety signal refers to evidence of a potentially new adverse event or a
new aspect of a known adverse event that is caused by a medicinal
product and that warrants further investigation.</p>
<p><strong>SSD Process</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Strategy and Scope Setting:</strong>
<ul>
<li>At the early phases of drug development, the clinical team, along
with the benefit-risk lead (subject to confirmation), discusses and
determines the SSD strategy. This includes deciding the frequency of
reviews and the scope of included studies.</li>
<li>The strategy is tailored to ensure that all potential safety issues
are promptly identified and addressed. This involves periodic
assessments that could be aligned with other regulatory requirements
like Periodic Safety Update Reports (PSURs) or Development Safety Update
Reports (DSURs).</li>
</ul></li>
<li><strong>Data Collection and Aggregation:</strong>
<ul>
<li>Relevant data from clinical trials and other sources are collected
and aggregated.</li>
</ul></li>
<li><strong>Analysis and Review:</strong>
<ul>
<li>The data undergoes statistical analysis to identify trends or
patterns that could indicate potential safety issues.</li>
</ul></li>
<li><strong>Signal Evaluation:</strong>
<ul>
<li>Identified signals are then evaluated to confirm their validity and
potential impact on patient safety. This evaluation includes a detailed
investigation into whether the signal represents a true risk or is due
to other factors like underlying diseases or concurrent
medications.</li>
</ul></li>
<li><strong>Risk Management and Mitigation:</strong>
<ul>
<li>If a safety signal is confirmed, risk management strategies are
developed and implemented. These may include changes to the product
labeling, restrictions on use, or in some cases, drug withdrawal.</li>
</ul></li>
<li><strong>Documentation and Reporting:</strong>
<ul>
<li>All findings and actions are thoroughly documented and reported to
regulatory authorities as required.</li>
</ul></li>
</ol>
</div>
<div id="biostatistics-and-data-science-bds-role" class="section level2"
number="1.2">
<h2><span class="header-section-number">1.2</span> Biostatistics and
Data Science (BDS) Role</h2>
<ul>
<li>BDS is primarily responsible for authoring the Program Statistical
Analysis Plan (PSAP).</li>
<li>BDS provides clinical study data summaries, typically in the form of
Tables, Figures, and Listings (TFLs), which are essential for supporting
the detection of safety signals.</li>
<li>Additionally, BDS ensures that the clinical teams have access to
advanced visualization tools for data exploration. These tools help in
the intuitive understanding of complex datasets and trends, facilitating
a more robust safety signal detection process.</li>
</ul>
</div>
</div>
<div id="planning-for-ind-safety-reporting" class="section level1"
number="2">
<h1><span class="header-section-number">2</span> Planning for IND Safety
Reporting</h1>
<div id="safety-reports-ser-ssar" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Safety Reports (SER
&amp; SSAR)</h2>
<p>Safety Evaluation Report: A flexible approach for reviewing safety
topics which are not triggered from the signal detection process. An SER
can be upgraded to an SSAR if the safety topic becomes a valid signal
during the process. This report is led by the Safety Writer</p>
<p>Safety Signal Assessment Report: Further evaluated signal considering
all available evidence, to determine whether there are ne wrisk
causually assoiciated with active substance or medicinal product, or if
known risk have changed. his report is led by the Safety Writer</p>
</div>
<div id="expected-and-anticipated-serious-adverse-events-saes"
class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Expected and
Anticipated Serious Adverse Events (SAEs)</h2>
<ul>
<li><p>Expected SAEs refer to serious adverse events that can reasonably
be predicted based on the known pharmacological properties, previous
clinical trial outcomes, or typical characteristics of the drug class.
These events are usually documented in the drug’s label or other
professional literature. Therefore, when these events occur in new
clinical trials, they are considered “expected” because their potential
has already been identified and acknowledged based on existing data.
Expected SAEs are important for risk management and informed consent
processes, as they help set realistic expectations for both clinicians
and participants regarding the known risks associated with a
drug.</p></li>
<li><p>Anticipated SAEs, while similar to expected SAEs, generally refer
to events whose occurrence is foreseen based on less definitive evidence
than that for expected SAEs. These could be based on preliminary data,
such as early clinical trials, animal studies, or even theoretical
considerations linked to the drug’s mechanism of action. Anticipated
SAEs are not as firmly established as expected SAEs but are considered
likely enough that they should be monitored for in the context of
ongoing clinical research. They may or may not be included in the
product label but are anticipated from a safety surveillance
perspective.</p></li>
</ul>
<p><strong>Key Differences</strong></p>
<ul>
<li><strong>Basis of Prediction</strong>: Expected SAEs are based on
more solid, often clinically verified evidence, while anticipated SAEs
may rely on preliminary or less conclusive evidence.</li>
<li><strong>Documentation</strong>: Expected SAEs are typically
documented in official product materials like labeling, whereas
anticipated SAEs might not be, depending on their level of evidence and
regulatory requirements.</li>
<li><strong>Regulatory Impact</strong>: Expected SAEs have a direct
impact on the drug’s labeling and are crucial for regulatory compliance
and patient safety communications. Anticipated SAEs, while also
important, might influence ongoing monitoring strategies and potential
label updates as more data become available.</li>
</ul>
</div>
<div id="aggregate-analysis-planning" class="section level2"
number="2.3">
<h2><span class="header-section-number">2.3</span> Aggregate Analysis
Planning</h2>
<p>Planning for FDA IND (Investigational New Drug) safety reporting is a
critical component of clinical trial management, ensuring that serious
adverse events (SAEs) are properly identified, analyzed, and reported.
This process is especially vital during the transition from Phase 1 to
Phase 2 of clinical trials, where a clear understanding of the safety
profile of the investigational medicinal product (IMP) is essential for
further development.</p>
<p><strong>Aggregate Analysis Planning:</strong> Early in the product
development lifecycle, planning for the aggregate analysis of aSAEs and
expected SARs should commence. This is crucial as it sets the foundation
for ongoing safety monitoring and regulatory compliance. The planning
should start as the studies transition from Phase 1 to Phase 2, which is
typically when the target population for these studies has been clearly
identified and the safety data from initial human exposure is
available.</p>
<p><strong>Possible Approaches for Aggregate Analysis:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Analysis of All Serious Adverse Events (SAEs) by Treatment
Group:</strong>
<ul>
<li>This approach involves periodic reviews of all SAEs sorted by
treatment groups within the clinical trial. The primary focus is to
identify whether aSAEs or expected SARs are occurring at a significantly
higher incidence in the group receiving the IMP compared to a concurrent
control (either placebo or an active comparator) or a historical control
group. This method helps in understanding the direct impact of the drug
under study relative to other treatments or known data.</li>
</ul></li>
<li><strong>Unblinding Trigger Approach:</strong>
<ul>
<li>In this method, a blinded quantitative analysis is conducted. The
Unblinding Trigger Approach focuses on the analysis of anticipated
serious adverse events (aSAEs) and expected serious adverse reactions
(SARs). This approach uses a pre-specified threshold to determine
whether the overall blinded incidence rate of these events is higher
than either the estimated background incidence rate in the target
population or the incidence of expected SARs as listed in the Reference
Safety Information (RSI).</li>
<li>If these thresholds are exceeded, the SSDT may conduct a further
blinded review and, if necessary, escalate the safety issue to the
Benefit Risk Team (BRT) for consideration. If the BRT deems it
necessary, an unblinded review may be initiated.</li>
</ul></li>
</ol>
<p><strong>Selection and Initiation of Aggregate Analysis:</strong></p>
<p>The Safety Surveillance and Data Team (SSDT) is responsible for
selecting the appropriate methodology for aggregate analysis. The choice
between analyzing all events by treatment group or applying the
unblinding trigger approach depends on several factors including the
study population, the characteristics of the product, and the size and
duration of the clinical studies involved. Aggregate analysis is
typically initiated during Phase 2 of clinical studies, assuming there
are enough participants and observed SAEs to conduct a meaningful
analysis.</p>
<p><strong>Documentation in Safety Surveillance Plan (SSP):</strong> The
specific methodologies chosen for the aggregate analysis are detailed in
the product-specific FDA IND Safety Surveillance Plan (SSP), which is a
dedicated section of the Safety Signal Detection Strategy. The SSP is
crafted and reviewed by the SSDT and should include:</p>
<ul>
<li>The chosen methodology (Analysis of All Events by Treatment Group
and/or Unblinding Trigger Approach).</li>
<li>Criteria for further assessment if using the Unblinding Trigger
Approach, including thresholds that might trigger an IND safety
report.</li>
<li>A list of aSAEs with MedDRA search criteria used for identifying
these events in the clinical database.</li>
<li>Estimations of background incidence rates for aSAEs, if
possible.</li>
<li>Protocols for when unblinding is necessary to evaluate potential
causal relationships with the IMP.</li>
</ul>
<p><strong>Defining anticipated serious adverse events
(aSAEs)</strong></p>
<ul>
<li>The process begins when the Development Physician initiates the
definition of aSAEs as soon as the target patient population(s) have
been identified and the first study concepts in these populations have
been approved. This early initiation ensures that the safety monitoring
is tailored to the specific needs of the population from the
outset.</li>
<li>The Development Physician is responsible for defining the
characteristics of the target population and checking for any existing
lists of aSAEs relevant to this group.</li>
<li>They lead efforts to update or create new lists of aSAEs, involving
contributions from other functions such as Medical Affairs to identify
relevant clinical studies for evaluating aSAEs and background incidence
rates.</li>
<li>The RWE Representative uses Real World Data, starting with a focused
literature review, and if necessary, conducting studies using
fit-for-use Real World Databases to identify potential aSAEs.</li>
<li>If the initial literature review does not yield sufficient data,
further studies are conducted to estimate background incidence rates for
each aSAE. This step is critical for understanding the typical
occurrence rates of these events outside of clinical trials.</li>
<li>Since Real World Evidence might use non-MedDRA terms, the list of
aSAEs identified needs to be reviewed by the Medical Coding Oversight
Lead to define these events in standardized MedDRA terms.</li>
<li>The Development Physician consolidates a preliminary list of aSAEs
using MedDRA search terms based on the RWE and statistical
analyses.</li>
<li>The Statistical Representative then estimates the background
incidence rates for each aSAE using historical clinical data.</li>
</ul>
</div>
<div id="xsur---standard-required-safety-reporting-documents"
class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> XSUR - Standard
Required Safety Reporting Documents</h2>
<p><strong>DSUR/PSUR/IB/J-NUPR/RMP</strong></p>
<p>These documents are <strong>regulatory safety reporting
requirements</strong> that help ensure the ongoing evaluation of the
safety profile of investigational and marketed drugs.</p>
<div id="dsur-development-safety-update-report"
class="section level3 unnumbered">
<h3 class="unnumbered">1. DSUR (Development Safety Update Report)</h3>
<ul>
<li><p><strong>Purpose</strong>:<br />
The DSUR is a <strong>yearly regulatory document</strong> that provides
a comprehensive safety overview of an investigational product during its
development phase (pre-marketing).</p></li>
<li><p><strong>General Content</strong>:</p>
<ul>
<li>Summary of cumulative safety data across all clinical trials</li>
<li>Adverse event (AE) overview</li>
<li>Exposure data</li>
<li>Ongoing and completed study updates</li>
<li>Benefit-risk considerations</li>
</ul></li>
<li><p><strong>Timing</strong>:<br />
Annually, typically synchronized with the <strong>Investigational
Brochure (IB)</strong> update.</p></li>
<li><p><strong>BST Contribution</strong>:</p>
<ul>
<li>TFLs summarizing:
<ul>
<li><strong>Cumulative subject exposure</strong>, often broken down by
population (e.g., healthy vs. patient, age groups)</li>
<li><strong>Study-specific exposure summaries</strong></li>
<li><strong>Participant withdrawals due to adverse events</strong></li>
<li><strong>SAE/AE listings</strong> if required</li>
</ul></li>
</ul></li>
</ul>
<hr />
</div>
<div id="psur-periodic-safety-update-report"
class="section level3 unnumbered">
<h3 class="unnumbered">2. PSUR (Periodic Safety Update Report)</h3>
<ul>
<li><p><strong>Purpose</strong>:<br />
The PSUR is used to monitor the safety of <strong>marketed (authorized)
products</strong> over time, usually post-approval.</p></li>
<li><p><strong>General Content</strong>:</p>
<ul>
<li>Cumulative safety information since the product was authorized</li>
<li>Global safety data</li>
<li>Benefit-risk evaluation</li>
<li>Regulatory actions taken</li>
<li>Literature and spontaneous report summaries</li>
</ul></li>
<li><p><strong>Timing</strong>:<br />
Varies depending on the product’s time on the market and specific
regulatory agreements (e.g., every 6 months, 1 year, or 3
years).</p></li>
<li><p><strong>BST Contribution</strong>:</p>
<ul>
<li>TFLs supporting:
<ul>
<li><strong>Cumulative subject exposure</strong>, including dose and
duration</li>
<li><strong>Trend summaries</strong> (e.g., AE over time)</li>
<li><strong>Stratified summaries by indication or region</strong>, if
required</li>
</ul></li>
</ul></li>
</ul>
<hr />
</div>
<div id="ib-investigators-brochure" class="section level3 unnumbered">
<h3 class="unnumbered">3. IB (Investigator’s Brochure)</h3>
<ul>
<li><p><strong>Purpose</strong>:<br />
The IB is a reference document for investigators conducting clinical
trials and contains comprehensive data on the <strong>investigational
product</strong>, including safety and efficacy findings.</p></li>
<li><p><strong>General Content</strong>:</p>
<ul>
<li>Clinical and non-clinical safety data</li>
<li>Pharmacokinetics and pharmacodynamics</li>
<li>Investigator guidance</li>
<li>Benefit-risk summary</li>
</ul></li>
<li><p><strong>Timing</strong>:<br />
Updated <strong>annually</strong>, often in parallel with DSUR
preparation.</p></li>
<li><p><strong>BST Contribution</strong>:</p>
<ul>
<li>TFLs used in the <strong>Adverse Drug Reaction</strong> (ADR)
section:
<ul>
<li><strong>Listings or summary tables</strong> of AEs considered
related</li>
<li><strong>Cumulative AE rates</strong></li>
<li><strong>Narrative support</strong> via structured data</li>
</ul></li>
</ul></li>
</ul>
<hr />
</div>
<div id="j-nupr-japanese-non-serious-unlisted-periodic-report"
class="section level3 unnumbered">
<h3 class="unnumbered">4. J-NUPR (Japanese Non-serious Unlisted Periodic
Report)</h3>
<ul>
<li><p><strong>Purpose</strong>:<br />
A <strong>Japan-specific post-marketing requirement</strong> for
periodic reporting of <strong>non-serious and unlisted adverse
events</strong> observed during post-marketing surveillance.</p></li>
<li><p><strong>General Content</strong>:</p>
<ul>
<li>Line listings of applicable non-serious, unlisted AEs</li>
<li>Summary counts stratified by term, SOC, region, etc.</li>
</ul></li>
<li><p><strong>Timing</strong>:<br />
Regular intervals defined by the Japanese Ministry of Health, Labour and
Welfare (MHLW)</p></li>
<li><p><strong>BTS Contribution</strong>:</p>
<ul>
<li>Delivery of:
<ul>
<li><strong>Cumulative frequency tables</strong></li>
<li><strong>Listings of unlisted events</strong></li>
<li><strong>Patient-level datasets</strong>, filtered by local
criteria</li>
</ul></li>
</ul></li>
</ul>
<hr />
</div>
<div id="rmp-risk-management-plan" class="section level3 unnumbered">
<h3 class="unnumbered">5. RMP (Risk Management Plan)</h3>
<ul>
<li><p><strong>Purpose</strong>:<br />
The RMP outlines how the <strong>risks of a medicinal product</strong>
will be <strong>identified, characterized, prevented, or
minimized</strong> once the product is on the market.</p></li>
<li><p><strong>General Content</strong>:</p>
<ul>
<li>Product safety specification</li>
<li>Pharmacovigilance plans</li>
<li>Risk minimization measures (e.g., targeted education,
monitoring)</li>
</ul></li>
<li><p><strong>Timing</strong>:</p>
<ul>
<li>At the time of <strong>marketing authorization application
(MAA)</strong></li>
<li><strong>Updated as needed</strong> post-authorization (e.g., after
new safety signals)</li>
</ul></li>
<li><p><strong>BST Contribution</strong>:</p>
<ul>
<li>Statistical review and validation of:
<ul>
<li><strong>Exposure estimates</strong></li>
<li><strong>Incidence rates of identified and potential
risks</strong></li>
<li><strong>Monitoring metrics (e.g., patient compliance, reporting
rates)</strong></li>
</ul></li>
</ul></li>
<li><p><strong>Reference</strong>:<br />
EMA guidance:</p>
<ul>
<li><em>GVP Module V – Risk Management Systems (Rev 2)</em><br />
</li>
<li><em>RMP Q&amp;A on EMA website</em></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="bssd" class="section level1" number="3">
<h1><span class="header-section-number">3</span> BSSD</h1>
</div>
<div id="adverse-event" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Adverse Event</h1>
<ul>
<li><p><strong>Historical context:</strong><br />
Historically, <strong>safety has received less methodological
attention</strong> compared to efficacy. As a result, development of
advanced statistical techniques for safety evaluation is <strong>still
evolving</strong>, but catching up. Efficacy analyses have long relied
on sophisticated inferential models, whereas safety often remains
descriptive—this is changing.</p></li>
<li><p><strong>Descriptive statistics are central:</strong><br />
Safety analyses are <strong>typically descriptive</strong>, meant to
<strong>support medical interpretation</strong> rather than to test
formal hypotheses. This aligns with how safety data are often
<strong>exploratory in nature</strong>, looking for signals rather than
proving effects.</p></li>
<li><p><strong>Assumptions matter:</strong><br />
Like all statistical approaches, safety analyses rely on assumptions
(e.g., constant hazard, non-informative censoring, independence).
<strong>Acknowledging and validating these assumptions</strong> is vital
to ensuring results are meaningful and trustworthy.</p></li>
<li><p><strong>No one-size-fits-all approach:</strong><br />
While systematic methods are often used (like EAIRs or standard
incidence tables), they may not capture all nuances. Therefore,
<strong>flexibility to apply additional or alternative methods</strong>
(like time-to-event or competing risks models) is encouraged, depending
on the context.</p></li>
<li><p><strong>Apply broad statistical principles:</strong><br />
Sound practices such as <strong>assumption checking</strong>, use of
<strong>normal approximations</strong> when valid, and even
<strong>meta-analysis</strong> (especially in pooled studies or signal
detection across trials) are equally important for safety data as they
are for efficacy.</p></li>
</ul>
<div id="safety-topics-of-special-interest" class="section level2"
number="4.1">
<h2><span class="header-section-number">4.1</span> Safety Topics of
Special Interest</h2>
<p>Safety topics may emerge throughout the drug lifecycle from various
sources:</p>
<table>
<colgroup>
<col width="26%" />
<col width="73%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Source</td>
<td>Description</td>
</tr>
<tr class="even">
<td>Toxicology and nonclinical data</td>
<td>Suggest potential human toxicities</td>
</tr>
<tr class="odd">
<td>Known class effects</td>
<td>Effects typical to a drug class</td>
</tr>
<tr class="even">
<td>Literature</td>
<td>Reports of adverse effects</td>
</tr>
<tr class="odd">
<td>Post-marketing data</td>
<td>New or more frequent/severe adverse drug reactions discovered after
approval</td>
</tr>
<tr class="even">
<td>Phase I to IV clinical trials</td>
<td>Single events or imbalances in aggregate analyses indicating
potential safety concerns</td>
</tr>
<tr class="odd">
<td>Regulatory requests</td>
<td>Specific demands for analysis or reporting</td>
</tr>
<tr class="even">
<td>Safety reports review</td>
<td>Periodic Safety Update Reports (PSUR), Development Safety Update
Reports (DSUR)</td>
</tr>
</tbody>
</table>
<div id="definitions-of-important-terms"
class="section level3 unnumbered">
<h3 class="unnumbered">Definitions of Important Terms</h3>
<table>
<colgroup>
<col width="16%" />
<col width="83%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Term</td>
<td>Definition</td>
</tr>
<tr class="even">
<td><strong>Adverse Event (AE)</strong></td>
<td>&gt; Any untoward medical occurrence associated with the use of a
study drug in humans, whether or not considered study-drug-related.</td>
</tr>
<tr class="odd">
<td><strong>Adverse Drug Reaction (ADR)</strong></td>
<td>&gt; An undesirable effect reasonably likely caused by a study drug,
either as part of its pharmacological action or unpredictable in
occurrence.</td>
</tr>
<tr class="even">
<td><strong>Percent (AE reporting context)</strong></td>
<td>&gt; Number of patients with an event divided by the number of
patients at risk, multiplied by 100. Also called event rate, incidence
rate, crude incidence rate, or cumulative incidence.</td>
</tr>
<tr class="odd">
<td><strong>Exposure-Adjusted Event Rate (EAER)</strong></td>
<td>&gt; Number of events (all occurrences counted) divided by total
time exposed. Also known as person-time absolute rate. Time units may be
adjusted (e.g., events per 100 person-years).</td>
</tr>
<tr class="even">
<td><strong>Exposure-Adjusted Incidence Rate (EAIR)</strong></td>
<td>&gt; Number of patients with an event divided by total time at risk.
For patients with events, time from first dose to first event; for
others, total assessment interval time. Also called person-time
incidence rate.</td>
</tr>
<tr class="odd">
<td><strong>Safety Topics of Interest</strong></td>
<td>&gt; Broad term including AESIs, identified or potential risks
needing characterization, potential toxicities (e.g., hepatic), drug
class-related findings, or regulatory requests.</td>
</tr>
<tr class="even">
<td><strong>Study-Size Adjusted Percentage</strong></td>
<td>&gt; Weighted percentage from multiple controlled studies,
calculated by weighting observed percentages within studies by relative
study size in pooled population. Also called study-size-adjusted
incidence percentage.</td>
</tr>
<tr class="odd">
<td><strong>Treatment-Emergent Adverse Event (TEAE)</strong></td>
<td>&gt; An AE occurring after first administration of intervention that
is new or worsened. Implementation varies across industry.</td>
</tr>
</tbody>
</table>
</div>
<div id="general-recommendations-for-safety-data-analyses-and-displays"
class="section level3 unnumbered">
<h3 class="unnumbered">General Recommendations for Safety Data Analyses
and Displays</h3>
<ul>
<li><strong>Odds Ratios</strong> can take any value between <span
class="math inline">\(-\infty\)</span> and <span
class="math inline">\(+\infty\)</span> on the log scale, making them
robust for detecting differences regardless of control event rates.</li>
<li><strong>Relative Risks</strong> can be misleading when control event
rates are high because the maximum risk ratio is bounded.</li>
<li><strong>Confidence Intervals</strong> provide insight into the
uncertainty of estimates but must be interpreted with caution,
especially when wide.</li>
<li>The choice of metric and statistical summaries should be guided by
the goal of the analysis (public health impact vs. signal detection) and
the audience.</li>
</ul>
<div
id="choice-of-comparative-metric-for-incidence-proportionspercentages"
class="section level4 unnumbered">
<h4 class="unnumbered">Choice of Comparative Metric for Incidence
Proportions/Percentages</h4>
<ul>
<li><strong>Purpose:</strong> Establish the <strong>risk
profile</strong> of a drug by comparing adverse event (AE) data between
patients receiving the investigational drug and a control group (placebo
or active control).</li>
<li>Metrics fall into two categories:</li>
</ul>
<table>
<colgroup>
<col width="9%" />
<col width="21%" />
<col width="42%" />
<col width="25%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Metric Type</td>
<td>Examples</td>
<td>Characteristics</td>
<td>Use Case/Comments</td>
</tr>
<tr class="even">
<td><strong>Absolute Scale</strong></td>
<td>Risk difference</td>
<td>Directly reflects magnitude of affected patients; easier for rare
events</td>
<td>Good for understanding <strong>public health impact</strong></td>
</tr>
<tr class="odd">
<td><strong>Relative Scale</strong></td>
<td>Relative risk, Odds ratio, Hazard ratio</td>
<td>Useful as flagging mechanisms to identify events needing further
investigation</td>
<td>Good for understanding <strong>relative impact</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><p><strong>Risk Difference:</strong></p>
<ul>
<li>Reflects the absolute magnitude of patients affected.</li>
<li>Easier to implement for <strong>low-frequency events</strong>.</li>
<li>Less effective for identifying rare events needing further
investigation.</li>
</ul></li>
<li><p><strong>Relative Risk:</strong></p>
<ul>
<li>Easier to understand than odds ratio.</li>
<li>Problematic when control event rates are high (e.g., if control rate
= 50%, relative risk maxes at 2).</li>
<li>Good for understanding <strong>relative impact</strong>.</li>
<li>Not invariant to coding changes (event vs. no event).</li>
</ul></li>
<li><p><strong>Odds Ratio:</strong></p>
<ul>
<li><p>Has better mathematical properties, including:</p>
<ul>
<li>Log odds ratio ranges from <span
class="math inline">\(-\infty\)</span> to <span
class="math inline">\(+\infty\)</span> regardless of control event
rate.</li>
<li>Invariant to coding changes (reciprocal when switching event/no
event).</li>
</ul></li>
<li><p>More effective for <strong>signal detection</strong> regardless
of background rate.</p></li>
<li><p>Less intuitive for lay audiences.</p></li>
<li><p>Useful as a <strong>flagging mechanism</strong> for further
investigation.</p></li>
</ul></li>
<li><p><strong>Summary of Metric Usefulness:</strong></p></li>
</ul>
<table>
<colgroup>
<col width="11%" />
<col width="23%" />
<col width="19%" />
<col width="28%" />
<col width="16%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Metric</td>
<td>Understand Public Health Impact</td>
<td>Understand Relative Impact</td>
<td>Use for Signal Detection</td>
<td>Ease of Interpretation</td>
</tr>
<tr class="even">
<td>Risk Difference</td>
<td>Excellent</td>
<td>Poor</td>
<td>Difficult</td>
<td>Easy</td>
</tr>
<tr class="odd">
<td>Relative Risk</td>
<td>Poor</td>
<td>Good</td>
<td>Difficult (with high background rate)</td>
<td>Easy</td>
</tr>
<tr class="even">
<td>Odds Ratio</td>
<td>Moderate</td>
<td>Excellent</td>
<td>Excellent</td>
<td>Difficult</td>
</tr>
</tbody>
</table>
<ul>
<li><p><strong>Presentation Recommendations:</strong></p>
<ul>
<li>For public presentation, absolute differences or risk ratios are
preferred over odds ratios.</li>
<li>Interactive displays should allow users to select among multiple
metrics.</li>
<li>For Adverse Events of Special Interest (AESIs), showing <strong>both
absolute and relative metrics</strong> is often warranted.</li>
</ul></li>
</ul>
</div>
<div id="p-values-and-confidence-intervals-in-safety-assessments"
class="section level4 unnumbered">
<h4 class="unnumbered">P-values and Confidence Intervals in Safety
Assessments</h4>
<ul>
<li><p>There is ongoing debate about the <strong>value of p-values and
confidence intervals (CIs)</strong> in safety data.</p></li>
<li><p>According to the <strong>FDA Clinical Review Template</strong>
and <strong>ICH E9 Section 6.4</strong>:</p>
<ul>
<li>P-values and CIs are <strong>descriptive</strong>, not inferential,
unless trials are specifically powered for hypothesis testing.</li>
<li>CIs can aid interpretation by showing uncertainty.</li>
<li>P-values can serve as a <strong>flagging mechanism</strong> to
highlight differences warranting further attention.</li>
</ul></li>
<li><p><strong>Recommendations on Use:</strong></p>
<ul>
<li>Include some measure of uncertainty: confidence intervals, p-values,
posterior credible intervals, or posterior probabilities.</li>
<li>This white paper favors <strong>confidence intervals</strong> over
p-values to provide a crude estimate of evidence strength.</li>
<li>If p-values are used, report <strong>actual p-values</strong> rather
than threshold indicators (e.g., asterisks), to emphasize interpretation
over hypothesis testing.</li>
<li>Avoid basing adverse drug reaction (ADR) conclusions solely on
p-values or confidence intervals.</li>
</ul></li>
<li><p><strong>Potential Issues and Interpretation
Challenges:</strong></p></li>
</ul>
<table>
<colgroup>
<col width="33%" />
<col width="66%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Concern</td>
<td>Explanation</td>
</tr>
<tr class="even">
<td>High p-values or CIs including 0 (or 1)</td>
<td>May cause unwarranted dismissal of potential signals</td>
</tr>
<tr class="odd">
<td>Misinterpretation of p-values</td>
<td>Could lead to unnecessary concern over too many outcomes</td>
</tr>
<tr class="even">
<td>Wide confidence intervals</td>
<td>Often arise from low event frequencies; high upper bounds may cause
undue alarm</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Educating interpreters of safety analyses on these nuances is
<strong>critical</strong>.</p></li>
<li><p><strong>Recommendation for Reporting Safety Data:</strong></p>
<ul>
<li>Include within-arm descriptive statistics.</li>
<li>Report measures of difference between arms (e.g., risk
difference).</li>
<li>Accompany differences with confidence intervals.</li>
</ul></li>
<li><p><strong>Decision-Making Frameworks for ADR
Identification:</strong></p></li>
</ul>
<table>
<colgroup>
<col width="22%" />
<col width="77%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Framework</td>
<td>Description</td>
</tr>
<tr class="even">
<td><strong>CIOMS Working Group</strong></td>
<td>Flexible framework considering frequency, timing, preclinical
findings, mechanism of action</td>
</tr>
<tr class="odd">
<td><strong>Bradford Hill Criteria</strong></td>
<td>Provides criteria for causality assessment based on multiple
evidence sources</td>
</tr>
</tbody>
</table>
<ul>
<li>When only percentages are displayed (without p-values, CIs, or
comparative metrics), it can be difficult to identify events for further
scrutiny.</li>
<li>Objective processes or team decisions are necessary to prioritize AE
review.</li>
</ul>
</div>
</div>
</div>
<div
id="meddra-hierarchical-structure-and-adverse-events-of-special-interest-aesi"
class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> MedDRA Hierarchical
Structure and Adverse Events of Special Interest (AESI)</h2>
<p><strong>MedDRA Hierarchy Levels</strong></p>
<table>
<colgroup>
<col width="44%" />
<col width="56%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Level</td>
<td>Description</td>
</tr>
<tr class="even">
<td><strong>SOC (System Organ Class)</strong></td>
<td>Highest level grouping (e.g., “Neoplasms”)</td>
</tr>
<tr class="odd">
<td><strong>HLGT (High Level Group Terms)</strong></td>
<td>Subgroups within SOC</td>
</tr>
<tr class="even">
<td><strong>HLT (High Level Terms)</strong></td>
<td>Further subgroups within HLGT</td>
</tr>
<tr class="odd">
<td><strong>PT (Preferred Terms)</strong></td>
<td>Single medical concepts or events</td>
</tr>
<tr class="even">
<td><strong>LLT (Lowest Level Terms)</strong></td>
<td>Synonyms or variations of PTs</td>
</tr>
</tbody>
</table>
<ul>
<li>Each <strong>PT</strong> is assigned one <strong>primary
SOC</strong>, and may have additional <strong>secondary SOCs</strong>
based on site of manifestation or other factors.</li>
<li>Study databases usually populate only <strong>primary
SOC/HLT</strong> for PTs unless otherwise specified.</li>
<li>Analysts must specify if they want to include PTs with
<strong>primary SOC/HLT only</strong> or also those with
<strong>secondary SOC/HLT</strong>.</li>
<li>When sponsors create <strong>Custom MedDRA Queries (CMQs)</strong>,
the list of PTs used should be provided in a dataset.</li>
<li>Regulatory agencies should review PT lists to ensure appropriateness
and facilitate analysis integration.</li>
</ul>
<p><strong>Examples of PT Assignments with Primary and Secondary
SOCs</strong></p>
<table>
<colgroup>
<col width="17%" />
<col width="22%" />
<col width="20%" />
<col width="40%" />
</colgroup>
<tbody>
<tr class="odd">
<td>PT Term</td>
<td>Primary SOC</td>
<td>Secondary SOC</td>
<td>Notes</td>
</tr>
<tr class="even">
<td>Congenital absence of bile ducts</td>
<td>Congenital, familial and genetic disorders</td>
<td>Hepatobiliary disorders</td>
<td>Secondary SOC based on site of manifestation</td>
</tr>
<tr class="odd">
<td>Skin cancer</td>
<td>Neoplasms benign, malignant, unspecified</td>
<td>Skin and subcutaneous tissue disorders</td>
<td>Primary SOC assignment depends on site of manifestation for cysts
and polyps</td>
</tr>
<tr class="even">
<td>Enterocolitis infectious ducts</td>
<td>Infections and infestations</td>
<td>Gastrointestinal disorders</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="exposure-adjusted-incidence-rates-eairs" class="section level2"
number="4.3">
<h2><span class="header-section-number">4.3</span> Exposure-Adjusted
Incidence Rates (EAIRs)</h2>
<div id="applicability" class="section level3 unnumbered">
<h3 class="unnumbered">Applicability</h3>
<p>In the context of clinical studies, specifically as a <strong>measure
of the rate of occurrence of adverse events (AEs)</strong> associated
with exposure to a drug. It categorizes when these incidence rates most
accurately reflect the true risk, and when they may not.</p>
<p><strong>Incidence rates most accurately represent true risk
when:</strong></p>
<ul>
<li><p><strong>All study participants are treated and followed up for
the same duration</strong>: This ensures that any difference in AE rates
is not due to differing lengths of exposure or follow-up time. Uniform
exposure and observation periods across all subjects allow for more
reliable comparisons.</p></li>
<li><p><strong>The duration of drug exposure is very short</strong>: In
short-term treatments, the likelihood of external factors influencing AE
rates is minimized. As a result, AEs observed are more likely to be
directly attributable to the drug rather than prolonged exposure or
confounding variables over time.</p></li>
<li><p><strong>The AE is acute and occurs very soon after
exposure</strong>: When an adverse event is known to develop shortly
after drug administration, unadjusted incidence rates can reliably
reflect the true risk. The close temporal proximity between exposure and
AE minimizes uncertainty in causal interpretation.</p></li>
</ul>
<p><strong>Incidence rates may not accurately represent true risk
when:</strong></p>
<ul>
<li><p><strong>Different treatment or follow-up durations exist between
treatment arms by design</strong>: For example, if one treatment group
is followed for 6 months and another for 12 months, the difference in
follow-up time introduces bias in comparing incidence rates, as longer
durations naturally provide more opportunity for AEs to occur.</p></li>
<li><p><strong>There is a high or unequal rate of study participant
discontinuation between treatment arms</strong>: If more participants
discontinue treatment in one group than the other, the total exposure
time differs, which can distort comparisons and lead to inaccurate
estimates of AE risk.</p></li>
<li><p><strong>The duration of treatment exposure is very long</strong>:
Over longer periods, more external variables may come into play (e.g.,
aging, comorbidities, background medication use), which can dilute or
obscure the direct relationship between the drug and the AE.</p></li>
<li><p><strong>The AE is very rare or very common</strong>: If an AE is
extremely rare, the sample size might be insufficient to detect a
meaningful difference, leading to unstable or misleading incidence
rates. If the AE is very common, background noise may mask the specific
contribution of the drug, reducing the specificity of the risk
estimate.</p></li>
</ul>
<p>In summary, <strong>exposure-unadjusted incidence rates are best used
in controlled conditions with consistent exposure and follow-up</strong>
and are most informative for acute, clearly drug-related adverse events.
When conditions vary across groups or the observation period is
extended, these rates become less reliable for assessing true risk, and
<strong>exposure-adjusted analyses or more complex statistical
modeling</strong> may be necessary.</p>
</div>
<div id="defination-and-assumptions" class="section level3 unnumbered">
<h3 class="unnumbered">Defination and Assumptions</h3>
<p><strong>Exposure-Adjusted Incidence Rates (EAIRs):
Overview</strong></p>
<p>EAIRs quantify how frequently an adverse event occurs relative to the
total amount of time participants are exposed to treatment. It’s
typically expressed as the number of participants with an event per 100
patient-years.</p>
<p><strong>Definition of EAIRs</strong></p>
<p>EAIR is calculated as:</p>
<p><span class="math display">\[
\text{EAIR} = 100 \times \frac{n}{\sum_{i=1}^{N} T_{\text{Exp}}(i)}
\]</span></p>
<ul>
<li><strong>Numerator (<code>n</code>)</strong>: Number of study
participants who experienced the AE.</li>
<li><strong>Denominator</strong>: Sum of exposure time (in years) across
all participants:
<ul>
<li>For participants with an AE: from drug start to first AE.</li>
<li>For participants without an AE: from drug start to end of
follow-up.</li>
</ul></li>
</ul>
<p><strong>Key Assumptions for EAIRs</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Constant Hazard</strong>
<ul>
<li>The risk of the AE is assumed to remain constant over the
observation period.</li>
<li>This is often not the case, especially for chronic or delayed
AEs.</li>
<li>The assumption is more reasonable in short-duration trials.</li>
</ul></li>
<li><strong>Non-informative Censoring</strong>
<ul>
<li>Participants who discontinue early are assumed to have the same AE
risk as those who complete the study.</li>
<li>If discontinuation is related to the AE, this assumption is
violated.</li>
</ul></li>
</ol>
<p><strong>Worked Example</strong></p>
<ul>
<li><strong>Number of participants</strong>: 5</li>
<li><strong>Total participant-years at risk</strong>: 4 years</li>
<li><strong>Participants with AEs</strong>: 3</li>
</ul>
<p><strong>Exposure durations:</strong></p>
<ul>
<li>Participant 1: 1.0 year (no AE)</li>
<li>Participant 2: 0.6 year (AE)</li>
<li>Participant 3: 0.9 year (no AE)</li>
<li>Participant 4: 0.8 year (AE)</li>
<li>Participant 5: 0.7 year (AE)</li>
</ul>
<p>Total exposure time = 0.6 + 0.8 + 0.9 + 1.0 + 0.7 = 4.0 years<br />
Number with AEs = 3</p>
<p>So:</p>
<p><span class="math display">\[
\text{EAIR} = 100 \times \frac{3}{4} = 75.0 \text{ per 100
patient-years}
\]</span></p>
<p><strong>Interpretation:</strong> If 100 patients were treated for 1
year, 75 of them are expected to experience the AE of interest under
similar conditions.</p>
</div>
<div id="confidence-intervals-for-eairs"
class="section level3 unnumbered">
<h3 class="unnumbered">Confidence intervals for EAIRs</h3>
<p>How to calculate <strong>Confidence Intervals (CIs) for
Exposure-Adjusted Incidence Rates (EAIRs)</strong> and highlights the
importance of selecting an appropriate method, particularly when the
number of events is small.</p>
<p>Confidence intervals help express the <strong>uncertainty</strong>
around the point estimate of the EAIR, indicating the likely range in
which the true incidence rate lies.</p>
<p><strong>Two Methods to Calculate 95% Confidence Intervals for
EAIRs:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Exact Poisson Confidence Intervals</strong>
<ul>
<li><p>Preferred when event counts are small, because they do not rely
on assumptions of normality.</p></li>
<li><p>Based on the Chi-square (χ²) distribution.</p></li>
<li><p>The lower and upper bounds (LCL and UCL) are calculated
using:</p>
<p><span class="math display">\[
LCL = 100 \times \frac{\chi^2_{2n,\alpha/2}}{2 \sum_{i=1}^{N}
T_{\text{Exp}}(i)}
\quad \text{and} \quad
UCL = 100 \times \frac{\chi^2_{2(n+1),1-\alpha/2}}{2 \sum_{i=1}^{N}
T_{\text{Exp}}(i)}
\]</span></p></li>
</ul></li>
<li><strong>Normal Approximation</strong>
<ul>
<li><p>A simpler method using the normal distribution (Z-value of 1.96
for 95% CI).</p></li>
<li><p>Suitable when <strong>event counts are large</strong> and Poisson
distribution can be approximated by the normal distribution.</p></li>
<li><p>Formula:</p>
<p><span class="math display">\[
100 \times \left( \frac{n}{\sum T_{\text{Exp}}(i)} \pm 1.96 \times
\sqrt{\frac{n}{\left(\sum T_{\text{Exp}}(i)\right)^2}} \right)
\]</span></p></li>
</ul></li>
</ol>
<hr />
<p><strong>Worked Example:</strong></p>
<ul>
<li><strong>Participants</strong>: 5<br />
</li>
<li><strong>Total time at risk</strong>: 4 participant-years<br />
</li>
<li><strong>Number of AEs</strong>: 3<br />
</li>
<li><strong>EAIR</strong>: 75.0 per 100 participant-years</li>
</ul>
<p><strong>Using the Two CI Methods:</strong></p>
<ul>
<li><strong>Exact Poisson 95% CI</strong>: (15.47, 219.18)
<ul>
<li>Interpreted as a wide interval indicating considerable uncertainty,
especially due to the small number of events.</li>
</ul></li>
<li><strong>Normal 95% CI</strong>: (-9.87, 159.87)
<ul>
<li>Problematic because the <strong>lower limit is negative</strong>,
which is not meaningful for incidence rates.</li>
<li>Highlights why <strong>normal approximation is unreliable</strong>
with small event counts.</li>
</ul></li>
</ul>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>Use <strong>Poisson CIs</strong> when the number of events is small
or when accurate estimation is critical.</li>
<li>Always <strong>scale EAIR and its CI</strong> according to the
desired follow-up unit (e.g., per 100 patient-years).</li>
<li><strong>Avoid normal approximation</strong> in early-phase trials or
rare event settings—it can lead to misleading, even impossible values
(like negative rates).</li>
<li><strong>Every AE requires its own time-at-risk calculation</strong>:
This is one of the most frequent sources of EAIR errors. Different AEs
have different time windows (from drug start to AE or to censoring), and
each must be calculated independently.</li>
<li><strong>Denominator (time at risk) should not be calculated at the
TFL level</strong>: Instead, it should be included in the ADaM dataset
as a pre-derived variable to ensure consistency, reproducibility, and
ease of QC.</li>
<li><strong>Create a dedicated time-to-event ADaM dataset (e.g.,
ADTTAE)</strong>: Housing all AE-specific time-at-risk variables in one
dataset streamlines programming and QC processes and supports reliable
derivation of both EAIRs and confidence intervals.</li>
<li><strong>Consider specifying EAIR denominators in the table
shells</strong>: This makes statistical QC easier and reduces the risk
of mismatches during table generation.</li>
</ul>
</div>
<div id="interpretation-of-eairs" class="section level3 unnumbered">
<h3 class="unnumbered">Interpretation of EAIRs</h3>
<p><strong>EAIRs are descriptive statistics that can help with medical
interpretation of safety data</strong></p>
<p>EAIRs help normalize the occurrence of adverse events (AEs) by
accounting for the amount of time each participant is at risk (i.e.,
exposed to the drug). This allows for fairer comparisons across
treatment groups, especially when follow-up times vary. However, their
interpretability has limits and depends on several underlying
assumptions.</p>
<hr />
<p><strong>Interpretation of exposure-adjusted incidence rates is only
straightforward under assumption of constant event rate over
time</strong></p>
<p>This is a key statistical assumption behind EAIRs. It assumes the
hazard (risk) of an event remains <strong>constant over time</strong>,
which simplifies the interpretation. However, in real-world scenarios,
risk may vary over time due to accumulation of exposure, adaptive
resistance, seasonality, etc.</p>
<p>If the risk is <strong>not constant</strong>, then EAIRs become
harder to interpret, as they could under- or over-estimate the true risk
at different time points.</p>
<hr />
<p><strong>Interpretation of EAIRs depends on several
factors:</strong></p>
<ul>
<li><strong>Study design</strong>: Different designs (e.g., crossover,
parallel, open-label) impact how and when exposure is measured.</li>
<li><strong>Characteristics of the indication</strong>: Some diseases
may naturally carry time-varying risks or have episodic flare-ups.</li>
<li><strong>Study participant population</strong>: Age, sex,
comorbidities, and other population-specific factors can affect AE
risk.</li>
<li><strong>Characteristics of the adverse events themselves</strong>,
especially:
<ul>
<li><strong>Frequency</strong>: Whether the event is very rare or very
common can affect the stability and interpretability of the rate.</li>
<li><strong>Time dependency</strong>:
<ul>
<li><strong>Time to onset</strong>: If AEs tend to occur early or late
after exposure, this affects whether EAIRs capture the true risk.</li>
<li><strong>Seasonality</strong>: For diseases or AEs affected by time
of year (e.g., flu, allergy), constant hazard assumptions may not
apply.</li>
</ul></li>
</ul></li>
</ul>
<hr />
<p><strong>Confidence intervals can aid in the interpretation of
EAIRs</strong></p>
<p>Confidence intervals (CIs) reflect the <strong>uncertainty or
variability</strong> of the EAIR estimate.</p>
<ul>
<li>CIs provide a <strong>crude but informative range</strong> of where
the true value may lie.</li>
<li>They should be treated as descriptive statistics—not
hypothesis-testing tools.</li>
<li>CIs are generally <strong>preferred over p-values</strong>,
especially in safety analyses, where the focus is on understanding risk,
not testing for differences.</li>
</ul>
<hr />
<p><strong>Notes to consider when reviewing competitor
publications:</strong></p>
<ul>
<li><strong>Terminology varies</strong>: EAIRs may also be referred to
as <em>incidence density</em>, <em>incidence per person-time</em>, or
similar terms. It’s important to confirm definitions before making
comparisons.</li>
<li><strong>Incorrect exposure definitions are common</strong>: Some
publications may use the full study duration (e.g., up to last
follow-up) as the time at risk for all participants. This is not
correct. <strong>Exposure time should end when the first instance of the
AE occurs</strong>, since the individual is no longer at risk of
experiencing the first occurrence of that event.</li>
</ul>
</div>
<div id="alternative-and-supplementary-methods-to-consider"
class="section level3 unnumbered">
<h3 class="unnumbered">Alternative and supplementary methods to
consider</h3>
<p>Each method has its own strengths and assumptions, and please
<strong>check those assumptions</strong> carefully when selecting an
analytical approach.</p>
<p>When analyzing safety data, EAIRs are just one tool. Depending on
your objectives, event frequency, timing, and recurrence, you may need
to consider:</p>
<ul>
<li>Stratified or time-windowed EAIRs</li>
<li>Time-to-event methods for first occurrences</li>
<li>Event-based rates for multiple AEs</li>
<li>Competing risk or recurrent event models for complex cases</li>
</ul>
<hr />
<p><strong>Exposure-adjusted incidence rates for discrete
periods</strong></p>
<p>This method involves dividing the study period into separate
intervals (e.g., weeks or months) and calculating EAIRs for each
interval. This has two key advantages: - The <strong>constant hazard
assumption</strong> is more likely to be reasonable over shorter,
defined timeframes than over the entire study period. - It allows for
description of how AE risk <strong>changes over time</strong>, helping
identify periods of higher or lower risk (e.g., early onset
toxicity).</p>
<hr />
<p><strong>Time-to-event analyses</strong></p>
<p>This refers to survival-type methods, primarily: -
<strong>Kaplan-Meier analysis</strong>, which estimates the probability
of event-free survival over time. - These methods <strong>do not require
the assumption of constant hazard</strong>. - They are particularly
useful when focusing on <strong>time to the first occurrence</strong> of
an adverse event, rather than repeated or cumulative counts.</p>
<p>This approach provides a detailed look at the <strong>temporal aspect
of safety</strong>, helping answer: “When are events most likely to
occur?”</p>
<hr />
<p><strong>Exposure-adjusted event rates</strong></p>
<p>These are used to: - Account for <strong>recurrent events</strong>,
where the same AE can happen more than once in a participant. - It uses
the same framework as EAIRs but tracks <strong>event counts rather than
participant counts</strong>, offering a broader view of overall AE
burden. - Assumptions are generally <strong>similar to EAIRs</strong>,
including the need for constant rate assumptions and appropriate
handling of exposure time.</p>
<p>This method is valuable for chronic or cycling conditions where
multiple AEs per participant are expected.</p>
<hr />
<p><strong>Other multiple event-based analyses</strong></p>
<p>This category includes more advanced statistical methods designed to
address complex event patterns:</p>
<ul>
<li><strong>Recurrent event models</strong>: These go beyond just first
events and model all repeated occurrences.</li>
<li><strong>Mean cumulative function</strong>: Summarizes the average
number of events per subject over time.</li>
<li><strong>Competing risks models</strong>: Adjust for scenarios where
<strong>different types of events compete</strong>, such as when death
precludes the occurrence of a non-fatal AE.</li>
</ul>
<p>These methods are more complex but better reflect <strong>real-world
clinical scenarios</strong>, especially when multiple outcomes are
interrelated.</p>
</div>
</div>
</div>
<div id="structure-benefit-risk-assessment" class="section level1"
number="5">
<h1><span class="header-section-number">5</span> Structure Benefit-Risk
Assessment</h1>
<div id="door-desirability-of-outcome-ranking" class="section level2"
number="5.1">
<h2><span class="header-section-number">5.1</span> DOOR (Desirability of
Outcome Ranking)</h2>
<div id="background-and-motivation" class="section level3 unnumbered">
<h3 class="unnumbered">Background and Motivation</h3>
<p><strong>1. Limitations of Traditional Benefit-Risk (BR)
Assessments</strong></p>
<ul>
<li><p><strong>Separate Evaluation of Efficacy and
Safety</strong>:<br />
Often, efficacy (how well a treatment works) and safety (side effects or
adverse events) are analyzed in isolation. For example, a drug might be
reported as 50% effective and having 30% safety issues, but we don’t
know how these outcomes are distributed across the same patients. This
separation can lead to misleading conclusions when trying to understand
the full impact of a treatment.</p></li>
<li><p><strong>Ignoring Associations Between Outcomes</strong>:<br />
It’s important to know whether the same patients who benefit from a
treatment are also the ones who suffer side effects. For instance, do
successful outcomes come at the cost of more safety problems? Without
looking at this association, we can’t fully understand the
trade-offs.</p></li>
<li><p><strong>Overlooking Cumulative Patient Experience</strong>:<br />
Each patient experiences both benefits and risks together, not
separately. Traditional approaches often summarize outcomes in
percentages, ignoring how each individual patient is affected as a
whole. This simplification can hide clinically meaningful
patterns.</p></li>
<li><p><strong>Neglecting Patient Heterogeneity</strong>:<br />
Not all patients respond the same way. Some may benefit greatly with few
risks, while others may experience no benefit and many side effects.
Traditional methods don’t adequately account for this variability,
leading to generalizations that may not apply to subgroups.</p></li>
</ul>
<p><strong>2. CIOMS and New Directions in BR Assessment</strong></p>
<p><strong>CIOMS report</strong>, a respected international guideline
for benefit-risk evaluation of medicinal products. It introduces two
major shifts:</p>
<ul>
<li><p><strong>Structured and Proactive Benefit-Risk
Design</strong>:<br />
Instead of waiting until a trial is over and doing a benefit-risk
assessment retrospectively, researchers should now <strong>incorporate
BR thinking into trial design</strong> from the start. That means
clearly defining benefit and risk outcomes, understanding how they
relate, and planning how to evaluate them jointly.</p></li>
<li><p><strong>Patient-Centric Benefit-Risk Assessment</strong>:<br />
The new trend is to place <strong>patients’ perspectives and
experiences</strong> at the center of benefit-risk evaluation. It’s not
just about whether a treatment works statistically, but whether the
benefit justifies the risk <strong>for a real patient</strong>.
Different patients value outcomes differently—some may tolerate side
effects for a small benefit, others may not. This approach helps ensure
that regulatory decisions and clinical guidance better reflect patient
needs and values.</p></li>
</ul>
</div>
<div id="how-does-door-work" class="section level3 unnumbered">
<h3 class="unnumbered">How Does DOOR Work?</h3>
<p>DOOR is a <strong>patient-centric paradigm</strong> that supports the
design, monitoring, analysis, and reporting of clinical trials. It
shifts the focus from traditional, separated endpoints to
<strong>comprehensive, integrated outcomes</strong> that reflect what
matters most to patients. The table outlines four key features of
DOOR:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Patient-Centered Approach</strong><br />
DOOR prioritizes outcomes that are meaningful to patients—such as
combining information about treatment efficacy, safety, and quality of
life. This reflects real-world decision-making, where patients consider
multiple aspects simultaneously rather than in isolation.</p></li>
<li><p><strong>Holistic Evaluation</strong><br />
Rather than analyzing efficacy and safety separately, DOOR integrates
all benefit-risk dimensions into a single <strong>composite
outcome</strong>, giving a unified and intuitive understanding of the
overall clinical impact.</p></li>
<li><p><strong>Ordinal Ranking System</strong><br />
Outcomes are placed in <strong>ordered categories</strong>, from the
most desirable (e.g., cure without side effects) to the least desirable
(e.g., no improvement with severe side effects or death). This helps
translate clinical trial data into a more interpretable framework for
decision-making.</p></li>
<li><p><strong>Flexibility in Design</strong><br />
DOOR is adaptable—it can be tailored to the specific needs of different
diseases, therapeutic areas, or patient populations by selecting
<strong>clinically meaningful events</strong> for ranking. This makes it
relevant across diverse trial settings.</p></li>
</ol>
<p>The process of implementing DOOR in a clinical trial follows three
main steps:</p>
<ol style="list-style-type: decimal">
<li><strong>Define and Rank Outcomes</strong>
<ul>
<li>Based on the <strong>patient journey</strong>, outcomes are defined
that capture both benefit and risk dimensions.</li>
<li>These outcomes are then <strong>ranked from most desirable to least
desirable</strong>, reflecting clinical and patient-centered
priorities.</li>
</ul></li>
<li><strong>Assign Patients to DOOR Categories</strong>
<ul>
<li>Each patient is assigned to one of the predefined DOOR categories
according to the outcome they experienced.</li>
<li>For example, if the categories are:
<ol style="list-style-type: decimal">
<li>Full recovery, no adverse events<br />
</li>
<li>Recovery with mild adverse events<br />
</li>
<li>No recovery<br />
</li>
<li>Death<br />
→ Each patient will be placed into one of these based on their results
in the trial.</li>
</ol></li>
</ul></li>
<li><strong>Compare Treatment Arms</strong>
<ul>
<li>The treatment groups are compared <strong>based on the
probability</strong> that a patient from one group has a better DOOR
outcome than a patient from another group.</li>
<li>Two types of analyses can be conducted:
<ol style="list-style-type: decimal">
<li><strong>Rank-based</strong> comparison (using the full ordinal
scale)<br />
</li>
<li><strong>Grade-based</strong> (partial credit) approach that gives
different weights to each level, allowing more granularity (e.g., if one
group has more patients in slightly better categories).</li>
</ol></li>
</ul></li>
</ol>
<p><img src="02_Plots/Safety%20Evaluation/DOOR_Structure1.png" /></p>
<p><img src="02_Plots/Safety%20Evaluation/DOOR_Structure2.png" /></p>
<p><strong>Example of DOOR Components (Important Events) for Adaptive
covid-19 Treatment Trial(ACTT-1):</strong></p>
<ul>
<li>Death<br />
</li>
<li>Hospitalization with invasive mechanical ventilation / ECMO<br />
</li>
<li>Serious adverse event (SAE) not resolved or resolved with
sequelae</li>
</ul>
<table>
<colgroup>
<col width="34%" />
<col width="34%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>DOOR Rank Category</strong></th>
<th><strong>Remdesivir Frequency (N=541)</strong></th>
<th><strong>Placebo Frequency (N=521)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Alive with no events</td>
<td>433</td>
<td>382</td>
</tr>
<tr class="even">
<td>Alive with 1 event</td>
<td>42</td>
<td>57</td>
</tr>
<tr class="odd">
<td>Alive with 2 events</td>
<td>8</td>
<td>6</td>
</tr>
<tr class="even">
<td>Death</td>
<td>58</td>
<td>76</td>
</tr>
</tbody>
</table>
<p><strong>Why is DOOR Powerful?</strong></p>
<ul>
<li><strong>Reflects real-world patient experience</strong>: Instead of
reducing outcomes to binary variables (e.g., success/failure), DOOR
captures nuanced information across multiple dimensions.</li>
<li><strong>Improves interpretability</strong>: Ordinal categories are
more intuitive for clinicians, patients, and regulators.</li>
<li><strong>Supports better decision-making</strong>: When treatments
have similar efficacy but differ in safety or quality-of-life impact,
DOOR makes these differences more visible.</li>
</ul>
</div>
<div id="two-door-analyses-methods" class="section level3 unnumbered">
<h3 class="unnumbered">Two DOOR Analyses Methods</h3>
<p><strong>Rank-based Analysis Approach</strong></p>
<p>This approach focuses on <strong>pairwise comparisons</strong>
between individuals across treatment groups using the <strong>DOOR
probability</strong>, which reflects the chance that a participant from
one group has a <strong>more desirable outcome</strong> than a
participant from the other group.</p>
<ul>
<li><p><strong>Key Concept</strong>:<br />
It estimates the <strong>probability that a randomly chosen patient from
the experimental group has a better (or equal) outcome than one from the
control group</strong>.</p></li>
<li><p><strong>Methodology</strong>:<br />
The <strong>Wilcoxon-Mann-Whitney (WMW) statistic</strong> is used to
estimate this probability. It is a nonparametric method suitable for
<strong>ordinal outcomes</strong>, calculated by comparing all possible
patient pairs across groups and counting how often one outcome is better
than the other.</p></li>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>Captures the <strong>relative benefit</strong> of one treatment over
another at the individual level.</li>
<li>Does not rely on assumptions of normality or equal variances.</li>
</ul></li>
<li><p><strong>Note on Composite Outcomes</strong>:<br />
Since DOOR often includes composite outcomes (like “alive with 1 event”,
“alive with 2 events”, etc.), it’s helpful to <strong>break down each
component</strong> separately to explore <strong>how different events
contribute to the overall outcome</strong>.</p></li>
</ul>
<hr />
<p><strong>Grade-based Analysis Approach</strong></p>
<p>Also known as <strong>partial credit analysis</strong>, this approach
assigns <strong>numeric scores</strong> to DOOR outcome categories based
on <strong>their perceived desirability</strong>, which may vary by
patients or clinicians.</p>
<ul>
<li><p><strong>Key Concept</strong>:<br />
Treats DOOR outcomes as if they lie on a <strong>continuous 0–100
scale</strong>, where 100 represents the best outcome (e.g., “alive with
no events”) and 0 the worst (e.g., death), with intermediate outcomes
scored accordingly (e.g., partial credit for 1 or 2 adverse
events).</p></li>
<li><p><strong>Purpose</strong>:</p>
<ul>
<li>Evaluates how <strong>treatment groups differ in mean DOOR
scores</strong>, allowing a nuanced understanding of intervention
effects.</li>
<li>Uses statistical tests like <strong>Welch’s t-test</strong> to
compare group means.</li>
</ul></li>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>Reflects <strong>personalized preferences</strong> by adjusting
scores based on what patients and clinicians value.</li>
<li>Provides a <strong>more flexible and interpretable measure</strong>
of benefit-risk trade-offs.</li>
</ul></li>
</ul>
<hr />
<table>
<colgroup>
<col width="26%" />
<col width="37%" />
<col width="36%" />
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Rank-Based Analysis</th>
<th>Grade-Based Analysis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Type of Comparison</td>
<td>Pairwise patient comparison</td>
<td>Group-level mean score comparison</td>
</tr>
<tr class="even">
<td>Statistic</td>
<td>DOOR probability (via WMW test)</td>
<td>Mean score difference (Welch’s t-test)</td>
</tr>
<tr class="odd">
<td>Outcome Scale</td>
<td>Ordinal</td>
<td>Treated as continuous (0–100 scale)</td>
</tr>
<tr class="even">
<td>Interpretability</td>
<td>Probability a patient has a better outcome</td>
<td>Average desirability score</td>
</tr>
<tr class="odd">
<td>Flexibility for Preferences</td>
<td>Limited</td>
<td>High (can reflect personalized scoring)</td>
</tr>
<tr class="even">
<td>Focus</td>
<td>Relative ranking</td>
<td>Absolute importance/utility of outcomes</td>
</tr>
</tbody>
</table>
</div>
<div id="door-analyses-rank-based-analysis"
class="section level3 unnumbered">
<h3 class="unnumbered">DOOR Analyses: Rank-based Analysis</h3>
<ol style="list-style-type: decimal">
<li>Overview: What is Rank-Based DOOR Analysis?**</li>
</ol>
<p>DOOR (Desirability of Outcome Ranking) uses <strong>rank-based
statistics</strong> to compare overall patient outcomes between
treatment groups. This method does not focus on isolated endpoints but
evaluates the <strong>probability that a patient receiving the
experimental treatment (E)</strong> has a <strong>more desirable
outcome</strong> than a patient receiving the control treatment (C). The
summary measure is called the <strong>DOOR probability</strong>.</p>
<p>The rank-based DOOR analysis provides a <strong>flexible,
interpretable, and robust</strong> way to compare treatments in clinical
trials by:</p>
<ul>
<li>Integrating efficacy, safety, and quality-of-life into a single
ranking</li>
<li>Quantifying how often patients in one arm have better outcomes than
those in the other</li>
<li>Offering statistical tools (CI, hypothesis testing, p-values) for
inference</li>
<li>Allowing adjustment for ties and approximation methods when data are
less ideal</li>
</ul>
<p>This method supports <strong>patient-centered</strong>,
<strong>holistic decision-making</strong> and has become an increasingly
favored analytic approach in benefit-risk evaluations.</p>
<p><strong>2. Estimating DOOR Probability</strong></p>
<p>The DOOR probability is estimated using the
<strong>Wilcoxon-Mann-Whitney (WMW)</strong> statistic. This
nonparametric method compares every patient in group E to every patient
in group C and assigns scores based on outcome rankings:</p>
<p><span class="math display">\[
\hat{\pi}_{E \geq C} = \frac{1}{n_E n_C} \sum_{i=1}^{n_E}
\sum_{j=1}^{n_C} \phi(y_i^E, y_j^C)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\phi(y_i^E, y_j^C)\)</span> is:
<ul>
<li>1 if <span class="math inline">\(y_i^E &gt; y_j^C\)</span></li>
<li>½ if <span class="math inline">\(y_i^E = y_j^C\)</span></li>
<li>0 if <span class="math inline">\(y_i^E &lt; y_j^C\)</span></li>
</ul></li>
</ul>
<p>This represents the average probability that a randomly chosen
patient from the experimental group has a <strong>better or
equal</strong> outcome compared to a patient from the control group.</p>
<p><strong>3. Interpretation of DOOR Probability</strong></p>
<p><span class="math display">\[
\pi_{E \geq C} = P[Y^E &gt; Y^C] + \frac{1}{2}P[Y^E = Y^C]
\]</span></p>
<ul>
<li>If <span class="math inline">\(\pi_{E \geq C} &gt; 0.5\)</span>: The
experimental treatment is <strong>more desirable</strong> overall.</li>
<li>If <span class="math inline">\(\pi_{E \geq C} &lt; 0.5\)</span>: The
control is <strong>more desirable</strong>.</li>
<li><span class="math inline">\(\pi_{C \geq E} = 1 - \pi_{E \geq
C}\)</span></li>
</ul>
<p>This approach:</p>
<ul>
<li>Accounts for <strong>both central tendency and dispersion</strong>
(Simonoff et al., 1986)</li>
<li>Reflects a <strong>population-level causal effect</strong> rather
than individual-level effects (Fay et al., 2018)</li>
</ul>
<p><strong>4. Confidence Interval (CI) Methods for DOOR
Probability</strong></p>
<p>There are several ways to estimate the CI for DOOR probability, each
with pros and cons:</p>
<table style="width:100%;">
<colgroup>
<col width="20%" />
<col width="52%" />
<col width="26%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Method</strong></th>
<th><strong>Feature</strong></th>
<th><strong>Reference</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wald-type CI</td>
<td>Easy to construct, symmetric, but may exceed [0,1] in extreme
cases</td>
<td>Ryu &amp; Agresti, 2008</td>
</tr>
<tr class="even">
<td>Halperin et al. (1989)</td>
<td>Easy to construct, asymmetric CI using quadratic inequality</td>
<td>Halperin et al., 1989</td>
</tr>
<tr class="odd">
<td>Logit transformation-based CI</td>
<td>Uses logit scale for CI, then transforms back; handles
asymmetry</td>
<td>Edwardes, 1995</td>
</tr>
<tr class="even">
<td>Score/Pseudo-score/Likelihood</td>
<td>More accurate, handles asymmetry; computationally more
demanding</td>
<td>Ryu &amp; Agresti, 2008</td>
</tr>
<tr class="odd">
<td>Bootstrap</td>
<td>Flexible, but computationally intensive</td>
<td>van Duin et al., CID 2018</td>
</tr>
</tbody>
</table>
<p><strong>5. Hypothesis Testing for DOOR Probability</strong></p>
<p>Used to test whether the experimental treatment is statistically
superior:</p>
<ul>
<li><p><strong>One-sided</strong>:<br />
<span class="math inline">\(H_0: \pi_{E \geq C} \leq
\delta_0\)</span><br />
<span class="math inline">\(H_1: \pi_{E \geq C} &gt;
\delta_0\)</span></p></li>
<li><p><strong>Two-sided</strong>:<br />
<span class="math inline">\(H_0: \pi_{E \geq C} =
\delta_0\)</span><br />
<span class="math inline">\(H_1: \pi_{E \geq C} \ne
\delta_0\)</span><br />
where <span class="math inline">\(\delta_0 = 0.5\)</span> is typically
used.</p></li>
</ul>
<p><span class="math display">\[
z_{WMW} = \frac{\hat{\pi}_{E \geq C} - \delta_0}{\sqrt{\hat{V}_0}}
\]</span></p>
<ul>
<li><span class="math inline">\(\hat{V}_0\)</span> is the variance
estimate under the null hypothesis (see Lehmann &amp; D’Abrera,
1975).</li>
<li>Reject <span class="math inline">\(H_0\)</span> if the
<strong>p-value is below α (e.g., 0.05)</strong>.</li>
</ul>
<p><strong>6. Calculating P-Values</strong></p>
<p>Two approaches:</p>
<ul>
<li><strong>One-sided</strong>:<br />
<span class="math inline">\(p_{\text{1sided}}(z_{WMW}) = \Pr[Z &gt;
z_{WMW}]\)</span></li>
<li><strong>Two-sided</strong>:<br />
<span class="math inline">\(p_{\text{2sided}}(z_{WMW}) = \Pr[|Z| &gt;
|z_{WMW}|]\)</span></li>
</ul>
<p>When outcomes are heavily tied or sample sizes are small:</p>
<ul>
<li><strong>Continuity correction</strong>: Adjust the statistic by
0.5</li>
<li><strong>t-approximation</strong>: Use a t-distribution with <span
class="math inline">\(n_E + n_C - 1\)</span> degrees of freedom instead
of the normal distribution</li>
</ul>
<p><img src="02_Plots/Safety%20Evaluation/DOOR_Issues1.png" /></p>
</div>
<div id="door-analyses-grade-based-analysis-partial-credit-analysis"
class="section level3 unnumbered">
<h3 class="unnumbered">DOOR Analyses: Grade-based Analysis (Partial
Credit Analysis)</h3>
<p>Unlike rank-based DOOR analysis, which simply orders patient
outcomes, <strong>grade-based analysis assigns specific scores</strong>
to each outcome category to reflect <strong>their clinical and
patient-perceived importance</strong>. This method translates ordinal
categories into a <strong>continuous score</strong> on a 0–100 scale,
allowing more nuanced comparisons between groups.</p>
<p><strong>1. Assign Scores to DOOR Categories</strong></p>
<p>Each DOOR rank category is assigned a score that reflects its
desirability:</p>
<table>
<thead>
<tr class="header">
<th><strong>DOOR Rank Category</strong></th>
<th><strong>Score</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Alive with no events</td>
<td>100</td>
</tr>
<tr class="even">
<td>Alive with 1 event</td>
<td>Partial Score 1 (0 &lt; S₁ ≤ 100)</td>
</tr>
<tr class="odd">
<td>Alive with 2 events</td>
<td>Partial Score 2 (0 &lt; S₂ ≤ S₁)</td>
</tr>
<tr class="even">
<td>Alive with 3 events</td>
<td>Partial Score 3 (0 &lt; S₃ ≤ S₂)</td>
</tr>
<tr class="odd">
<td>Death</td>
<td>0</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Partial Scores</strong> (S₁, S₂, S₃) are chosen based on:
<ul>
<li>Clinical judgment</li>
<li>Patient values</li>
<li>Strategic differentiation between outcomes</li>
</ul></li>
</ul>
<p>This design provides <strong>flexibility</strong>, allowing the
analysis to reflect various stakeholder perspectives (e.g., patients
might value mild side effects differently from clinicians).</p>
<p><strong>2. Analyze Scores as Continuous Outcomes</strong></p>
<p>Once every patient has been assigned a score based on their DOOR
outcome:</p>
<ul>
<li>The scores are analyzed <strong>as if they were continuous</strong>
(like a patient satisfaction score).</li>
<li>A two-sample comparison is then performed, usually with
<strong>Welch’s t-test</strong> (which allows for unequal
variances).</li>
</ul>
<p>The result is an <strong>estimated difference in mean DOOR
scores</strong> between the treatment arms (e.g., Remdesivir
vs. Placebo).</p>
<p><img src="02_Plots/Safety%20Evaluation/DOOR_Score.png" /></p>
<p><strong>3. What Does Partial Credit Help With?</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Strategic Spacing</strong><br />
It allows deliberate differences in scores between categories—e.g.,
death vs. survival with one adverse event may be weighted much more
heavily than 1 event vs. 2 events.</p></li>
<li><p><strong>Personalized Interpretation</strong><br />
Customizes the analysis for how <strong>patients and clinicians</strong>
value trade-offs in outcomes.</p></li>
<li><p><strong>Robustness Checks</strong><br />
Analysts can test how results change under different partial credit
assumptions to assess the stability of conclusions.</p></li>
</ol>
</div>
</div>
<div id="mcda-multi-criteria-decision-analysis" class="section level2"
number="5.2">
<h2><span class="header-section-number">5.2</span> MCDA (Multi-Criteria
Decision Analysis)</h2>
</div>
</div>
<div id="laboratory" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Laboratory</h1>
<div id="individual-studies" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Individual
Studies</h2>
<p>Laboratory data should be presented using a combination of visual and
tabular displays that are clear, clinically meaningful, and consistent
across treatment arms. The primary display format recommended is a
<strong>three-panel figure</strong>. The <strong>top panel</strong> is a
<strong>box plot</strong> showing observed laboratory values over time.
The box plot includes the median, mean (as white dots), interquartile
range (25th–75th percentiles), and whiskers at the 5th and 95th
percentiles. Individual participant data points are overlaid and
color-coded—<strong>red</strong> for values above the upper limit of
normal (ULN), <strong>blue</strong> for values below the lower limit of
normal (LLN), and <strong>gray</strong> for values within range. These
colors reflect subject-specific reference ranges, which can vary by
demographic factors.</p>
<p>The <strong>middle panel</strong> is a <strong>summary text
line</strong> for each time point, showing the number of observations
and the counts of high or low values. These counts are color-coded to
match the plot and provide a quick numerical summary. Unlike earlier
versions, detailed statistics like mean, standard deviation, min, and
max are not recommended in this display to conserve space and allow more
time points to be shown.</p>
<p>The <strong>bottom panel</strong> is a <strong>line plot</strong>
displaying the group means over time with 95% confidence intervals. This
addition helps reviewers compare trends across treatment arms more
easily and complements the box plot above.</p>
<p>In addition to observed value plots, <strong>change-from-baseline box
plots</strong> (similar format) are recommended. These do not include
reference limit coloring or counts of high/low, since there are no
defined thresholds for change values. Importantly, the practice of
including “change from baseline to last observation” has been
discouraged, as it has limited value in identifying safety signals.</p>
<p>For <strong>shift analyses</strong>, separate <strong>scatter
plots</strong> should be used to show shifts from baseline to
post-baseline values. <strong>Figure 6.3</strong> focuses on
<strong>maximum values</strong>, and <strong>Figure 6.4</strong> on
<strong>minimum values</strong>. Each treatment group should be shown in
a <strong>separate panel</strong> with identical axes for comparability.
Reference lines for ULN/LLN are removed due to population variability,
and instead, special <strong>symbols (e.g., stars)</strong> indicate
subjects who shifted from normal to abnormal ranges.</p>
<p>A <strong>summary shift table (Table 6.1)</strong> is used to
quantify these shifts, displaying the percentage of participants moving
between normal and abnormal categories, with comparisons between
treatment arms including 95% confidence intervals. Related lab analytes
should be grouped together to support integrated interpretation.</p>
<p>For <strong>qualitative or ordinal lab analytes</strong> (e.g.,
“normal/abnormal” or “+/++/+++”), a similar summary table format is
used. These focus on the shift from “normal” at baseline to “abnormal”
post-baseline, without distinguishing between degrees of
abnormality.</p>
<p>Finally, to ensure comprehensive review, <strong>a listing
format</strong> is recommended for participants who <strong>lack
baseline values</strong> but have abnormal post-baseline results. This
ensures that potential safety signals are not overlooked due to missing
baseline data. The listing should include any abnormal post-baseline
values for such subjects.</p>
<p><img src="02_Plots/Visualization/LB/BOX_Raw.png" /></p>
<p><img src="02_Plots/Visualization/LB/BOX_CFB.png" /></p>
<p><img src="02_Plots/Visualization/LB/Scatter_Max_min.png" /></p>
<p><img src="02_Plots/Visualization/LB/Table_High_Low.png" /></p>
<p><img src="02_Plots/Visualization/LB/Listing.png" /></p>
</div>
<div id="integrated-summaries" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Integrated
Summaries</h2>
<p>In integrated summaries of laboratory data across multiple studies,
the recommended approach focuses on simplified and consolidated displays
to support cross-study safety evaluation. Unlike individual study
presentations, which emphasize time trends through box plots and line
plots, integrated summaries prioritize <strong>minimum and maximum
values</strong> observed during baseline and post-baseline periods. A
key display is <strong>Table 6.2</strong>, which summarizes these
extremes along with <strong>changes from baseline</strong>, providing
<strong>group-level statistics</strong> (mean, standard deviation) and
<strong>treatment comparison metrics</strong> adjusted for study effect
with 95% confidence intervals. Changes are typically used as the modeled
outcome, but minimum or maximum post-baseline values can also serve as
alternatives. Related analytes are grouped to assist clinical review.
While box plots could be used in integrated summaries when visit
schedules are consistent across studies, the recommendation is to rely
on <strong>summary tables</strong> instead, as integrated box plots may
obscure study-specific patterns and offer limited added value beyond
individual study plots.</p>
<p>For <strong>shift analyses</strong>, the updated guidance proposes a
single <strong>summary table (Table 6.3)</strong> that captures shifts
from low/normal to high and from high/normal to low for all lab analytes
in one consolidated format, replacing the prior approach that separated
analytes by category (e.g., metabolic, renal) and included multiple sets
of box plots and scatter plots. The rationale is to avoid redundancy and
potential confusion introduced by pooled scatter plots, which may
conflate diverse study-level effects. Instead, the emphasis is on the
summary table’s ability to clearly highlight group-level imbalances.</p>
<p>For <strong>qualitative lab measures</strong> (e.g., normal/abnormal,
or ordinal values like “+”, “++”, etc.), a similar table format is
recommended. Here, only the shift from <strong>baseline normal to
post-baseline abnormal</strong> is evaluated, aligning with previous
recommendations. Finally, integrated summaries are intended to
<strong>complement</strong>, not duplicate, the individual study
displays—by combining time-based visuals at the study level with concise
summary statistics at the integrated level, reviewers are provided a
balanced and efficient safety assessment framework.</p>
<p><img src="02_Plots/Visualization/LB/Table_Summary.png" /></p>
<p><img src="02_Plots/Visualization/LB/Table_Shift.png" /></p>
</div>
</div>
<div id="referencwe" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Referencwe</h1>
<p>PHUSE. (2017). Analyses &amp; Displays Associated with Adverse
Events: Focus on Adverse Events in Phase 2–4 Clinical Trials and
Integrated Summary [White paper]. PhRMA. Available as: Analyses and
Displays Associated with Adverse Events Focus on Adverse Events in Phase
2-4 Clinical Trials and Integrated Summary.pdf</p>
<p>PHUSE. (2015). Analyses &amp; Displays Associated with Outliers or
Shifts from Normal to Abnormal: Focus on Vital Signs, Electrocardiogram
&amp; Laboratory Analyte Measurements in Phase 2–4 Clinical Trials and
Integrated Summary [White paper]. PhRMA. Available as: Analyses &amp;
Displays Associated with Outliers or Shifts from Normal To Abnormal
Focus on Vital Signes &amp; Electrocardiogram &amp; Laboratory Analyte
Measurements in Phase 2-4 Clinical Trials and Integrated Summary.pdf</p>
<p>PHUSE. (2013). Analyses &amp; Displays Associated with Measures of
Central Tendency - Focus on Vital Sign, Electrocardiogram, &amp;
Laboratory Analyte Measurements in Phase 2-4 Clinical Trials &amp;
Integrated Submission Documents. [serial online]. Available from: <a
href="https://phuse.s3.eu-central-1.amazonaws.com/Deliverables/Standard+Analyses+and+Code+Sharing/Analyses+%26+Displays+Associated+with+Measures+of+Central+Tendency-+Focus+on+Vital+Sign,+Electrocardiogram+%26+Laboratory+Analyte+Measurements+in-"
class="uri">https://phuse.s3.eu-central-1.amazonaws.com/Deliverables/Standard+Analyses+and+Code+Sharing/Analyses+%26+Displays+Associated+with+Measures+of+Central+Tendency-+Focus+on+Vital+Sign,+Electrocardiogram+%26+Laboratory+Analyte+Measurements+in-</a>
+Phase+2-4+Clinical+Trials+and+Integrated+Submissions.pdf</p>
<p>PHUSE (2015). Analyses and Displays Associated with Outliers or
Shifts from Normal to Abnormal: Focus on Vital Signs, Electrocardiogram,
and Laboratory Analyte Measurements in Phase 2-4 Clinical Trials and
Integrated Summary Documents. [serial online]. Available from: <a
href="https://phuse.s3.eu-central-1.amazonaws.com/Deliverables/Standard+Analyses+and+Code+Sharing/Analyses+%26+Displays+Associated+with+Outliers+or+Shifts+from+Normal+To+Abnormal+Focus+on+Vital+Signes+%26+Electrocardiogram+%26+Laboratory+Analyte+Measurements+in+Phase+2-4+Clinical+Trials+and+Integrated+Summary.pdf"
class="uri">https://phuse.s3.eu-central-1.amazonaws.com/Deliverables/Standard+Analyses+and+Code+Sharing/Analyses+%26+Displays+Associated+with+Outliers+or+Shifts+from+Normal+To+Abnormal+Focus+on+Vital+Signes+%26+Electrocardiogram+%26+Laboratory+Analyte+Measurements+in+Phase+2-4+Clinical+Trials+and+Integrated+Summary.pdf</a></p>
<div id="exposure-adjusted-incidence-rates-eairs-1"
class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Exposure-Adjusted
Incidence Rates (EAIRs)</h2>
<p>Crowe B, Chang-Stein C, Lettis S, Brueckner A. Reporting Adverse Drug
Reactions in Product Labels. Therapeutic Innovation &amp; Regulatory
Science, 2016; 50(4):455-463</p>
<p>Fay MP, Feuer EJ. Confidence intervals for directly standardized
rates: A method based on the gamma distribution. Statistics in Medicine
1997; 16(7):791-801</p>
<p>Kraemer HC. Events per person-time (incidence rate): A misleading
statistic. Statistics in Medicine, 2009; 28:1028–1039</p>
<p>Rücker G, Schumacher M. Simpson’s paradox visualized: The example of
the Rosiglitazone meta-analysis. BMC Medical Research Methodology 2008;
8(34):18-20</p>
<p>Ulm K., A simple method to calculate the confidence interval of a
standardized mortality ratio. American Journal of Epidemiology, 1990;
131(12):373-375</p>
<p>Zhou Y, Ke C, Jiang Q, Shahin S, Snapinn S. Choosing Appropriate
Metrics to Evaluate Adverse Events in Safety Evaluation. Therapeutic
Innovation &amp; Regulatory Science, 2015; 49(3):398-404</p>
<p>R Core Team (2023). <em>R: A Language and Environment for Statistical
Computing</em>. R Foundation for Statistical Computing, Vienna, Austria.
<a href="https://www.R-project.org/"
class="uri">https://www.R-project.org/</a></p>
<p>H. Wickham (2016). ggplot2: Elegant Graphics for Data Analysis.
Springer-Verlag New York. <a href="https://ggplot2.tidyverse.org"
class="uri">https://ggplot2.tidyverse.org</a></p>
<p>Zhu J, Sabanés Bové D, Stoilova J, Garolini D, de la Rua E,
Yogasekaram A, Wang H, Collin F, Waddell A, Rucki P, Liao C, Li J
(2024). <em>tern: Create Common TLGs Used in Clinical Trials</em>. R
package version 0.9.6. <a href="https://CRAN.R-project.org/package=tern"
class="uri">https://CRAN.R-project.org/package=tern</a></p>
</div>
<div id="door" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> DOOR</h2>
<p>Toshimitsu Hamasaki, Daniel Rubin and Scott. R Evans. DISS short
course(2024):The DOOR is Open-Pragmatic Benefit:Risk Evaluation Using
Outcomes to Analyze Patients Rather than Patients to Analyze
Outcomes​</p>
<p>Evans, S. R., Follmann, D., &amp; Powers, J. H. (2015).”Desirability
of outcome ranking (DOOR) and response adjusted for duration of
antibiotic risk (RADAR).”Clinical Infectious Diseases, 61(5),
800-806.DOI: 10.1093/cid/civ495​</p>
<p>Beigel, J. H., Tomashek, K. M., Dodd, L. E., Mehta, A. K., Zingman,
B. S., Kalil, A. C., … &amp; ACTT-1 Study Group Members. (2020).
Remdesivir for the treatment of Covid-19 — Final report. The New England
Journal of Medicine, 383(19), 1813–1826. <a
href="https://doi.org/10.1056/NEJMoa2007764"
class="uri">https://doi.org/10.1056/NEJMoa2007764</a>​</p>
<p><a
href="https://arlg.org/desirability-of-outcome-ranking-door/">Desirability
of Outcome Ranking (DOOR) | ARLG</a></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
