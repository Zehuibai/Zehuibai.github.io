---
title: |
  ![](logo.png){width=3in}  
  Bayesian Theory
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_float: yes
  word_document:
    toc: yes
fontsize: 10pt
editor_options:
  chunk_output_type: console
colorlinks: yes
---
 
```{r setup, include=FALSE, echo = FALSE,message = FALSE, error = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)

# <!-- ---------------------------------------------------------------------- -->
# <!--                    1. load the required packages                       -->
# <!-- ---------------------------------------------------------------------- --> 

## if(!require(psych)){install.packages("psych")}
packages<-c("tidyverse", "kableExtra", "gtsummary","inTextSummaryTable",
            "Hmisc","htmltools","clinUtils",
            "bayess")
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}
ipak(packages)
 

# <!-- ---------------------------------------------------------------------- -->
# <!--                        2. Basic system settings                        -->
# <!-- ---------------------------------------------------------------------- -->
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
getwd()
Sys.setlocale("LC_ALL","English")
```

 

# Introduction

## Frequency and Bayesian

- In the realm of statistics, two main schools of thought offer distinct approaches to understanding and interpreting data: the frequency school and the Bayesian school.
- The frequency school posits that overall parameters are fixed and that samples are acquired randomly. This perspective views each random sample as an imperfect representation of an ideal entity. By applying methods like maximum likelihood estimation, the frequency school aims to infer the most probable parameters that could result in the observed samples.
- Contrarily, the Bayesian school considers overall parameters as random variables, while the samples obtained are seen as fixed. Bayesians are less concerned with pinpointing the exact parameters; instead, they focus on updating beliefs about these parameters. They utilize prior knowledge combined with newly acquired data to compute the posterior probability distribution, facilitating statistical inference through this updated belief system.


**Bayesian Inference: Priors, Posteriors, and Predictive Analysis**

- Prior probability distributions represent our beliefs about hypotheses before we analyze any data. These priors are foundational in Bayesian inference, which updates these beliefs to posterior probabilities upon receiving new data.
- The posterior probability distribution, denoted as $$\mathrm{P}(\theta | \text{data})$$, is a cornerstone of Bayesian reasoning. This distribution encapsulates our uncertainty about parameter values. A narrower distribution suggests higher confidence in our estimates of these values. By gathering more data, we can achieve more precise posterior distributions.
- Moreover, the posterior distribution is instrumental in forecasting future outcomes of experiments and testing models. It allows statisticians to make informed predictions and validate hypotheses effectively.


## Bayesian and Classical Methods

Bayesian analysis has several advantages over classical analysis in the context of clinical trials. These include the ability to incorporate prior information about treatment efficacies into the analysis, the flexibility to make multiple unscheduled inspections of accumulating data without increasing the error rate, and the capability to calculate the probability that one treatment is more effective than another.

In contrast to classical methods, Bayesian analysis is conditional on the observed data and focuses on the probability that a conclusion or hypothesis is true given the available data. Classical inference, however, is not conditional on the observed data but instead concerns the behavior of a statistical procedure over an infinite number of repetitions, considering all potential data that might have been observed under a hypothesis. Bayesians deal with the probabilities of hypotheses given a dataset, whereas frequentists concern themselves with the probabilities of datasets given a hypothesis.


**1. Overview of Bayesian and Classical Analysis**

- **Bayesian Analysis:**
  - **Incorporates Prior Information:** Utilizes existing knowledge about treatment effects, enhancing analytical precision.
  - **Flexible Data Inspection:** Allows multiple reviews of ongoing data without affecting the error rates, promoting adaptive research approaches.
  - **Probabilistic Outcomes:** Computes the likelihood of one treatment outperforming another, providing direct answers to clinical questions.

- **Classical Analysis:**
  - **Fixed Procedure:** Relies on a set framework involving hypothesis testing with less adaptability in procedure once the analysis begins.
  - **Repetition-Based:** Focuses on long-term behavior over many hypothetical repeats of the study, which can disconnect results from the practical needs of clinicians.

**2. Methodological Contrasts**

- **Conditional vs. Unconditional Frameworks:**
  - **Bayesian:** Analysis is conditional on the data observed, directly tying conclusions to the evidence at hand.
  - **Classical:** Operates independent of the specific data set, which can lead to less direct applicability to the individual study results.

- **Hypothesis Testing Approach:**
  - **Bayesian:** Engages directly with the probability of hypotheses given the data, making it inherently responsive to new information.
  - **Classical:** Concentrates on the probability of data given predefined hypotheses, often leading to rigid interpretations.

**3. Limitations in Classical Hypothesis Testing**

- **Inflexibility in Hypothesis Evaluation:** Classical methods typically commit to the first plausible alternative hypothesis upon rejecting the null, without thorough consideration of other viable hypotheses.
- **Impact of Data Peeking:** Interim data reviews can affect the study's error rates under classical approaches, a scenario not adequately addressed in traditional frameworks.

**4. Advantages of Bayesian Methodology**

- **Utilization of Bayes' Theorem:** Allows for calculating the true probability of a hypothesis based on both prior knowledge and new data.
- **Integration of Prior Beliefs:** Bayesian methods can quantitatively incorporate uncertainties about prior information, adjusting the analysis to reflect varying degrees of prior reliability.
- **Flexibility in Clinical Trials:** Does not require preset patient numbers or analysis timings, adapting more naturally to the dynamics of trial execution.

**5. Implementation and Impact**

- **Defining Prior Knowledge:** Establishing the initial probability distributions based on literature, expert opinions, and preliminary studies to guide the analysis.
- **Data Acquisition and Adjustment:** Continuous updating of prior estimates with incoming trial data to refine the posterior estimates.
- **Posterior Analysis:** Results in detailed probability distributions that offer nuanced insights into treatment efficacy, enhancing decision-making with probabilistic ranges for treatment effects.


## Bayes' Theorem

Bayes' theorem can be expressed mathematically in the context of Bayesian inference as:

\[
\overbrace{p(\theta/D)}^{\text{Posterior}} = \frac{\overbrace{p(D/\theta)}^{\text{Likelihood}} \cdot \overbrace{p(\theta)}^{\text{Prior}}}{\underbrace{p(D)}_{\text{Evidence}}}
\]

This equation is fundamental to Bayesian analysis and can be broken down into three critical components:

1. **Posterior Probability ( \( p(\theta/D) \) ):**
   - This is the probability of the hypothesis \( \theta \) given the data \( D \).
   - It is updated knowledge after considering new evidence.
   - It provides a measure of how plausible the hypothesis is in the light of the available data.

2. **Likelihood ( \( p(D/\theta) \) ):**
   - This is the probability of observing the data \( D \) given that the hypothesis \( \theta \) is true.
   - It assesses how probable the observed data are under different hypothetical conditions specified by \( \theta \).

3. **Prior Probability ( \( p(\theta) \) ):**
   - This is the probability of the hypothesis before observing the current data.
   - It incorporates existing knowledge or beliefs about the parameter before new data is taken into account.

4. **Evidence or Marginal Likelihood ( \( p(D) \) ):**
   - This is also known as the marginal probability of the observed data.
   - It is calculated by integrating or summing over all possible values of \( \theta \), essentially averaging the likelihoods weighted by the prior probabilities.
   - In practice, this acts as a normalizing constant to ensure the posterior probabilities sum to one.
   
### Prior Distribution {-}

The **Prior Distribution** in Bayesian statistics is a fundamental component that encapsulates our knowledge or beliefs about a parameter before we observe any data. It's an expression of our subjective or objective preconceptions about the values that a parameter, typically denoted as \( \theta \), might take based on previous experience, existing knowledge, or expert opinion.

**Characteristics of Prior Distributions**

1. **Subjective or Objective**:
   - **Subjective Priors**: These are based on personal beliefs or expert opinions and are particularly useful when historical data is sparse or when new phenomena are being studied. Subjective priors can incorporate insights from experts, results from previous studies that are not strictly comparable, or institutional knowledge.
   - **Objective Priors**: These are formulated to minimize the influence of the prior, aiming to let the data speak for themselves. Objective priors include non-informative priors, which are designed to have minimal impact on the posterior outcomes. Examples include Jeffreys’ prior and uniform distributions in certain contexts.

2. **Informative vs. Non-Informative**:
   - **Informative Priors**: These contain specific information about a parameter. For instance, if previous studies suggest that a parameter is likely centered around a particular value with some variance, the prior distribution can be centered at this value with a spread reflecting this variance.
   - **Non-Informative Priors**: These are used when no substantial prior knowledge about a parameter is available or when it is desirable to not let prior assumptions heavily influence the results. They are often broad and flat, indicating equal probability across a wide range of parameter values, thereby allowing the data to have a stronger influence on the posterior distribution.

**Role of Prior Distribution in Bayesian Analysis**

- **Initial Belief Modeling**: The prior distribution models the initial belief about the parameter before new data is taken into account.
- **Updating Beliefs**: In Bayesian inference, the prior distribution is updated with the likelihood of observing the new data given possible parameter values, resulting in the posterior distribution. This process is governed by Bayes' theorem:
  \[
  \text{Posterior} \propto \text{Likelihood} \times \text{Prior}
  \]
- **Impact on Posterior**: The strength and nature of the prior can significantly affect the posterior, especially when the amount of data is small. With more data, the influence of the prior generally diminishes, particularly if the prior is non-informative.


### Likelihood Function {-}

Bayesian inference updates the prior probability distribution based on newly acquired data. According to Bayes' theorem, the posterior distribution \( p(\theta| x) \) is proportional to the product of the likelihood \( p(x | \theta) \) and the prior distribution \( p(\theta) \), expressed as:

\[ p(\theta|x) \propto p(x|\theta)p(\theta) \]

The integral of the likelihood function over the prior distribution, normalized by the probability of the data \( p(x) \), provides the marginal likelihood:

\[ p(x) = \int p(x|\theta)p(\theta) d\theta \]

This marginal likelihood \( p(x) \) serves as the normalizing constant for the posterior distribution:

\[ p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)} \]

Bayesian inference effectively incorporates nuisance parameters by integrating them out of the joint posterior to provide a marginal posterior distribution \( p(\theta_1 | x) \), which is calculated by integrating over the nuisance parameter \( \theta_2 \):

\[ p(\theta_1 | x) = \int p(\theta_1, \theta_2 | x) p(\theta_2 | d\theta_2) \]


### Posterior Distribution {-}


1. **Bayesian Update**:
   - Bayesian analysis modifies the likelihood by incorporating a prior belief about the parameters, \(\pi(\theta)\), leading to the posterior distribution.
   - The posterior distribution is calculated using Bayes' theorem:
     \[
     \pi(\theta \mid \mathscr{D}_{n}) = \frac{\ell(\theta \mid \mathscr{D}_{n}) \pi(\theta)}{\int \ell(\theta \mid \mathscr{D}_{n}) \pi(\theta) \, d \theta}
     \]
   - This results in a probability distribution over the parameter space \(\Theta\), reflecting updated beliefs after considering the observed data.

2. **Choosing the Prior**:
   - The selection of the prior, \(\pi(\theta)\), is crucial as it represents the initial beliefs about the parameters before observing any data.
   - The prior needs to be chosen carefully to reflect prior knowledge or assumptions about the parameters.
   
The predictive distribution in Bayesian inference uses the posterior distribution to make predictions about future data. This approach is inherently probabilistic, reflecting the uncertainty inherent in the data and the model parameters. Key elements of Bayesian prediction include:

1. **Predictive Mean:**
   - The expected value of the prediction \( E(y) \) is computed as the integral of the potential outcomes weighted by their probabilities, calculated over the posterior distribution.
   - Formula: \( E(y) = \int \theta p(\theta | x) d\theta \)

2. **Mode of the Predictive Distribution:**
   - Represents the most probable value of the prediction, identified by the maximum of the posterior distribution.
   - Formula: \( \text{Mode} = \arg\max_{\theta} p(\theta | x) \)

3. **Predictive Distribution:**
   - The predictive distribution provides a complete probabilistic description of the possible future values, integrating over all uncertainties.
   - It summarizes not just a single value but the likelihood of all possible future outcomes.
   



## Credible Intervals

1. **Bayesian Inferential Approach**:
   - The Bayesian approach is comprehensive, encompassing confidence evaluation, hypothesis testing, prediction, model checking, and point estimation.
   - It treats parameters as random variables and derives inferential statistics based on the posterior distribution \( \pi(\theta \mid \mathscr{D}_{n}) \).

2. **Definition of Credible Intervals**:
   - In Bayesian statistics, what traditional statistics call a confidence interval is referred to as a "credible interval."
   - A credible interval for a parameter \(\theta\) based on data \(\mathscr{D}_{n}\) is defined as a set \( C(\mathscr{D}_{n}) \) such that:
     \[
     \pi(\theta \in C(\mathscr{D}_{n}) \mid \mathscr{D}_{n}) = 1 - \alpha
     \]
     Here, \( \alpha \) is the significance level (e.g., 0.05), indicating that the interval contains the parameter with probability \( 1-\alpha \).

3. **Integration over Parameter Space**:
   - Unlike classical methods that integrate over the observation space to compute confidence intervals, Bayesian methods integrate over the parameter space.
   - This means that \( 1-\alpha \) represents the probability that the random variable \(\theta\) falls within the interval \( C(\mathscr{D}_{n}) \), rather than the probability that a random interval contains the true parameter value.

4. **Highest Posterior Density (HPD) Region**:
   - The HPD region is a type of Bayesian credible interval which contains the values of \(\theta\) with the highest posterior densities.
   - It is defined as:
     \[
     C(\mathscr{D}_{n}) = \{\theta : \pi(\theta \mid \mathscr{D}_{n}) \geq k_{\alpha}\}
     \]
     where \( k_{\alpha} \) is determined so that the probability content of the HPD region is exactly \( 1-\alpha \).
     
### Highest Density Region (HDR)

1. **Definition of HDR**:
   - The Highest Density Region (HDR) for a given posterior distribution \( p(\theta | \text{data}) \) at a probability level \( 1-\alpha \) is defined as the subset of the parameter space where the density of \( \theta \) is highest.
   - Mathematically, it is defined as:
     \[
     \{\theta : p(\theta | \text{data}) \geq k(\alpha)\}
     \]
     where \( k(\alpha) \) is the largest constant such that the probability mass of this region is \( 1-\alpha \):
     \[
     \int_{\{\theta: p(\theta | \text{data}) \geq k(\alpha)\}} p(\theta | \text{data}) d\theta = 1 - \alpha
     \]

2. **Interpretation and Importance**:
   - The HDR contains the most probable values of \( \theta \) under the posterior distribution.
   - It is used to specify the region in the parameter space where the true parameter value is most likely to lie, given the observed data.

3. **Calculation of HDR**:
   - To determine the HDR, identify the level \( k(\alpha) \) such that the integral of the posterior distribution over the region where \( p(\theta | \text{data}) \geq k(\alpha) \) equals \( 1-\alpha \).
   - This requires solving for \( k(\alpha) \) in a way that balances between covering the highest density of the distribution and ensuring that the total probability of the region is exactly \( 1-\alpha \).

4. **Practical Implications of HDR**
   - **Confidence in Estimates**: The HDR provides a way to understand the uncertainty and variability of parameter estimates. It can be considered as a Bayesian analogue to confidence intervals in frequentist statistics.
   - **Decision Making**: In practical applications, such as in policy settings or scientific research, identifying the HDR helps in making decisions based on the most probable parameter values.
   - **Comparative Analysis**: Comparing HDRs from different posterior distributions can provide insights into how different prior beliefs or data sets influence the inferences about the parameters.
   

### Key Differences from Classical Confidence Intervals

- **Probability Interpretation**:
  - In Bayesian analysis, the probability \( 1-\alpha \) directly quantifies our belief about the parameter’s location based on the data and prior information.
  - In classical statistics, \( 1-\alpha \) indicates how often the true parameter will be captured by the interval over repeated sampling from the population.

- **Simplicity of Construction**:
  - Determining the best credible interval in Bayesian terms is typically simpler than constructing classical confidence intervals because it directly targets the areas of highest probability density without regard to potential sampling variability.
  

## Hypothesis Testing

In Bayesian hypothesis testing, the likelihood of two competing hypotheses \(H_0\) and \(H_1\) (for example, \(H_0: \theta = 0\) and \(H_1: \theta = 1\)) is evaluated based on the data, taking into account prior beliefs about these hypotheses.

**Bayes Factors**:
   - The Bayes factor (BF) is a crucial metric in Bayesian hypothesis testing. It is used to provide a quantifiable measure of support for one hypothesis over another, based on the observed data.

1. **Calculation of Bayes Factors**:

   - For two hypotheses \(H_0\) and \(H_1\), Bayes factors are calculated as follows:
     \[
     B_1 = \frac{p(\theta = 1 | \text{data})}{p(\theta = 0 | \text{data})} = \frac{p(\text{data} | \theta = 1) \cdot p(\theta = 1)}{p(\text{data} | \theta = 0) \cdot p(\theta = 0)}
     \]
     \[
     B_0 = \frac{p(\theta = 0 | \text{data})}{p(\theta = 1 | \text{data})} = \frac{p(\text{data} | \theta = 0) \cdot p(\theta = 0)}{p(\text{data} | \theta = 1) \cdot p(\theta = 1)}
     \]
   - Here, \(p(\text{data} | \theta = i)\) is the likelihood of the data under hypothesis \(i\), and \(p(\theta = i)\) is the prior probability of hypothesis \(i\).

2. **Interpretation of Bayes Factors**:

   - A Bayes factor \(B_1\) greater than 1 indicates stronger support for \(H_1\) relative to \(H_0\), while a \(B_1\) less than 1 supports \(H_0\) more.
   - \(B_0\) is the reciprocal of \(B_1\) and interprets support in the opposite direction.
   
  
## P-values and Bayes factors 

P-values and Bayes factors  are two approaches for hypothesis testing and assessing evidence, but they represent fundamentally different statistical paradigms. Here's a comparison and detailed explanation:


**P-Values (Frequentist Paradigm)**

A **P-value** is a frequentist measure used to test a null hypothesis (\(H_0\)):

1. **Definition:**
   - The probability of observing data as extreme as, or more extreme than, the observed data, assuming \(H_0\) is true.
   - It does not give the probability that \(H_0\) is true.

2. **Purpose:**
   - To assess whether the evidence is inconsistent with \(H_0\).

3. **Interpretation:**
   - A small \(P\)-value (e.g., \(P < 0.05\)) suggests evidence against \(H_0\), but it does not confirm \(H_1\) (the alternative hypothesis).
   - A large \(P\)-value suggests insufficient evidence to reject \(H_0\), not that \(H_0\) is true.

4. **Limitations:**
   - Dependence on sample size: Large datasets may produce small \(P\)-values even for trivial effects.
   - Misinterpretation: Often misunderstood as the probability of \(H_0\) being true or false.

5. **P-Value Example**
- \(H_0\): A new drug has no effect (\(\mu = 0\)).
- A test yields \(P = 0.03\).
  - Interpretation: There is a 3% probability of observing data as extreme as the observed, assuming \(H_0\) is true.
  - Action: Reject \(H_0\) at the 5% significance level.
  

**Bayes Factors (Bayesian Paradigm)**

A **Bayes factor (BF)** is a Bayesian measure of evidence that compares two hypotheses, \(H_0\) (null) and \(H_1\) (alternative):

1. **Definition:**
   - The ratio of the likelihood of the observed data under two competing hypotheses:
     \[
     BF = \frac{P(\text{Data} | H_1)}{P(\text{Data} | H_0)}
     \]

2. **Purpose:**
   - To quantify how much more (or less) the data supports \(H_1\) compared to \(H_0\).

3. **Interpretation:**
   - \(BF > 1\): Evidence in favor of \(H_1\).
   - \(BF < 1\): Evidence in favor of \(H_0\).
   - \(BF = 1\): Data equally supports both hypotheses.

4. **Bayes Factor Scale (Jeffreys’ interpretation):**

   | **Bayes Factor (BF)** | **Evidence Strength**         |
   |------------------------|-------------------------------|
   | \(1\)                 | No evidence                  |
   | \(1 - 3\)             | Weak evidence for \(H_1\)    |
   | \(3 - 10\)            | Moderate evidence for \(H_1\)|
   | \(> 10\)              | Strong evidence for \(H_1\)  |

5. **Advantages:**
   - Accounts for prior beliefs (\(P(H_0)\), \(P(H_1)\)).
   - Allows direct comparison of evidence for both hypotheses.
   - Works well with small sample sizes or complex models.


6. **Bayes Factor Example**
- Same \(H_0\): New drug has no effect.
- Bayes Factor \(BF = 5\):
  - Interpretation: The data are 5 times more likely under \(H_1\) (the drug has an effect) than \(H_0\).
  - Action: Strong evidence in favor of \(H_1\).


**Comparison: P-Values vs. Bayes Factors**

| **Aspect**                | **P-Values**                                   | **Bayes Factors**                                |
|---------------------------|-----------------------------------------------|------------------------------------------------|
| **Paradigm**              | Frequentist                                   | Bayesian                                       |
| **Key Concept**           | Probability of data given \(H_0\).            | Likelihood ratio of data under \(H_1\) and \(H_0\). |
| **Prior Knowledge**       | Not considered.                               | Incorporates prior beliefs.                   |
| **Output**                | Single probability value.                     | A ratio quantifying evidence.                 |
| **Hypotheses Comparison** | Only tests against \(H_0\).                   | Direct comparison of \(H_0\) and \(H_1\).     |
| **Effect of Sample Size** | Large sample size can lead to small \(P\)-values even for trivial effects. | Directly incorporates data strength.          |
| **Interpretation**        | Often misinterpreted as evidence for \(H_1\). | Provides explicit evidence for one hypothesis over another. |

 
  
   
## Parameter Estimates

To determine a data's probability density distribution accurately, two main components are essential:

1. **Form of the Probability Density Function (PDF)**:

   - Sometimes, the form of the PDF is known (e.g., Gaussian, Rayleigh) but the specific parameters (like mean or variance) are unknown. This scenario requires parameter estimation based on observed data.

2. **Parameters of the PDF**:

   - Other times, the type of probability density may not be known, but some estimated parameters (like mean and variance) are available. This information can guide the selection of an appropriate PDF.

In statistical modeling, estimating unknown parameters is a common task:

- **In basic models like linear regression**, the objective is often to calculate a specific parameter vector, **W**.
- **In Bayesian models**, instead of calculating a point estimate of **W**, the focus shifts to determining the distribution of **W**. This distribution is then used to predict outcomes (e.g., **p(y|x, D)**), incorporating all possible values of **W**.
 
Bayesian models are complex because they consider a distribution of parameter values rather than a single point estimate. This complexity often necessitates sophisticated computational techniques:

- **Markov Chain Monte Carlo (MCMC)**: This technique is used instead of direct optimization methods to integrate over possible parameter values (all possible **W** vectors) effectively.

As more data is observed, Bayesian models provide clearer inference about the distribution of parameters, known as **posterior inference**. This approach contrasts with other predictive strategies:

1. **Maximum Likelihood Estimation (MLE)**:

   - This is a point estimation method that finds the parameter values which maximize the likelihood of observing the given data. It does not consider prior knowledge about parameter values.

2. **Maximum a Posteriori (MAP)**:

   - Also a point estimation method, MAP considers both the likelihood of the observed data and a prior distribution of the parameters. It calculates the mode of the posterior distribution.

3. **Bayesian Model**:

   - This method estimates the distribution of parameters rather than a single point. It provides a full probabilistic description of parameter uncertainty, making it more robust against overfitting and more informative for decision-making.

**Comparison and Applications**   

- **MLE** is often simpler and computationally faster but can be biased if the model assumptions are incorrect.
- **MAP** incorporates prior beliefs into the estimation process, providing regularization that can lead to more robust estimates in the presence of limited data.
- **Bayesian Models** are the most comprehensive, considering a range of possible parameter values. This approach is particularly beneficial in complex systems where the uncertainty in model parameters needs to be quantified and propagated through to predictions.

### a. Maximum Likelihood Estimation (MLE) {-}

**1. Concept of MLE:**

   - MLE is a method used to determine the parameters of a statistical model that make the observed data most probable. The goal is to find the parameter values that maximize the likelihood function, which represents the probability of the observed data given those parameter values.

**2. Assumptions in MLE:**

   - **Homogeneity**: Assumes that subsets of data from different categories (such as different classes or groups) share the same type of probability density function but differ in parameter values.
   - **Independence between Categories**: Assumes that data in one category are independently sampled from those in another, meaning the parameter estimation for one category doesn't affect another.
   - **Statistical Independence within Categories**: Assumes that samples within each category are independently and identically distributed (iid).

**3. Formulation:**

   - Given a random sample \( x_1, x_2, \ldots, x_N \) from a probability density function \( p(x;\theta) \), the joint probability density function of the sample is given by:
     \[
     p(X;\theta) = \prod_{k=1}^N p(x_k;\theta)
     \]
   - The MLE \( \hat{\theta}_{ML} \) is obtained by maximizing this product:
     \[
     \hat{\theta}_{ML} = \arg \max_{\theta} \prod_{k=1}^N p(x_k;\theta)
     \]
   - Typically, this optimization is performed on the log-likelihood function \( L(\theta) \) to simplify calculations:
     \[
     L(\theta) = \ln \prod_{k=1}^N p(x_k;\theta) = \sum_{k=1}^N \ln p(x_k;\theta)
     \]
     \[
     \frac{\partial L(\theta)}{\partial \theta} = \sum_{k=1}^N \frac{\partial \ln p(x_k;\theta)}{\partial \theta} = \sum_{k=1}^N \frac{1}{p(x_k;\theta)} \frac{\partial p(x_k;\theta)}{\partial \theta} = 0
     \]

**4. Properties of MLE:**

   - **Asymptotic Unbiasedness**: As the sample size \( N \) approaches infinity, the expected value of the MLE converges to the true parameter value \( \theta_0 \):
     \[
     \lim_{N \to \infty} E[\hat{\theta}_{ML}] = \theta_0
     \]
   - **Asymptotic Consistency**: As the sample size increases, the probability that the MLE differs from the true parameter value by more than any small positive number \( \epsilon \) approaches zero:
     \[
     \lim_{N \to \infty} \Pr\{ \|\hat{\theta}_{ML} - \theta_0\| \leq \epsilon \} = 1
     \]
     \[
     \lim_{N \to \infty} E\| \hat{\theta}_{ML} - \theta_0 \|^2 = 0
     \]
   - These properties ensure that the estimator is reliable as the amount of data increases.

**5. Limitations:**

   - MLE can be prone to overfitting when the dataset is small because it maximizes the probability of observing the data without considering model complexity or penalizing for it.

### b. Maximum a Posteriori Estimation (MAP) {-}

- **MLE** treats the parameter \( \theta \) as an unknown fixed value that needs to be estimated from the data.
- The goal of MLE is to find the value of \( \theta \) that maximizes the likelihood function \( p(X; \theta) \), which is the probability of observing the data given the parameter.

**MAP Concept and Methodology:**

- **MAP** considers the parameter \( \theta \) as a random variable with a prior distribution \( p(\theta) \), reflecting prior beliefs about the possible values of \( \theta \).
- Unlike MLE, MAP estimates \( \theta \) by maximizing the posterior distribution \( p(\theta | X) \) rather than just the likelihood:
  \[
  p(\theta|X) = \frac{p(\theta) p(X|\theta)}{p(X)}
  \]
- The MAP estimate \( \hat{\theta}_{MAP} \) is given by:
  \[
  \hat{\theta}_{MAP} = \arg \max_{\theta} p(\theta) p(X|\theta)
  \]
- In the optimization, the marginal likelihood \( p(X) \) does not affect the location of the maximum since it does not depend on \( \theta \).

**Differences:**

- **Prior Influence:** MLE does not incorporate a prior distribution, treating \( \theta \) as a fixed but unknown quantity. MAP, on the other hand, explicitly includes a prior distribution, which can significantly influence the estimate especially when the sample size is small or the prior is strong (informative).
- **Resulting Estimates:** For non-informative or flat priors, MAP results converge to MLE results. However, with informative priors, MAP can yield different estimates from MLE, depending on the strength and nature of the prior.
- As the sample size increases, the influence of the prior in MAP diminishes, aligning MAP estimates more closely with MLE estimates, reflecting the dominance of the data over the prior.


### c. Bayesian Model {-}
 
Bayesian modeling distinguishes itself by considering the entire distribution of the data \(X\) and the parameters \( \theta \) instead of just optimizing parameter values based on a given sample set \(X\). This approach naturally helps prevent overfitting by integrating over all possible parameter values rather than selecting a single optimal set.

1. **Sample Set and Parameters**:
   - The data sample set is denoted as \(D\) (previously \(X\)) to avoid notation confusion. Samples in \(D\) are assumed to be independently drawn from an unknown but fixed probability density function \(p(x)\).

2. **Bayesian Estimation Problem**:
   - The core problem in Bayesian estimation is to estimate the probability distribution \(p(x|D)\), making it as close as possible to the true distribution \(p(x)\). This involves calculating the distribution of \(x\) given the data \(D\), rather than finding a single optimized value for \(x\).

3. **Conditional Probability Density Function \(p(x|\theta)\)**:
   - \(p(x|\theta)\) is assumed to be known in form but with unknown parameters \( \theta \). It represents the likelihood estimation of \( \theta \) at the point \( x \).

4. **Prior and Posterior Distributions**:
   - **Prior Distribution \(p(\theta)\)**: Represents all prior knowledge about \( \theta \) before observing any data, expressed through a probability density function.
   - **Posterior Distribution \(p(\theta|D)\)**: Updated belief about \( \theta \) after observing the data \(D\). It is obtained by transforming the prior based on the new data:
     \[
     p(\theta|D) = \frac{p(D|\theta)p(\theta)}{\int p(D|\theta)p(\theta)d\theta}
     \]
     where \( p(D|\theta) = \prod_{k=1}^N p(x_k|\theta) \), assuming independence among the sampled data points.

5. **Bayesian Estimation Formula**:
   - The core Bayesian estimation problem \(p(x|D)\) is resolved using the integral over the joint distribution of \(x\) and \( \theta \):
     \[
     p(x|D) = \int p(x|\theta)p(\theta|D)d\theta
     \]
   - Here, \( p(x|\theta) \) is the likelihood of \( x \) under \( \theta \), and \( p(\theta|D) \) is the posterior distribution of \( \theta \) after observing \(D\).

**Advantages of Bayesian Modeling**

- **Comprehensive Parameter Estimation**: By integrating over all possible values of \( \theta \), Bayesian models provide a more holistic view of parameter uncertainty.
- **Prevention of Overfitting**: The use of prior distributions and the consideration of all possible parameter values help in regularizing the model, thus preventing overfitting.
- **Flexibility and Robustness**: Bayesian models are adaptable to new data, allowing continuous updating of beliefs about parameters as more data become available.





# Prior Distribution

1. **Selection of Priors**:
   - In Bayesian statistics, the choice of prior \( p(\theta) \) is crucial because it fundamentally influences the resulting posterior distribution \( p(\theta | \text{data}) \). Selecting a prior that reflects genuine knowledge or reasonable assumptions about \( \theta \) is important for ensuring that the posterior distribution is meaningful and accurate.
   - If the prior is too restrictive or if it does not align with the actual data characteristics, it can lead to misleading inferences, where the data cannot correct a poorly chosen prior.

2. **Precision of Prior Distributions**:
   - The text discusses the concept of the "precision" of prior distributions, indicating that a precise prior has a major impact on the determination of the posterior. A precise prior effectively means that the prior distribution is tightly concentrated, suggesting high confidence in the prior knowledge about \( \theta \).
   - The implication is that when the precision of the prior is high, the influence of the data on the posterior might be relatively diminished unless the data strongly contradicts the prior assumptions.

3. **Behavior of Improper Priors**:
   - Improper priors are those that do not integrate to one (e.g., priors that are uniform over an infinite range). These priors are sometimes used in Bayesian analysis due to their non-informative nature, allowing the data to play a more significant role in shaping the posterior.
   - The discussion notes that while improper priors can be useful, especially in the absence of strong prior knowledge, they must be handled with care. Improper priors can sometimes lead to undefined or ambiguous posterior distributions if not properly regularized or if the data does not sufficiently inform the posterior.
   
   
Determining the appropriate prior distribution in Bayesian statistics involves considering several options, each suited to different circumstances and amounts of prior knowledge.  

**1. Non-informative Priors**

Non-informative priors, also known as flat or objective priors, are used when there is no specific prior knowledge about the parameters. These priors are designed to exert minimal influence on the posterior distribution, allowing the data to speak for themselves. 

- **Purpose**: Ideal for situations where you want to remain as unbiased as possible or when prior knowledge is genuinely absent.
- **Examples**: Uniform distributions across the range of possible parameter values, Jeffreys’ prior which is invariant under reparameterization and often used for scale parameters.

**2. Conjugate Priors**
Conjugate priors are chosen because they simplify the computation of the posterior distribution. A prior is conjugate to the likelihood function if the posterior distribution belongs to the same family as the prior distribution. 

- **Benefits**: The use of conjugate priors transforms Bayesian updating into a matter of updating the parameters of the prior distribution based on the observed data, which can often be done analytically without complex numerical methods.
- **Examples**: The Beta distribution as a prior for the Binomial likelihood, or the Gamma distribution for the Exponential likelihood.

**3. Empirical Bayes Methods**

Empirical Bayes methods use the data to estimate the parameters of the prior distribution. This approach sits between fully Bayesian and frequentist methods, leveraging the strengths of both.

- **Process**: Start with an assumed form of the prior distribution, then use a portion of the data or external data to estimate the parameters of this prior.
- **Applications**: Useful in settings where some data are available that can inform the prior, but not enough to fully determine the posterior without additional data. This method is commonly used in hierarchical models and large-scale data analysis.

**4. Expert Elicitation Priors**

Priors derived from expert elicitation involve consulting subject-matter experts to quantify their beliefs about parameters before observing the current data. This method is particularly useful in fields where prior experimental or empirical data are sparse, but expert domain knowledge is rich.

- **Implementation**: Structured elicitation processes are used to translate expert knowledge into a quantifiable prior distribution. This might involve using tools like probability distribution fitting, where experts specify quantiles, means, variances, or other moments based on their understanding.
- **Challenges**: Requires careful consideration to avoid biases inherent in expert opinions and to accurately represent uncertainty in expert estimates.

## 1. Non-informative Priors

When engaging in Bayesian analysis without specific prior knowledge about the parameters in question, employing non-informative priors can be an effective strategy. These types of priors are designed to minimally influence the posterior outcomes, allowing the data itself to primarily drive the inferences. Here is a detailed description of two significant types of non-informative priors: **Jeffreys Prior** and **Reference Prior**.

### Jeffreys Prior {-}

**Background:**
Jeffreys Prior is named after Sir Harold Jeffreys, who introduced it in his work on Bayesian statistics. This prior is particularly noted for its property of invariance, meaning that it remains unchanged under transformation of parameters.

**Key Features:**

- **Invariance**: The form of Jeffreys prior does not change with the parameterization of the model. This property is crucial because it ensures that the prior behaves consistently across different parameterizations, avoiding biases that could arise from arbitrary choices of parameter scales or units.
- **Construction**: Jeffreys Prior is constructed using the square root of the determinant of the Fisher information matrix. The Fisher information quantifies the amount of information that an observable random variable carries about an unknown parameter upon which the likelihood depends.
  
**Formula:**
\[ p(\theta) \propto \sqrt{|I(\theta)|} \]
where \( I(\theta) \) is the Fisher information matrix for parameter \( \theta \).

**Applications and Limitations:**

- Jeffreys Prior is particularly useful for parameters that are naturally scale-invariant, such as variance and standard deviation.
- While it addresses the issue of uniform priors not translating uniformly over transformations of the parameters, Jeffreys Prior can sometimes lead to priors that are improper or do not integrate to one, particularly in complex models or multi-parameter settings.

### Reference Prior {-}

**Background:**

The concept of Reference Priors was developed to address some of the limitations encountered with Jeffreys Prior, especially in multivariate contexts where interactions between parameters can complicate the definition and application of non-informative priors.

**Key Features:**

- **Maximization of Information Divergence**: Reference priors are designed to maximize the Kullback-Leibler divergence between the prior and the posterior distributions under large sample conditions. This divergence measures the information gain provided by the data, relative to the prior.
- **Minimally Informative**: By maximizing the divergence, the reference prior aims to minimize its impact on the posterior, making the results as data-driven as possible. This feature makes it an ideal choice when seeking to minimize the influence of subjective assumptions on the analysis.

**Formula:**

While the specific form of a reference prior can depend on the model and the parameters, its derivation generally involves complex calculations aimed at maximizing the Kullback-Leibler divergence, which may not have a closed-form expression and often requires numerical methods to solve.

**Applications and Limitations:**

- Reference Priors are particularly useful in settings involving multiple parameters where interactions can complicate the analysis.
- They are also used in problems where the sample size is large, and the aim is to make inferences that are as objective as possible.

## 2. Conjugate Priors 
 
Conjugate priors are a type of prior that, when used with a particular likelihood function, results in a posterior distribution that is of the same family as the prior distribution. This property of conjugacy is particularly valuable because it simplifies the mathematical operations involved in Bayesian updates.

**Key Characteristics of Conjugate Priors:**

1. **Mathematical Simplicity**: Conjugate priors simplify the Bayesian updating process because the posterior distributions are analytically tractable. This means that one can derive explicit formulas for updating the parameters of the distribution, typically referred to as hyperparameters, based on the observed data.

2. **Parameterization**: In the context of conjugate priors, the prior distribution is often characterized by a few key parameters, known as hyperparameters. For example, in the case of a normal distribution used as a likelihood, the conjugate prior would also be normal, characterized by parameters like the mean and variance. These hyperparameters are updated to form the posterior based on the data.

For practical Bayesian analysis, conjugate priors are particularly prevalent in cases where the likelihood functions belong to the exponential family, such as:

- **Beta distribution** for binomial data,
- **Gamma distribution** for Poisson data,
- **Normal distribution** for normal data.

```{r echo =F, error=FALSE, message=FALSE, warning=FALSE, fig.cap="Conjugate priors for the most common statistical families"}
knitr::include_graphics("./02_Plots/Bayesian/Bayer_Conjugate.png")
```


**Advantages of Using Conjugate Priors:**

1. **Computational Efficiency**: The algebraic convenience of conjugate priors allows for straightforward updates of beliefs in light of new data. This efficiency is particularly advantageous in iterative processes or when dealing with large datasets.

2. **Theoretical Elegance**: The ability to maintain the same family of distributions before and after observing data offers a closed-form solution for the posterior, which can be elegantly described and understood.

3. **Ease of Interpretation**: Because the form of the distribution remains constant, the interpretation of the parameters (such as mean or variance in a normal distribution) remains intuitive and consistent throughout the Bayesian analysis.

**Drawbacks of Using Conjugate Priors:**

1. **Restrictive Assumptions**: The main limitation of conjugate priors is that they might force one to adopt specific distributional forms that may not be substantively justified. The need to maintain conjugacy can impose restrictions on the choice of the prior that might not align with the actual prior knowledge about the parameters.

2. **Limited Flexibility**: While the use of conjugate priors simplifies calculations, it also reduces flexibility in modeling. The specific structure required for conjugacy might not adequately capture the complexities or nuances of the prior beliefs or the data.

3. **Hyperparameter Sensitivity**: The process requires the selection of hyperparameters, which can significantly influence the posterior. Incorrect or suboptimal choices of these parameters can lead to biased or misleading results, especially if the prior information is insufficient or vague.


## 3. Empirical Bayes Priors

**Concept and Foundation of Empirical Bayes**

Empirical Bayes methods are based on the idea of using observed data to estimate the parameters of the prior distribution in a Bayesian setup. Unlike traditional Bayesian methods, which require the specification of a prior based purely on subjective belief or external information, Empirical Bayes uses an evidence-based approach to determine the prior. This hybrid method falls between the fully Bayesian approach (which relies entirely on subjective priors) and the purely frequentist approach (which does not incorporate prior information at all).

**How Empirical Bayes Methods Work** The process involves two main steps:

1. **Estimation of Prior Parameters**: First, the method uses the aggregate data to estimate the parameters of the prior distribution. This is typically done using maximum likelihood estimation or another suitable frequentist method. The goal here is to capture the common characteristics of the parameter across different observations or experiments.

2. **Bayesian Updating**: Once the prior parameters are estimated, each specific instance or data point is analyzed using Bayesian methods, where the empirically estimated prior is updated with the actual observed data to produce a posterior distribution.

**Key Features of Empirical Bayes**

- **Data-Driven Priors**: The priors are not fixed before seeing the data; instead, they are determined based on the data itself. This is particularly useful in scenarios where little is known about the system beforehand, or when subjective priors are hard to justify.

- **Reduction in Variance**: By borrowing strength from the entire dataset to form the prior, Empirical Bayes methods can reduce the variance of the estimates compared to purely frequentist approaches that treat each problem separately.

- **Computational Efficiency**: Empirical Bayes can be more computationally efficient than fully Bayesian methods since it avoids the need for complex prior specification and the intensive computations that can entail, especially with large datasets.


## 4. Expert Elicitation Priors

Expert elicitation priors are a method in Bayesian statistics where subjective judgments from experts are formally incorporated into the Bayesian framework as prior distributions. This approach is particularly useful in scenarios where empirical data is sparse, but expert knowledge is abundant and reliable.  

Expert elicitation involves systematically gathering opinions from one or more experts about uncertain quantities and then using these opinions to form prior distributions in Bayesian analysis. The experts provide their insights based on experience, existing research, and intuition, which are then quantified into a statistical format that can be directly used in the probabilistic models.

**Process of Developing Expert Elicitation Priors**

1. **Selection of Experts**: Careful selection of experts is crucial. Experts should have deep and relevant knowledge about the subject matter. Diversity in expertise can help capture a broad range of perspectives and reduce individual bias.

2. **Elicitation Technique**: Various techniques can be used to elicit quantitative data from experts, such as interviews, structured questionnaires, or interactive workshops. Techniques like the Delphi method, which involves multiple rounds of questioning with feedback, are commonly used to converge expert opinions towards a consensus.

3. **Quantification of Expert Opinions**: The elicited qualitative assessments are converted into quantitative measures. Experts might be asked to estimate parameters directly, provide percentiles for distributions, or express their confidence in different outcomes.

4. **Aggregation of Responses**: When multiple experts are involved, their responses need to be aggregated. This can be done through mathematical pooling of individual probability distributions or by using more sophisticated models that weigh expert opinions by their reliability or coherence with empirical data.

**Advantages of Using Expert Elicitation Priors**

- **Fills Data Gaps**: In cases where empirical data is not available or is incomplete, expert opinions can provide valuable insights that would otherwise be unattainable.
  
- **Improves Model Relevance**: By incorporating real-world knowledge, the models become more reflective of the actual phenomena being studied, enhancing the relevance and applicability of the statistical analyses.

- **Facilitates Complex Decision Making**: Expert elicitation is particularly beneficial in complex decision-making scenarios, such as policy formulation or risk assessment, where the stakes are high and the problems are too intricate to be captured fully by available data.


## Sensitivity Analysis and ‘Robust’ Priors

Sensitivity analysis in Bayesian statistics is a crucial step to evaluate how the conclusions of a model are affected by the assumptions made, particularly about the **prior distributions**. Unlike frequentist methods, Bayesian approaches inherently depend on prior assumptions, which makes it vital to test how robust the results are to variations in those priors. 

- **Definition:** Robust priors refer to a class of priors that lead to consistent and stable conclusions, even when varied within a reasonable range.
- **Key Idea:** Instead of committing to a single prior, the robust Bayesian approach explores a **community of priors** to determine how conclusions depend on prior assumptions.
- Sensitivity analysis is particularly useful in clinical trials, where stakeholders may have varying prior beliefs about the efficacy of an intervention.
  - Assessing how trial results support the superiority of a treatment under skeptical vs. optimistic prior assumptions.
  - Examining how conclusions change with different prior beliefs about the null hypothesis.
- **Complexity:** Conducting sensitivity analysis across a wide range of priors can be computationally intensive. A narrow or overly restricted sensitivity analysis may miss critical variations in prior assumptions.


**1. Purpose of Sensitivity Analysis in Bayesian Approaches**

- **Assess Dependence on Priors:** Bayesian results are influenced by prior distributions. Sensitivity analysis examines whether the conclusions would change significantly under different reasonable priors.
- **Address Subjectivity:** Priors are subjective by nature, reflecting beliefs or knowledge before observing data. Sensitivity analysis helps ensure that conclusions are not unduly dependent on a single prior choice.
- **Transparency:** Allows readers or stakeholders to judge how their own prior beliefs might influence the conclusions.

**2. Steps in a Robust Bayesian Sensitivity Analysis**

1. **Select a Flexible Class of Priors:**
   - Choose a broad range of plausible priors, including skeptical, optimistic, and neutral priors.
   - Ensure the priors reflect diverse perspectives (e.g., clinical expert opinions, data-driven priors, or "ignorance" priors).

2. **Examine Dependence on Prior Choices:**
   - Analyze how posterior conclusions (e.g., posterior probabilities, credible intervals) change as priors vary.
   - Identify regions where prior assumptions significantly alter conclusions.

3. **Identify Critical Priors:**
   - Determine which subsets of priors lead to specific posterior outcomes of interest, such as the superiority of a treatment.
   - Highlight priors that would be pivotal for decision-making.

4. **Report Results Transparently:**
   - Present findings clearly, allowing the audience to see how different priors affect conclusions.
   - Provide tools or visualizations (e.g., graphs of posterior probabilities vs. prior parameters) to facilitate interpretation.
   
   
**3. Types of Communities of Priors**

There are three main approaches to defining a community of priors:

**(a) Discrete Set of Priors:**

- Analyze sensitivity to a limited, predefined list of priors, such as:
  - **Skeptical prior:** Reflecting doubt about a treatment’s efficacy.
  - **Optimistic prior:** Assuming strong efficacy.
  - **Neutral prior:** Representing "ignorance" or minimal assumptions.
- Examples:
  - Sensitivity to the opinions of multiple experts.
  - Extreme prior scenarios that reflect opposing views.

**(b) Parametric Family of Priors:**

- Define a family of priors characterized by one or more parameters (e.g., a beta distribution with varying shape parameters).
- Plot posterior results as a function of these parameters to visualize sensitivity.
- Example:
  - Varying the weight of prior information (e.g., increasing skepticism or optimism) and observing the effect on posterior probabilities.

**(c) Non-Parametric Family of Priors:**

- Use flexible priors that are not constrained by a specific parametric form.
- Example:
  - Gustafson (1989): Introduced a "neighborhood" of priors around a non-informative prior, with some contamination from alternative priors.
- Tools like maximum and minimum posterior probabilities within the class can highlight the range of plausible conclusions.

# Distribution 

## Bernoulli Distribution 

This delve into the application of Bayesian statistics for Poisson-distributed data using a Gamma distribution as a conjugate prior. This scenario is commonly encountered in settings where the data consists of counts or events that follow a Poisson process, and the prior information about the event rate (λ, lambda) is modeled using a Gamma distribution. 
 
**Context and Setup**

- **Bernoulli Distribution**: This is used to model binary data, where each trial has two possible outcomes, typically represented as 0 or 1. In the context given, each trial (or observation) can result in success (1) or failure (0).
- **Beta Distribution for Prior**: The Beta distribution is commonly used as a prior in Bayesian analysis for binomial and Bernoulli distributions due to its conjugate properties. The Beta distribution is parameterized by two positive shape parameters, α (alpha) and β (beta), which represent prior knowledge about the probability of success in Bernoulli trials.

**Mathematical Formulation**

- The likelihood of observing a particular set of Bernoulli data given a probability of success θ is:
  \[
  p(X|\theta) = \theta^{\sum x_i} (1-\theta)^{n - \sum x_i}
  \]
  where \( \sum x_i \) is the total number of successes, and \( n \) is the total number of trials.
- The conjugate prior for θ in this scenario is a Beta distribution:
  \[
  p(\theta) \propto \theta^{\alpha - 1} (1-\theta)^{\beta - 1}
  \]
- The posterior distribution, after observing the data, remains a Beta distribution:
  \[
  p(\theta|X) = \text{Beta}(\alpha + \sum x_i, \beta + n - \sum x_i)
  \]
  This formula shows that the parameters of the Beta distribution are updated by adding the number of successes to α and the number of failures to β.


![](./02_Plots/Bayesian/Bayer_Distribution_Bernoulli.png)
 

**Statistical Inference**

- **Posterior Mean**: The expectation of the posterior distribution \( \theta|X \) can be estimated as:
  \[
  E[\theta|X] = \frac{\alpha + \sum x_i}{\alpha + \beta + n}
  \]
  This represents a weighted average between the prior belief and the observed data, where the influence of the prior diminishes as more data is collected.
- **Practical Example**: Suppose a prior belief models the probability of success as somewhat uncertain but leaning towards being less likely (e.g., \( \alpha = 2, \beta = 18 \)). After observing 15 successes out of 20 trials, the posterior parameters would be updated to \( \alpha' = 2+15 = 17 \) and \( \beta' = 18+5 = 23 \). The posterior distribution would then be Beta(17, 23).

 
## Poisson Distribution

This delve into the application of Bayesian statistics for Poisson-distributed data using a Gamma distribution as a conjugate prior. This scenario is commonly encountered in settings where the data consists of counts or events that follow a Poisson process, and the prior information about the event rate (λ, lambda) is modeled using a Gamma distribution.  

1. **Poisson Distribution**:
   - The Poisson distribution is used to model the probability of a given number of events happening in a fixed interval of time or space, given the average number of events (rate λ).
   - The likelihood function for observing data \( y = (y_1, y_2, \dots, y_n) \) under a Poisson model is:
     \[
     p(y|\lambda) = \prod_{i=1}^n \frac{\lambda^{y_i} e^{-\lambda}}{y_i!}
     \]

2. **Gamma Distribution as a Conjugate Prior**:
   - The Gamma distribution is a suitable choice as a conjugate prior for λ in Poisson models because it results in a posterior distribution that is also a Gamma, facilitating computational ease and analytical tractability.
   - The Gamma distribution is parameterized by a shape parameter (α, alpha) and a rate parameter (β, beta), with the probability density function given by:
     \[
     p(\lambda) = \frac{\beta^\alpha}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta \lambda}
     \]

3. **Posterior Distribution**:
   - By Bayes’ theorem, the posterior distribution of λ after observing data \( y \) combines the prior and the likelihood, yielding another Gamma distribution:
     \[
     p(\lambda|y) \propto p(y|\lambda) p(\lambda) = \text{Gamma}(\alpha + \sum y_i, \beta + n)
     \]
   - Here, \( \sum y_i \) is the sum of the observed counts, and \( n \) is the number of observations or trials.


![](./02_Plots/Bayesian/Bayer_Distribution_Poisson.png)

**Example Illustration**

- Suppose we have a set of counts over ten time periods, and we assume that these counts are Poisson-distributed with an unknown rate λ. Using a Gamma prior for λ with parameters α = 1 and β = 1, we incorporate the observed data to update these parameters.

- After observing the data, the posterior parameters become:
  - New alpha (α'): α + sum of observed counts
  - New beta (β'): β + number of observations

- If the observed counts sum to 77 over 10 periods, the posterior distribution for λ becomes:
  - Alpha: 1 + 77 = 78
  - Beta: 1 + 10 = 11
  - Resulting in a posterior distribution Gamma(78, 11).
  
## Normal Distribution

This provided delve into Bayesian inference for normally distributed data, employing conjugate priors. 

1. **Background and Setup:**
   - The data is assumed to follow a Normal distribution, \( N(\mu, \sigma^2) \), where both the mean (\( \mu \)) and variance (\( \sigma^2 \)) are unknown.
   - A common approach in Bayesian analysis is to assume conjugate priors for these parameters because conjugate priors simplify the computation of the posterior distributions.

2. **Conjugate Priors Used:**
   - For the mean \( \mu \), when \( \sigma^2 \) is known, the conjugate prior is a Normal distribution, \( N(\mu_0, \tau_0) \).
   - For the variance \( \sigma^2 \), the conjugate prior is an inverse-Gamma distribution, which ensures that the posterior distributions for \( \mu \) and \( \sigma^2 \) are tractable and remain within the family of Normal and inverse-Gamma distributions respectively.

3. **Mathematical Formulation:**
   - **Likelihood Function:** Given the data \( x = (x_1, x_2, ..., x_n) \), the likelihood for a normal model is:
     \[
     p(x | \mu, \sigma^2) \propto \sigma^{-n} \exp\left(-\frac{1}{2\sigma^2} \sum_{i=1}^n (x_i - \mu)^2\right)
     \]
   - **Posterior for Mean \( \mu \):** When \( \sigma^2 \) is known, the posterior distribution of \( \mu \) after observing data is also a Normal distribution:
     \[
     \mu | x, \sigma^2 \sim N\left(\frac{\tau_0 \mu_0 + n\bar{x}}{\tau_0 + n}, \frac{\sigma^2}{\tau_0 + n}\right)
     \]
     where \( \bar{x} \) is the sample mean.
   - **Posterior for Variance \( \sigma^2 \):** The posterior for \( \sigma^2 \) is an inverse-Gamma distribution, parameterized by updated shape and scale parameters derived from the data.

4. **Updating Process:**
   - Given the priors and the observed data, the parameters of the priors (\(\mu_0, \tau_0\) for the mean and shape and rate for the variance) are updated to reflect the new evidence provided by the data.
   - This Bayesian updating allows continuous learning as new data becomes available, adjusting the beliefs about the parameters based on cumulative evidence.

![](./02_Plots/Bayesian/Bayer_Distribution_Normal.png)


# Bayesian Inference Algorithm

## Maximum A Posteriori (MAP) Estimation

1. **Definition and Formula**:
   - MAP estimation is similar to MLE but incorporates a prior distribution on the parameters. It modifies the estimation process by not just considering the likelihood of the observed data but also how probable parameters are a priori.
   - The formula for MAP estimation is:
     \[
     \hat{\theta}_{MAP} = \arg \max_{\theta} p(\theta | x) = \arg \max_{\theta} \log \left( p(x | \theta) p(\theta) \right)
     \]
   - This can be expanded using Bayes' theorem to:
     \[
     \hat{\theta}_{MAP} = \arg \max_{\theta} \log \left( \prod_{i=1}^n p(x_i | \theta) p(\theta) \right)
     \]

2. **Differences from MLE**:
   - While MLE solely focuses on maximizing the likelihood, MAP also considers the prior distribution of the parameters, which can lead to different estimates especially when the amount of data is limited.
   - MAP is a regularization of MLE, incorporating additional information (or beliefs) about the parameters before observing the data.

## Laplace Approximation


1. **Purpose and Use**:
   - Laplace approximation is used to simplify the computation of posterior distributions in Bayesian inference by approximating these distributions with a Gaussian distribution centered at the MAP estimate.
   - This method is particularly advantageous in high-dimensional settings where the integral over the parameter space becomes intractable.

2. **Mathematical Foundation**:
   - Given a posterior distribution \( p(\theta | x) \), the goal is to approximate it around the point \( \hat{\theta} \) where it reaches its maximum, i.e., the MAP estimate.
   - The approximation assumes that the log of the posterior distribution can be approximated by a second-order Taylor expansion around \( \hat{\theta} \).

3. **Procedure**:
   - **Find the MAP**: Solve \( \hat{\theta} = \arg \max_{\theta} \log p(\theta | x) \), which involves derivatives of the log-posterior to find the point where it peaks.
   - **Second-Order Taylor Expansion**: Expand \( \log p(\theta | x) \) around \( \hat{\theta} \) using a second-order Taylor series:
     \[
     \log p(\theta | x) \approx \log p(\hat{\theta} | x) - \frac{1}{2} (\theta - \hat{\theta})^T A (\theta - \hat{\theta})
     \]
     where \( A \) is the Hessian matrix of the negative log-posterior evaluated at \( \hat{\theta} \).
   - **Approximate the Posterior**: The approximate posterior is then:
     \[
     q(\theta) \propto \exp\left(-\frac{1}{2} (\theta - \hat{\theta})^T A (\theta - \hat{\theta})\right)
     \]
     which is the form of a Gaussian distribution with mean \( \hat{\theta} \) and covariance matrix \( A^{-1} \).
     
4. **Implications and Applications**
  - **Efficiency**: The Laplace approximation allows for more efficient numerical calculations and integrations over the parameter space by reducing complex posterior distributions to Gaussian approximations.
  - **Model Comparison**: It facilitates model comparison and selection using Bayesian model comparison criteria like the Bayesian Information Criterion (BIC) and Akaike Information Criterion (AIC), which require the evaluation of the log-posterior or its approximations.

5. **Limitations**
- **Accuracy**: The approximation assumes that the posterior is unimodal and symmetric near the MAP, which may not hold in cases with multi-modal distributions or significant skewness.
- **Dimensionality**: In very high-dimensional spaces, even the computation of the Hessian and its inversion can become computationally challenging.


## Markov Chain Monte Carlo (MCMC)


Markov Chain Monte Carlo (MCMC) is a class of algorithms that allows for the sampling from a probability distribution based on constructing a Markov chain that has the desired distribution as its equilibrium distribution. This approach is particularly useful for obtaining a sequence of random samples from a multivariate probability distribution where direct sampling is difficult.  

**Monte Carlo Simulation**:

- Named after the Monte Carlo Casino due to the random nature of the methods, similar to gambling.
- These methods involve using randomness to solve problems that might be deterministic in principle. For example, they can be used to compute integrals by simulating random draws from a distribution and approximating sums or integrals.

**Markov Chains**:

- A Markov Chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.
- In the context of MCMC, the chain uses transition probabilities that depend only on the current state, not on how the current state was reached.


```{r echo =F, error=FALSE, message=FALSE, warning=FALSE}
knitr::include_graphics("./02_Plots/Bayesian/Bayer_MCMC1.png")
```

**MCMC Process**:

1. **Initialization**: Start from an arbitrary point in the support of the distribution.
2. **Iteration**: Move around the state space according to some probabilistic rules designed so that the chain will eventually converge to the target distribution.

**Key Methods within MCMC**:

- **Metropolis-Hastings Algorithm**: Proposes a new state from a proposal distribution and accepts or rejects the new state based on an acceptance ratio, which ensures that the detailed balance is maintained and the stationary distribution of the Markov chain is the target distribution.
- **Gibbs Sampling**: A special case of Metropolis-Hastings used when the joint distribution can be easily sampled by sequentially sampling from the conditional distributions of each variable given all other variables. It is particularly useful when each conditional distribution is easier to sample from than the joint distribution.

**Advantages of MCMC**:

- Enables sampling from complex, multi-dimensional distributions.
- Useful in Bayesian inference for obtaining posterior distributions where analytical solutions are not feasible.

**Challenges with MCMC**:

- Requires a large number of iterations to reach convergence, and determining convergence can be non-trivial.
- The samples are correlated, which means that the effective sample size is less than the total number of samples generated.


## Expectation-Maximization (EM) 

The Expectation-Maximization (EM) algorithm is a robust technique used for parameter estimation in cases where data is incomplete, missing, or has latent variables. It consists of two main steps repeated iteratively: the Expectation step (E-step) and the Maximization step (M-step).

1. **E-step**: In this step, the algorithm calculates the expected value of the log-likelihood function, with respect to the conditional distribution of the latent variables given the observed data and the current estimates of the parameters. This step involves filling in missing data, estimating latent variables, or more generally, calculating the expected sufficient statistics that are necessary for the parameter updates in the next step.

2. **M-step**: Here, the algorithm finds the parameter values that maximize the expected log-likelihood found in the E-step. These parameters are updated to new values that are used in the next E-step.

The process repeats with these new parameters until the convergence criteria are met, which typically involves the change in the log-likelihood or in the parameter estimates falling below a threshold.

This iterative process helps in making the EM algorithm particularly useful for situations where the model depends on unobserved latent data. The EM algorithm is widely used in various applications like clustering in machine learning (e.g., Gaussian mixture models), bioinformatics (e.g., gene expression analysis), and more.

**Key Benefits:**

- **Handling of Missing Data**: Efficiently deals with missing or hidden data during model fitting.
- **Flexibility**: Can be applied to a wide range of problems including those involving latent variables.
- **Convergence Guarantee**: Under mild conditions, EM is guaranteed to converge to a local (sometimes global) maximum of the likelihood function.

**Limitations:**

- **Local Maxima**: The algorithm can converge to local maxima, which means the initial values of parameters can affect the final solution.
- **Computationally Intensive**: The E-step and M-step can be computationally demanding, especially with large datasets or complex models.
- **Sensitivity to Model Specification**: The performance and convergence of the EM algorithm can be highly sensitive to how well the model and its assumptions match the underlying data structure.

## Variational inference 

Variational inference (VI) is a method used in Bayesian statistics that approximates probability densities through optimization rather than sampling, as seen in Markov Chain Monte Carlo (MCMC) methods. It is particularly useful when dealing with complex models and large datasets, providing a faster computational alternative.

**Process of Variational Inference:**

1. **Setup**: VI transforms the computation of the posterior distribution into an optimization problem. This involves selecting a simpler, tractable family of distributions known as the variational family.
2. **Objective**: The aim is to find a distribution within this family that most closely approximates the true posterior distribution. The measure of "closeness" is typically quantified using the Kullback-Leibler (KL) divergence.
3. **Optimization**: To achieve this, VI minimizes the KL divergence between the chosen variational distribution and the true posterior distribution. This is often done using standard optimization techniques.
4. **Outcome**: The result is a deterministic approximation of the posterior, which offers insights into parameter estimates and uncertainties more rapidly than sampling methods.

**Advantages of Variational Inference:**

- **Speed**: Generally faster than MCMC due to its deterministic nature.
- **Scalability**: Handles large datasets and complex models more efficiently by avoiding the computationally intensive process of drawing samples.
- **Applicability**: Useful in scenarios with large parameter spaces where MCMC methods might converge slowly or be impractical.

**Limitations:**

- **Accuracy**: There can be significant discrepancies between the variational approximation and the true posterior, especially if the posterior is multi-modal or particularly complex.
- **Bias**: VI introduces bias because the variational family may not encompass the true posterior.
- **Dependency on Form**: The effectiveness of VI depends greatly on the chosen variational family. If too restrictive, it may not adequately capture the posterior distribution.
 
