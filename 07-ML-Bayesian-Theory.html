<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title> Bayesian Theory</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Zehui Bai</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="02-Clinical_Experience.html">
    <span class="fa fa-user"></span>
     
    Clinical Experience
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-sliders"></span>
     
    Sample Size
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="03-SSC-Everything-to-Know-About-Sample-Size-Determination.html">Everything to Know About Sample Size Determination</a>
    </li>
    <li>
      <a href="03-SSC-Choosing-the-Effect-Size-for-Sample-Size-Calculations.html">Choosing the Effect Size</a>
    </li>
    <li>
      <a href="03-SSC-Biosimilar-Trials.html">Statistical Considerations for the Design and Analysis of Biosimilar Trials</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-and-Power-for-Non-Parametric-Analysis.html">Sample Size and Power for Non-Parametric Analysis</a>
    </li>
    <li>
      <a href="03-SSC-Power-for-Complex-Hypotheses.html">Power for Complex Hypotheses</a>
    </li>
    <li>
      <a href="03-SSC-Alternatives-to-Power.html">Bayesian methods - Alternatives to Power</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-for-Pilot-Studies.html">Sample Size for Pilot Studies</a>
    </li>
    <li>
      <a href="03-SSC-Case-Continuous-Endpoint.html">Sample Size Determination for Continuous Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Categorical-Endpoint.html">Sample Size Determination for Categorical Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-Determination-for-Counts-and-Rates.html">Sample Size Determination for Counts and Rates</a>
    </li>
    <li>
      <a href="03-SSC-Case-Survival-Endpoint.html">Sample Size Determination for Survival Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Repeated-Measures.html">Sample Size Determination for Repeated Measures</a>
    </li>
    <li>
      <a href="03-SSC-IA-Sequential-Design.html">Statistical Considerations for Group Sequential Design</a>
    </li>
    <li>
      <a href="03-SSC-IA-Adaptive-Design.html">Statistical Considerations for Adaptive Design</a>
    </li>
    <li>
      <a href="03-SSC-Multiple-Test.html">Sample Size for Multiple Test</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-pencil-square-o"></span>
     
    Study Design
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="04-Design-Estimands-Framework.html">Estimands Framework</a>
    </li>
    <li>
      <a href="04-Design-Estimands-Practice.html">Estimands and Sensitivity Analyses</a>
    </li>
    <li>
      <a href="04-Design-Phase-I-Trials---Design-Considerations.html">Phase I Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-II-Trials---Design-Considerations.html">Phase II Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-III-Trials---Design-Considerations.html">Phase III Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-IV-Trials---Design-Considerations.html">Phase IV Trials - Design Considerations for Post Marketing Surveillance</a>
    </li>
    <li>
      <a href="04-Design-Complex-Sequential-Trials.html">Complex Sequential Analysis Trials</a>
    </li>
    <li>
      <a href="04-Design-Adaptive-Clinical-Trials.html">Adaptive Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Bayesian-Clinical-Trials.html">Bayesian Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Dose-Escalation-and-Stratification-Designs.html">Dose Escalation and Stratification Designs in Early Oncology Development</a>
    </li>
    <li>
      <a href="04-Design-Single-Arm-Clinical-Trials.html">Single Arm Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Diagnostic-Study-Design-and-Evaluation.html">Diagnostic Study-Design and Evaluation</a>
    </li>
    <li>
      <a href="04-Design-Diagnostic-Study-MRMC.html">Diagnostic Study-Multireader Multicase (MRMC)</a>
    </li>
    <li>
      <a href="04-Design-Hierarchical-composite-endpoints.html">Hierarchical Composite Endpoints</a>
    </li>
    <li>
      <a href="04-Design-Externally-Controlled-Trials.html">Considerations for the Design and Conduct of Externally Controlled Trials</a>
    </li>
    <li>
      <a href="04-Design-Noninferiority-Trials.html">Noninferiority Trials</a>
    </li>
    <li>
      <a href="04-Design-Bioequivalence-and-Biosimilar-Trials.html">Bioequivalence and Biosimilar Trials</a>
    </li>
    <li>
      <a href="04-Design-Exploring-Survival-Analysis-Designs-for-Clinical-Trials.html">Exploring Survival Analysis Designs for Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Projecting-How-Long-Your-Trial-Will-Take.html">Projecting How Long Your Trial Will Take</a>
    </li>
    <li>
      <a href="04-Design-Regulatory-Submission.html">Regulatory Submission from Stats Perspective</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-line-chart"></span>
     
    Data Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="05-Plot-Adverse-Event.html">Adverse Event Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Laboratory-Data.html">Laboratory Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Time-To-Event.html">Time to Event Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-PRO-Data.html">Patient Reported Outcome Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-SSC-and-Power-Calculation.html">Sample Size and Power Calculations Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Correlation.html">Correlation Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Model-Table.html">Clinical Data and Model visualization</a>
    </li>
    <li>
      <a href="05-Plot-ScatterPlot.html">Scatter and Line Plot</a>
    </li>
    <li>
      <a href="05-Plot-BarPlot.html">Bar Chart</a>
    </li>
    <li>
      <a href="05-Plot-PieChart.html">Pie Chart</a>
    </li>
    <li>
      <a href="05-Plot-BoxPlot.html">Box Plot</a>
    </li>
    <li>
      <a href="05-Plot-Histogram.html">Histogram</a>
    </li>
    <li>
      <a href="05-Plot-Forest-Plot.html">Forest Plot</a>
    </li>
    <li>
      <a href="05-Plot-Flow-Chart.html">Flow Chart</a>
    </li>
    <li>
      <a href="05-Plot-Some-Interesting.html">Some Interesting Plots</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-calculator"></span>
     
    Statistical Analysis
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06-Analysis-Linear-Regression.html">Linear Regression</a>
    </li>
    <li>
      <a href="06-Analysis-Logistic-Regression.html">Logistic Regression</a>
    </li>
    <li>
      <a href="06-Analysis-Mixed-Model.html">Mixed Model</a>
    </li>
    <li>
      <a href="06-Analysis-MMRM.html">Mixed Model Repeated Measures</a>
    </li>
    <li>
      <a href="06-Analysis-GEE.html">Generalized Estimating Equation</a>
    </li>
    <li>
      <a href="06-Analysis-ANOVA.html">Analysis of Variance</a>
    </li>
    <li>
      <a href="06-Analysis-Survival-Analysis.html">Survival Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Survival-Competing-Risk.html">Survival Analysis - Competing Risk</a>
    </li>
    <li>
      <a href="06-Analysis-Missing-Data.html">Missing Data Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-MI-Implementation.html">Multiple Imputation Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-SSD.html">Safety Signal Detection and Evaluation</a>
    </li>
    <li>
      <a href="06-Analysis-Meta-Analysis.html">Meta Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-PK-and-PD.html">PK and PD Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Time-Series-Analysis.html">Time Series Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-SEM.html">Structural Equation Modeling</a>
    </li>
    <li>
      <a href="06-Analysis-Factor-Analysis.html">Factor Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="07-ML-Bayesian-Theory.html">Bayesian Theory</a>
    </li>
    <li>
      <a href="07-ML-Bayesian-Analysis.html">Bayesian Analysis</a>
    </li>
    <li>
      <a href="07-ML-Regularization-Penalized-Regression.html">Regularization Penalized Regression</a>
    </li>
    <li>
      <a href="07-ML-Loss-Regression.html">Loss Functions in Machine Learning</a>
    </li>
    <li>
      <a href="07-ML-PCA.html">Principal Component Analysis</a>
    </li>
    <li>
      <a href="07-ML-KNN.html">K-Nearest Neighbors</a>
    </li>
    <li>
      <a href="07-ML-SVM.html">Support Vector Machine</a>
    </li>
    <li>
      <a href="07-ML-Tree-Models.html">Tree Models</a>
    </li>
    <li>
      <a href="07-ML-LDA.html">Linear Discriminant Analysis</a>
    </li>
    <li>
      <a href="07-ML-Cluster-Analysis.html">Cluster Analysis</a>
    </li>
    <li>
      <a href="07-ML-Neural-Networks.html">Neural Network</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="08-CV.html">
    <span class="fa fa-file-pdf-o"></span>
     
    CV
  </a>
</li>
<li>
  <a href="mailto:zehuibai@outlook.com">
    <span class="fa fa-envelope-o"></span>
     
    Contact me
  </a>
</li>
<li>
  <a href="https://github.com/Zehuibai">
    <span class="fa fa-github"></span>
     
    GitHub
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore"><p><img src="logo.png"
style="width:3in" /><br />
Bayesian Theory</p></h1>

</div>


<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<div id="frequency-and-bayesian" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Frequency and
Bayesian</h2>
<ul>
<li>In the realm of statistics, two main schools of thought offer
distinct approaches to understanding and interpreting data: the
frequency school and the Bayesian school.</li>
<li>The frequency school posits that overall parameters are fixed and
that samples are acquired randomly. This perspective views each random
sample as an imperfect representation of an ideal entity. By applying
methods like maximum likelihood estimation, the frequency school aims to
infer the most probable parameters that could result in the observed
samples.</li>
<li>Contrarily, the Bayesian school considers overall parameters as
random variables, while the samples obtained are seen as fixed.
Bayesians are less concerned with pinpointing the exact parameters;
instead, they focus on updating beliefs about these parameters. They
utilize prior knowledge combined with newly acquired data to compute the
posterior probability distribution, facilitating statistical inference
through this updated belief system.</li>
</ul>
<p><strong>Bayesian Inference: Priors, Posteriors, and Predictive
Analysis</strong></p>
<ul>
<li>Prior probability distributions represent our beliefs about
hypotheses before we analyze any data. These priors are foundational in
Bayesian inference, which updates these beliefs to posterior
probabilities upon receiving new data.</li>
<li>The posterior probability distribution, denoted as <span
class="math display">\[\mathrm{P}(\theta | \text{data})\]</span>, is a
cornerstone of Bayesian reasoning. This distribution encapsulates our
uncertainty about parameter values. A narrower distribution suggests
higher confidence in our estimates of these values. By gathering more
data, we can achieve more precise posterior distributions.</li>
<li>Moreover, the posterior distribution is instrumental in forecasting
future outcomes of experiments and testing models. It allows
statisticians to make informed predictions and validate hypotheses
effectively.</li>
</ul>
</div>
<div id="bayesian-and-classical-methods" class="section level2"
number="1.2">
<h2><span class="header-section-number">1.2</span> Bayesian and
Classical Methods</h2>
<p>Bayesian analysis has several advantages over classical analysis in
the context of clinical trials. These include the ability to incorporate
prior information about treatment efficacies into the analysis, the
flexibility to make multiple unscheduled inspections of accumulating
data without increasing the error rate, and the capability to calculate
the probability that one treatment is more effective than another.</p>
<p>In contrast to classical methods, Bayesian analysis is conditional on
the observed data and focuses on the probability that a conclusion or
hypothesis is true given the available data. Classical inference,
however, is not conditional on the observed data but instead concerns
the behavior of a statistical procedure over an infinite number of
repetitions, considering all potential data that might have been
observed under a hypothesis. Bayesians deal with the probabilities of
hypotheses given a dataset, whereas frequentists concern themselves with
the probabilities of datasets given a hypothesis.</p>
<p><strong>1. Overview of Bayesian and Classical Analysis</strong></p>
<ul>
<li><strong>Bayesian Analysis:</strong>
<ul>
<li><strong>Incorporates Prior Information:</strong> Utilizes existing
knowledge about treatment effects, enhancing analytical precision.</li>
<li><strong>Flexible Data Inspection:</strong> Allows multiple reviews
of ongoing data without affecting the error rates, promoting adaptive
research approaches.</li>
<li><strong>Probabilistic Outcomes:</strong> Computes the likelihood of
one treatment outperforming another, providing direct answers to
clinical questions.</li>
</ul></li>
<li><strong>Classical Analysis:</strong>
<ul>
<li><strong>Fixed Procedure:</strong> Relies on a set framework
involving hypothesis testing with less adaptability in procedure once
the analysis begins.</li>
<li><strong>Repetition-Based:</strong> Focuses on long-term behavior
over many hypothetical repeats of the study, which can disconnect
results from the practical needs of clinicians.</li>
</ul></li>
</ul>
<p><strong>2. Methodological Contrasts</strong></p>
<ul>
<li><strong>Conditional vs. Unconditional Frameworks:</strong>
<ul>
<li><strong>Bayesian:</strong> Analysis is conditional on the data
observed, directly tying conclusions to the evidence at hand.</li>
<li><strong>Classical:</strong> Operates independent of the specific
data set, which can lead to less direct applicability to the individual
study results.</li>
</ul></li>
<li><strong>Hypothesis Testing Approach:</strong>
<ul>
<li><strong>Bayesian:</strong> Engages directly with the probability of
hypotheses given the data, making it inherently responsive to new
information.</li>
<li><strong>Classical:</strong> Concentrates on the probability of data
given predefined hypotheses, often leading to rigid
interpretations.</li>
</ul></li>
</ul>
<p><strong>3. Limitations in Classical Hypothesis Testing</strong></p>
<ul>
<li><strong>Inflexibility in Hypothesis Evaluation:</strong> Classical
methods typically commit to the first plausible alternative hypothesis
upon rejecting the null, without thorough consideration of other viable
hypotheses.</li>
<li><strong>Impact of Data Peeking:</strong> Interim data reviews can
affect the study’s error rates under classical approaches, a scenario
not adequately addressed in traditional frameworks.</li>
</ul>
<p><strong>4. Advantages of Bayesian Methodology</strong></p>
<ul>
<li><strong>Utilization of Bayes’ Theorem:</strong> Allows for
calculating the true probability of a hypothesis based on both prior
knowledge and new data.</li>
<li><strong>Integration of Prior Beliefs:</strong> Bayesian methods can
quantitatively incorporate uncertainties about prior information,
adjusting the analysis to reflect varying degrees of prior
reliability.</li>
<li><strong>Flexibility in Clinical Trials:</strong> Does not require
preset patient numbers or analysis timings, adapting more naturally to
the dynamics of trial execution.</li>
</ul>
<p><strong>5. Implementation and Impact</strong></p>
<ul>
<li><strong>Defining Prior Knowledge:</strong> Establishing the initial
probability distributions based on literature, expert opinions, and
preliminary studies to guide the analysis.</li>
<li><strong>Data Acquisition and Adjustment:</strong> Continuous
updating of prior estimates with incoming trial data to refine the
posterior estimates.</li>
<li><strong>Posterior Analysis:</strong> Results in detailed probability
distributions that offer nuanced insights into treatment efficacy,
enhancing decision-making with probabilistic ranges for treatment
effects.</li>
</ul>
</div>
<div id="bayes-theorem" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Bayes’ Theorem</h2>
<p>Bayes’ theorem can be expressed mathematically in the context of
Bayesian inference as:</p>
<p><span class="math display">\[
\overbrace{p(\theta/D)}^{\text{Posterior}} =
\frac{\overbrace{p(D/\theta)}^{\text{Likelihood}} \cdot
\overbrace{p(\theta)}^{\text{Prior}}}{\underbrace{p(D)}_{\text{Evidence}}}
\]</span></p>
<p>This equation is fundamental to Bayesian analysis and can be broken
down into three critical components:</p>
<ol style="list-style-type: decimal">
<li><strong>Posterior Probability ( <span
class="math inline">\(p(\theta/D)\)</span> ):</strong>
<ul>
<li>This is the probability of the hypothesis <span
class="math inline">\(\theta\)</span> given the data <span
class="math inline">\(D\)</span>.</li>
<li>It is updated knowledge after considering new evidence.</li>
<li>It provides a measure of how plausible the hypothesis is in the
light of the available data.</li>
</ul></li>
<li><strong>Likelihood ( <span
class="math inline">\(p(D/\theta)\)</span> ):</strong>
<ul>
<li>This is the probability of observing the data <span
class="math inline">\(D\)</span> given that the hypothesis <span
class="math inline">\(\theta\)</span> is true.</li>
<li>It assesses how probable the observed data are under different
hypothetical conditions specified by <span
class="math inline">\(\theta\)</span>.</li>
</ul></li>
<li><strong>Prior Probability ( <span
class="math inline">\(p(\theta)\)</span> ):</strong>
<ul>
<li>This is the probability of the hypothesis before observing the
current data.</li>
<li>It incorporates existing knowledge or beliefs about the parameter
before new data is taken into account.</li>
</ul></li>
<li><strong>Evidence or Marginal Likelihood ( <span
class="math inline">\(p(D)\)</span> ):</strong>
<ul>
<li>This is also known as the marginal probability of the observed
data.</li>
<li>It is calculated by integrating or summing over all possible values
of <span class="math inline">\(\theta\)</span>, essentially averaging
the likelihoods weighted by the prior probabilities.</li>
<li>In practice, this acts as a normalizing constant to ensure the
posterior probabilities sum to one.</li>
</ul></li>
</ol>
<div id="prior-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Prior Distribution</h3>
<p>The <strong>Prior Distribution</strong> in Bayesian statistics is a
fundamental component that encapsulates our knowledge or beliefs about a
parameter before we observe any data. It’s an expression of our
subjective or objective preconceptions about the values that a
parameter, typically denoted as <span
class="math inline">\(\theta\)</span>, might take based on previous
experience, existing knowledge, or expert opinion.</p>
<p><strong>Characteristics of Prior Distributions</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Subjective or Objective</strong>:
<ul>
<li><strong>Subjective Priors</strong>: These are based on personal
beliefs or expert opinions and are particularly useful when historical
data is sparse or when new phenomena are being studied. Subjective
priors can incorporate insights from experts, results from previous
studies that are not strictly comparable, or institutional
knowledge.</li>
<li><strong>Objective Priors</strong>: These are formulated to minimize
the influence of the prior, aiming to let the data speak for themselves.
Objective priors include non-informative priors, which are designed to
have minimal impact on the posterior outcomes. Examples include
Jeffreys’ prior and uniform distributions in certain contexts.</li>
</ul></li>
<li><strong>Informative vs. Non-Informative</strong>:
<ul>
<li><strong>Informative Priors</strong>: These contain specific
information about a parameter. For instance, if previous studies suggest
that a parameter is likely centered around a particular value with some
variance, the prior distribution can be centered at this value with a
spread reflecting this variance.</li>
<li><strong>Non-Informative Priors</strong>: These are used when no
substantial prior knowledge about a parameter is available or when it is
desirable to not let prior assumptions heavily influence the results.
They are often broad and flat, indicating equal probability across a
wide range of parameter values, thereby allowing the data to have a
stronger influence on the posterior distribution.</li>
</ul></li>
</ol>
<p><strong>Role of Prior Distribution in Bayesian Analysis</strong></p>
<ul>
<li><strong>Initial Belief Modeling</strong>: The prior distribution
models the initial belief about the parameter before new data is taken
into account.</li>
<li><strong>Updating Beliefs</strong>: In Bayesian inference, the prior
distribution is updated with the likelihood of observing the new data
given possible parameter values, resulting in the posterior
distribution. This process is governed by Bayes’ theorem: <span
class="math display">\[
\text{Posterior} \propto \text{Likelihood} \times \text{Prior}
\]</span></li>
<li><strong>Impact on Posterior</strong>: The strength and nature of the
prior can significantly affect the posterior, especially when the amount
of data is small. With more data, the influence of the prior generally
diminishes, particularly if the prior is non-informative.</li>
</ul>
</div>
<div id="likelihood-function" class="section level3 unnumbered">
<h3 class="unnumbered">Likelihood Function</h3>
<p>Bayesian inference updates the prior probability distribution based
on newly acquired data. According to Bayes’ theorem, the posterior
distribution <span class="math inline">\(p(\theta| x)\)</span> is
proportional to the product of the likelihood <span
class="math inline">\(p(x | \theta)\)</span> and the prior distribution
<span class="math inline">\(p(\theta)\)</span>, expressed as:</p>
<p><span class="math display">\[ p(\theta|x) \propto
p(x|\theta)p(\theta) \]</span></p>
<p>The integral of the likelihood function over the prior distribution,
normalized by the probability of the data <span
class="math inline">\(p(x)\)</span>, provides the marginal
likelihood:</p>
<p><span class="math display">\[ p(x) = \int p(x|\theta)p(\theta)
d\theta \]</span></p>
<p>This marginal likelihood <span class="math inline">\(p(x)\)</span>
serves as the normalizing constant for the posterior distribution:</p>
<p><span class="math display">\[ p(\theta|x) =
\frac{p(x|\theta)p(\theta)}{p(x)} \]</span></p>
<p>Bayesian inference effectively incorporates nuisance parameters by
integrating them out of the joint posterior to provide a marginal
posterior distribution <span class="math inline">\(p(\theta_1 |
x)\)</span>, which is calculated by integrating over the nuisance
parameter <span class="math inline">\(\theta_2\)</span>:</p>
<p><span class="math display">\[ p(\theta_1 | x) = \int p(\theta_1,
\theta_2 | x) p(\theta_2 | d\theta_2) \]</span></p>
</div>
<div id="posterior-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Posterior Distribution</h3>
<ol style="list-style-type: decimal">
<li><strong>Bayesian Update</strong>:
<ul>
<li>Bayesian analysis modifies the likelihood by incorporating a prior
belief about the parameters, <span
class="math inline">\(\pi(\theta)\)</span>, leading to the posterior
distribution.</li>
<li>The posterior distribution is calculated using Bayes’ theorem: <span
class="math display">\[
\pi(\theta \mid \mathscr{D}_{n}) = \frac{\ell(\theta \mid
\mathscr{D}_{n}) \pi(\theta)}{\int \ell(\theta \mid \mathscr{D}_{n})
\pi(\theta) \, d \theta}
\]</span></li>
<li>This results in a probability distribution over the parameter space
<span class="math inline">\(\Theta\)</span>, reflecting updated beliefs
after considering the observed data.</li>
</ul></li>
<li><strong>Choosing the Prior</strong>:
<ul>
<li>The selection of the prior, <span
class="math inline">\(\pi(\theta)\)</span>, is crucial as it represents
the initial beliefs about the parameters before observing any data.</li>
<li>The prior needs to be chosen carefully to reflect prior knowledge or
assumptions about the parameters.</li>
</ul></li>
</ol>
<p>The predictive distribution in Bayesian inference uses the posterior
distribution to make predictions about future data. This approach is
inherently probabilistic, reflecting the uncertainty inherent in the
data and the model parameters. Key elements of Bayesian prediction
include:</p>
<ol style="list-style-type: decimal">
<li><strong>Predictive Mean:</strong>
<ul>
<li>The expected value of the prediction <span
class="math inline">\(E(y)\)</span> is computed as the integral of the
potential outcomes weighted by their probabilities, calculated over the
posterior distribution.</li>
<li>Formula: <span class="math inline">\(E(y) = \int \theta p(\theta |
x) d\theta\)</span></li>
</ul></li>
<li><strong>Mode of the Predictive Distribution:</strong>
<ul>
<li>Represents the most probable value of the prediction, identified by
the maximum of the posterior distribution.</li>
<li>Formula: <span class="math inline">\(\text{Mode} = \arg\max_{\theta}
p(\theta | x)\)</span></li>
</ul></li>
<li><strong>Predictive Distribution:</strong>
<ul>
<li>The predictive distribution provides a complete probabilistic
description of the possible future values, integrating over all
uncertainties.</li>
<li>It summarizes not just a single value but the likelihood of all
possible future outcomes.</li>
</ul></li>
</ol>
</div>
</div>
<div id="credible-intervals" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Credible
Intervals</h2>
<ol style="list-style-type: decimal">
<li><strong>Bayesian Inferential Approach</strong>:
<ul>
<li>The Bayesian approach is comprehensive, encompassing confidence
evaluation, hypothesis testing, prediction, model checking, and point
estimation.</li>
<li>It treats parameters as random variables and derives inferential
statistics based on the posterior distribution <span
class="math inline">\(\pi(\theta \mid \mathscr{D}_{n})\)</span>.</li>
</ul></li>
<li><strong>Definition of Credible Intervals</strong>:
<ul>
<li>In Bayesian statistics, what traditional statistics call a
confidence interval is referred to as a “credible interval.”</li>
<li>A credible interval for a parameter <span
class="math inline">\(\theta\)</span> based on data <span
class="math inline">\(\mathscr{D}_{n}\)</span> is defined as a set <span
class="math inline">\(C(\mathscr{D}_{n})\)</span> such that: <span
class="math display">\[
\pi(\theta \in C(\mathscr{D}_{n}) \mid \mathscr{D}_{n}) = 1 - \alpha
\]</span> Here, <span class="math inline">\(\alpha\)</span> is the
significance level (e.g., 0.05), indicating that the interval contains
the parameter with probability <span
class="math inline">\(1-\alpha\)</span>.</li>
</ul></li>
<li><strong>Integration over Parameter Space</strong>:
<ul>
<li>Unlike classical methods that integrate over the observation space
to compute confidence intervals, Bayesian methods integrate over the
parameter space.</li>
<li>This means that <span class="math inline">\(1-\alpha\)</span>
represents the probability that the random variable <span
class="math inline">\(\theta\)</span> falls within the interval <span
class="math inline">\(C(\mathscr{D}_{n})\)</span>, rather than the
probability that a random interval contains the true parameter
value.</li>
</ul></li>
<li><strong>Highest Posterior Density (HPD) Region</strong>:
<ul>
<li>The HPD region is a type of Bayesian credible interval which
contains the values of <span class="math inline">\(\theta\)</span> with
the highest posterior densities.</li>
<li>It is defined as: <span class="math display">\[
C(\mathscr{D}_{n}) = \{\theta : \pi(\theta \mid \mathscr{D}_{n}) \geq
k_{\alpha}\}
\]</span> where <span class="math inline">\(k_{\alpha}\)</span> is
determined so that the probability content of the HPD region is exactly
<span class="math inline">\(1-\alpha\)</span>.</li>
</ul></li>
</ol>
<div id="highest-density-region-hdr" class="section level3"
number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Highest Density
Region (HDR)</h3>
<ol style="list-style-type: decimal">
<li><strong>Definition of HDR</strong>:
<ul>
<li>The Highest Density Region (HDR) for a given posterior distribution
<span class="math inline">\(p(\theta | \text{data})\)</span> at a
probability level <span class="math inline">\(1-\alpha\)</span> is
defined as the subset of the parameter space where the density of <span
class="math inline">\(\theta\)</span> is highest.</li>
<li>Mathematically, it is defined as: <span class="math display">\[
\{\theta : p(\theta | \text{data}) \geq k(\alpha)\}
\]</span> where <span class="math inline">\(k(\alpha)\)</span> is the
largest constant such that the probability mass of this region is <span
class="math inline">\(1-\alpha\)</span>: <span class="math display">\[
\int_{\{\theta: p(\theta | \text{data}) \geq k(\alpha)\}} p(\theta |
\text{data}) d\theta = 1 - \alpha
\]</span></li>
</ul></li>
<li><strong>Interpretation and Importance</strong>:
<ul>
<li>The HDR contains the most probable values of <span
class="math inline">\(\theta\)</span> under the posterior
distribution.</li>
<li>It is used to specify the region in the parameter space where the
true parameter value is most likely to lie, given the observed
data.</li>
</ul></li>
<li><strong>Calculation of HDR</strong>:
<ul>
<li>To determine the HDR, identify the level <span
class="math inline">\(k(\alpha)\)</span> such that the integral of the
posterior distribution over the region where <span
class="math inline">\(p(\theta | \text{data}) \geq k(\alpha)\)</span>
equals <span class="math inline">\(1-\alpha\)</span>.</li>
<li>This requires solving for <span
class="math inline">\(k(\alpha)\)</span> in a way that balances between
covering the highest density of the distribution and ensuring that the
total probability of the region is exactly <span
class="math inline">\(1-\alpha\)</span>.</li>
</ul></li>
<li><strong>Practical Implications of HDR</strong>
<ul>
<li><strong>Confidence in Estimates</strong>: The HDR provides a way to
understand the uncertainty and variability of parameter estimates. It
can be considered as a Bayesian analogue to confidence intervals in
frequentist statistics.</li>
<li><strong>Decision Making</strong>: In practical applications, such as
in policy settings or scientific research, identifying the HDR helps in
making decisions based on the most probable parameter values.</li>
<li><strong>Comparative Analysis</strong>: Comparing HDRs from different
posterior distributions can provide insights into how different prior
beliefs or data sets influence the inferences about the parameters.</li>
</ul></li>
</ol>
</div>
<div id="key-differences-from-classical-confidence-intervals"
class="section level3" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Key Differences
from Classical Confidence Intervals</h3>
<ul>
<li><strong>Probability Interpretation</strong>:
<ul>
<li>In Bayesian analysis, the probability <span
class="math inline">\(1-\alpha\)</span> directly quantifies our belief
about the parameter’s location based on the data and prior
information.</li>
<li>In classical statistics, <span
class="math inline">\(1-\alpha\)</span> indicates how often the true
parameter will be captured by the interval over repeated sampling from
the population.</li>
</ul></li>
<li><strong>Simplicity of Construction</strong>:
<ul>
<li>Determining the best credible interval in Bayesian terms is
typically simpler than constructing classical confidence intervals
because it directly targets the areas of highest probability density
without regard to potential sampling variability.</li>
</ul></li>
</ul>
</div>
</div>
<div id="hypothesis-testing" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Hypothesis
Testing</h2>
<div id="bayesian-theorem-for-two-hypotheses"
class="section level3 unnumbered">
<h3 class="unnumbered">Bayesian Theorem for Two Hypotheses</h3>
<p>In Bayesian inference, we often deal with two <strong>mutually
exclusive and exhaustive hypotheses</strong>:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: the null hypothesis
(e.g. “the person has HIV”)</li>
<li><span class="math inline">\(H_1\)</span>: the alternative hypothesis
(e.g. “the person does not have HIV”)</li>
</ul>
<p>Let:</p>
<ul>
<li><span class="math inline">\(p(H_0)\)</span> and <span
class="math inline">\(p(H_1)\)</span> be the <strong>prior
probabilities</strong> (our beliefs before seeing the data)</li>
<li><span class="math inline">\(p(y \mid H_0)\)</span> and <span
class="math inline">\(p(y \mid H_1)\)</span> be the
<strong>likelihoods</strong>, i.e., the probability of observing the
data <span class="math inline">\(y\)</span> assuming each hypothesis is
true</li>
</ul>
<p>Bayes’ Theorem allows us to update our beliefs after observing data
<span class="math inline">\(y\)</span>. The <strong>posterior
probability</strong> for <span class="math inline">\(H_0\)</span>
is:</p>
<p><span class="math display">\[
p(H_0 \mid y) = \frac{p(y \mid H_0) \cdot p(H_0)}{p(y)}
\]</span></p>
<p>Where the denominator <span class="math inline">\(p(y)\)</span> is
the <strong>marginal likelihood</strong> or
<strong>evidence</strong>:</p>
<p><span class="math display">\[
p(y) = p(y \mid H_0) \cdot p(H_0) + p(y \mid H_1) \cdot p(H_1)
\]</span></p>
<p>Since <span class="math inline">\(H_1 = \text{not } H_0\)</span>, we
also have <span class="math inline">\(p(H_1) = 1 - p(H_0)\)</span>.</p>
<p>Bayes’ Theorem can also be written in terms of
<strong>odds</strong>:</p>
<p><span class="math display">\[
\frac{p(H_0 \mid y)}{p(H_1 \mid y)} = \frac{p(y \mid H_0)}{p(y \mid
H_1)} \cdot \frac{p(H_0)}{p(H_1)}
\]</span></p>
<p>In this expression:</p>
<ul>
<li><span class="math inline">\(\frac{p(H_0)}{p(H_1)}\)</span> is the
<strong>prior odds</strong></li>
<li><span class="math inline">\(\frac{p(y \mid H_0)}{p(y \mid
H_1)}\)</span> is the <strong>likelihood ratio</strong></li>
<li><span class="math inline">\(\frac{p(H_0 \mid y)}{p(H_1 \mid
y)}\)</span> is the <strong>posterior odds</strong></li>
</ul>
<p>This version shows that:</p>
<p><span class="math display">\[
\text{Posterior odds} = \text{Likelihood ratio} \times \text{Prior odds}
\]</span></p>
<p>Taking the logarithm of both sides:</p>
<p><span class="math display">\[
\log(\text{Posterior odds}) = \log(\text{Likelihood ratio}) +
\log(\text{Prior odds})
\]</span></p>
<p>The term <span class="math inline">\(\log(\text{Likelihood
ratio})\)</span> is known as the <strong>weight of evidence</strong>, a
concept first introduced by <strong>Alan Turing</strong> during World
War II in his work on decoding the Enigma machine.</p>
<p><img
src="02_Plots/Bayesian/Bayer_Relationship%20likelihood%20ratio.png" />
A typical graph of Bayes’ Theorem under different <strong>likelihood
ratios</strong> illustrates how prior and posterior probabilities
relate:</p>
<ul>
<li><strong>X-axis</strong>: Prior probability <span
class="math inline">\(p(H_0)\)</span> — your belief in the hypothesis
before seeing data</li>
<li><strong>Y-axis</strong>: Posterior probability <span
class="math inline">\(p(H_0 \mid y)\)</span> — your updated belief after
observing data</li>
</ul>
<p>Each curve represents a different likelihood ratio (e.g., 1, 5, 10,
20, 50).</p>
<p><strong>Interpretation examples</strong>:</p>
<ul>
<li>If your prior probability is <strong>0.01</strong> (a very low
initial belief), then <strong>even a strong likelihood ratio (e.g.,
50)</strong> may only raise the posterior probability to around
<strong>0.33</strong></li>
<li>But if your prior is <strong>0.5</strong> and the likelihood ratio
is <strong>20</strong>, the posterior probability can increase to
<strong>around 0.95</strong></li>
</ul>
<blockquote>
<p><strong>The result of Bayesian inference depends not only on the
strength of the evidence (likelihood ratio) but also heavily on the
initial belief (prior probability).</strong></p>
</blockquote>
<p>In particular:</p>
<ul>
<li>With a <strong>low prior</strong>, even strong evidence may not
produce high posterior belief</li>
<li>With a <strong>moderate or high prior</strong>, strong evidence can
sharply raise your confidence</li>
</ul>
</div>
<div id="bayes-factors-likelihood-ratios" class="section level3"
number="1.5.1">
<h3><span class="header-section-number">1.5.1</span> Bayes Factors
(Likelihood Ratios)</h3>
<p>In Bayesian hypothesis testing, the likelihood of two competing
hypotheses <span class="math inline">\(H_0\)</span> and <span
class="math inline">\(H_1\)</span> (for example, <span
class="math inline">\(H_0: \theta = 0\)</span> and <span
class="math inline">\(H_1: \theta = 1\)</span>) is evaluated based on
the data, taking into account prior beliefs about these hypotheses.</p>
<p><strong>Bayes Factors</strong>: is a crucial metric in Bayesian
hypothesis testing. It is used to provide a quantifiable measure of
support for one hypothesis over another, based on the observed data.</p>
<p>The <strong>Bayes Factor</strong> is essentially the same as the
likelihood ratio when comparing two simple hypotheses. It quantifies the
evidence provided by the data in favor of one hypothesis over
another:</p>
<p><span class="math display">\[
\text{Bayes Factor (BF)} = \frac{p(y \mid H_0)}{p(y \mid H_1)}
\]</span></p>
<p>Interpretation:</p>
<ul>
<li>If BF &gt; 1, the evidence favors <span
class="math inline">\(H_0\)</span></li>
<li>If BF &lt; 1, the evidence favors <span
class="math inline">\(H_1\)</span></li>
<li>The further BF is from 1, the stronger the evidence</li>
</ul>
<p>This is also referred to by Cornfield as the <strong>“relative
betting odds”</strong> and is central to Bayesian inference.</p>
<hr />
<p>Bayes factors are used to transform <strong>prior odds</strong> into
<strong>posterior odds</strong>:</p>
<p><span class="math display">\[
\frac{p(H_0 \mid y)}{p(H_1 \mid y)} = \text{Bayes Factor} \times
\frac{p(H_0)}{p(H_1)}
\]</span></p>
<p>This shows how evidence from data (through the BF) updates our prior
beliefs to form our posterior beliefs.</p>
<hr />
<p>Interpreting the Bayes Factor: Jeffreys’ Scale</p>
<p>The strength of evidence indicated by the Bayes factor can be
interpreted using <strong>Harold Jeffreys’ scale</strong> (see Table
3.2):</p>
<table>
<thead>
<tr class="header">
<th>Bayes Factor (BF)</th>
<th>Evidence Strength (in favor of <span
class="math inline">\(H_0\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&gt; 100</td>
<td>Decisive</td>
</tr>
<tr class="even">
<td>32 to 100</td>
<td>Very strong</td>
</tr>
<tr class="odd">
<td>10 to 32</td>
<td>Strong</td>
</tr>
<tr class="even">
<td>3.2 to 10</td>
<td>Substantial</td>
</tr>
<tr class="odd">
<td>1 to 3.2</td>
<td>Barely worth mentioning</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Bayes Factor (BF)</th>
<th>Evidence Strength (in favor of <span
class="math inline">\(H_1\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1 to 1/3.2</td>
<td>Barely worth mentioning</td>
</tr>
<tr class="even">
<td>1/3.2 to 1/10</td>
<td>Substantial</td>
</tr>
<tr class="odd">
<td>1/10 to 1/32</td>
<td>Strong</td>
</tr>
<tr class="even">
<td>1/32 to 1/100</td>
<td>Very strong</td>
</tr>
<tr class="odd">
<td>&lt; 1/100</td>
<td>Decisive</td>
</tr>
</tbody>
</table>
</div>
<div id="p-values-and-bayes-factors" class="section level3 unnumbered">
<h3 class="unnumbered">P-values and Bayes Factors</h3>
<p>P-values and Bayes factors are two approaches for hypothesis testing
and assessing evidence, but they represent fundamentally different
statistical paradigms. Here’s a comparison and detailed explanation:</p>
<p><strong>P-Values (Frequentist Paradigm)</strong></p>
<p>A <strong>P-value</strong> is a frequentist measure used to test a
null hypothesis (<span class="math inline">\(H_0\)</span>):</p>
<ol style="list-style-type: decimal">
<li><strong>Definition:</strong>
<ul>
<li>The probability of observing data as extreme as, or more extreme
than, the observed data, assuming <span
class="math inline">\(H_0\)</span> is true.</li>
<li>It does not give the probability that <span
class="math inline">\(H_0\)</span> is true.</li>
</ul></li>
<li><strong>Purpose:</strong>
<ul>
<li>To assess whether the evidence is inconsistent with <span
class="math inline">\(H_0\)</span>.</li>
</ul></li>
<li><strong>Interpretation:</strong>
<ul>
<li>A small <span class="math inline">\(P\)</span>-value (e.g., <span
class="math inline">\(P &lt; 0.05\)</span>) suggests evidence against
<span class="math inline">\(H_0\)</span>, but it does not confirm <span
class="math inline">\(H_1\)</span> (the alternative hypothesis).</li>
<li>A large <span class="math inline">\(P\)</span>-value suggests
insufficient evidence to reject <span
class="math inline">\(H_0\)</span>, not that <span
class="math inline">\(H_0\)</span> is true.</li>
</ul></li>
<li><strong>Limitations:</strong>
<ul>
<li>Dependence on sample size: Large datasets may produce small <span
class="math inline">\(P\)</span>-values even for trivial effects.</li>
<li>Misinterpretation: Often misunderstood as the probability of <span
class="math inline">\(H_0\)</span> being true or false.</li>
</ul></li>
<li><strong>P-Value Example</strong></li>
</ol>
<ul>
<li><span class="math inline">\(H_0\)</span>: A new drug has no effect
(<span class="math inline">\(\mu = 0\)</span>).</li>
<li>A test yields <span class="math inline">\(P = 0.03\)</span>.
<ul>
<li>Interpretation: There is a 3% probability of observing data as
extreme as the observed, assuming <span
class="math inline">\(H_0\)</span> is true.</li>
<li>Action: Reject <span class="math inline">\(H_0\)</span> at the 5%
significance level.</li>
</ul></li>
</ul>
<p><strong>Bayes Factors (Bayesian Paradigm)</strong></p>
<p>A <strong>Bayes factor (BF)</strong> is a Bayesian measure of
evidence that compares two hypotheses, <span
class="math inline">\(H_0\)</span> (null) and <span
class="math inline">\(H_1\)</span> (alternative):</p>
<ol style="list-style-type: decimal">
<li><p><strong>Definition:</strong></p>
<ul>
<li>The ratio of the likelihood of the observed data under two competing
hypotheses: <span class="math display">\[
BF = \frac{P(\text{Data} | H_1)}{P(\text{Data} | H_0)}
\]</span></li>
</ul></li>
<li><p><strong>Purpose:</strong></p>
<ul>
<li>To quantify how much more (or less) the data supports <span
class="math inline">\(H_1\)</span> compared to <span
class="math inline">\(H_0\)</span>.</li>
</ul></li>
<li><p><strong>Interpretation:</strong></p>
<ul>
<li><span class="math inline">\(BF &gt; 1\)</span>: Evidence in favor of
<span class="math inline">\(H_1\)</span>.</li>
<li><span class="math inline">\(BF &lt; 1\)</span>: Evidence in favor of
<span class="math inline">\(H_0\)</span>.</li>
<li><span class="math inline">\(BF = 1\)</span>: Data equally supports
both hypotheses.</li>
</ul></li>
<li><p><strong>Bayes Factor Scale (Jeffreys’
interpretation):</strong></p>
<table>
<thead>
<tr class="header">
<th><strong>Bayes Factor (BF)</strong></th>
<th><strong>Evidence Strength</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(1\)</span></td>
<td>No evidence</td>
</tr>
<tr class="even">
<td><span class="math inline">\(1 - 3\)</span></td>
<td>Weak evidence for <span class="math inline">\(H_1\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(3 - 10\)</span></td>
<td>Moderate evidence for <span class="math inline">\(H_1\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(&gt; 10\)</span></td>
<td>Strong evidence for <span class="math inline">\(H_1\)</span></td>
</tr>
</tbody>
</table></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Accounts for prior beliefs (<span
class="math inline">\(P(H_0)\)</span>, <span
class="math inline">\(P(H_1)\)</span>).</li>
<li>Allows direct comparison of evidence for both hypotheses.</li>
<li>Works well with small sample sizes or complex models.</li>
</ul></li>
<li><p><strong>Bayes Factor Example</strong></p></li>
</ol>
<ul>
<li>Same <span class="math inline">\(H_0\)</span>: New drug has no
effect.</li>
<li>Bayes Factor <span class="math inline">\(BF = 5\)</span>:
<ul>
<li>Interpretation: The data are 5 times more likely under <span
class="math inline">\(H_1\)</span> (the drug has an effect) than <span
class="math inline">\(H_0\)</span>.</li>
<li>Action: Strong evidence in favor of <span
class="math inline">\(H_1\)</span>.</li>
</ul></li>
</ul>
<p><strong>Comparison: P-Values vs. Bayes Factors</strong></p>
<table>
<colgroup>
<col width="22%" />
<col width="38%" />
<col width="39%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Aspect</strong></th>
<th><strong>P-Values</strong></th>
<th><strong>Bayes Factors</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Paradigm</strong></td>
<td>Frequentist</td>
<td>Bayesian</td>
</tr>
<tr class="even">
<td><strong>Key Concept</strong></td>
<td>Probability of data given <span
class="math inline">\(H_0\)</span>.</td>
<td>Likelihood ratio of data under <span
class="math inline">\(H_1\)</span> and <span
class="math inline">\(H_0\)</span>.</td>
</tr>
<tr class="odd">
<td><strong>Prior Knowledge</strong></td>
<td>Not considered.</td>
<td>Incorporates prior beliefs.</td>
</tr>
<tr class="even">
<td><strong>Output</strong></td>
<td>Single probability value.</td>
<td>A ratio quantifying evidence.</td>
</tr>
<tr class="odd">
<td><strong>Hypotheses Comparison</strong></td>
<td>Only tests against <span class="math inline">\(H_0\)</span>.</td>
<td>Direct comparison of <span class="math inline">\(H_0\)</span> and
<span class="math inline">\(H_1\)</span>.</td>
</tr>
<tr class="even">
<td><strong>Effect of Sample Size</strong></td>
<td>Large sample size can lead to small <span
class="math inline">\(P\)</span>-values even for trivial effects.</td>
<td>Directly incorporates data strength.</td>
</tr>
<tr class="odd">
<td><strong>Interpretation</strong></td>
<td>Often misinterpreted as evidence for <span
class="math inline">\(H_1\)</span>.</td>
<td>Provides explicit evidence for one hypothesis over another.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="parameter-estimates" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Parameter
Estimates</h2>
<p>To determine a data’s probability density distribution accurately,
two main components are essential:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Form of the Probability Density Function
(PDF)</strong>:</p>
<ul>
<li>Sometimes, the form of the PDF is known (e.g., Gaussian, Rayleigh)
but the specific parameters (like mean or variance) are unknown. This
scenario requires parameter estimation based on observed data.</li>
</ul></li>
<li><p><strong>Parameters of the PDF</strong>:</p>
<ul>
<li>Other times, the type of probability density may not be known, but
some estimated parameters (like mean and variance) are available. This
information can guide the selection of an appropriate PDF.</li>
</ul></li>
</ol>
<p>In statistical modeling, estimating unknown parameters is a common
task:</p>
<ul>
<li><strong>In basic models like linear regression</strong>, the
objective is often to calculate a specific parameter vector,
<strong>W</strong>.</li>
<li><strong>In Bayesian models</strong>, instead of calculating a point
estimate of <strong>W</strong>, the focus shifts to determining the
distribution of <strong>W</strong>. This distribution is then used to
predict outcomes (e.g., <strong>p(y|x, D)</strong>), incorporating all
possible values of <strong>W</strong>.</li>
</ul>
<p>Bayesian models are complex because they consider a distribution of
parameter values rather than a single point estimate. This complexity
often necessitates sophisticated computational techniques:</p>
<ul>
<li><strong>Markov Chain Monte Carlo (MCMC)</strong>: This technique is
used instead of direct optimization methods to integrate over possible
parameter values (all possible <strong>W</strong> vectors)
effectively.</li>
</ul>
<p>As more data is observed, Bayesian models provide clearer inference
about the distribution of parameters, known as <strong>posterior
inference</strong>. This approach contrasts with other predictive
strategies:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Maximum Likelihood Estimation (MLE)</strong>:</p>
<ul>
<li>This is a point estimation method that finds the parameter values
which maximize the likelihood of observing the given data. It does not
consider prior knowledge about parameter values.</li>
</ul></li>
<li><p><strong>Maximum a Posteriori (MAP)</strong>:</p>
<ul>
<li>Also a point estimation method, MAP considers both the likelihood of
the observed data and a prior distribution of the parameters. It
calculates the mode of the posterior distribution.</li>
</ul></li>
<li><p><strong>Bayesian Model</strong>:</p>
<ul>
<li>This method estimates the distribution of parameters rather than a
single point. It provides a full probabilistic description of parameter
uncertainty, making it more robust against overfitting and more
informative for decision-making.</li>
</ul></li>
</ol>
<p><strong>Comparison and Applications</strong></p>
<ul>
<li><strong>MLE</strong> is often simpler and computationally faster but
can be biased if the model assumptions are incorrect.</li>
<li><strong>MAP</strong> incorporates prior beliefs into the estimation
process, providing regularization that can lead to more robust estimates
in the presence of limited data.</li>
<li><strong>Bayesian Models</strong> are the most comprehensive,
considering a range of possible parameter values. This approach is
particularly beneficial in complex systems where the uncertainty in
model parameters needs to be quantified and propagated through to
predictions.</li>
</ul>
<div id="a.-maximum-likelihood-estimation-mle"
class="section level3 unnumbered">
<h3 class="unnumbered">a. Maximum Likelihood Estimation (MLE)</h3>
<p><strong>1. Concept of MLE:</strong></p>
<ul>
<li>MLE is a method used to determine the parameters of a statistical
model that make the observed data most probable. The goal is to find the
parameter values that maximize the likelihood function, which represents
the probability of the observed data given those parameter values.</li>
</ul>
<p><strong>2. Assumptions in MLE:</strong></p>
<ul>
<li><strong>Homogeneity</strong>: Assumes that subsets of data from
different categories (such as different classes or groups) share the
same type of probability density function but differ in parameter
values.</li>
<li><strong>Independence between Categories</strong>: Assumes that data
in one category are independently sampled from those in another, meaning
the parameter estimation for one category doesn’t affect another.</li>
<li><strong>Statistical Independence within Categories</strong>: Assumes
that samples within each category are independently and identically
distributed (iid).</li>
</ul>
<p><strong>3. Formulation:</strong></p>
<ul>
<li>Given a random sample <span class="math inline">\(x_1, x_2, \ldots,
x_N\)</span> from a probability density function <span
class="math inline">\(p(x;\theta)\)</span>, the joint probability
density function of the sample is given by: <span
class="math display">\[
p(X;\theta) = \prod_{k=1}^N p(x_k;\theta)
\]</span></li>
<li>The MLE <span class="math inline">\(\hat{\theta}_{ML}\)</span> is
obtained by maximizing this product: <span class="math display">\[
\hat{\theta}_{ML} = \arg \max_{\theta} \prod_{k=1}^N p(x_k;\theta)
\]</span></li>
<li>Typically, this optimization is performed on the log-likelihood
function <span class="math inline">\(L(\theta)\)</span> to simplify
calculations: <span class="math display">\[
L(\theta) = \ln \prod_{k=1}^N p(x_k;\theta) = \sum_{k=1}^N \ln
p(x_k;\theta)
\]</span> <span class="math display">\[
\frac{\partial L(\theta)}{\partial \theta} = \sum_{k=1}^N \frac{\partial
\ln p(x_k;\theta)}{\partial \theta} = \sum_{k=1}^N
\frac{1}{p(x_k;\theta)} \frac{\partial p(x_k;\theta)}{\partial \theta} =
0
\]</span></li>
</ul>
<p><strong>4. Properties of MLE:</strong></p>
<ul>
<li><strong>Asymptotic Unbiasedness</strong>: As the sample size <span
class="math inline">\(N\)</span> approaches infinity, the expected value
of the MLE converges to the true parameter value <span
class="math inline">\(\theta_0\)</span>: <span class="math display">\[
\lim_{N \to \infty} E[\hat{\theta}_{ML}] = \theta_0
\]</span></li>
<li><strong>Asymptotic Consistency</strong>: As the sample size
increases, the probability that the MLE differs from the true parameter
value by more than any small positive number <span
class="math inline">\(\epsilon\)</span> approaches zero: <span
class="math display">\[
\lim_{N \to \infty} \Pr\{ \|\hat{\theta}_{ML} - \theta_0\| \leq \epsilon
\} = 1
\]</span> <span class="math display">\[
\lim_{N \to \infty} E\| \hat{\theta}_{ML} - \theta_0 \|^2 = 0
\]</span></li>
<li>These properties ensure that the estimator is reliable as the amount
of data increases.</li>
</ul>
<p><strong>5. Limitations:</strong></p>
<ul>
<li>MLE can be prone to overfitting when the dataset is small because it
maximizes the probability of observing the data without considering
model complexity or penalizing for it.</li>
</ul>
</div>
<div id="b.-maximum-a-posteriori-estimation-map"
class="section level3 unnumbered">
<h3 class="unnumbered">b. Maximum a Posteriori Estimation (MAP)</h3>
<ul>
<li><strong>MLE</strong> treats the parameter <span
class="math inline">\(\theta\)</span> as an unknown fixed value that
needs to be estimated from the data.</li>
<li>The goal of MLE is to find the value of <span
class="math inline">\(\theta\)</span> that maximizes the likelihood
function <span class="math inline">\(p(X; \theta)\)</span>, which is the
probability of observing the data given the parameter.</li>
</ul>
<p><strong>MAP Concept and Methodology:</strong></p>
<ul>
<li><strong>MAP</strong> considers the parameter <span
class="math inline">\(\theta\)</span> as a random variable with a prior
distribution <span class="math inline">\(p(\theta)\)</span>, reflecting
prior beliefs about the possible values of <span
class="math inline">\(\theta\)</span>.</li>
<li>Unlike MLE, MAP estimates <span
class="math inline">\(\theta\)</span> by maximizing the posterior
distribution <span class="math inline">\(p(\theta | X)\)</span> rather
than just the likelihood: <span class="math display">\[
p(\theta|X) = \frac{p(\theta) p(X|\theta)}{p(X)}
\]</span></li>
<li>The MAP estimate <span
class="math inline">\(\hat{\theta}_{MAP}\)</span> is given by: <span
class="math display">\[
\hat{\theta}_{MAP} = \arg \max_{\theta} p(\theta) p(X|\theta)
\]</span></li>
<li>In the optimization, the marginal likelihood <span
class="math inline">\(p(X)\)</span> does not affect the location of the
maximum since it does not depend on <span
class="math inline">\(\theta\)</span>.</li>
</ul>
<p><strong>Differences:</strong></p>
<ul>
<li><strong>Prior Influence:</strong> MLE does not incorporate a prior
distribution, treating <span class="math inline">\(\theta\)</span> as a
fixed but unknown quantity. MAP, on the other hand, explicitly includes
a prior distribution, which can significantly influence the estimate
especially when the sample size is small or the prior is strong
(informative).</li>
<li><strong>Resulting Estimates:</strong> For non-informative or flat
priors, MAP results converge to MLE results. However, with informative
priors, MAP can yield different estimates from MLE, depending on the
strength and nature of the prior.</li>
<li>As the sample size increases, the influence of the prior in MAP
diminishes, aligning MAP estimates more closely with MLE estimates,
reflecting the dominance of the data over the prior.</li>
</ul>
</div>
<div id="c.-bayesian-model" class="section level3 unnumbered">
<h3 class="unnumbered">c. Bayesian Model</h3>
<p>Bayesian modeling distinguishes itself by considering the entire
distribution of the data <span class="math inline">\(X\)</span> and the
parameters <span class="math inline">\(\theta\)</span> instead of just
optimizing parameter values based on a given sample set <span
class="math inline">\(X\)</span>. This approach naturally helps prevent
overfitting by integrating over all possible parameter values rather
than selecting a single optimal set.</p>
<ol style="list-style-type: decimal">
<li><strong>Sample Set and Parameters</strong>:
<ul>
<li>The data sample set is denoted as <span
class="math inline">\(D\)</span> (previously <span
class="math inline">\(X\)</span>) to avoid notation confusion. Samples
in <span class="math inline">\(D\)</span> are assumed to be
independently drawn from an unknown but fixed probability density
function <span class="math inline">\(p(x)\)</span>.</li>
</ul></li>
<li><strong>Bayesian Estimation Problem</strong>:
<ul>
<li>The core problem in Bayesian estimation is to estimate the
probability distribution <span class="math inline">\(p(x|D)\)</span>,
making it as close as possible to the true distribution <span
class="math inline">\(p(x)\)</span>. This involves calculating the
distribution of <span class="math inline">\(x\)</span> given the data
<span class="math inline">\(D\)</span>, rather than finding a single
optimized value for <span class="math inline">\(x\)</span>.</li>
</ul></li>
<li><strong>Conditional Probability Density Function <span
class="math inline">\(p(x|\theta)\)</span></strong>:
<ul>
<li><span class="math inline">\(p(x|\theta)\)</span> is assumed to be
known in form but with unknown parameters <span
class="math inline">\(\theta\)</span>. It represents the likelihood
estimation of <span class="math inline">\(\theta\)</span> at the point
<span class="math inline">\(x\)</span>.</li>
</ul></li>
<li><strong>Prior and Posterior Distributions</strong>:
<ul>
<li><strong>Prior Distribution <span
class="math inline">\(p(\theta)\)</span></strong>: Represents all prior
knowledge about <span class="math inline">\(\theta\)</span> before
observing any data, expressed through a probability density
function.</li>
<li><strong>Posterior Distribution <span
class="math inline">\(p(\theta|D)\)</span></strong>: Updated belief
about <span class="math inline">\(\theta\)</span> after observing the
data <span class="math inline">\(D\)</span>. It is obtained by
transforming the prior based on the new data: <span
class="math display">\[
p(\theta|D) = \frac{p(D|\theta)p(\theta)}{\int
p(D|\theta)p(\theta)d\theta}
\]</span> where <span class="math inline">\(p(D|\theta) = \prod_{k=1}^N
p(x_k|\theta)\)</span>, assuming independence among the sampled data
points.</li>
</ul></li>
<li><strong>Bayesian Estimation Formula</strong>:
<ul>
<li>The core Bayesian estimation problem <span
class="math inline">\(p(x|D)\)</span> is resolved using the integral
over the joint distribution of <span class="math inline">\(x\)</span>
and <span class="math inline">\(\theta\)</span>: <span
class="math display">\[
p(x|D) = \int p(x|\theta)p(\theta|D)d\theta
\]</span></li>
<li>Here, <span class="math inline">\(p(x|\theta)\)</span> is the
likelihood of <span class="math inline">\(x\)</span> under <span
class="math inline">\(\theta\)</span>, and <span
class="math inline">\(p(\theta|D)\)</span> is the posterior distribution
of <span class="math inline">\(\theta\)</span> after observing <span
class="math inline">\(D\)</span>.</li>
</ul></li>
</ol>
<p><strong>Advantages of Bayesian Modeling</strong></p>
<ul>
<li><strong>Comprehensive Parameter Estimation</strong>: By integrating
over all possible values of <span class="math inline">\(\theta\)</span>,
Bayesian models provide a more holistic view of parameter
uncertainty.</li>
<li><strong>Prevention of Overfitting</strong>: The use of prior
distributions and the consideration of all possible parameter values
help in regularizing the model, thus preventing overfitting.</li>
<li><strong>Flexibility and Robustness</strong>: Bayesian models are
adaptable to new data, allowing continuous updating of beliefs about
parameters as more data become available.</li>
</ul>
</div>
</div>
<div id="predictions" class="section level2" number="1.7">
<h2><span class="header-section-number">1.7</span> Predictions</h2>
<p><strong>Making predictions</strong> is a central goal of statistical
modeling. In the <strong>Bayesian framework</strong>, predictions are
straightforward and intuitively built upon the prior and posterior
distributions.</p>
<div id="predictive-distribution-in-the-bayesian-framework"
class="section level3 unnumbered">
<h3 class="unnumbered">Predictive Distribution in the Bayesian
Framework</h3>
<p>Suppose you have observed some data <span
class="math inline">\(y\)</span> and wish to predict future observations
<span class="math inline">\(x\)</span>. The <strong>predictive
distribution</strong> is:</p>
<p><span class="math display">\[
p(x \mid y) = \int p(x \mid \theta) \cdot p(\theta \mid y) \, d\theta
\]</span></p>
<p>This is a <strong>weighted average of the sampling
distribution</strong> <span class="math inline">\(p(x \mid
\theta)\)</span> over the <strong>posterior distribution</strong> of the
parameter <span class="math inline">\(\theta\)</span>. It accounts for
both:</p>
<ul>
<li>Uncertainty in the future data (given <span
class="math inline">\(\theta\)</span>)</li>
<li>Uncertainty in the parameter <span
class="math inline">\(\theta\)</span> itself</li>
</ul>
<p>If <span class="math inline">\(x\)</span> and <span
class="math inline">\(y\)</span> are conditionally independent given
<span class="math inline">\(\theta\)</span>, then:</p>
<p><span class="math display">\[
p(x \mid y) = \int p(x \mid \theta) \cdot p(\theta \mid y) \, d\theta
\]</span></p>
<p>This integration provides a <strong>posterior predictive
distribution</strong>, useful for:</p>
<ul>
<li>Power calculations</li>
<li>Interim monitoring</li>
<li>Decision-making in health economics or clinical trial design</li>
</ul>
</div>
<div id="predictions-for-binary-data" class="section level3 unnumbered">
<h3 class="unnumbered">Predictions for Binary Data</h3>
<p>Suppose:</p>
<ul>
<li>The unknown success rate is <span
class="math inline">\(\theta\)</span></li>
<li>The prior or posterior distribution of <span
class="math inline">\(\theta\)</span> has a mean <span
class="math inline">\(\mu\)</span></li>
<li>You plan to observe <span class="math inline">\(n\)</span> new
Bernoulli trials</li>
</ul>
<p>Then:</p>
<ul>
<li><p>The <strong>expected number of successes</strong> is:</p>
<p><span class="math display">\[
E(Y_n) = n \cdot \mu
\]</span></p></li>
<li><p>For a <strong>single future trial</strong>, the predicted
probability of success is simply the current mean:</p>
<p><span class="math display">\[
P(Y = 1) = E(\theta)
\]</span></p></li>
</ul>
<p>If your current distribution for <span
class="math inline">\(\theta\)</span> is <strong>Beta[a, b]</strong>,
the <strong>predictive distribution</strong> for the number of future
successes <span class="math inline">\(Y_n\)</span> follows a
<strong>beta-binomial distribution</strong>:</p>
<p><span class="math display">\[
p(y_n) = \binom{n}{y_n} \cdot \frac{B(a + y_n, b + n - y_n)}{B(a, b)}
\]</span></p>
<p>Where <span class="math inline">\(B(a, b)\)</span> is the Beta
function.</p>
<p>Key properties:</p>
<ul>
<li><p>Mean:</p>
<p><span class="math display">\[
E(Y_n) = n \cdot \frac{a}{a + b}
\]</span></p></li>
<li><p>Variance:</p>
<p><span class="math display">\[
V(Y_n) = n \cdot \frac{ab}{(a + b)^2} \cdot \frac{a + b + n}{a + b + 1}
\]</span></p></li>
</ul>
<p><strong>Laplace’s Law of Succession</strong> is a special case: if
all <span class="math inline">\(m\)</span> past outcomes were successes
and the prior is uniform (Beta[1, 1]), the posterior becomes Beta[m+1,
1], and the predicted success probability for the next trial is:</p>
<p><span class="math display">\[
P(Y = 1) = \frac{m + 1}{m + 2}
\]</span></p>
<hr />
<p><strong>Example: Drug Trial Prediction (Binary)</strong></p>
<ul>
<li>Prior: Beta[9.2, 13.8]</li>
<li>Data: 15 successes in 20 trials</li>
<li>Posterior: Beta[24.2, 18.8], with mean 0.56</li>
</ul>
<p>Now suppose you want to predict the number of successes in <strong>40
future patients</strong>. The prediction follows a beta-binomial
distribution with:</p>
<ul>
<li>Mean ≈ 22.5</li>
<li>Standard deviation ≈ 4.3</li>
</ul>
<p>If your decision rule is to continue development <strong>only if at
least 25 out of 40</strong> are successful, the <strong>posterior
predictive probability</strong> of this happening is:</p>
<p><span class="math display">\[
P(Y \geq 25) \approx 0.329
\]</span></p>
<p>This probability can be computed by summing the right-hand tail of
the beta-binomial.</p>
</div>
<div id="predictions-for-normal-data" class="section level3 unnumbered">
<h3 class="unnumbered">Predictions for Normal Data</h3>
<p>Suppose:</p>
<ul>
<li><p>You’re predicting future data <span
class="math inline">\(Y_n\)</span> which is assumed to follow:</p>
<p><span class="math display">\[
Y_n \sim N(\theta, \sigma^2/n)
\]</span></p></li>
<li><p>The parameter <span class="math inline">\(\theta\)</span> itself
has a <strong>prior</strong>:</p>
<p><span class="math display">\[
\theta \sim N(\mu, \sigma^2/n_0)
\]</span></p></li>
</ul>
<p>Then the <strong>predictive distribution</strong> for <span
class="math inline">\(Y_n\)</span> is:</p>
<p><span class="math display">\[
Y_n \sim N\left(\mu, \sigma^2 \left(\frac{1}{n} +
\frac{1}{n_0}\right)\right)
\]</span></p>
<p>The <strong>mean</strong> of the predictive distribution is the prior
mean <span class="math inline">\(\mu\)</span>, and the
<strong>variance</strong> reflects both the sampling error of future
data and the uncertainty in the parameter estimate.</p>
<p>If you already observed data <span
class="math inline">\(y_m\)</span>, and now have a
<strong>posterior</strong>:</p>
<p><span class="math display">\[
\theta \sim N\left(\frac{n_0 \mu + m y_m}{n_0 + m}, \frac{\sigma^2}{n_0
+ m}\right)
\]</span></p>
<p>Then the <strong>updated predictive distribution</strong>
becomes:</p>
<p><span class="math display">\[
Y_n \sim N\left(\frac{n_0 \mu + m y_m}{n_0 + m},
\sigma^2\left(\frac{1}{n_0 + m} + \frac{1}{n}\right)\right)
\]</span></p>
<p>This means we’re more confident in our prediction when:</p>
<ul>
<li>The prior is strong (large <span
class="math inline">\(n_0\)</span>)</li>
<li>We have more data (large <span
class="math inline">\(m\)</span>)</li>
<li>The future sample is large (large <span
class="math inline">\(n\)</span>)</li>
</ul>
<hr />
<p><strong>Example: The GREAT Study (Normal Prediction)</strong></p>
<p>Goal: Predict log(OR) for 100 future patients in each trial arm.</p>
<ul>
<li><p>Observed mortality ~10% ⇒ around 20 events</p></li>
<li><p>Prior + data ⇒ posterior for log(OR): <span
class="math inline">\(N(-0.31, \sigma^2/267.2)\)</span></p></li>
<li><p>Predictive variance:</p>
<p><span class="math display">\[
\sigma^2 \left(\frac{1}{267.2} + \frac{1}{20}\right) = \sigma^2/18.6
\Rightarrow \text{SD} ≈ 0.462
\]</span></p></li>
</ul>
<p>Without prior (flat prior):</p>
<ul>
<li><p>Posterior becomes likelihood-based only: <span
class="math inline">\(N(-0.74, \sigma^2/30.5)\)</span></p></li>
<li><p>Predictive variance becomes:</p>
<p><span class="math display">\[
\sigma^2 \left(\frac{1}{30.5} + \frac{1}{20}\right) = \sigma^2/12.1
\Rightarrow \text{SD} ≈ 0.582
\]</span></p></li>
</ul>
<p>This shows:</p>
<ul>
<li>Predictions based solely on data are more uncertain</li>
<li>Including prior reduces predictive variance and shifts the mean</li>
</ul>
<p><strong>Probability of achieving OR &lt; 0.5 in the
future:</strong></p>
<ul>
<li>With prior: 21%</li>
<li>Without prior: 53%</li>
</ul>
<p>This demonstrates how prior beliefs can significantly influence
<strong>posterior predictive probabilities</strong>, especially in small
or uncertain samples.</p>
</div>
</div>
</div>
<div id="prior-distribution-1" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Prior Distribution</h1>
<div
id="sampling-distributions-likelihood-and-prior-distributions-beliefs-about-parameters"
class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Sampling
Distributions (Likelihood) and Prior Distributions (Beliefs about
Parameters)</h2>
<p>These describe how the <strong>data</strong> are generated given
certain parameters. They are foundational to both classical and Bayesian
statistics, as they provide the <strong>likelihood function</strong> —
the probability of observing the data given specific parameter
values.</p>
<ul>
<li><p><strong>Standard distributions</strong> often used:</p>
<ul>
<li><strong>Normal distribution</strong> – commonly used for continuous
data, assumes symmetry and homoscedasticity.</li>
<li><strong>Binomial distribution</strong> – used for binary or
success/failure data (e.g., number of heads in coin tosses).</li>
<li><strong>Poisson distribution</strong> – used for count data (e.g.,
number of events in a time interval).</li>
</ul></li>
<li><p><strong>Non-standard distributions</strong>:</p>
<ul>
<li><strong>Log-normal distribution</strong> – used especially for
<strong>cost or income data</strong>, where values are strictly positive
and typically skewed.</li>
</ul></li>
</ul>
<p>In Bayesian analysis, selecting an appropriate sampling distribution
is critical because it influences how information from the observed data
is incorporated.</p>
<p>Prior Distributions (Beliefs about Parameters) represent our
<strong>beliefs about parameter values</strong> <em>before</em>
observing the data. This is where Bayesian methods diverge significantly
from classical methods.</p>
<ul>
<li><p>The <strong>shape of the prior</strong> is crucial, as it
reflects the plausibility of different parameter values. It needs to
be:</p>
<ul>
<li><p><strong>Flexible</strong> to represent various forms of
uncertainty</p></li>
<li><p>Capable of expressing features like:</p>
<ul>
<li><strong>Skewness</strong> (asymmetric beliefs)</li>
<li><strong>Heavy tails</strong> (more weight on extreme values)</li>
</ul></li>
</ul></li>
<li><p>Common prior distributions:</p>
<ul>
<li><strong>Normal distribution</strong> – often used due to its
simplicity and analytic convenience.</li>
<li><strong>Beta distribution</strong> – bounded between 0 and 1, ideal
for parameters like probabilities.</li>
<li><strong>Root-inverse-gamma</strong> – used particularly in
hierarchical models or for variances.</li>
<li><strong>Half-normal</strong> – used for strictly positive
parameters, such as standard deviations.</li>
</ul></li>
</ul>
<table>
<colgroup>
<col width="10%" />
<col width="9%" />
<col width="42%" />
<col width="15%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Support</th>
<th>PDF / PMF</th>
<th>Mean</th>
<th>Variance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binomial</td>
<td>y ∈ {0, …, n}</td>
<td>P(Y=y) = C(n, y) θ^y (1−θ)^(n−y)</td>
<td>nθ</td>
<td>nθ(1−θ)</td>
</tr>
<tr class="even">
<td>Bernoulli</td>
<td>y ∈ {0, 1}</td>
<td>P(Y=1)=θ, P(Y=0)=1−θ</td>
<td>θ</td>
<td>θ(1−θ)</td>
</tr>
<tr class="odd">
<td>Poisson</td>
<td>y ∈ {0, 1, 2, …}</td>
<td>P(Y=y) = λ^y e^(−λ) / y!</td>
<td>λ</td>
<td>λ</td>
</tr>
<tr class="even">
<td>Beta</td>
<td>y ∈ (0, 1)</td>
<td>f(y) = [Γ(a+b)/(Γ(a)Γ(b))] y<sup>(a−1)(1−y)</sup>(b−1)</td>
<td>a / (a + b)</td>
<td>ab / [(a + b)^2 (a + b + 1)]</td>
</tr>
<tr class="odd">
<td>Uniform</td>
<td>y ∈ (a, b)</td>
<td>f(y) = 1 / (b − a)</td>
<td>(a + b)/2</td>
<td>(b − a)^2 / 12</td>
</tr>
<tr class="even">
<td>Gamma</td>
<td>y &gt; 0</td>
<td>f(y) = (b^a / Γ(a)) y^(a−1) e^(−by)</td>
<td>a / b</td>
<td>a / b²</td>
</tr>
<tr class="odd">
<td>Root-Inverse-Gamma</td>
<td>y &gt; 0</td>
<td>f(y) = [2b^a / Γ(a)] × y^(−2a−1) × exp(−b / y²)</td>
<td>√b × Γ(a−½)/Γ(a)</td>
<td>b / (a − 1) − [E(Y)]² (defined if a &gt; 1)</td>
</tr>
<tr class="even">
<td>Half-Normal</td>
<td>y &gt; 0</td>
<td>f(y) = √(2 / πσ²) × exp(−y² / (2σ²))</td>
<td>σ√(2/π)</td>
<td>σ² (1 − 2/π)</td>
</tr>
<tr class="odd">
<td>Log-Normal</td>
<td>y &gt; 0</td>
<td>f(y) = (1 / y√(2πσ²)) × exp(−(log y − μ)² / (2σ²))</td>
<td>e^(μ + σ² / 2)</td>
<td>e^(2μ + σ²)(e^σ² − 1)</td>
</tr>
<tr class="even">
<td>Student’s t</td>
<td>y ∈ ℝ</td>
<td>f(y) ∝ [1 + (y−μ)² / (νσ²)]^(−(ν+1)/2)</td>
<td>μ (if ν &gt; 1)</td>
<td>(νσ²) / (ν − 2) (defined if ν &gt; 2)</td>
</tr>
<tr class="odd">
<td>Bivariate Normal</td>
<td>(x, y) ∈ ℝ²</td>
<td>f(x,y) = 1 / (2πσ_Xσ_Y√(1−ρ²)) × exp(−Q / [2(1−ρ²)])</td>
<td>(μ_X, μ_Y)</td>
<td>Var(Y</td>
</tr>
</tbody>
</table>
<hr />
<div id="binomial-and-bernoulli-distributions"
class="section level3 unnumbered">
<h3 class="unnumbered">Binomial and Bernoulli Distributions</h3>
<p>A binomial distribution models the number of successes in <span
class="math inline">\(n\)</span> independent trials, each with success
probability <span class="math inline">\(\theta\)</span>. If <span
class="math inline">\(Y \sim \text{Binomial}(n, \theta)\)</span>,
then:</p>
<ul>
<li><p>Probability mass function (pmf):</p>
<p><span class="math display">\[
P(Y = y) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}, \quad y = 0, 1,
\dots, n
\]</span></p></li>
<li><p>Mean:</p>
<p><span class="math display">\[
E(Y) = n\theta
\]</span></p></li>
<li><p>Variance:</p>
<p><span class="math display">\[
\text{Var}(Y) = n\theta(1 - \theta)
\]</span></p></li>
</ul>
<p>If <span class="math inline">\(n = 1\)</span>, the binomial becomes a
<strong>Bernoulli distribution</strong>.</p>
<p>This delve into the application of Bayesian statistics for
Poisson-distributed data using a Gamma distribution as a conjugate
prior. This scenario is commonly encountered in settings where the data
consists of counts or events that follow a Poisson process, and the
prior information about the event rate (λ, lambda) is modeled using a
Gamma distribution.</p>
<p><strong>Context and Setup</strong></p>
<ul>
<li><strong>Bernoulli Distribution</strong>: This is used to model
binary data, where each trial has two possible outcomes, typically
represented as 0 or 1. In the context given, each trial (or observation)
can result in success (1) or failure (0).</li>
<li><strong>Beta Distribution for Prior</strong>: The Beta distribution
is commonly used as a prior in Bayesian analysis for binomial and
Bernoulli distributions due to its conjugate properties. The Beta
distribution is parameterized by two positive shape parameters, α
(alpha) and β (beta), which represent prior knowledge about the
probability of success in Bernoulli trials.</li>
</ul>
<p><strong>Mathematical Formulation</strong></p>
<ul>
<li>The likelihood of observing a particular set of Bernoulli data given
a probability of success θ is: <span class="math display">\[
p(X|\theta) = \theta^{\sum x_i} (1-\theta)^{n - \sum x_i}
\]</span> where <span class="math inline">\(\sum x_i\)</span> is the
total number of successes, and <span class="math inline">\(n\)</span> is
the total number of trials.</li>
<li>The conjugate prior for θ in this scenario is a Beta distribution:
<span class="math display">\[
p(\theta) \propto \theta^{\alpha - 1} (1-\theta)^{\beta - 1}
\]</span></li>
<li>The posterior distribution, after observing the data, remains a Beta
distribution: <span class="math display">\[
p(\theta|X) = \text{Beta}(\alpha + \sum x_i, \beta + n - \sum x_i)
\]</span> This formula shows that the parameters of the Beta
distribution are updated by adding the number of successes to α and the
number of failures to β.</li>
</ul>
<p><img
src="02_Plots/Bayesian/Bayer_Distribution_Bernoulli.PNG" /></p>
<p><strong>Statistical Inference</strong></p>
<ul>
<li><strong>Posterior Mean</strong>: The expectation of the posterior
distribution <span class="math inline">\(\theta|X\)</span> can be
estimated as: <span class="math display">\[
E[\theta|X] = \frac{\alpha + \sum x_i}{\alpha + \beta + n}
\]</span> This represents a weighted average between the prior belief
and the observed data, where the influence of the prior diminishes as
more data is collected.</li>
<li><strong>Practical Example</strong>: Suppose a prior belief models
the probability of success as somewhat uncertain but leaning towards
being less likely (e.g., <span class="math inline">\(\alpha = 2, \beta =
18\)</span>). After observing 15 successes out of 20 trials, the
posterior parameters would be updated to <span
class="math inline">\(\alpha&#39; = 2+15 = 17\)</span> and <span
class="math inline">\(\beta&#39; = 18+5 = 23\)</span>. The posterior
distribution would then be Beta(17, 23).</li>
</ul>
<hr />
</div>
<div id="poisson-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Poisson Distribution</h3>
<p>Models the number of events in a fixed interval when events happen
independently and at a constant rate <span
class="math inline">\(\lambda\)</span>. If <span class="math inline">\(Y
\sim \text{Poisson}(\lambda)\)</span>, then:</p>
<ul>
<li><p>Probability mass function:</p>
<p><span class="math display">\[
P(Y = y) = \frac{\lambda^y e^{-\lambda}}{y!}, \quad y = 0, 1, 2, \dots
\]</span></p></li>
<li><p>Mean:</p>
<p><span class="math display">\[
E(Y) = \lambda
\]</span></p></li>
<li><p>Variance:</p>
<p><span class="math display">\[
\text{Var}(Y) = \lambda
\]</span></p></li>
</ul>
<p>This delve into the application of Bayesian statistics for
Poisson-distributed data using a Gamma distribution as a conjugate
prior. This scenario is commonly encountered in settings where the data
consists of counts or events that follow a Poisson process, and the
prior information about the event rate (λ, lambda) is modeled using a
Gamma distribution.</p>
<ol style="list-style-type: decimal">
<li><strong>Poisson Distribution</strong>:
<ul>
<li>The Poisson distribution is used to model the probability of a given
number of events happening in a fixed interval of time or space, given
the average number of events (rate λ).</li>
<li>The likelihood function for observing data <span
class="math inline">\(y = (y_1, y_2, \dots, y_n)\)</span> under a
Poisson model is: <span class="math display">\[
p(y|\lambda) = \prod_{i=1}^n \frac{\lambda^{y_i} e^{-\lambda}}{y_i!}
\]</span></li>
</ul></li>
<li><strong>Gamma Distribution as a Conjugate Prior</strong>:
<ul>
<li>The Gamma distribution is a suitable choice as a conjugate prior for
λ in Poisson models because it results in a posterior distribution that
is also a Gamma, facilitating computational ease and analytical
tractability.</li>
<li>The Gamma distribution is parameterized by a shape parameter (α,
alpha) and a rate parameter (β, beta), with the probability density
function given by: <span class="math display">\[
p(\lambda) = \frac{\beta^\alpha}{\Gamma(\alpha)} \lambda^{\alpha-1}
e^{-\beta \lambda}
\]</span></li>
</ul></li>
<li><strong>Posterior Distribution</strong>:
<ul>
<li>By Bayes’ theorem, the posterior distribution of λ after observing
data <span class="math inline">\(y\)</span> combines the prior and the
likelihood, yielding another Gamma distribution: <span
class="math display">\[
p(\lambda|y) \propto p(y|\lambda) p(\lambda) = \text{Gamma}(\alpha +
\sum y_i, \beta + n)
\]</span></li>
<li>Here, <span class="math inline">\(\sum y_i\)</span> is the sum of
the observed counts, and <span class="math inline">\(n\)</span> is the
number of observations or trials.</li>
</ul></li>
</ol>
<p><img src="02_Plots/Bayesian/Bayer_Distribution_Poisson.PNG" /></p>
<p><strong>Example Illustration</strong></p>
<ul>
<li><p>Suppose we have a set of counts over ten time periods, and we
assume that these counts are Poisson-distributed with an unknown rate λ.
Using a Gamma prior for λ with parameters α = 1 and β = 1, we
incorporate the observed data to update these parameters.</p></li>
<li><p>After observing the data, the posterior parameters become:</p>
<ul>
<li>New alpha (α’): α + sum of observed counts</li>
<li>New beta (β’): β + number of observations</li>
</ul></li>
<li><p>If the observed counts sum to 77 over 10 periods, the posterior
distribution for λ becomes:</p>
<ul>
<li>Alpha: 1 + 77 = 78</li>
<li>Beta: 1 + 10 = 11</li>
<li>Resulting in a posterior distribution Gamma(78, 11).</li>
</ul></li>
</ul>
<hr />
</div>
<div id="beta-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Beta Distribution</h3>
<p>Defined on the interval <span class="math inline">\((0, 1)\)</span>,
flexible for modeling probabilities. If <span class="math inline">\(Y
\sim \text{Beta}(a, b)\)</span>, then:</p>
<ul>
<li><p>Probability density function (pdf):</p>
<p><span class="math display">\[
f(y) = \frac{\Gamma(a + b)}{\Gamma(a)\Gamma(b)} y^{a - 1} (1 - y)^{b -
1}, \quad 0 &lt; y &lt; 1
\]</span></p></li>
<li><p>Mean:</p>
<p><span class="math display">\[
E(Y) = \frac{a}{a + b}
\]</span></p></li>
<li><p>Variance:</p>
<p><span class="math display">\[
\text{Var}(Y) = \frac{ab}{(a + b)^2(a + b + 1)}
\]</span></p></li>
</ul>
<hr />
</div>
<div id="uniform-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Uniform Distribution</h3>
<p>Models equal probability over an interval <span
class="math inline">\((a, b)\)</span>. If <span class="math inline">\(Y
\sim \text{Uniform}(a, b)\)</span>, then:</p>
<ul>
<li><p>Probability density function:</p>
<p><span class="math display">\[
f(y) = \frac{1}{b - a}, \quad a &lt; y &lt; b
\]</span></p></li>
<li><p>Mean:</p>
<p><span class="math display">\[
E(Y) = \frac{a + b}{2}
\]</span></p></li>
<li><p>Variance:</p>
<p><span class="math display">\[
\text{Var}(Y) = \frac{(b - a)^2}{12}
\]</span></p></li>
</ul>
<hr />
</div>
<div id="gamma-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Gamma Distribution</h3>
<p>Defined on <span class="math inline">\((0, \infty)\)</span>, often
used for modeling rates or waiting times. If <span
class="math inline">\(Y \sim \text{Gamma}(a, b)\)</span> with shape
<span class="math inline">\(a\)</span> and rate <span
class="math inline">\(b\)</span>, then:</p>
<ul>
<li><p>Probability density function:</p>
<p><span class="math display">\[
f(y) = \frac{b^a}{\Gamma(a)} y^{a - 1} e^{-b y}, \quad y &gt; 0
\]</span></p></li>
<li><p>Mean:</p>
<p><span class="math display">\[
E(Y) = \frac{a}{b}
\]</span></p></li>
<li><p>Variance:</p>
<p><span class="math display">\[
\text{Var}(Y) = \frac{a}{b^2}
\]</span></p></li>
</ul>
<hr />
</div>
<div id="root-inverse-gamma-distribution"
class="section level3 unnumbered">
<h3 class="unnumbered">Root-Inverse-Gamma Distribution</h3>
<p>If <span class="math inline">\(X \sim \text{Gamma}(a, b)\)</span>,
then <span class="math inline">\(Y = \frac{1}{\sqrt{X}} \sim
\text{RIG}(a, b)\)</span>. Then:</p>
<ul>
<li><p>Probability density function:</p>
<p><span class="math display">\[
f(y) = \frac{2b^a}{\Gamma(a)} \cdot \frac{1}{y^{2a + 1}} \exp\left(
-\frac{b}{y^2} \right), \quad y &gt; 0
\]</span></p></li>
<li><p>Mean (if <span class="math inline">\(a &gt;
\tfrac{1}{2}\)</span>):</p>
<p><span class="math display">\[
E(Y) = \sqrt{b} \cdot \frac{\Gamma(a - \tfrac{1}{2})}{\Gamma(a)}
\]</span></p></li>
<li><p>Variance (if <span class="math inline">\(a &gt; 1\)</span>):</p>
<p><span class="math display">\[
\text{Var}(Y) = \frac{b}{a - 1} - \left( E(Y) \right)^2
\]</span></p></li>
</ul>
<hr />
</div>
<div id="half-normal-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Half-Normal Distribution</h3>
<p>If <span class="math inline">\(X \sim \mathcal{N}(0,
\sigma^2)\)</span>, then <span class="math inline">\(Y = |X| \sim
\text{HalfNormal}(\sigma^2)\)</span>. Then:</p>
<ul>
<li><p>Probability density function:</p>
<p><span class="math display">\[
f(y) = \sqrt{\frac{2}{\pi \sigma^2}} e^{-y^2 / (2\sigma^2)}, \quad y
&gt; 0
\]</span></p></li>
<li><p>Mean:</p>
<p><span class="math display">\[
E(Y) = \sigma \sqrt{\frac{2}{\pi}}
\]</span></p></li>
<li><p>Variance:</p>
<p><span class="math display">\[
\text{Var}(Y) = \sigma^2 \left(1 - \frac{2}{\pi}\right)
\]</span></p></li>
</ul>
<hr />
</div>
<div id="log-normal-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Log-Normal Distribution</h3>
<p>If <span class="math inline">\(\log(Y) \sim \mathcal{N}(\mu,
\sigma^2)\)</span>, then <span class="math inline">\(Y \sim
\text{LogNormal}(\mu, \sigma^2)\)</span>. Then:</p>
<ul>
<li><p>Probability density function:</p>
<p><span class="math display">\[
f(y) = \frac{1}{y \sqrt{2\pi \sigma^2}} \exp\left( -\frac{(\log y -
\mu)^2}{2\sigma^2} \right), \quad y &gt; 0
\]</span></p></li>
<li><p>Mean:</p>
<p><span class="math display">\[
E(Y) = e^{\mu + \sigma^2 / 2}
\]</span></p></li>
<li><p>Variance:</p>
<p><span class="math display">\[
\text{Var}(Y) = e^{2\mu + \sigma^2} (e^{\sigma^2} - 1)
\]</span></p></li>
</ul>
<hr />
</div>
<div id="students-t-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Student’s t-Distribution</h3>
<p>Defined by location <span class="math inline">\(\mu\)</span>, scale
<span class="math inline">\(\sigma^2\)</span>, and degrees of freedom
<span class="math inline">\(\nu\)</span>. If <span
class="math inline">\(Y \sim t(\mu, \sigma^2, \nu)\)</span>, then:</p>
<ul>
<li><p>Probability density function:</p>
<p><span class="math display">\[
f(y) = \frac{\Gamma\left( \frac{\nu + 1}{2} \right)}{\Gamma\left(
\frac{\nu}{2} \right) \sqrt{\nu \pi \sigma^2}} \left[ 1 + \frac{(y -
\mu)^2}{\nu \sigma^2} \right]^{-\frac{\nu + 1}{2}}
\]</span></p></li>
<li><p>Mean (if <span class="math inline">\(\nu &gt; 1\)</span>):</p>
<p><span class="math display">\[
E(Y) = \mu
\]</span></p></li>
<li><p>Variance (if <span class="math inline">\(\nu &gt;
2\)</span>):</p>
<p><span class="math display">\[
\text{Var}(Y) = \frac{\nu \sigma^2}{\nu - 2}
\]</span></p></li>
</ul>
<hr />
</div>
<div id="bivariate-normal-distribution"
class="section level3 unnumbered">
<h3 class="unnumbered">Bivariate Normal Distribution</h3>
<p>Models two jointly normal variables <span
class="math inline">\(X\)</span> and <span
class="math inline">\(Y\)</span> with correlation <span
class="math inline">\(\rho\)</span>. If <span class="math inline">\((X,
Y) \sim \text{BN}(\mu_X, \mu_Y, \sigma_X, \sigma_Y, \rho)\)</span>, then
the joint density is:</p>
<ul>
<li><p>Joint probability density function:</p>
<p><span class="math display">\[
f(x, y) = \frac{1}{2\pi \sigma_X \sigma_Y \sqrt{1 - \rho^2}} \exp\left(
-\frac{1}{2(1 - \rho^2)} Q \right)
\]</span></p>
<p>where</p>
<p><span class="math display">\[
Q = \left( \frac{x - \mu_X}{\sigma_X} \right)^2 - 2\rho \left( \frac{x -
\mu_X}{\sigma_X} \right) \left( \frac{y - \mu_Y}{\sigma_Y} \right) +
\left( \frac{y - \mu_Y}{\sigma_Y} \right)^2
\]</span></p></li>
<li><p>Conditional expectation:</p>
<p><span class="math display">\[
E(Y \mid X = x) = \mu_Y + \rho \frac{\sigma_Y}{\sigma_X}(x - \mu_X)
\]</span></p></li>
<li><p>Conditional variance:</p>
<p><span class="math display">\[
\text{Var}(Y \mid X) = \sigma_Y^2 (1 - \rho^2)
\]</span></p></li>
</ul>
<p>This distribution is used for modeling two correlated outcomes or as
a prior for two dependent parameters.</p>
</div>
<div id="normal-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Normal Distribution</h3>
<p>This provided delve into Bayesian inference for normally distributed
data, employing conjugate priors.</p>
<ol style="list-style-type: decimal">
<li><strong>Background and Setup:</strong>
<ul>
<li>The data is assumed to follow a Normal distribution, <span
class="math inline">\(N(\mu, \sigma^2)\)</span>, where both the mean
(<span class="math inline">\(\mu\)</span>) and variance (<span
class="math inline">\(\sigma^2\)</span>) are unknown.</li>
<li>A common approach in Bayesian analysis is to assume conjugate priors
for these parameters because conjugate priors simplify the computation
of the posterior distributions.</li>
</ul></li>
<li><strong>Conjugate Priors Used:</strong>
<ul>
<li>For the mean <span class="math inline">\(\mu\)</span>, when <span
class="math inline">\(\sigma^2\)</span> is known, the conjugate prior is
a Normal distribution, <span class="math inline">\(N(\mu_0,
\tau_0)\)</span>.</li>
<li>For the variance <span class="math inline">\(\sigma^2\)</span>, the
conjugate prior is an inverse-Gamma distribution, which ensures that the
posterior distributions for <span class="math inline">\(\mu\)</span> and
<span class="math inline">\(\sigma^2\)</span> are tractable and remain
within the family of Normal and inverse-Gamma distributions
respectively.</li>
</ul></li>
<li><strong>Mathematical Formulation:</strong>
<ul>
<li><strong>Likelihood Function:</strong> Given the data <span
class="math inline">\(x = (x_1, x_2, ..., x_n)\)</span>, the likelihood
for a normal model is: <span class="math display">\[
p(x | \mu, \sigma^2) \propto \sigma^{-n} \exp\left(-\frac{1}{2\sigma^2}
\sum_{i=1}^n (x_i - \mu)^2\right)
\]</span></li>
<li><strong>Posterior for Mean <span
class="math inline">\(\mu\)</span>:</strong> When <span
class="math inline">\(\sigma^2\)</span> is known, the posterior
distribution of <span class="math inline">\(\mu\)</span> after observing
data is also a Normal distribution: <span class="math display">\[
\mu | x, \sigma^2 \sim N\left(\frac{\tau_0 \mu_0 + n\bar{x}}{\tau_0 +
n}, \frac{\sigma^2}{\tau_0 + n}\right)
\]</span> where <span class="math inline">\(\bar{x}\)</span> is the
sample mean.</li>
<li><strong>Posterior for Variance <span
class="math inline">\(\sigma^2\)</span>:</strong> The posterior for
<span class="math inline">\(\sigma^2\)</span> is an inverse-Gamma
distribution, parameterized by updated shape and scale parameters
derived from the data.</li>
</ul></li>
<li><strong>Updating Process:</strong>
<ul>
<li>Given the priors and the observed data, the parameters of the priors
(<span class="math inline">\(\mu_0, \tau_0\)</span> for the mean and
shape and rate for the variance) are updated to reflect the new evidence
provided by the data.</li>
<li>This Bayesian updating allows continuous learning as new data
becomes available, adjusting the beliefs about the parameters based on
cumulative evidence.</li>
</ul></li>
</ol>
<p><img src="02_Plots/Bayesian/Bayer_Distribution_Normal.PNG" /></p>
</div>
</div>
<div id="appropriate-prior-distribution" class="section level2"
number="2.2">
<h2><span class="header-section-number">2.2</span> Appropriate Prior
Distribution</h2>
<ol style="list-style-type: decimal">
<li><strong>Selection of Priors</strong>:
<ul>
<li>In Bayesian statistics, the choice of prior <span
class="math inline">\(p(\theta)\)</span> is crucial because it
fundamentally influences the resulting posterior distribution <span
class="math inline">\(p(\theta | \text{data})\)</span>. Selecting a
prior that reflects genuine knowledge or reasonable assumptions about
<span class="math inline">\(\theta\)</span> is important for ensuring
that the posterior distribution is meaningful and accurate.</li>
<li>If the prior is too restrictive or if it does not align with the
actual data characteristics, it can lead to misleading inferences, where
the data cannot correct a poorly chosen prior.</li>
</ul></li>
<li><strong>Precision of Prior Distributions</strong>:
<ul>
<li>The text discusses the concept of the “precision” of prior
distributions, indicating that a precise prior has a major impact on the
determination of the posterior. A precise prior effectively means that
the prior distribution is tightly concentrated, suggesting high
confidence in the prior knowledge about <span
class="math inline">\(\theta\)</span>.</li>
<li>The implication is that when the precision of the prior is high, the
influence of the data on the posterior might be relatively diminished
unless the data strongly contradicts the prior assumptions.</li>
</ul></li>
<li><strong>Behavior of Improper Priors</strong>:
<ul>
<li>Improper priors are those that do not integrate to one (e.g., priors
that are uniform over an infinite range). These priors are sometimes
used in Bayesian analysis due to their non-informative nature, allowing
the data to play a more significant role in shaping the posterior.</li>
<li>The discussion notes that while improper priors can be useful,
especially in the absence of strong prior knowledge, they must be
handled with care. Improper priors can sometimes lead to undefined or
ambiguous posterior distributions if not properly regularized or if the
data does not sufficiently inform the posterior.</li>
</ul></li>
</ol>
<p>Determining the appropriate prior distribution in Bayesian statistics
involves considering several options, each suited to different
circumstances and amounts of prior knowledge.</p>
<p><strong>1. Non-informative Priors</strong></p>
<p>Non-informative priors, also known as flat or objective priors, are
used when there is no specific prior knowledge about the parameters.
These priors are designed to exert minimal influence on the posterior
distribution, allowing the data to speak for themselves.</p>
<ul>
<li><strong>Purpose</strong>: Ideal for situations where you want to
remain as unbiased as possible or when prior knowledge is genuinely
absent.</li>
<li><strong>Examples</strong>: Uniform distributions across the range of
possible parameter values, Jeffreys’ prior which is invariant under
reparameterization and often used for scale parameters.</li>
</ul>
<p><strong>2. Conjugate Priors</strong> Conjugate priors are chosen
because they simplify the computation of the posterior distribution. A
prior is conjugate to the likelihood function if the posterior
distribution belongs to the same family as the prior distribution.</p>
<ul>
<li><strong>Benefits</strong>: The use of conjugate priors transforms
Bayesian updating into a matter of updating the parameters of the prior
distribution based on the observed data, which can often be done
analytically without complex numerical methods.</li>
<li><strong>Examples</strong>: The Beta distribution as a prior for the
Binomial likelihood, or the Gamma distribution for the Exponential
likelihood.</li>
</ul>
<p><strong>3. Empirical Bayes Methods</strong></p>
<p>Empirical Bayes methods use the data to estimate the parameters of
the prior distribution. This approach sits between fully Bayesian and
frequentist methods, leveraging the strengths of both.</p>
<ul>
<li><strong>Process</strong>: Start with an assumed form of the prior
distribution, then use a portion of the data or external data to
estimate the parameters of this prior.</li>
<li><strong>Applications</strong>: Useful in settings where some data
are available that can inform the prior, but not enough to fully
determine the posterior without additional data. This method is commonly
used in hierarchical models and large-scale data analysis.</li>
</ul>
<p><strong>4. Expert Elicitation Priors</strong></p>
<p>Priors derived from expert elicitation involve consulting
subject-matter experts to quantify their beliefs about parameters before
observing the current data. This method is particularly useful in fields
where prior experimental or empirical data are sparse, but expert domain
knowledge is rich.</p>
<ul>
<li><strong>Implementation</strong>: Structured elicitation processes
are used to translate expert knowledge into a quantifiable prior
distribution. This might involve using tools like probability
distribution fitting, where experts specify quantiles, means, variances,
or other moments based on their understanding.</li>
<li><strong>Challenges</strong>: Requires careful consideration to avoid
biases inherent in expert opinions and to accurately represent
uncertainty in expert estimates.</li>
</ul>
<div id="non-informative-priors" class="section level3 unnumbered">
<h3 class="unnumbered">1. Non-informative Priors</h3>
<p>When engaging in Bayesian analysis without specific prior knowledge
about the parameters in question, employing non-informative priors can
be an effective strategy. These types of priors are designed to
minimally influence the posterior outcomes, allowing the data itself to
primarily drive the inferences. Here is a detailed description of two
significant types of non-informative priors: <strong>Jeffreys
Prior</strong> and <strong>Reference Prior</strong>.</p>
<div id="jeffreys-prior" class="section level4 unnumbered">
<h4 class="unnumbered">Jeffreys Prior</h4>
<p><strong>Background:</strong> Jeffreys Prior is named after Sir Harold
Jeffreys, who introduced it in his work on Bayesian statistics. This
prior is particularly noted for its property of invariance, meaning that
it remains unchanged under transformation of parameters.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Invariance</strong>: The form of Jeffreys prior does not
change with the parameterization of the model. This property is crucial
because it ensures that the prior behaves consistently across different
parameterizations, avoiding biases that could arise from arbitrary
choices of parameter scales or units.</li>
<li><strong>Construction</strong>: Jeffreys Prior is constructed using
the square root of the determinant of the Fisher information matrix. The
Fisher information quantifies the amount of information that an
observable random variable carries about an unknown parameter upon which
the likelihood depends.</li>
</ul>
<p><strong>Formula:</strong> <span class="math display">\[ p(\theta)
\propto \sqrt{|I(\theta)|} \]</span> where <span
class="math inline">\(I(\theta)\)</span> is the Fisher information
matrix for parameter <span class="math inline">\(\theta\)</span>.</p>
<p><strong>Applications and Limitations:</strong></p>
<ul>
<li>Jeffreys Prior is particularly useful for parameters that are
naturally scale-invariant, such as variance and standard deviation.</li>
<li>While it addresses the issue of uniform priors not translating
uniformly over transformations of the parameters, Jeffreys Prior can
sometimes lead to priors that are improper or do not integrate to one,
particularly in complex models or multi-parameter settings.</li>
</ul>
</div>
<div id="reference-prior" class="section level4 unnumbered">
<h4 class="unnumbered">Reference Prior</h4>
<p><strong>Background:</strong></p>
<p>The concept of Reference Priors was developed to address some of the
limitations encountered with Jeffreys Prior, especially in multivariate
contexts where interactions between parameters can complicate the
definition and application of non-informative priors.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Maximization of Information Divergence</strong>: Reference
priors are designed to maximize the Kullback-Leibler divergence between
the prior and the posterior distributions under large sample conditions.
This divergence measures the information gain provided by the data,
relative to the prior.</li>
<li><strong>Minimally Informative</strong>: By maximizing the
divergence, the reference prior aims to minimize its impact on the
posterior, making the results as data-driven as possible. This feature
makes it an ideal choice when seeking to minimize the influence of
subjective assumptions on the analysis.</li>
</ul>
<p><strong>Formula:</strong></p>
<p>While the specific form of a reference prior can depend on the model
and the parameters, its derivation generally involves complex
calculations aimed at maximizing the Kullback-Leibler divergence, which
may not have a closed-form expression and often requires numerical
methods to solve.</p>
<p><strong>Applications and Limitations:</strong></p>
<ul>
<li>Reference Priors are particularly useful in settings involving
multiple parameters where interactions can complicate the analysis.</li>
<li>They are also used in problems where the sample size is large, and
the aim is to make inferences that are as objective as possible.</li>
</ul>
</div>
</div>
<div id="conjugate-priors" class="section level3 unnumbered">
<h3 class="unnumbered">2. Conjugate Priors</h3>
<p>Conjugate priors are a type of prior that, when used with a
particular likelihood function, results in a posterior distribution that
is of the same family as the prior distribution. This property of
conjugacy is particularly valuable because it simplifies the
mathematical operations involved in Bayesian updates.</p>
<p><strong>Key Characteristics of Conjugate Priors:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Mathematical Simplicity</strong>: Conjugate priors
simplify the Bayesian updating process because the posterior
distributions are analytically tractable. This means that one can derive
explicit formulas for updating the parameters of the distribution,
typically referred to as hyperparameters, based on the observed
data.</p></li>
<li><p><strong>Parameterization</strong>: In the context of conjugate
priors, the prior distribution is often characterized by a few key
parameters, known as hyperparameters. For example, in the case of a
normal distribution used as a likelihood, the conjugate prior would also
be normal, characterized by parameters like the mean and variance. These
hyperparameters are updated to form the posterior based on the
data.</p></li>
</ol>
<p>For practical Bayesian analysis, conjugate priors are particularly
prevalent in cases where the likelihood functions belong to the
exponential family, such as:</p>
<ul>
<li><strong>Beta distribution</strong> for binomial data,</li>
<li><strong>Gamma distribution</strong> for Poisson data,</li>
<li><strong>Normal distribution</strong> for normal data.</li>
</ul>
<div class="figure">
<img src="02_Plots/Bayesian/Bayer_Conjugate.PNG" alt="Conjugate priors for the most common statistical families" width="342" />
<p class="caption">
Conjugate priors for the most common statistical families
</p>
</div>
<p><strong>Advantages of Using Conjugate Priors:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Computational Efficiency</strong>: The algebraic
convenience of conjugate priors allows for straightforward updates of
beliefs in light of new data. This efficiency is particularly
advantageous in iterative processes or when dealing with large
datasets.</p></li>
<li><p><strong>Theoretical Elegance</strong>: The ability to maintain
the same family of distributions before and after observing data offers
a closed-form solution for the posterior, which can be elegantly
described and understood.</p></li>
<li><p><strong>Ease of Interpretation</strong>: Because the form of the
distribution remains constant, the interpretation of the parameters
(such as mean or variance in a normal distribution) remains intuitive
and consistent throughout the Bayesian analysis.</p></li>
</ol>
<p><strong>Drawbacks of Using Conjugate Priors:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Restrictive Assumptions</strong>: The main limitation of
conjugate priors is that they might force one to adopt specific
distributional forms that may not be substantively justified. The need
to maintain conjugacy can impose restrictions on the choice of the prior
that might not align with the actual prior knowledge about the
parameters.</p></li>
<li><p><strong>Limited Flexibility</strong>: While the use of conjugate
priors simplifies calculations, it also reduces flexibility in modeling.
The specific structure required for conjugacy might not adequately
capture the complexities or nuances of the prior beliefs or the
data.</p></li>
<li><p><strong>Hyperparameter Sensitivity</strong>: The process requires
the selection of hyperparameters, which can significantly influence the
posterior. Incorrect or suboptimal choices of these parameters can lead
to biased or misleading results, especially if the prior information is
insufficient or vague.</p></li>
</ol>
</div>
<div id="empirical-bayes-priors" class="section level3 unnumbered">
<h3 class="unnumbered">3. Empirical Bayes Priors</h3>
<p><strong>Concept and Foundation of Empirical Bayes</strong></p>
<p>Empirical Bayes methods are based on the idea of using observed data
to estimate the parameters of the prior distribution in a Bayesian
setup. Unlike traditional Bayesian methods, which require the
specification of a prior based purely on subjective belief or external
information, Empirical Bayes uses an evidence-based approach to
determine the prior. This hybrid method falls between the fully Bayesian
approach (which relies entirely on subjective priors) and the purely
frequentist approach (which does not incorporate prior information at
all).</p>
<p><strong>How Empirical Bayes Methods Work</strong> The process
involves two main steps:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Estimation of Prior Parameters</strong>: First, the
method uses the aggregate data to estimate the parameters of the prior
distribution. This is typically done using maximum likelihood estimation
or another suitable frequentist method. The goal here is to capture the
common characteristics of the parameter across different observations or
experiments.</p></li>
<li><p><strong>Bayesian Updating</strong>: Once the prior parameters are
estimated, each specific instance or data point is analyzed using
Bayesian methods, where the empirically estimated prior is updated with
the actual observed data to produce a posterior distribution.</p></li>
</ol>
<p><strong>Key Features of Empirical Bayes</strong></p>
<ul>
<li><p><strong>Data-Driven Priors</strong>: The priors are not fixed
before seeing the data; instead, they are determined based on the data
itself. This is particularly useful in scenarios where little is known
about the system beforehand, or when subjective priors are hard to
justify.</p></li>
<li><p><strong>Reduction in Variance</strong>: By borrowing strength
from the entire dataset to form the prior, Empirical Bayes methods can
reduce the variance of the estimates compared to purely frequentist
approaches that treat each problem separately.</p></li>
<li><p><strong>Computational Efficiency</strong>: Empirical Bayes can be
more computationally efficient than fully Bayesian methods since it
avoids the need for complex prior specification and the intensive
computations that can entail, especially with large datasets.</p></li>
</ul>
</div>
<div id="expert-elicitation-priors" class="section level3 unnumbered">
<h3 class="unnumbered">4. Expert Elicitation Priors</h3>
<p>Expert elicitation priors are a method in Bayesian statistics where
subjective judgments from experts are formally incorporated into the
Bayesian framework as prior distributions. This approach is particularly
useful in scenarios where empirical data is sparse, but expert knowledge
is abundant and reliable.</p>
<p>Expert elicitation involves systematically gathering opinions from
one or more experts about uncertain quantities and then using these
opinions to form prior distributions in Bayesian analysis. The experts
provide their insights based on experience, existing research, and
intuition, which are then quantified into a statistical format that can
be directly used in the probabilistic models.</p>
<p><strong>Process of Developing Expert Elicitation Priors</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Selection of Experts</strong>: Careful selection of
experts is crucial. Experts should have deep and relevant knowledge
about the subject matter. Diversity in expertise can help capture a
broad range of perspectives and reduce individual bias.</p></li>
<li><p><strong>Elicitation Technique</strong>: Various techniques can be
used to elicit quantitative data from experts, such as interviews,
structured questionnaires, or interactive workshops. Techniques like the
Delphi method, which involves multiple rounds of questioning with
feedback, are commonly used to converge expert opinions towards a
consensus.</p></li>
<li><p><strong>Quantification of Expert Opinions</strong>: The elicited
qualitative assessments are converted into quantitative measures.
Experts might be asked to estimate parameters directly, provide
percentiles for distributions, or express their confidence in different
outcomes.</p></li>
<li><p><strong>Aggregation of Responses</strong>: When multiple experts
are involved, their responses need to be aggregated. This can be done
through mathematical pooling of individual probability distributions or
by using more sophisticated models that weigh expert opinions by their
reliability or coherence with empirical data.</p></li>
</ol>
<p><strong>Advantages of Using Expert Elicitation Priors</strong></p>
<ul>
<li><p><strong>Fills Data Gaps</strong>: In cases where empirical data
is not available or is incomplete, expert opinions can provide valuable
insights that would otherwise be unattainable.</p></li>
<li><p><strong>Improves Model Relevance</strong>: By incorporating
real-world knowledge, the models become more reflective of the actual
phenomena being studied, enhancing the relevance and applicability of
the statistical analyses.</p></li>
<li><p><strong>Facilitates Complex Decision Making</strong>: Expert
elicitation is particularly beneficial in complex decision-making
scenarios, such as policy formulation or risk assessment, where the
stakes are high and the problems are too intricate to be captured fully
by available data.</p></li>
</ul>
</div>
</div>
<div id="sensitivity-analysis-and-robust-priors" class="section level2"
number="2.3">
<h2><span class="header-section-number">2.3</span> Sensitivity Analysis
and ‘Robust’ Priors</h2>
<p>Sensitivity analysis in Bayesian statistics is a crucial step to
evaluate how the conclusions of a model are affected by the assumptions
made, particularly about the <strong>prior distributions</strong>.
Unlike frequentist methods, Bayesian approaches inherently depend on
prior assumptions, which makes it vital to test how robust the results
are to variations in those priors.</p>
<ul>
<li><strong>Definition:</strong> Robust priors refer to a class of
priors that lead to consistent and stable conclusions, even when varied
within a reasonable range.</li>
<li><strong>Key Idea:</strong> Instead of committing to a single prior,
the robust Bayesian approach explores a <strong>community of
priors</strong> to determine how conclusions depend on prior
assumptions.</li>
<li>Sensitivity analysis is particularly useful in clinical trials,
where stakeholders may have varying prior beliefs about the efficacy of
an intervention.
<ul>
<li>Assessing how trial results support the superiority of a treatment
under skeptical vs. optimistic prior assumptions.</li>
<li>Examining how conclusions change with different prior beliefs about
the null hypothesis.</li>
</ul></li>
<li><strong>Complexity:</strong> Conducting sensitivity analysis across
a wide range of priors can be computationally intensive. A narrow or
overly restricted sensitivity analysis may miss critical variations in
prior assumptions.</li>
</ul>
<hr />
<p><strong>A Framework for Bayesian Sensitivity Analysis</strong></p>
<p>This process, also called the <strong>“robust Bayesian”
approach</strong>, includes these steps:</p>
<ol style="list-style-type: decimal">
<li><strong>Choose a flexible set of priors</strong> that span the
spectrum of plausible beliefs.</li>
<li><strong>Evaluate posterior results</strong> (e.g., probability
treatment is superior) for each prior.</li>
<li><strong>Identify prior beliefs</strong> that would change key
conclusions (e.g., make an effect clinically significant or not).</li>
<li><strong>Report</strong> the results so readers can see where their
own beliefs might fall—and what that would imply.</li>
</ol>
<p>This is sometimes referred to as <strong>prior
partitioning</strong>.</p>
<p>A <strong>Bayesian sensitivity analysis</strong> aims to answer:</p>
<blockquote>
<p><em>How robust are our conclusions to different reasonable beliefs
about the unknown parameters?</em></p>
</blockquote>
<p>This allows more <strong>transparent</strong>,
<strong>context-aware</strong>, and <strong>decision-relevant</strong>
interpretation of results. For instance, even if the posterior
probability of treatment superiority is high, we may still find that
under many reasonable priors, the probability of a <em>clinically
significant</em> effect is modest—shifting the interpretation.</p>
<hr />
<p><strong>1. Purpose of Sensitivity Analysis in Bayesian
Approaches</strong></p>
<ul>
<li><strong>Assess Dependence on Priors:</strong> Bayesian results are
influenced by prior distributions. Sensitivity analysis examines whether
the conclusions would change significantly under different reasonable
priors.</li>
<li><strong>Address Subjectivity:</strong> Priors are subjective by
nature, reflecting beliefs or knowledge before observing data.
Sensitivity analysis helps ensure that conclusions are not unduly
dependent on a single prior choice.</li>
<li><strong>Transparency:</strong> Allows readers or stakeholders to
judge how their own prior beliefs might influence the conclusions.</li>
</ul>
<p><strong>2. Steps in a Robust Bayesian Sensitivity
Analysis</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Select a Flexible Class of Priors:</strong>
<ul>
<li>Choose a broad range of plausible priors, including skeptical,
optimistic, and neutral priors.</li>
<li>Ensure the priors reflect diverse perspectives (e.g., clinical
expert opinions, data-driven priors, or “ignorance” priors).</li>
</ul></li>
<li><strong>Examine Dependence on Prior Choices:</strong>
<ul>
<li>Analyze how posterior conclusions (e.g., posterior probabilities,
credible intervals) change as priors vary.</li>
<li>Identify regions where prior assumptions significantly alter
conclusions.</li>
</ul></li>
<li><strong>Identify Critical Priors:</strong>
<ul>
<li>Determine which subsets of priors lead to specific posterior
outcomes of interest, such as the superiority of a treatment.</li>
<li>Highlight priors that would be pivotal for decision-making.</li>
</ul></li>
<li><strong>Report Results Transparently:</strong>
<ul>
<li>Present findings clearly, allowing the audience to see how different
priors affect conclusions.</li>
<li>Provide tools or visualizations (e.g., graphs of posterior
probabilities vs. prior parameters) to facilitate interpretation.</li>
</ul></li>
</ol>
<p><strong>3. Types of Prior Communities (Increasing in
Complexity)</strong></p>
<p>There are three main approaches to defining a community of
priors:</p>
<p><strong>(a) Discrete Set of Priors:</strong></p>
<ul>
<li>Analyze sensitivity to a limited, predefined list of priors, such
as:
<ul>
<li><strong>Skeptical prior:</strong> Reflecting doubt about a
treatment’s efficacy.</li>
<li><strong>Optimistic prior:</strong> Assuming strong efficacy.</li>
<li><strong>Neutral prior:</strong> Representing “ignorance” or minimal
assumptions.</li>
</ul></li>
<li>Examples:
<ul>
<li>Sensitivity to the opinions of multiple experts.</li>
<li>Extreme prior scenarios that reflect opposing views.</li>
</ul></li>
</ul>
<p><strong>(b) Parametric Family of Priors:</strong></p>
<ul>
<li>Define a family of priors characterized by one or more parameters
(e.g., a beta distribution with varying shape parameters).</li>
<li>Plot posterior results as a function of these parameters to
visualize sensitivity.</li>
<li>Example:
<ul>
<li>Varying the weight of prior information (e.g., increasing skepticism
or optimism) and observing the effect on posterior probabilities.</li>
</ul></li>
</ul>
<p><strong>(c) Non-Parametric Family of Priors:</strong></p>
<ul>
<li>Use flexible priors that are not constrained by a specific
parametric form.</li>
<li>Example:
<ul>
<li>Gustafson (1989): Introduced a “neighborhood” of priors around a
non-informative prior, with some contamination from alternative
priors.</li>
</ul></li>
<li>Tools like maximum and minimum posterior probabilities within the
class can highlight the range of plausible conclusions.</li>
</ul>
</div>
<div id="hierarchical-priors" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Hierarchical
Priors</h2>
<p><strong>Overview of Hierarchical Models and τ</strong></p>
<p>In a Bayesian <strong>hierarchical model</strong>, you assume that
unit-level parameters (e.g., treatment effects in different studies),
denoted as <span class="math inline">\(\theta_k\)</span>, are drawn from
a <strong>shared population distribution</strong>:</p>
<p><span class="math display">\[
\theta_k \sim \mathcal{N}(\mu, \tau^2)
\]</span></p>
<p>This assumes the <span class="math inline">\(\theta_k\)</span> are
<strong>exchangeable</strong>, meaning you believe there’s no systematic
reason to expect one unit’s effect to be predictably different from
another, unless explained by covariates.</p>
<p>The key <strong>hyperparameter</strong> in this setup is the
<strong>between-unit standard deviation <span
class="math inline">\(\tau\)</span></strong>, which governs the
<strong>degree of heterogeneity</strong>:</p>
<ul>
<li><span class="math inline">\(\tau = 0\)</span>: all units are assumed
identical (fixed effects).</li>
<li>Larger <span class="math inline">\(\tau\)</span>: more heterogeneity
allowed across units (random effects).</li>
</ul>
<p>Bayesian inference requires a <strong>prior distribution</strong> for
<span class="math inline">\(\tau\)</span>. Choosing this prior carefully
is essential because:</p>
<ul>
<li>It affects how much <strong>shrinkage</strong> is applied to
unit-level estimates.</li>
<li>In sparse data situations, it can strongly influence the
<strong>posterior</strong>.</li>
</ul>
<p><strong>Three Critical Assumptions in Hierarchical
Priors</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Exchangeability</strong>: Are the <span
class="math inline">\(\theta_k\)</span>s similar enough to be drawn from
a common distribution?</li>
<li><strong>Form of random-effects distribution</strong>: Is a Normal
distribution appropriate for the <span
class="math inline">\(\theta_k\)</span>? Often used, but alternatives
like Student’s t may be more robust.</li>
<li><strong>Prior for <span
class="math inline">\(\tau\)</span></strong>: The most delicate part—how
much heterogeneity do we <em>a priori</em> expect?</li>
</ol>
</div>
</div>
<div id="bayesian-inference-algorithm" class="section level1"
number="3">
<h1><span class="header-section-number">3</span> Bayesian Inference
Algorithm</h1>
<div id="maximum-a-posteriori-map-estimation" class="section level2"
number="3.1">
<h2><span class="header-section-number">3.1</span> Maximum A Posteriori
(MAP) Estimation</h2>
<ol style="list-style-type: decimal">
<li><strong>Definition and Formula</strong>:
<ul>
<li>MAP estimation is similar to MLE but incorporates a prior
distribution on the parameters. It modifies the estimation process by
not just considering the likelihood of the observed data but also how
probable parameters are a priori.</li>
<li>The formula for MAP estimation is: <span class="math display">\[
\hat{\theta}_{MAP} = \arg \max_{\theta} p(\theta | x) = \arg
\max_{\theta} \log \left( p(x | \theta) p(\theta) \right)
\]</span></li>
<li>This can be expanded using Bayes’ theorem to: <span
class="math display">\[
\hat{\theta}_{MAP} = \arg \max_{\theta} \log \left( \prod_{i=1}^n p(x_i
| \theta) p(\theta) \right)
\]</span></li>
</ul></li>
<li><strong>Differences from MLE</strong>:
<ul>
<li>While MLE solely focuses on maximizing the likelihood, MAP also
considers the prior distribution of the parameters, which can lead to
different estimates especially when the amount of data is limited.</li>
<li>MAP is a regularization of MLE, incorporating additional information
(or beliefs) about the parameters before observing the data.</li>
</ul></li>
</ol>
</div>
<div id="laplace-approximation" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Laplace
Approximation</h2>
<ol style="list-style-type: decimal">
<li><strong>Purpose and Use</strong>:
<ul>
<li>Laplace approximation is used to simplify the computation of
posterior distributions in Bayesian inference by approximating these
distributions with a Gaussian distribution centered at the MAP
estimate.</li>
<li>This method is particularly advantageous in high-dimensional
settings where the integral over the parameter space becomes
intractable.</li>
</ul></li>
<li><strong>Mathematical Foundation</strong>:
<ul>
<li>Given a posterior distribution <span class="math inline">\(p(\theta
| x)\)</span>, the goal is to approximate it around the point <span
class="math inline">\(\hat{\theta}\)</span> where it reaches its
maximum, i.e., the MAP estimate.</li>
<li>The approximation assumes that the log of the posterior distribution
can be approximated by a second-order Taylor expansion around <span
class="math inline">\(\hat{\theta}\)</span>.</li>
</ul></li>
<li><strong>Procedure</strong>:
<ul>
<li><strong>Find the MAP</strong>: Solve <span
class="math inline">\(\hat{\theta} = \arg \max_{\theta} \log p(\theta |
x)\)</span>, which involves derivatives of the log-posterior to find the
point where it peaks.</li>
<li><strong>Second-Order Taylor Expansion</strong>: Expand <span
class="math inline">\(\log p(\theta | x)\)</span> around <span
class="math inline">\(\hat{\theta}\)</span> using a second-order Taylor
series: <span class="math display">\[
\log p(\theta | x) \approx \log p(\hat{\theta} | x) - \frac{1}{2}
(\theta - \hat{\theta})^T A (\theta - \hat{\theta})
\]</span> where <span class="math inline">\(A\)</span> is the Hessian
matrix of the negative log-posterior evaluated at <span
class="math inline">\(\hat{\theta}\)</span>.</li>
<li><strong>Approximate the Posterior</strong>: The approximate
posterior is then: <span class="math display">\[
q(\theta) \propto \exp\left(-\frac{1}{2} (\theta - \hat{\theta})^T A
(\theta - \hat{\theta})\right)
\]</span> which is the form of a Gaussian distribution with mean <span
class="math inline">\(\hat{\theta}\)</span> and covariance matrix <span
class="math inline">\(A^{-1}\)</span>.</li>
</ul></li>
<li><strong>Implications and Applications</strong></li>
</ol>
<ul>
<li><strong>Efficiency</strong>: The Laplace approximation allows for
more efficient numerical calculations and integrations over the
parameter space by reducing complex posterior distributions to Gaussian
approximations.</li>
<li><strong>Model Comparison</strong>: It facilitates model comparison
and selection using Bayesian model comparison criteria like the Bayesian
Information Criterion (BIC) and Akaike Information Criterion (AIC),
which require the evaluation of the log-posterior or its
approximations.</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li><strong>Limitations</strong></li>
</ol>
<ul>
<li><strong>Accuracy</strong>: The approximation assumes that the
posterior is unimodal and symmetric near the MAP, which may not hold in
cases with multi-modal distributions or significant skewness.</li>
<li><strong>Dimensionality</strong>: In very high-dimensional spaces,
even the computation of the Hessian and its inversion can become
computationally challenging.</li>
</ul>
</div>
<div id="markov-chain-monte-carlo-mcmc" class="section level2"
number="3.3">
<h2><span class="header-section-number">3.3</span> Markov Chain Monte
Carlo (MCMC)</h2>
<p>Markov Chain Monte Carlo (MCMC) is a class of algorithms that allows
for the sampling from a probability distribution based on constructing a
Markov chain that has the desired distribution as its equilibrium
distribution. This approach is particularly useful for obtaining a
sequence of random samples from a multivariate probability distribution
where direct sampling is difficult.</p>
<p><strong>Monte Carlo Simulation</strong>:</p>
<ul>
<li>Named after the Monte Carlo Casino due to the random nature of the
methods, similar to gambling.</li>
<li>These methods involve using randomness to solve problems that might
be deterministic in principle. For example, they can be used to compute
integrals by simulating random draws from a distribution and
approximating sums or integrals.</li>
</ul>
<p><strong>Markov Chains</strong>:</p>
<ul>
<li>A Markov Chain is a stochastic model describing a sequence of
possible events in which the probability of each event depends only on
the state attained in the previous event.</li>
<li>In the context of MCMC, the chain uses transition probabilities that
depend only on the current state, not on how the current state was
reached.</li>
</ul>
<p><img src="02_Plots/Bayesian/Bayer_MCMC1.PNG" width="416" /></p>
<p><strong>MCMC Process</strong>:</p>
<ol style="list-style-type: decimal">
<li><strong>Initialization</strong>: Start from an arbitrary point in
the support of the distribution.</li>
<li><strong>Iteration</strong>: Move around the state space according to
some probabilistic rules designed so that the chain will eventually
converge to the target distribution.</li>
</ol>
<p><strong>Key Methods within MCMC</strong>:</p>
<ul>
<li><strong>Metropolis-Hastings Algorithm</strong>: Proposes a new state
from a proposal distribution and accepts or rejects the new state based
on an acceptance ratio, which ensures that the detailed balance is
maintained and the stationary distribution of the Markov chain is the
target distribution.</li>
<li><strong>Gibbs Sampling</strong>: A special case of
Metropolis-Hastings used when the joint distribution can be easily
sampled by sequentially sampling from the conditional distributions of
each variable given all other variables. It is particularly useful when
each conditional distribution is easier to sample from than the joint
distribution.</li>
</ul>
<p><strong>Advantages of MCMC</strong>:</p>
<ul>
<li>Enables sampling from complex, multi-dimensional distributions.</li>
<li>Useful in Bayesian inference for obtaining posterior distributions
where analytical solutions are not feasible.</li>
</ul>
<p><strong>Challenges with MCMC</strong>:</p>
<ul>
<li>Requires a large number of iterations to reach convergence, and
determining convergence can be non-trivial.</li>
<li>The samples are correlated, which means that the effective sample
size is less than the total number of samples generated.</li>
</ul>
</div>
<div id="expectation-maximization-em" class="section level2"
number="3.4">
<h2><span class="header-section-number">3.4</span>
Expectation-Maximization (EM)</h2>
<p>The Expectation-Maximization (EM) algorithm is a robust technique
used for parameter estimation in cases where data is incomplete,
missing, or has latent variables. It consists of two main steps repeated
iteratively: the Expectation step (E-step) and the Maximization step
(M-step).</p>
<ol style="list-style-type: decimal">
<li><p><strong>E-step</strong>: In this step, the algorithm calculates
the expected value of the log-likelihood function, with respect to the
conditional distribution of the latent variables given the observed data
and the current estimates of the parameters. This step involves filling
in missing data, estimating latent variables, or more generally,
calculating the expected sufficient statistics that are necessary for
the parameter updates in the next step.</p></li>
<li><p><strong>M-step</strong>: Here, the algorithm finds the parameter
values that maximize the expected log-likelihood found in the E-step.
These parameters are updated to new values that are used in the next
E-step.</p></li>
</ol>
<p>The process repeats with these new parameters until the convergence
criteria are met, which typically involves the change in the
log-likelihood or in the parameter estimates falling below a
threshold.</p>
<p>This iterative process helps in making the EM algorithm particularly
useful for situations where the model depends on unobserved latent data.
The EM algorithm is widely used in various applications like clustering
in machine learning (e.g., Gaussian mixture models), bioinformatics
(e.g., gene expression analysis), and more.</p>
<p><strong>Key Benefits:</strong></p>
<ul>
<li><strong>Handling of Missing Data</strong>: Efficiently deals with
missing or hidden data during model fitting.</li>
<li><strong>Flexibility</strong>: Can be applied to a wide range of
problems including those involving latent variables.</li>
<li><strong>Convergence Guarantee</strong>: Under mild conditions, EM is
guaranteed to converge to a local (sometimes global) maximum of the
likelihood function.</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li><strong>Local Maxima</strong>: The algorithm can converge to local
maxima, which means the initial values of parameters can affect the
final solution.</li>
<li><strong>Computationally Intensive</strong>: The E-step and M-step
can be computationally demanding, especially with large datasets or
complex models.</li>
<li><strong>Sensitivity to Model Specification</strong>: The performance
and convergence of the EM algorithm can be highly sensitive to how well
the model and its assumptions match the underlying data structure.</li>
</ul>
</div>
<div id="variational-inference" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Variational
inference</h2>
<p>Variational inference (VI) is a method used in Bayesian statistics
that approximates probability densities through optimization rather than
sampling, as seen in Markov Chain Monte Carlo (MCMC) methods. It is
particularly useful when dealing with complex models and large datasets,
providing a faster computational alternative.</p>
<p><strong>Process of Variational Inference:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Setup</strong>: VI transforms the computation of the
posterior distribution into an optimization problem. This involves
selecting a simpler, tractable family of distributions known as the
variational family.</li>
<li><strong>Objective</strong>: The aim is to find a distribution within
this family that most closely approximates the true posterior
distribution. The measure of “closeness” is typically quantified using
the Kullback-Leibler (KL) divergence.</li>
<li><strong>Optimization</strong>: To achieve this, VI minimizes the KL
divergence between the chosen variational distribution and the true
posterior distribution. This is often done using standard optimization
techniques.</li>
<li><strong>Outcome</strong>: The result is a deterministic
approximation of the posterior, which offers insights into parameter
estimates and uncertainties more rapidly than sampling methods.</li>
</ol>
<p><strong>Advantages of Variational Inference:</strong></p>
<ul>
<li><strong>Speed</strong>: Generally faster than MCMC due to its
deterministic nature.</li>
<li><strong>Scalability</strong>: Handles large datasets and complex
models more efficiently by avoiding the computationally intensive
process of drawing samples.</li>
<li><strong>Applicability</strong>: Useful in scenarios with large
parameter spaces where MCMC methods might converge slowly or be
impractical.</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li><strong>Accuracy</strong>: There can be significant discrepancies
between the variational approximation and the true posterior, especially
if the posterior is multi-modal or particularly complex.</li>
<li><strong>Bias</strong>: VI introduces bias because the variational
family may not encompass the true posterior.</li>
<li><strong>Dependency on Form</strong>: The effectiveness of VI depends
greatly on the chosen variational family. If too restrictive, it may not
adequately capture the posterior distribution.</li>
</ul>
</div>
</div>
<div id="historical-data-in-bayesian-analysis" class="section level1"
number="4">
<h1><span class="header-section-number">4</span> Historical Data in
Bayesian Analysis</h1>
<div id="introduction-1" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p><strong>Historical data</strong> has always played a role in
experimental planning and meta-analysis. However, <strong>Bayesian
methods</strong> provide a <strong>principled and flexible
framework</strong> to incorporate historical information not just in
design, but also in <strong>estimation, inference, prediction, and
decision-making</strong>.</p>
<p>In Bayesian reasoning, historical data can help shape the
<strong>prior distribution</strong>, inform assumptions, or contribute
directly to <strong>combined evidence</strong>. But not all historical
data are equally relevant or reliable — so it’s crucial to judge
<strong>how</strong> and <strong>to what extent</strong> past data
should influence current analysis.</p>
<p>The framework described here outlines <strong>six levels of
relevance</strong>, ranging from completely discarding historical data
to treating it as fully equivalent to current data.</p>
</div>
<div id="incorporate-into-bayesian-analysis" class="section level2"
number="4.2">
<h2><span class="header-section-number">4.2</span> Incorporate into
Bayesian Analysis</h2>
<p><img src="02_Plots/Bayesian/Bayer_Historical.png" /></p>
<p><em>Different assumptions relating parameters underlying historical
data to the parameter of current interest: single arrows represent a
distribution, double arrows represent logical functions, and wavy arrows
represent discounting.</em></p>
<div id="a-irrelevance" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> (a)
<strong>Irrelevance</strong></h3>
<ul>
<li><p>Historical data are judged to have no bearing on the current
study.</p></li>
<li><p>This might be because of:</p>
<ul>
<li>Vast differences in population, methods, or outcomes</li>
<li>Poor data quality</li>
<li>Known biases</li>
</ul></li>
<li><p>In Bayesian terms, this means the <strong>prior</strong> is
formed <strong>without using</strong> the historical data.</p></li>
</ul>
<p>This assumes that <strong>past studies provide no useful
information</strong> about the current study’s parameter (θ). Therefore,
the prior is constructed <strong>without reference</strong> to
historical data—possibly using a vague, flat, or reference prior.</p>
<ul>
<li>Example: A new trial uses a completely different treatment strategy
or patient population compared to earlier trials.</li>
<li>Implication: Past data is <strong>fully ignored</strong>.</li>
</ul>
<hr />
</div>
<div id="b-exchangeable" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> (b)
<strong>Exchangeable</strong></h3>
<ul>
<li><p>The past and current studies are assumed to be <strong>similar in
structure and quality</strong>, though not identical.</p></li>
<li><p>This allows for <strong>exchangeability of parameters</strong>,
meaning:</p>
<ul>
<li>The data are not pooled directly</li>
<li>Instead, they are modelled <strong>hierarchically</strong>, with
partial pooling</li>
</ul></li>
<li><p>This is a <strong>standard approach in meta-analysis</strong>,
and Bayesian <strong>hierarchical models</strong> (or multilevel models)
are well-suited to this setup.</p></li>
</ul>
<p>Here, we assume the current parameter (θ) and historical parameters
(θ₁, …, θ_H) are <strong>exchangeable</strong>, meaning they are thought
to come from the <strong>same population distribution</strong>:</p>
<p><span class="math display">\[
θ₁, θ₂, ..., θ_H, θ \sim \mathcal{N}(\mu, \tau^2)
\]</span></p>
<ul>
<li>Exchangeability means we think past and current studies are
measuring similar (but not identical) effects.</li>
<li>The prior for θ becomes the <strong>posterior predictive
distribution</strong> of a new value in this exchangeable sequence.</li>
</ul>
<p>If the variances (σ²_h) and τ² are known, the <strong>posterior for
θ</strong> is:</p>
<p><span class="math display">\[
θ \mid y₁, ..., y_H \sim \mathcal{N} \left( \frac{\sum y_h w_h}{\sum
w_h}, \frac{1}{\sum w_h} + \tau^2 \right)
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
w_h = \frac{1}{σ_h^2 + \tau^2}
\]</span></p>
<ul>
<li><strong>Note</strong>: If τ² is small, this implies strong
similarity (tight clustering); if τ² is large, the model treats the
studies as more different.</li>
<li><strong>Example</strong>: Meta-analyses or hierarchical models that
use multiple past studies.</li>
</ul>
<hr />
</div>
<div id="c-potential-biases" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> (c)
<strong>Potential Biases</strong></h3>
<ul>
<li><p>Historical data may contain <strong>internal</strong>
(methodological flaws) or <strong>external</strong> (population/context
mismatch) biases.</p></li>
<li><p>Rather than discarding them, Bayesian models can:</p>
<ul>
<li><strong>Quantify potential biases</strong></li>
<li>Adjust the historical estimates accordingly</li>
</ul></li>
<li><p>This is especially useful in <strong>observational
studies</strong> or when reusing <strong>non-randomised
data</strong>.</p></li>
<li><p>The adjustments can be formalised using <strong>bias
distributions</strong> or <strong>discount functions</strong>.</p></li>
</ul>
<p>Historical parameters are modeled as <strong>biased versions</strong>
of the current parameter. For each h:</p>
<p><span class="math display">\[
θ_h = θ + δ_h
\]</span></p>
<ul>
<li><p>δ_h is a bias term that can be:</p>
<ol style="list-style-type: decimal">
<li><strong>Known</strong> (fixed value).</li>
<li><strong>Random</strong>, with known distribution (e.g., δ_h ∼ N(0,
τ_h²)).</li>
<li><strong>Random with non-zero mean</strong> (e.g., δ_h ∼ N(μ_δ,
τ_h²)) to account for systematic directional bias.</li>
</ol></li>
</ul>
<p>This results in a prior:</p>
<p><span class="math display">\[
θ \mid y_h \sim \mathcal{N}(y_h, σ_h^2 + τ_h^2)
\]</span></p>
<ul>
<li>This approach acknowledges uncertainty or possible systematic errors
in the past study design or population.</li>
</ul>
<hr />
</div>
<div id="d-equal-but-discounted" class="section level3" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> (d) <strong>Equal
but Discounted</strong></h3>
<ul>
<li><p>The past data are considered <strong>unbiased</strong>, but
<strong>less reliable</strong> than current data.</p></li>
<li><p>So they are included <strong>with reduced precision</strong> — in
effect, you “shrink” their influence.</p></li>
<li><p>This approach acknowledges that historical data may be:</p>
<ul>
<li>Based on older methods</li>
<li>Less complete</li>
<li>Less relevant to the current setting</li>
</ul></li>
<li><p>In practice, this can be implemented by:</p>
<ul>
<li>Inflating the variance of historical data</li>
<li>Down-weighting the historical sample size (e.g., using <strong>power
priors</strong>)</li>
</ul></li>
</ul>
<p>Here we assume:</p>
<p><span class="math display">\[
θ_h = θ
\]</span></p>
<p>so the parameters are identical across studies, <strong>but</strong>
we <strong>discount</strong> the strength of the past evidence by a
factor α (0 &lt; α ≤ 1), known as the <strong>power prior</strong>.</p>
<p>The effect is to reduce the effective sample size (or weight) of
historical data:</p>
<p><span class="math display">\[
θ \mid y_h \sim \mathcal{N}(y_h, \frac{σ_h^2}{α})
\]</span></p>
<ul>
<li>α = 0 means full discount (historical data is irrelevant).</li>
<li>α = 1 means no discount (full pooling).</li>
<li>Intermediate α values allow <strong>partial borrowing</strong> of
strength.</li>
<li><strong>Criticism</strong>: The α value is arbitrary and lacks a
natural operational meaning.</li>
</ul>
<hr />
</div>
<div id="e-functional-dependence" class="section level3" number="4.2.5">
<h3><span class="header-section-number">4.2.5</span> (e)
<strong>Functional Dependence</strong></h3>
<ul>
<li><p>The current parameter of interest is a <strong>deterministic or
functional function</strong> of parameters estimated in past
studies.</p></li>
<li><p>For example:</p>
<ul>
<li>A cost-effectiveness model may use historical data to inform
baseline costs or risks, while current data inform treatment
effect.</li>
<li>Or a risk model may use parameters from external registries.</li>
</ul></li>
<li><p>This kind of structure can be expressed using <strong>Bayesian
networks</strong> or <strong>modular models</strong>, linking different
sources via functional relationships.</p></li>
</ul>
<p>The current parameter is a <strong>known function</strong> of
parameters from historical studies.</p>
<p>Example:</p>
<ul>
<li><p>θ₁ = treatment effect in males</p></li>
<li><p>θ₂ = treatment effect in females</p></li>
<li><p>If a future study involves 60% males, then:</p>
<p><span class="math display">\[
θ = 0.6 θ₁ + 0.4 θ₂
\]</span></p></li>
<li><p>Prior for θ is derived from known or estimated priors for θ₁ and
θ₂.</p></li>
<li><p>This method is particularly useful when populations differ but in
predictable ways.</p></li>
</ul>
<hr />
</div>
<div id="f-equal-full-pooling" class="section level3" number="4.2.6">
<h3><span class="header-section-number">4.2.6</span> (f) <strong>Equal
(Full Pooling)</strong></h3>
<ul>
<li><p>Historical and current data are considered <strong>completely
equivalent</strong>.</p></li>
<li><p>Parameters are assumed to be drawn from the <strong>same
distribution</strong>, and data can be <strong>pooled
directly</strong>.</p></li>
<li><p>This is the most optimistic assumption and works best when:</p>
<ul>
<li>The populations, protocols, and measurements are nearly
identical</li>
<li>There is strong confidence in the <strong>quality and
comparability</strong> of historical data</li>
</ul></li>
<li><p>In effect, you assume <strong>exchangeability of
individuals</strong> (not just studies), so the prior and current data
are merged seamlessly.</p></li>
</ul>
<p>This assumes all studies are measuring <strong>exactly the same
parameter</strong>:</p>
<p><span class="math display">\[
θ_h = θ \quad \text{for all } h
\]</span></p>
<ul>
<li>This is the <strong>strongest assumption</strong> and leads to
<strong>complete pooling</strong>:</li>
</ul>
<p><span class="math display">\[
θ \mid y₁, ..., y_H \sim \mathcal{N} \left( \frac{\sum y_h / σ_h^2}{\sum
1 / σ_h^2}, \frac{1}{\sum 1 / σ_h^2} \right)
\]</span></p>
<ul>
<li>Appropriate if the studies are very similar in design, population,
and implementation.</li>
<li>More acceptable in <strong>design</strong> phase (e.g., for sample
size calculation) than in analysis.</li>
</ul>
</div>
</div>
</div>
<div id="hierarchical-models" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Hierarchical
Models</h1>
<p>In real-world health care evaluation, statistical inference often
faces <strong>multiplicity</strong>—the need to analyze multiple
parameters:</p>
<ul>
<li>Multiple subgroups in a trial (e.g. age, gender)</li>
<li>Multiple endpoints (e.g. death, complications)</li>
<li>Multiple institutions (e.g. hospitals, regions)</li>
<li>Multiple treatment comparisons or repeated trials</li>
</ul>
<p>To handle this, <strong>Bayesian hierarchical models</strong> offer a
structured approach that accounts for:</p>
<ul>
<li>Similarities (exchangeability) across units</li>
<li>Variability between units</li>
<li>The influence of prior beliefs</li>
</ul>
<p>Three conceptual assumptions help guide the modeling:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Identical parameters (complete pooling)</strong> All
units are assumed to estimate the same underlying effect <span
class="math inline">\(\theta\)</span>, and their data are fully pooled.
For example:</p>
<p><span class="math display">\[
Y_k \sim N(\theta, \sigma_k^2)
\]</span></p>
<p>Bayesian updating leads to a pooled posterior for <span
class="math inline">\(\theta\)</span>, resembling a weighted average of
individual estimates.</p></li>
<li><p><strong>Independent parameters (no pooling)</strong> Each <span
class="math inline">\(\theta_k\)</span> is estimated independently.</p>
<p><span class="math display">\[
\theta_k \sim \text{Uniform}, \quad Y_k \sim N(\theta_k, \sigma_k^2)
\]</span></p>
<p>This gives posterior:</p>
<p><span class="math display">\[
\theta_k \mid y_k \sim N(y_k, \sigma_k^2)
\]</span></p>
<p>No information is shared between units.</p></li>
<li><p><strong>Exchangeable parameters (partial pooling via hierarchical
models)</strong> Each <span class="math inline">\(\theta_k\)</span> is
viewed as drawn from a population distribution:</p>
<p><span class="math display">\[
\theta_k \sim N(\mu, \tau^2), \quad Y_k \sim N(\theta_k, \sigma_k^2)
\]</span></p>
<p>Here, <span class="math inline">\(\mu\)</span> and <span
class="math inline">\(\tau^2\)</span> are hyperparameters—estimated from
the data (empirical Bayes) or given priors (full Bayes). The posterior
shrinks each unit’s estimate toward <span
class="math inline">\(\mu\)</span>, with the <strong>shrinkage
factor</strong>:</p>
<p><span class="math display">\[
B_k = \frac{\sigma_k^2}{\sigma_k^2 + \tau^2}
\]</span></p>
<p>Larger <span class="math inline">\(\tau^2\)</span>: less pooling.
Smaller <span class="math inline">\(\tau^2\)</span>: more
shrinkage.</p></li>
</ol>
<p>First, assuming all parameters are identical implies complete
pooling. Under this model, each unit (e.g., trial or subgroup) is
estimating the same underlying effect. All data are combined into one
analysis, and individual differences are ignored. Statistically, this is
equivalent to estimating a single parameter using weighted averages. The
result is a high degree of certainty, but potentially oversimplified if
real variation exists.</p>
<p>Second, assuming all parameters are independent implies no pooling.
Each unit is analyzed separately, with no borrowing of information. This
is the most conservative approach and gives wide uncertainty intervals.
Statistically, this treats each observed effect as arising from its own
prior, typically uniform, resulting in posterior distributions that are
just normal likelihoods centered on the data.</p>
<p>Third, the most nuanced assumption is that of exchangeability. Here,
the individual parameters (such as treatment effects) are assumed to be
drawn from a common population distribution. This does not imply they
are the same, but rather that we have no reason to believe any one is
systematically different from the others. Exchangeability leads
naturally to hierarchical or multi-level models, where the unit-specific
effects are modeled as random effects with a common mean and
variance.</p>
<p>Under the exchangeability assumption, each observed effect is shrunk
toward the group mean, and the degree of shrinkage depends on the
relative variances of the data and the prior. Smaller, more uncertain
studies shrink more; large, precise studies shrink less. This is known
as partial pooling and helps stabilize estimates, particularly when
individual studies are small or noisy.</p>
<p>A practical example is the magnesium meta-analysis. Early small
trials showed a large mortality benefit for magnesium in acute
myocardial infarction. A fixed-effects meta-analysis found a significant
odds ratio of 0.67. A hierarchical Bayesian model, assuming
exchangeability of trial effects, moderated this to an odds ratio of
0.58, as extreme results from small trials were shrunk toward the
overall mean. This demonstrates how Bayesian models can temper
overoptimistic findings from underpowered studies.</p>
<p>To assess the credibility of such findings, sceptical priors centered
on no effect (odds ratio = 1) are introduced. In the pooled analysis, a
highly sceptical prior equivalent to 421 events is needed to make the
posterior just include 1—an unrealistically extreme prior. In the
random-effects model, a sceptical prior equivalent to only 58 events is
sufficient to neutralize the evidence. This suggests the evidence is
more fragile and less convincing under the hierarchical model.</p>
</div>
<div id="nuisance-parameters" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Nuisance
Parameters</h1>
<p><strong>Nuisance parameters</strong> are common in most real-world
models. For example, if the main goal is to estimate a treatment effect
(denoted by θ), the data may also depend on background factors,
variances, or baseline event rates, which are not of direct interest.
These are nuisance parameters.</p>
<p><strong>Classical Methods for Eliminating Nuisance
Parameters</strong></p>
<p>Several techniques in traditional statistics aim to remove or reduce
the influence of nuisance parameters from the likelihood function for
θ:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Likelihood approximation</strong> Use a summary statistic
or transformation whose likelihood does not depend on nuisance
parameters. For example, normal approximations for odds ratios or hazard
ratios eliminate dependence on unknown variances.</p></li>
<li><p><strong>Plug-in estimates</strong> Estimate the nuisance
parameters (usually by maximum likelihood) and substitute them into the
likelihood for θ. This is computationally simple but can underestimate
uncertainty, especially if the number of nuisance parameters is large.
In Bayesian terms, this is known as the <strong>empirical Bayes</strong>
approach.</p></li>
<li><p><strong>Conditional likelihood</strong> Form a conditional
likelihood that depends only on θ, by conditioning on aspects of the
data that are uninformative about the nuisance parameters. This is a
popular method in likelihood-based inference.</p></li>
<li><p><strong>Profile likelihood</strong> Maximize the likelihood over
nuisance parameters for each value of θ, producing a “profile”
likelihood function. This function depends only on θ and can be used for
inference. This method is illustrated in the hierarchical
modeling.</p></li>
</ol>
<p>Each of these methods ultimately reduces the problem to one involving
only θ, which can then be combined with a prior to conduct a Bayesian
analysis.</p>
<p><strong>The Fully Bayesian Approach</strong></p>
<p>The full Bayesian treatment of nuisance parameters avoids removing
them from the likelihood altogether. Instead:</p>
<ol style="list-style-type: decimal">
<li><strong>Assign priors</strong> to all parameters, including nuisance
ones.</li>
<li><strong>Construct the joint posterior distribution</strong> for all
parameters.</li>
<li><strong>Integrate out the nuisance parameters</strong> to obtain the
marginal posterior for θ.</li>
</ol>
<p>This method fully accounts for uncertainty in the nuisance parameters
and is consistent with Bayesian principles. However, it can be
computationally intensive, especially in high-dimensional models.</p>
<p>This approach is used in various situations, such as:</p>
<ul>
<li>Binomial data with uncertain control risks</li>
<li>Poisson models with unknown baseline rates</li>
<li>Normal models with unknown variances</li>
</ul>
<p>When hierarchical models are used, often the full Bayesian model is
used only at the higher levels (e.g., for between-group variance τ),
while using approximations at the lower (sampling) level.</p>
<p><strong>Sensitivity analysis</strong> is emphasized as essential when
placing priors on nuisance parameters. Even seemingly non-informative
priors can exert significant influence on the posterior if not carefully
chosen. In such cases, combining traditional techniques for handling
nuisance parameters with Bayesian analysis of the primary parameter may
offer a good compromise.</p>
</div>
<div id="how-to-use-bayesian" class="section level1" number="7">
<h1><span class="header-section-number">7</span> How to Use
Bayesian</h1>
<div id="bayesian-checklist" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Bayesian
Checklist</h2>
<p>Here is a detailed explanation of the <strong>Bayesian
Checklist</strong> for reporting and evaluating Bayesian analyses,
especially in the context of health-care intervention studies. The
checklist serves as a framework to ensure transparency, reproducibility,
and credibility of Bayesian modeling and decision-making.</p>
<hr />
<p><strong>1. Background</strong></p>
<p><strong>The Intervention</strong> Clearly describe the intervention
being evaluated, the context (clinical or policy), and the target
population. This should make clear the relevance and scope of the
analysis.</p>
<p><strong>Aim of Study</strong> Specify what you are trying to infer
(the parameters of interest, such as treatment effect) and what
decisions or actions (if any) may follow from the analysis. The former
requires a prior distribution; the latter should be supported by a loss
or utility function.</p>
<hr />
<p><strong>2. Methods</strong></p>
<p><strong>Study Design</strong> Describe the design of the study or
studies being analyzed. If data are pooled from multiple sources,
comment on their similarity to justify any assumptions of
<em>exchangeability</em> (i.e. whether they can be treated as if drawn
from the same distribution).</p>
<p><strong>Outcome Measure</strong> State the quantity of primary
interest (e.g. odds ratio, risk difference, mean effect) that you are
estimating or predicting.</p>
<p><strong>Statistical Model</strong> Lay out the relationship between
the observed data and the underlying parameters. This could be a full
probabilistic model (likelihood plus prior), or a description detailed
enough for a competent analyst to reconstruct it mathematically.</p>
<p><strong>Prospective Bayesian Analysis</strong> Indicate whether the
Bayesian components (e.g., priors, utility functions) were defined
before data collection (prospective), or adapted after seeing the data
(retrospective). Mention whether interim analyses were planned.</p>
<p><strong>Prior Distribution</strong> Clearly specify priors for all
parameters of interest.</p>
<ul>
<li>If <strong>informative</strong>, explain how it was elicited (e.g.,
expert opinion, historical data).</li>
<li>If <strong>non-informative</strong>, justify why it is reasonable in
the context.</li>
<li>If multiple priors are compared (for sensitivity analysis), describe
them all explicitly.</li>
</ul>
<p><strong>Loss Function or Decision Framework</strong> If the study
involves decisions (e.g., whether to proceed with treatment approval),
specify the loss or utility function. This might involve:</p>
<ul>
<li>A threshold for clinical equivalence</li>
<li>A cost-benefit tradeoff</li>
<li>An expert-elicited function Explain how it was derived and how it
connects to the posterior distribution.</li>
</ul>
<p><strong>Computation and Software</strong> Describe what computational
methods were used—especially if Markov Chain Monte Carlo (MCMC) or
similar techniques were involved.</p>
<ul>
<li>Mention the software used</li>
<li>Justify that the MCMC chains converged</li>
<li>Provide enough detail for results to be reproducible</li>
</ul>
<hr />
<p><strong>3. Results</strong></p>
<p><strong>Evidence from the Study</strong> Report the raw data as
clearly as confidentiality permits:</p>
<ul>
<li>Sample sizes</li>
<li>Measurements</li>
<li>Event counts</li>
<li>Observed means or proportions This ensures that others can
reconstruct the likelihood and use the results in subsequent
meta-analyses.</li>
</ul>
<hr />
<p><strong>4. Interpretation</strong></p>
<p><strong>Bayesian Interpretation</strong> Summarize the posterior
distribution:</p>
<ul>
<li>Give credible intervals (e.g., 95%)</li>
<li>Include plots where helpful</li>
<li>Report posterior probabilities of clinically relevant thresholds
being exceeded</li>
<li>If decision rules were used, interpret results in terms of the
associated losses or utilities</li>
</ul>
<p>Make a clear distinction between:</p>
<ul>
<li>A <strong>stand-alone analysis</strong> intended to guide an
immediate decision</li>
<li>A <strong>contributory analysis</strong> that will be part of a
larger evidence synthesis later</li>
</ul>
<p><strong>Sensitivity Analysis</strong> Report how different prior
distributions or loss functions affected the results. If the conclusions
change substantially, this needs to be acknowledged and discussed.</p>
<p><strong>Comments</strong> Provide a candid evaluation of:</p>
<ul>
<li>The strengths of the model (e.g., ability to handle uncertainty, use
of external data)</li>
<li>Potential weaknesses (e.g., dependence on prior assumptions, model
misspecification) This promotes scientific transparency and helps users
judge the robustness of the conclusions.</li>
</ul>
<hr />
<p>This checklist functions as a <strong>template for best
practices</strong> in Bayesian analysis, ensuring clarity and
reproducibility. It complements more general reporting standards like
CONSORT but is focused on Bayesian-specific elements like priors,
posterior distributions, and decision-making under uncertainty.</p>
</div>
<div id="structure-of-the-alternative" class="section level2"
number="7.2">
<h2><span class="header-section-number">7.2</span> Structure of the
Alternative</h2>
<p>It would be misleading to dichotomise statistical methods as either
‘classical’ or ‘Bayesian’, since both terms cover a bewildering range of
techniques. A rough taxonomy can be developed by distinguishing two
characteristics: whether or not prior distributions are used for
inferences, and whether the objective is estimation, hypothesis testing
or a decision requiring a loss function of some form. A</p>
<ul>
<li><p><strong>Whether prior knowledge is used</strong>:</p>
<ul>
<li><em>Informal</em>: no formal incorporation of prior beliefs (typical
in classical statistics).</li>
<li><em>Formal</em>: prior information is incorporated through a
specified prior distribution (Bayesian approach).</li>
</ul></li>
<li><p><strong>What the analysis aims to achieve</strong>:</p>
<ul>
<li><em>Inference (estimation)</em>: estimating unknown parameters.</li>
<li><em>Hypothesis testing</em>: comparing competing models or
claims.</li>
<li><em>Decision-making</em>: making choices under uncertainty,
typically using a loss or utility function.</li>
</ul></li>
</ul>
<p>Here is the summarized structure:</p>
<table>
<colgroup>
<col width="18%" />
<col width="36%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th>Objective</th>
<th>Informal (No Prior)</th>
<th>Formal (Uses Prior)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Inference</td>
<td><strong>Fisherian</strong></td>
<td><strong>Proper Bayesian</strong></td>
</tr>
<tr class="even">
<td>Hypothesis Test</td>
<td><strong>Neyman–Pearson</strong></td>
<td><strong>Bayes Factors</strong></td>
</tr>
<tr class="odd">
<td>Decision</td>
<td><strong>Classical Decision Theory</strong></td>
<td><strong>Full Decision-Theoretic Bayesian</strong></td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li><p><strong>Fisherian (Inference + No Prior)</strong></p>
<p>Focuses on likelihood-based estimation, using maximum likelihood or
likelihood intervals without formal priors.</p>
<p>The Fisherian method focuses on the <strong>likelihood
function</strong>, which measures how well different parameter values
are supported by the observed data. Key elements include:</p>
<ul>
<li><strong>Maximum Likelihood Estimation (MLE)</strong>: Selects the
parameter value that maximizes the likelihood.</li>
<li><strong>Likelihood-based intervals</strong>: Constructed from
regions with high likelihood support.</li>
<li><strong>P-values</strong>: Proposed by Fisher as a guide to measure
evidence against the null hypothesis. However, Fisher intended P-values
to be <strong>informal</strong>, not as rigid decision thresholds.</li>
</ul>
<p><strong>Criticism</strong>: Fisher’s use of P-values has been
misapplied over time—used as formal proof rather than as measures of
evidence.</p></li>
<li><p><strong>Proper Bayesian (Inference + Prior)</strong></p>
<p>Estimates parameters by combining prior distributions with
likelihoods to form posterior distributions.</p></li>
<li><p><strong>Neyman–Pearson (Testing + No Prior)</strong></p>
<p>Classical hypothesis testing framework: use of null/alternative
hypotheses, p-values, Type I and II errors.</p>
<p>Neyman–Pearson theory is based on <strong>decision-making under
repeated sampling</strong> and is more procedural:</p>
<ul>
<li><strong>Type I error (α)</strong>: Probability of incorrectly
rejecting the null hypothesis.</li>
<li><strong>Type II error (β)</strong>: Probability of failing to detect
a real effect.</li>
<li><strong>Power</strong>: 1 − β, the probability of correctly
detecting a true effect.</li>
<li><strong>Confidence intervals</strong>: Constructed so that, in the
long run, 95% of them will contain the true value.</li>
</ul>
<p><strong>Criticism</strong>: The approach doesn’t allow direct
probability statements about the hypothesis or observed result in a
specific trial. Its concepts apply to <strong>repeated
experiments</strong>, not necessarily to the one at hand.</p></li>
<li><p><strong>Bayes Factors (Testing + Prior)</strong></p>
<p>Bayesian hypothesis testing using the ratio of marginal likelihoods
under two models (see Bayes Factor).</p>
<ul>
<li>P-values do <strong>not</strong> obey the likelihood principle (they
can depend on the study design or stopping rules).</li>
<li>Bayes factors <strong>do</strong> obey the likelihood principle:
they assess evidence <strong>purely from the observed
data</strong>.</li>
<li>P-values are often <strong>misinterpreted</strong> as the
probability that H₀ is true. Bayes factors more naturally address that
question.</li>
</ul></li>
<li><p><strong>Classical Decision Theory (Decision + No
Prior)</strong></p>
<p>Uses frequentist ideas to minimize expected loss, assuming no prior
distribution on parameters.</p></li>
<li><p><strong>Full Decision-Theoretic Bayesian (Decision +
Prior)</strong></p>
<p>Makes decisions by minimizing expected loss with respect to a
posterior distribution. Explicitly combines beliefs and
consequences.</p></li>
</ol>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
