<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title> Bayesian Theory</title>

<script src="site_libs/header-attrs-2.28/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Zehui Bai</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="02-Clinical_Experience.html">
    <span class="fa fa-user"></span>
     
    Clinical Experience
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-sliders"></span>
     
    Sample Size
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="03-SSC-Everything-to-Know-About-Sample-Size-Determination.html">Everything to Know About Sample Size Determination</a>
    </li>
    <li>
      <a href="03-SSC-Choosing-the-Effect-Size-for-Sample-Size-Calculations.html">Choosing the Effect Size</a>
    </li>
    <li>
      <a href="03-SSC-Biosimilar-Trials.html">Statistical Considerations for the Design and Analysis of Biosimilar Trials</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-and-Power-for-Non-Parametric-Analysis.html">Sample Size and Power for Non-Parametric Analysis</a>
    </li>
    <li>
      <a href="03-SSC-Power-for-Complex-Hypotheses.html">Power for Complex Hypotheses</a>
    </li>
    <li>
      <a href="03-SSC-Alternatives-to-Power.html">Bayesian methods - Alternatives to Power</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-for-Pilot-Studies.html">Sample Size for Pilot Studies</a>
    </li>
    <li>
      <a href="03-SSC-Case-Continuous-Endpoint.html">Sample Size Determination for Continuous Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Categorical-Endpoint.html">Sample Size Determination for Categorical Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Survival-Endpoint.html">Sample Size Determination for Survival Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Repeated-Measures.html">Sample Size Determination for Repeated Measures</a>
    </li>
    <li>
      <a href="03-SSC-IA-Sequential-Design.html">Statistical Considerations for Group Sequential Design</a>
    </li>
    <li>
      <a href="03-SSC-IA-Adaptive-Design.html">Statistical Considerations for Adaptive Design</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-pencil-square-o"></span>
     
    Study Design
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="04-Design-Estimands.html">Estimands and Sensitivity Analyses</a>
    </li>
    <li>
      <a href="04-Design-Dose-Escalation-and-Stratification-Designs.html">Dose Escalation and Stratification Designs in Early Oncology Development</a>
    </li>
    <li>
      <a href="04-Design-Phase-I-Trials---Design-Considerations.html">Phase I Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-II-Trials---Design-Considerations.html">Phase II Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-III-Trials---Design-Considerations.html">Phase III Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-IV-Trials---Design-Considerations.html">Phase IV Trials - Design Considerations for Post Marketing Surveillance</a>
    </li>
    <li>
      <a href="04-Design-Design-and-Monitoring-of-Adaptive-Clinical-Trials.html">Design and Monitoring of Adaptive Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Design-and-Evaluation-of-Complex-Sequential-Trials.html">Design and Evaluation of Complex Sequential Analysis Trials</a>
    </li>
    <li>
      <a href="04-Design-Design-and-Evaluation-of-Diagnostic-Study.html">Design and Evaluation of Diagnostic Study</a>
    </li>
    <li>
      <a href="04-Design-Hierarchical-composite-endpoints.html">Hierarchical Composite Endpoints</a>
    </li>
    <li>
      <a href="04-Design-Externally-Controlled-Trials.html">Considerations for the Design and Conduct of Externally Controlled Trials</a>
    </li>
    <li>
      <a href="04-Design-Noninferiority-Trials.html">Noninferiority Trials</a>
    </li>
    <li>
      <a href="04-Design-Bioequivalence-and-Biosimilar-Trials.html">Bioequivalence and Biosimilar Trials</a>
    </li>
    <li>
      <a href="04-Design-Exploring-Survival-Analysis-Designs-for-Clinical-Trials.html">Exploring Survival Analysis Designs for Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Projecting-How-Long-Your-Trial-Will-Take.html">Projecting How Long Your Trial Will Take</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-line-chart"></span>
     
    Data Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="05-Plot-Adverse-Event.html">Adverse Event Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Laboratory-Data.html">Laboratory Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Time-To-Event.html">Time to Event Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-PRO-Data.html">Patient Reported Outcome Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-SSC-and-Power-Calculation.html">Sample Size and Power Calculations Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Correlation.html">Correlation Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Model-Table.html">Clinical Data and Model visualization</a>
    </li>
    <li>
      <a href="05-Plot-ScatterPlot.html">Scatter and Line Plot</a>
    </li>
    <li>
      <a href="05-Plot-BarPlot.html">Bar Chart</a>
    </li>
    <li>
      <a href="05-Plot-PieChart.html">Pie Chart</a>
    </li>
    <li>
      <a href="05-Plot-BoxPlot.html">Box Plot</a>
    </li>
    <li>
      <a href="05-Plot-Histogram.html">Histogram</a>
    </li>
    <li>
      <a href="05-Plot-Forest-Plot.html">Forest Plot</a>
    </li>
    <li>
      <a href="05-Plot-Flow-Chart.html">Flow Chart</a>
    </li>
    <li>
      <a href="05-Plot-Some-Interesting.html">Some Interesting Plots</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-calculator"></span>
     
    Statistical Analysis
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06-Analysis-Linear-Regression.html">Linear Regression</a>
    </li>
    <li>
      <a href="06-Analysis-Logistic-Regression.html">Logistic Regression</a>
    </li>
    <li>
      <a href="06-Analysis-Mixed-Model.html">Mixed Model</a>
    </li>
    <li>
      <a href="06-Analysis-MMRM.html">Mixed Model Repeated Measures</a>
    </li>
    <li>
      <a href="06-Analysis-GEE.html">Generalized Estimating Equation</a>
    </li>
    <li>
      <a href="06-Analysis-ANOVA.html">Analysis of Variance</a>
    </li>
    <li>
      <a href="06-Analysis-Survival-Analysis.html">Survival Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Survival-Competing-Risk.html">Survival Analysis - Competing Risk</a>
    </li>
    <li>
      <a href="06-Analysis-Missing-Data.html">Missing Data Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-MI-Implementation.html">Multiple Imputation Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Meta-Analysis.html">Meta Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-PK-and-PD.html">PK and PD Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Time-Series-Analysis.html">Time Series Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-SEM.html">Structural Equation Modeling</a>
    </li>
    <li>
      <a href="06-Analysis-Factor-Analysis.html">Factor Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="07-ML-Bayesian-Theory.html">Bayesian Theory</a>
    </li>
    <li>
      <a href="07-ML-Bayesian-Analysis.html">Bayesian Analysis</a>
    </li>
    <li>
      <a href="07-ML-Regularization-Penalized-Regression.html">Regularization Penalized Regression</a>
    </li>
    <li>
      <a href="07-ML-Loss-Regression.html">Loss Functions in Machine Learning</a>
    </li>
    <li>
      <a href="07-ML-PCA.html">Principal Component Analysis</a>
    </li>
    <li>
      <a href="07-ML-KNN.html">K-Nearest Neighbors</a>
    </li>
    <li>
      <a href="07-ML-SVM.html">Support Vector Machine</a>
    </li>
    <li>
      <a href="07-ML-Tree-Models.html">Tree Models</a>
    </li>
    <li>
      <a href="07-ML-LDA.html">Linear Discriminant Analysis</a>
    </li>
    <li>
      <a href="07-ML-Cluster-Analysis.html">Cluster Analysis</a>
    </li>
    <li>
      <a href="07-ML-Neural-Networks.html">Neural Network</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="08-CV.html">
    <span class="fa fa-file-pdf-o"></span>
     
    CV
  </a>
</li>
<li>
  <a href="mailto:zehuibai@outlook.com">
    <span class="fa fa-envelope-o"></span>
     
    Contact me
  </a>
</li>
<li>
  <a href="https://github.com/Zehuibai">
    <span class="fa fa-github"></span>
     
    GitHub
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore"><p><img src="logo.png"
style="width:3in" /><br />
Bayesian Theory</p></h1>

</div>


<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<div id="frequency-and-bayesian" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Frequency and
Bayesian</h2>
<ul>
<li>In the realm of statistics, two main schools of thought offer
distinct approaches to understanding and interpreting data: the
frequency school and the Bayesian school.</li>
<li>The frequency school posits that overall parameters are fixed and
that samples are acquired randomly. This perspective views each random
sample as an imperfect representation of an ideal entity. By applying
methods like maximum likelihood estimation, the frequency school aims to
infer the most probable parameters that could result in the observed
samples.</li>
<li>Contrarily, the Bayesian school considers overall parameters as
random variables, while the samples obtained are seen as fixed.
Bayesians are less concerned with pinpointing the exact parameters;
instead, they focus on updating beliefs about these parameters. They
utilize prior knowledge combined with newly acquired data to compute the
posterior probability distribution, facilitating statistical inference
through this updated belief system.</li>
</ul>
<p><strong>Bayesian Inference: Priors, Posteriors, and Predictive
Analysis</strong></p>
<ul>
<li>Prior probability distributions represent our beliefs about
hypotheses before we analyze any data. These priors are foundational in
Bayesian inference, which updates these beliefs to posterior
probabilities upon receiving new data.</li>
<li>The posterior probability distribution, denoted as <span
class="math display">\[\mathrm{P}(\theta | \text{data})\]</span>, is a
cornerstone of Bayesian reasoning. This distribution encapsulates our
uncertainty about parameter values. A narrower distribution suggests
higher confidence in our estimates of these values. By gathering more
data, we can achieve more precise posterior distributions.</li>
<li>Moreover, the posterior distribution is instrumental in forecasting
future outcomes of experiments and testing models. It allows
statisticians to make informed predictions and validate hypotheses
effectively.</li>
</ul>
</div>
<div id="bayesian-and-classical-methods" class="section level2"
number="1.2">
<h2><span class="header-section-number">1.2</span> Bayesian and
Classical Methods</h2>
<p>Bayesian analysis has several advantages over classical analysis in
the context of clinical trials. These include the ability to incorporate
prior information about treatment efficacies into the analysis, the
flexibility to make multiple unscheduled inspections of accumulating
data without increasing the error rate, and the capability to calculate
the probability that one treatment is more effective than another.</p>
<p>In contrast to classical methods, Bayesian analysis is conditional on
the observed data and focuses on the probability that a conclusion or
hypothesis is true given the available data. Classical inference,
however, is not conditional on the observed data but instead concerns
the behavior of a statistical procedure over an infinite number of
repetitions, considering all potential data that might have been
observed under a hypothesis. Bayesians deal with the probabilities of
hypotheses given a dataset, whereas frequentists concern themselves with
the probabilities of datasets given a hypothesis.</p>
<p><strong>1. Overview of Bayesian and Classical Analysis</strong></p>
<ul>
<li><strong>Bayesian Analysis:</strong>
<ul>
<li><strong>Incorporates Prior Information:</strong> Utilizes existing
knowledge about treatment effects, enhancing analytical precision.</li>
<li><strong>Flexible Data Inspection:</strong> Allows multiple reviews
of ongoing data without affecting the error rates, promoting adaptive
research approaches.</li>
<li><strong>Probabilistic Outcomes:</strong> Computes the likelihood of
one treatment outperforming another, providing direct answers to
clinical questions.</li>
</ul></li>
<li><strong>Classical Analysis:</strong>
<ul>
<li><strong>Fixed Procedure:</strong> Relies on a set framework
involving hypothesis testing with less adaptability in procedure once
the analysis begins.</li>
<li><strong>Repetition-Based:</strong> Focuses on long-term behavior
over many hypothetical repeats of the study, which can disconnect
results from the practical needs of clinicians.</li>
</ul></li>
</ul>
<p><strong>2. Methodological Contrasts</strong></p>
<ul>
<li><strong>Conditional vs. Unconditional Frameworks:</strong>
<ul>
<li><strong>Bayesian:</strong> Analysis is conditional on the data
observed, directly tying conclusions to the evidence at hand.</li>
<li><strong>Classical:</strong> Operates independent of the specific
data set, which can lead to less direct applicability to the individual
study results.</li>
</ul></li>
<li><strong>Hypothesis Testing Approach:</strong>
<ul>
<li><strong>Bayesian:</strong> Engages directly with the probability of
hypotheses given the data, making it inherently responsive to new
information.</li>
<li><strong>Classical:</strong> Concentrates on the probability of data
given predefined hypotheses, often leading to rigid
interpretations.</li>
</ul></li>
</ul>
<p><strong>3. Limitations in Classical Hypothesis Testing</strong></p>
<ul>
<li><strong>Inflexibility in Hypothesis Evaluation:</strong> Classical
methods typically commit to the first plausible alternative hypothesis
upon rejecting the null, without thorough consideration of other viable
hypotheses.</li>
<li><strong>Impact of Data Peeking:</strong> Interim data reviews can
affect the study’s error rates under classical approaches, a scenario
not adequately addressed in traditional frameworks.</li>
</ul>
<p><strong>4. Advantages of Bayesian Methodology</strong></p>
<ul>
<li><strong>Utilization of Bayes’ Theorem:</strong> Allows for
calculating the true probability of a hypothesis based on both prior
knowledge and new data.</li>
<li><strong>Integration of Prior Beliefs:</strong> Bayesian methods can
quantitatively incorporate uncertainties about prior information,
adjusting the analysis to reflect varying degrees of prior
reliability.</li>
<li><strong>Flexibility in Clinical Trials:</strong> Does not require
preset patient numbers or analysis timings, adapting more naturally to
the dynamics of trial execution.</li>
</ul>
<p><strong>5. Implementation and Impact</strong></p>
<ul>
<li><strong>Defining Prior Knowledge:</strong> Establishing the initial
probability distributions based on literature, expert opinions, and
preliminary studies to guide the analysis.</li>
<li><strong>Data Acquisition and Adjustment:</strong> Continuous
updating of prior estimates with incoming trial data to refine the
posterior estimates.</li>
<li><strong>Posterior Analysis:</strong> Results in detailed probability
distributions that offer nuanced insights into treatment efficacy,
enhancing decision-making with probabilistic ranges for treatment
effects.</li>
</ul>
</div>
<div id="bayes-theorem" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Bayes’ Theorem</h2>
<p>Bayes’ theorem can be expressed mathematically in the context of
Bayesian inference as:</p>
<p><span class="math display">\[
\overbrace{p(\theta/D)}^{\text{Posterior}} =
\frac{\overbrace{p(D/\theta)}^{\text{Likelihood}} \cdot
\overbrace{p(\theta)}^{\text{Prior}}}{\underbrace{p(D)}_{\text{Evidence}}}
\]</span></p>
<p>This equation is fundamental to Bayesian analysis and can be broken
down into three critical components:</p>
<ol style="list-style-type: decimal">
<li><strong>Posterior Probability ( <span
class="math inline">\(p(\theta/D)\)</span> ):</strong>
<ul>
<li>This is the probability of the hypothesis <span
class="math inline">\(\theta\)</span> given the data <span
class="math inline">\(D\)</span>.</li>
<li>It is updated knowledge after considering new evidence.</li>
<li>It provides a measure of how plausible the hypothesis is in the
light of the available data.</li>
</ul></li>
<li><strong>Likelihood ( <span
class="math inline">\(p(D/\theta)\)</span> ):</strong>
<ul>
<li>This is the probability of observing the data <span
class="math inline">\(D\)</span> given that the hypothesis <span
class="math inline">\(\theta\)</span> is true.</li>
<li>It assesses how probable the observed data are under different
hypothetical conditions specified by <span
class="math inline">\(\theta\)</span>.</li>
</ul></li>
<li><strong>Prior Probability ( <span
class="math inline">\(p(\theta)\)</span> ):</strong>
<ul>
<li>This is the probability of the hypothesis before observing the
current data.</li>
<li>It incorporates existing knowledge or beliefs about the parameter
before new data is taken into account.</li>
</ul></li>
<li><strong>Evidence or Marginal Likelihood ( <span
class="math inline">\(p(D)\)</span> ):</strong>
<ul>
<li>This is also known as the marginal probability of the observed
data.</li>
<li>It is calculated by integrating or summing over all possible values
of <span class="math inline">\(\theta\)</span>, essentially averaging
the likelihoods weighted by the prior probabilities.</li>
<li>In practice, this acts as a normalizing constant to ensure the
posterior probabilities sum to one.</li>
</ul></li>
</ol>
<div id="prior-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Prior Distribution</h3>
<p>The <strong>Prior Distribution</strong> in Bayesian statistics is a
fundamental component that encapsulates our knowledge or beliefs about a
parameter before we observe any data. It’s an expression of our
subjective or objective preconceptions about the values that a
parameter, typically denoted as <span
class="math inline">\(\theta\)</span>, might take based on previous
experience, existing knowledge, or expert opinion.</p>
<p><strong>Characteristics of Prior Distributions</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Subjective or Objective</strong>:
<ul>
<li><strong>Subjective Priors</strong>: These are based on personal
beliefs or expert opinions and are particularly useful when historical
data is sparse or when new phenomena are being studied. Subjective
priors can incorporate insights from experts, results from previous
studies that are not strictly comparable, or institutional
knowledge.</li>
<li><strong>Objective Priors</strong>: These are formulated to minimize
the influence of the prior, aiming to let the data speak for themselves.
Objective priors include non-informative priors, which are designed to
have minimal impact on the posterior outcomes. Examples include
Jeffreys’ prior and uniform distributions in certain contexts.</li>
</ul></li>
<li><strong>Informative vs. Non-Informative</strong>:
<ul>
<li><strong>Informative Priors</strong>: These contain specific
information about a parameter. For instance, if previous studies suggest
that a parameter is likely centered around a particular value with some
variance, the prior distribution can be centered at this value with a
spread reflecting this variance.</li>
<li><strong>Non-Informative Priors</strong>: These are used when no
substantial prior knowledge about a parameter is available or when it is
desirable to not let prior assumptions heavily influence the results.
They are often broad and flat, indicating equal probability across a
wide range of parameter values, thereby allowing the data to have a
stronger influence on the posterior distribution.</li>
</ul></li>
</ol>
<p><strong>Role of Prior Distribution in Bayesian Analysis</strong></p>
<ul>
<li><strong>Initial Belief Modeling</strong>: The prior distribution
models the initial belief about the parameter before new data is taken
into account.</li>
<li><strong>Updating Beliefs</strong>: In Bayesian inference, the prior
distribution is updated with the likelihood of observing the new data
given possible parameter values, resulting in the posterior
distribution. This process is governed by Bayes’ theorem: <span
class="math display">\[
\text{Posterior} \propto \text{Likelihood} \times \text{Prior}
\]</span></li>
<li><strong>Impact on Posterior</strong>: The strength and nature of the
prior can significantly affect the posterior, especially when the amount
of data is small. With more data, the influence of the prior generally
diminishes, particularly if the prior is non-informative.</li>
</ul>
</div>
<div id="likelihood-function" class="section level3 unnumbered">
<h3 class="unnumbered">Likelihood Function</h3>
<p>Bayesian inference updates the prior probability distribution based
on newly acquired data. According to Bayes’ theorem, the posterior
distribution <span class="math inline">\(p(\theta| x)\)</span> is
proportional to the product of the likelihood <span
class="math inline">\(p(x | \theta)\)</span> and the prior distribution
<span class="math inline">\(p(\theta)\)</span>, expressed as:</p>
<p><span class="math display">\[ p(\theta|x) \propto
p(x|\theta)p(\theta) \]</span></p>
<p>The integral of the likelihood function over the prior distribution,
normalized by the probability of the data <span
class="math inline">\(p(x)\)</span>, provides the marginal
likelihood:</p>
<p><span class="math display">\[ p(x) = \int p(x|\theta)p(\theta)
d\theta \]</span></p>
<p>This marginal likelihood <span class="math inline">\(p(x)\)</span>
serves as the normalizing constant for the posterior distribution:</p>
<p><span class="math display">\[ p(\theta|x) =
\frac{p(x|\theta)p(\theta)}{p(x)} \]</span></p>
<p>Bayesian inference effectively incorporates nuisance parameters by
integrating them out of the joint posterior to provide a marginal
posterior distribution <span class="math inline">\(p(\theta_1 |
x)\)</span>, which is calculated by integrating over the nuisance
parameter <span class="math inline">\(\theta_2\)</span>:</p>
<p><span class="math display">\[ p(\theta_1 | x) = \int p(\theta_1,
\theta_2 | x) p(\theta_2 | d\theta_2) \]</span></p>
</div>
<div id="posterior-distribution" class="section level3 unnumbered">
<h3 class="unnumbered">Posterior Distribution</h3>
<ol style="list-style-type: decimal">
<li><strong>Bayesian Update</strong>:
<ul>
<li>Bayesian analysis modifies the likelihood by incorporating a prior
belief about the parameters, <span
class="math inline">\(\pi(\theta)\)</span>, leading to the posterior
distribution.</li>
<li>The posterior distribution is calculated using Bayes’ theorem: <span
class="math display">\[
\pi(\theta \mid \mathscr{D}_{n}) = \frac{\ell(\theta \mid
\mathscr{D}_{n}) \pi(\theta)}{\int \ell(\theta \mid \mathscr{D}_{n})
\pi(\theta) \, d \theta}
\]</span></li>
<li>This results in a probability distribution over the parameter space
<span class="math inline">\(\Theta\)</span>, reflecting updated beliefs
after considering the observed data.</li>
</ul></li>
<li><strong>Choosing the Prior</strong>:
<ul>
<li>The selection of the prior, <span
class="math inline">\(\pi(\theta)\)</span>, is crucial as it represents
the initial beliefs about the parameters before observing any data.</li>
<li>The prior needs to be chosen carefully to reflect prior knowledge or
assumptions about the parameters.</li>
</ul></li>
</ol>
<p>The predictive distribution in Bayesian inference uses the posterior
distribution to make predictions about future data. This approach is
inherently probabilistic, reflecting the uncertainty inherent in the
data and the model parameters. Key elements of Bayesian prediction
include:</p>
<ol style="list-style-type: decimal">
<li><strong>Predictive Mean:</strong>
<ul>
<li>The expected value of the prediction <span
class="math inline">\(E(y)\)</span> is computed as the integral of the
potential outcomes weighted by their probabilities, calculated over the
posterior distribution.</li>
<li>Formula: <span class="math inline">\(E(y) = \int \theta p(\theta |
x) d\theta\)</span></li>
</ul></li>
<li><strong>Mode of the Predictive Distribution:</strong>
<ul>
<li>Represents the most probable value of the prediction, identified by
the maximum of the posterior distribution.</li>
<li>Formula: <span class="math inline">\(\text{Mode} = \arg\max_{\theta}
p(\theta | x)\)</span></li>
</ul></li>
<li><strong>Predictive Distribution:</strong>
<ul>
<li>The predictive distribution provides a complete probabilistic
description of the possible future values, integrating over all
uncertainties.</li>
<li>It summarizes not just a single value but the likelihood of all
possible future outcomes.</li>
</ul></li>
</ol>
</div>
</div>
<div id="credible-intervals" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Credible
Intervals</h2>
<ol style="list-style-type: decimal">
<li><strong>Bayesian Inferential Approach</strong>:
<ul>
<li>The Bayesian approach is comprehensive, encompassing confidence
evaluation, hypothesis testing, prediction, model checking, and point
estimation.</li>
<li>It treats parameters as random variables and derives inferential
statistics based on the posterior distribution <span
class="math inline">\(\pi(\theta \mid \mathscr{D}_{n})\)</span>.</li>
</ul></li>
<li><strong>Definition of Credible Intervals</strong>:
<ul>
<li>In Bayesian statistics, what traditional statistics call a
confidence interval is referred to as a “credible interval.”</li>
<li>A credible interval for a parameter <span
class="math inline">\(\theta\)</span> based on data <span
class="math inline">\(\mathscr{D}_{n}\)</span> is defined as a set <span
class="math inline">\(C(\mathscr{D}_{n})\)</span> such that: <span
class="math display">\[
\pi(\theta \in C(\mathscr{D}_{n}) \mid \mathscr{D}_{n}) = 1 - \alpha
\]</span> Here, <span class="math inline">\(\alpha\)</span> is the
significance level (e.g., 0.05), indicating that the interval contains
the parameter with probability <span
class="math inline">\(1-\alpha\)</span>.</li>
</ul></li>
<li><strong>Integration over Parameter Space</strong>:
<ul>
<li>Unlike classical methods that integrate over the observation space
to compute confidence intervals, Bayesian methods integrate over the
parameter space.</li>
<li>This means that <span class="math inline">\(1-\alpha\)</span>
represents the probability that the random variable <span
class="math inline">\(\theta\)</span> falls within the interval <span
class="math inline">\(C(\mathscr{D}_{n})\)</span>, rather than the
probability that a random interval contains the true parameter
value.</li>
</ul></li>
<li><strong>Highest Posterior Density (HPD) Region</strong>:
<ul>
<li>The HPD region is a type of Bayesian credible interval which
contains the values of <span class="math inline">\(\theta\)</span> with
the highest posterior densities.</li>
<li>It is defined as: <span class="math display">\[
C(\mathscr{D}_{n}) = \{\theta : \pi(\theta \mid \mathscr{D}_{n}) \geq
k_{\alpha}\}
\]</span> where <span class="math inline">\(k_{\alpha}\)</span> is
determined so that the probability content of the HPD region is exactly
<span class="math inline">\(1-\alpha\)</span>.</li>
</ul></li>
</ol>
<div id="highest-density-region-hdr" class="section level3"
number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Highest Density
Region (HDR)</h3>
<ol style="list-style-type: decimal">
<li><strong>Definition of HDR</strong>:
<ul>
<li>The Highest Density Region (HDR) for a given posterior distribution
<span class="math inline">\(p(\theta | \text{data})\)</span> at a
probability level <span class="math inline">\(1-\alpha\)</span> is
defined as the subset of the parameter space where the density of <span
class="math inline">\(\theta\)</span> is highest.</li>
<li>Mathematically, it is defined as: <span class="math display">\[
\{\theta : p(\theta | \text{data}) \geq k(\alpha)\}
\]</span> where <span class="math inline">\(k(\alpha)\)</span> is the
largest constant such that the probability mass of this region is <span
class="math inline">\(1-\alpha\)</span>: <span class="math display">\[
\int_{\{\theta: p(\theta | \text{data}) \geq k(\alpha)\}} p(\theta |
\text{data}) d\theta = 1 - \alpha
\]</span></li>
</ul></li>
<li><strong>Interpretation and Importance</strong>:
<ul>
<li>The HDR contains the most probable values of <span
class="math inline">\(\theta\)</span> under the posterior
distribution.</li>
<li>It is used to specify the region in the parameter space where the
true parameter value is most likely to lie, given the observed
data.</li>
</ul></li>
<li><strong>Calculation of HDR</strong>:
<ul>
<li>To determine the HDR, identify the level <span
class="math inline">\(k(\alpha)\)</span> such that the integral of the
posterior distribution over the region where <span
class="math inline">\(p(\theta | \text{data}) \geq k(\alpha)\)</span>
equals <span class="math inline">\(1-\alpha\)</span>.</li>
<li>This requires solving for <span
class="math inline">\(k(\alpha)\)</span> in a way that balances between
covering the highest density of the distribution and ensuring that the
total probability of the region is exactly <span
class="math inline">\(1-\alpha\)</span>.</li>
</ul></li>
<li><strong>Practical Implications of HDR</strong>
<ul>
<li><strong>Confidence in Estimates</strong>: The HDR provides a way to
understand the uncertainty and variability of parameter estimates. It
can be considered as a Bayesian analogue to confidence intervals in
frequentist statistics.</li>
<li><strong>Decision Making</strong>: In practical applications, such as
in policy settings or scientific research, identifying the HDR helps in
making decisions based on the most probable parameter values.</li>
<li><strong>Comparative Analysis</strong>: Comparing HDRs from different
posterior distributions can provide insights into how different prior
beliefs or data sets influence the inferences about the parameters.</li>
</ul></li>
</ol>
</div>
<div id="key-differences-from-classical-confidence-intervals"
class="section level3" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Key Differences
from Classical Confidence Intervals</h3>
<ul>
<li><strong>Probability Interpretation</strong>:
<ul>
<li>In Bayesian analysis, the probability <span
class="math inline">\(1-\alpha\)</span> directly quantifies our belief
about the parameter’s location based on the data and prior
information.</li>
<li>In classical statistics, <span
class="math inline">\(1-\alpha\)</span> indicates how often the true
parameter will be captured by the interval over repeated sampling from
the population.</li>
</ul></li>
<li><strong>Simplicity of Construction</strong>:
<ul>
<li>Determining the best credible interval in Bayesian terms is
typically simpler than constructing classical confidence intervals
because it directly targets the areas of highest probability density
without regard to potential sampling variability.</li>
</ul></li>
</ul>
</div>
</div>
<div id="hypothesis-testing" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Hypothesis
Testing</h2>
<p>In Bayesian hypothesis testing, the likelihood of two competing
hypotheses <span class="math inline">\(H_0\)</span> and <span
class="math inline">\(H_1\)</span> (for example, <span
class="math inline">\(H_0: \theta = 0\)</span> and <span
class="math inline">\(H_1: \theta = 1\)</span>) is evaluated based on
the data, taking into account prior beliefs about these hypotheses.</p>
<p><strong>Bayes Factors</strong>: - The Bayes factor (BF) is a crucial
metric in Bayesian hypothesis testing. It is used to provide a
quantifiable measure of support for one hypothesis over another, based
on the observed data.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Calculation of Bayes Factors</strong>:</p>
<ul>
<li>For two hypotheses <span class="math inline">\(H_0\)</span> and
<span class="math inline">\(H_1\)</span>, Bayes factors are calculated
as follows: <span class="math display">\[
B_1 = \frac{p(\theta = 1 | \text{data})}{p(\theta = 0 | \text{data})} =
\frac{p(\text{data} | \theta = 1) \cdot p(\theta = 1)}{p(\text{data} |
\theta = 0) \cdot p(\theta = 0)}
\]</span> <span class="math display">\[
B_0 = \frac{p(\theta = 0 | \text{data})}{p(\theta = 1 | \text{data})} =
\frac{p(\text{data} | \theta = 0) \cdot p(\theta = 0)}{p(\text{data} |
\theta = 1) \cdot p(\theta = 1)}
\]</span></li>
<li>Here, <span class="math inline">\(p(\text{data} | \theta =
i)\)</span> is the likelihood of the data under hypothesis <span
class="math inline">\(i\)</span>, and <span
class="math inline">\(p(\theta = i)\)</span> is the prior probability of
hypothesis <span class="math inline">\(i\)</span>.</li>
</ul></li>
<li><p><strong>Interpretation of Bayes Factors</strong>:</p>
<ul>
<li>A Bayes factor <span class="math inline">\(B_1\)</span> greater than
1 indicates stronger support for <span
class="math inline">\(H_1\)</span> relative to <span
class="math inline">\(H_0\)</span>, while a <span
class="math inline">\(B_1\)</span> less than 1 supports <span
class="math inline">\(H_0\)</span> more.</li>
<li><span class="math inline">\(B_0\)</span> is the reciprocal of <span
class="math inline">\(B_1\)</span> and interprets support in the
opposite direction.</li>
</ul></li>
</ol>
</div>
<div id="parameter-estimates" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Parameter
Estimates</h2>
<p>To determine a data’s probability density distribution accurately,
two main components are essential:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Form of the Probability Density Function
(PDF)</strong>:</p>
<ul>
<li>Sometimes, the form of the PDF is known (e.g., Gaussian, Rayleigh)
but the specific parameters (like mean or variance) are unknown. This
scenario requires parameter estimation based on observed data.</li>
</ul></li>
<li><p><strong>Parameters of the PDF</strong>:</p>
<ul>
<li>Other times, the type of probability density may not be known, but
some estimated parameters (like mean and variance) are available. This
information can guide the selection of an appropriate PDF.</li>
</ul></li>
</ol>
<p>In statistical modeling, estimating unknown parameters is a common
task:</p>
<ul>
<li><strong>In basic models like linear regression</strong>, the
objective is often to calculate a specific parameter vector,
<strong>W</strong>.</li>
<li><strong>In Bayesian models</strong>, instead of calculating a point
estimate of <strong>W</strong>, the focus shifts to determining the
distribution of <strong>W</strong>. This distribution is then used to
predict outcomes (e.g., <strong>p(y|x, D)</strong>), incorporating all
possible values of <strong>W</strong>.</li>
</ul>
<p>Bayesian models are complex because they consider a distribution of
parameter values rather than a single point estimate. This complexity
often necessitates sophisticated computational techniques:</p>
<ul>
<li><strong>Markov Chain Monte Carlo (MCMC)</strong>: This technique is
used instead of direct optimization methods to integrate over possible
parameter values (all possible <strong>W</strong> vectors)
effectively.</li>
</ul>
<p>As more data is observed, Bayesian models provide clearer inference
about the distribution of parameters, known as <strong>posterior
inference</strong>. This approach contrasts with other predictive
strategies:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Maximum Likelihood Estimation (MLE)</strong>:</p>
<ul>
<li>This is a point estimation method that finds the parameter values
which maximize the likelihood of observing the given data. It does not
consider prior knowledge about parameter values.</li>
</ul></li>
<li><p><strong>Maximum a Posteriori (MAP)</strong>:</p>
<ul>
<li>Also a point estimation method, MAP considers both the likelihood of
the observed data and a prior distribution of the parameters. It
calculates the mode of the posterior distribution.</li>
</ul></li>
<li><p><strong>Bayesian Model</strong>:</p>
<ul>
<li>This method estimates the distribution of parameters rather than a
single point. It provides a full probabilistic description of parameter
uncertainty, making it more robust against overfitting and more
informative for decision-making.</li>
</ul></li>
</ol>
<p><strong>Comparison and Applications</strong></p>
<ul>
<li><strong>MLE</strong> is often simpler and computationally faster but
can be biased if the model assumptions are incorrect.</li>
<li><strong>MAP</strong> incorporates prior beliefs into the estimation
process, providing regularization that can lead to more robust estimates
in the presence of limited data.</li>
<li><strong>Bayesian Models</strong> are the most comprehensive,
considering a range of possible parameter values. This approach is
particularly beneficial in complex systems where the uncertainty in
model parameters needs to be quantified and propagated through to
predictions.</li>
</ul>
<div id="a.-maximum-likelihood-estimation-mle"
class="section level3 unnumbered">
<h3 class="unnumbered">a. Maximum Likelihood Estimation (MLE)</h3>
<p><strong>1. Concept of MLE:</strong></p>
<ul>
<li>MLE is a method used to determine the parameters of a statistical
model that make the observed data most probable. The goal is to find the
parameter values that maximize the likelihood function, which represents
the probability of the observed data given those parameter values.</li>
</ul>
<p><strong>2. Assumptions in MLE:</strong></p>
<ul>
<li><strong>Homogeneity</strong>: Assumes that subsets of data from
different categories (such as different classes or groups) share the
same type of probability density function but differ in parameter
values.</li>
<li><strong>Independence between Categories</strong>: Assumes that data
in one category are independently sampled from those in another, meaning
the parameter estimation for one category doesn’t affect another.</li>
<li><strong>Statistical Independence within Categories</strong>: Assumes
that samples within each category are independently and identically
distributed (iid).</li>
</ul>
<p><strong>3. Formulation:</strong></p>
<ul>
<li>Given a random sample <span class="math inline">\(x_1, x_2, \ldots,
x_N\)</span> from a probability density function <span
class="math inline">\(p(x;\theta)\)</span>, the joint probability
density function of the sample is given by: <span
class="math display">\[
p(X;\theta) = \prod_{k=1}^N p(x_k;\theta)
\]</span></li>
<li>The MLE <span class="math inline">\(\hat{\theta}_{ML}\)</span> is
obtained by maximizing this product: <span class="math display">\[
\hat{\theta}_{ML} = \arg \max_{\theta} \prod_{k=1}^N p(x_k;\theta)
\]</span></li>
<li>Typically, this optimization is performed on the log-likelihood
function <span class="math inline">\(L(\theta)\)</span> to simplify
calculations: <span class="math display">\[
L(\theta) = \ln \prod_{k=1}^N p(x_k;\theta) = \sum_{k=1}^N \ln
p(x_k;\theta)
\]</span> <span class="math display">\[
\frac{\partial L(\theta)}{\partial \theta} = \sum_{k=1}^N \frac{\partial
\ln p(x_k;\theta)}{\partial \theta} = \sum_{k=1}^N
\frac{1}{p(x_k;\theta)} \frac{\partial p(x_k;\theta)}{\partial \theta} =
0
\]</span></li>
</ul>
<p><strong>4. Properties of MLE:</strong></p>
<ul>
<li><strong>Asymptotic Unbiasedness</strong>: As the sample size <span
class="math inline">\(N\)</span> approaches infinity, the expected value
of the MLE converges to the true parameter value <span
class="math inline">\(\theta_0\)</span>: <span class="math display">\[
\lim_{N \to \infty} E[\hat{\theta}_{ML}] = \theta_0
\]</span></li>
<li><strong>Asymptotic Consistency</strong>: As the sample size
increases, the probability that the MLE differs from the true parameter
value by more than any small positive number <span
class="math inline">\(\epsilon\)</span> approaches zero: <span
class="math display">\[
\lim_{N \to \infty} \Pr\{ \|\hat{\theta}_{ML} - \theta_0\| \leq \epsilon
\} = 1
\]</span> <span class="math display">\[
\lim_{N \to \infty} E\| \hat{\theta}_{ML} - \theta_0 \|^2 = 0
\]</span></li>
<li>These properties ensure that the estimator is reliable as the amount
of data increases.</li>
</ul>
<p><strong>5. Limitations:</strong></p>
<ul>
<li>MLE can be prone to overfitting when the dataset is small because it
maximizes the probability of observing the data without considering
model complexity or penalizing for it.</li>
</ul>
</div>
<div id="b.-maximum-a-posteriori-estimation-map"
class="section level3 unnumbered">
<h3 class="unnumbered">b. Maximum a Posteriori Estimation (MAP)</h3>
<ul>
<li><strong>MLE</strong> treats the parameter <span
class="math inline">\(\theta\)</span> as an unknown fixed value that
needs to be estimated from the data.</li>
<li>The goal of MLE is to find the value of <span
class="math inline">\(\theta\)</span> that maximizes the likelihood
function <span class="math inline">\(p(X; \theta)\)</span>, which is the
probability of observing the data given the parameter.</li>
</ul>
<p><strong>MAP Concept and Methodology:</strong></p>
<ul>
<li><strong>MAP</strong> considers the parameter <span
class="math inline">\(\theta\)</span> as a random variable with a prior
distribution <span class="math inline">\(p(\theta)\)</span>, reflecting
prior beliefs about the possible values of <span
class="math inline">\(\theta\)</span>.</li>
<li>Unlike MLE, MAP estimates <span
class="math inline">\(\theta\)</span> by maximizing the posterior
distribution <span class="math inline">\(p(\theta | X)\)</span> rather
than just the likelihood: <span class="math display">\[
p(\theta|X) = \frac{p(\theta) p(X|\theta)}{p(X)}
\]</span></li>
<li>The MAP estimate <span
class="math inline">\(\hat{\theta}_{MAP}\)</span> is given by: <span
class="math display">\[
\hat{\theta}_{MAP} = \arg \max_{\theta} p(\theta) p(X|\theta)
\]</span></li>
<li>In the optimization, the marginal likelihood <span
class="math inline">\(p(X)\)</span> does not affect the location of the
maximum since it does not depend on <span
class="math inline">\(\theta\)</span>.</li>
</ul>
<p><strong>Differences:</strong></p>
<ul>
<li><strong>Prior Influence:</strong> MLE does not incorporate a prior
distribution, treating <span class="math inline">\(\theta\)</span> as a
fixed but unknown quantity. MAP, on the other hand, explicitly includes
a prior distribution, which can significantly influence the estimate
especially when the sample size is small or the prior is strong
(informative).</li>
<li><strong>Resulting Estimates:</strong> For non-informative or flat
priors, MAP results converge to MLE results. However, with informative
priors, MAP can yield different estimates from MLE, depending on the
strength and nature of the prior.</li>
<li>As the sample size increases, the influence of the prior in MAP
diminishes, aligning MAP estimates more closely with MLE estimates,
reflecting the dominance of the data over the prior.</li>
</ul>
</div>
<div id="c.-bayesian-model" class="section level3 unnumbered">
<h3 class="unnumbered">c. Bayesian Model</h3>
<p>Bayesian modeling distinguishes itself by considering the entire
distribution of the data <span class="math inline">\(X\)</span> and the
parameters <span class="math inline">\(\theta\)</span> instead of just
optimizing parameter values based on a given sample set <span
class="math inline">\(X\)</span>. This approach naturally helps prevent
overfitting by integrating over all possible parameter values rather
than selecting a single optimal set.</p>
<ol style="list-style-type: decimal">
<li><strong>Sample Set and Parameters</strong>:
<ul>
<li>The data sample set is denoted as <span
class="math inline">\(D\)</span> (previously <span
class="math inline">\(X\)</span>) to avoid notation confusion. Samples
in <span class="math inline">\(D\)</span> are assumed to be
independently drawn from an unknown but fixed probability density
function <span class="math inline">\(p(x)\)</span>.</li>
</ul></li>
<li><strong>Bayesian Estimation Problem</strong>:
<ul>
<li>The core problem in Bayesian estimation is to estimate the
probability distribution <span class="math inline">\(p(x|D)\)</span>,
making it as close as possible to the true distribution <span
class="math inline">\(p(x)\)</span>. This involves calculating the
distribution of <span class="math inline">\(x\)</span> given the data
<span class="math inline">\(D\)</span>, rather than finding a single
optimized value for <span class="math inline">\(x\)</span>.</li>
</ul></li>
<li><strong>Conditional Probability Density Function <span
class="math inline">\(p(x|\theta)\)</span></strong>:
<ul>
<li><span class="math inline">\(p(x|\theta)\)</span> is assumed to be
known in form but with unknown parameters <span
class="math inline">\(\theta\)</span>. It represents the likelihood
estimation of <span class="math inline">\(\theta\)</span> at the point
<span class="math inline">\(x\)</span>.</li>
</ul></li>
<li><strong>Prior and Posterior Distributions</strong>:
<ul>
<li><strong>Prior Distribution <span
class="math inline">\(p(\theta)\)</span></strong>: Represents all prior
knowledge about <span class="math inline">\(\theta\)</span> before
observing any data, expressed through a probability density
function.</li>
<li><strong>Posterior Distribution <span
class="math inline">\(p(\theta|D)\)</span></strong>: Updated belief
about <span class="math inline">\(\theta\)</span> after observing the
data <span class="math inline">\(D\)</span>. It is obtained by
transforming the prior based on the new data: <span
class="math display">\[
p(\theta|D) = \frac{p(D|\theta)p(\theta)}{\int
p(D|\theta)p(\theta)d\theta}
\]</span> where <span class="math inline">\(p(D|\theta) = \prod_{k=1}^N
p(x_k|\theta)\)</span>, assuming independence among the sampled data
points.</li>
</ul></li>
<li><strong>Bayesian Estimation Formula</strong>:
<ul>
<li>The core Bayesian estimation problem <span
class="math inline">\(p(x|D)\)</span> is resolved using the integral
over the joint distribution of <span class="math inline">\(x\)</span>
and <span class="math inline">\(\theta\)</span>: <span
class="math display">\[
p(x|D) = \int p(x|\theta)p(\theta|D)d\theta
\]</span></li>
<li>Here, <span class="math inline">\(p(x|\theta)\)</span> is the
likelihood of <span class="math inline">\(x\)</span> under <span
class="math inline">\(\theta\)</span>, and <span
class="math inline">\(p(\theta|D)\)</span> is the posterior distribution
of <span class="math inline">\(\theta\)</span> after observing <span
class="math inline">\(D\)</span>.</li>
</ul></li>
</ol>
<p><strong>Advantages of Bayesian Modeling</strong></p>
<ul>
<li><strong>Comprehensive Parameter Estimation</strong>: By integrating
over all possible values of <span class="math inline">\(\theta\)</span>,
Bayesian models provide a more holistic view of parameter
uncertainty.</li>
<li><strong>Prevention of Overfitting</strong>: The use of prior
distributions and the consideration of all possible parameter values
help in regularizing the model, thus preventing overfitting.</li>
<li><strong>Flexibility and Robustness</strong>: Bayesian models are
adaptable to new data, allowing continuous updating of beliefs about
parameters as more data become available.</li>
</ul>
</div>
</div>
</div>
<div id="prior-distribution-1" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Prior Distribution</h1>
<ol style="list-style-type: decimal">
<li><strong>Selection of Priors</strong>:
<ul>
<li>In Bayesian statistics, the choice of prior <span
class="math inline">\(p(\theta)\)</span> is crucial because it
fundamentally influences the resulting posterior distribution <span
class="math inline">\(p(\theta | \text{data})\)</span>. Selecting a
prior that reflects genuine knowledge or reasonable assumptions about
<span class="math inline">\(\theta\)</span> is important for ensuring
that the posterior distribution is meaningful and accurate.</li>
<li>If the prior is too restrictive or if it does not align with the
actual data characteristics, it can lead to misleading inferences, where
the data cannot correct a poorly chosen prior.</li>
</ul></li>
<li><strong>Precision of Prior Distributions</strong>:
<ul>
<li>The text discusses the concept of the “precision” of prior
distributions, indicating that a precise prior has a major impact on the
determination of the posterior. A precise prior effectively means that
the prior distribution is tightly concentrated, suggesting high
confidence in the prior knowledge about <span
class="math inline">\(\theta\)</span>.</li>
<li>The implication is that when the precision of the prior is high, the
influence of the data on the posterior might be relatively diminished
unless the data strongly contradicts the prior assumptions.</li>
</ul></li>
<li><strong>Behavior of Improper Priors</strong>:
<ul>
<li>Improper priors are those that do not integrate to one (e.g., priors
that are uniform over an infinite range). These priors are sometimes
used in Bayesian analysis due to their non-informative nature, allowing
the data to play a more significant role in shaping the posterior.</li>
<li>The discussion notes that while improper priors can be useful,
especially in the absence of strong prior knowledge, they must be
handled with care. Improper priors can sometimes lead to undefined or
ambiguous posterior distributions if not properly regularized or if the
data does not sufficiently inform the posterior.</li>
</ul></li>
</ol>
<p>Determining the appropriate prior distribution in Bayesian statistics
involves considering several options, each suited to different
circumstances and amounts of prior knowledge.</p>
<p><strong>1. Non-informative Priors</strong></p>
<p>Non-informative priors, also known as flat or objective priors, are
used when there is no specific prior knowledge about the parameters.
These priors are designed to exert minimal influence on the posterior
distribution, allowing the data to speak for themselves.</p>
<ul>
<li><strong>Purpose</strong>: Ideal for situations where you want to
remain as unbiased as possible or when prior knowledge is genuinely
absent.</li>
<li><strong>Examples</strong>: Uniform distributions across the range of
possible parameter values, Jeffreys’ prior which is invariant under
reparameterization and often used for scale parameters.</li>
</ul>
<p><strong>2. Conjugate Priors</strong> Conjugate priors are chosen
because they simplify the computation of the posterior distribution. A
prior is conjugate to the likelihood function if the posterior
distribution belongs to the same family as the prior distribution.</p>
<ul>
<li><strong>Benefits</strong>: The use of conjugate priors transforms
Bayesian updating into a matter of updating the parameters of the prior
distribution based on the observed data, which can often be done
analytically without complex numerical methods.</li>
<li><strong>Examples</strong>: The Beta distribution as a prior for the
Binomial likelihood, or the Gamma distribution for the Exponential
likelihood.</li>
</ul>
<p><strong>3. Empirical Bayes Methods</strong></p>
<p>Empirical Bayes methods use the data to estimate the parameters of
the prior distribution. This approach sits between fully Bayesian and
frequentist methods, leveraging the strengths of both.</p>
<ul>
<li><strong>Process</strong>: Start with an assumed form of the prior
distribution, then use a portion of the data or external data to
estimate the parameters of this prior.</li>
<li><strong>Applications</strong>: Useful in settings where some data
are available that can inform the prior, but not enough to fully
determine the posterior without additional data. This method is commonly
used in hierarchical models and large-scale data analysis.</li>
</ul>
<p><strong>4. Expert Elicitation Priors</strong></p>
<p>Priors derived from expert elicitation involve consulting
subject-matter experts to quantify their beliefs about parameters before
observing the current data. This method is particularly useful in fields
where prior experimental or empirical data are sparse, but expert domain
knowledge is rich.</p>
<ul>
<li><strong>Implementation</strong>: Structured elicitation processes
are used to translate expert knowledge into a quantifiable prior
distribution. This might involve using tools like probability
distribution fitting, where experts specify quantiles, means, variances,
or other moments based on their understanding.</li>
<li><strong>Challenges</strong>: Requires careful consideration to avoid
biases inherent in expert opinions and to accurately represent
uncertainty in expert estimates.</li>
</ul>
<div id="non-informative-priors" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> 1. Non-informative
Priors</h2>
<p>When engaging in Bayesian analysis without specific prior knowledge
about the parameters in question, employing non-informative priors can
be an effective strategy. These types of priors are designed to
minimally influence the posterior outcomes, allowing the data itself to
primarily drive the inferences. Here is a detailed description of two
significant types of non-informative priors: <strong>Jeffreys
Prior</strong> and <strong>Reference Prior</strong>.</p>
<div id="jeffreys-prior" class="section level3 unnumbered">
<h3 class="unnumbered">Jeffreys Prior</h3>
<p><strong>Background:</strong> Jeffreys Prior is named after Sir Harold
Jeffreys, who introduced it in his work on Bayesian statistics. This
prior is particularly noted for its property of invariance, meaning that
it remains unchanged under transformation of parameters.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Invariance</strong>: The form of Jeffreys prior does not
change with the parameterization of the model. This property is crucial
because it ensures that the prior behaves consistently across different
parameterizations, avoiding biases that could arise from arbitrary
choices of parameter scales or units.</li>
<li><strong>Construction</strong>: Jeffreys Prior is constructed using
the square root of the determinant of the Fisher information matrix. The
Fisher information quantifies the amount of information that an
observable random variable carries about an unknown parameter upon which
the likelihood depends.</li>
</ul>
<p><strong>Formula:</strong> <span class="math display">\[ p(\theta)
\propto \sqrt{|I(\theta)|} \]</span> where <span
class="math inline">\(I(\theta)\)</span> is the Fisher information
matrix for parameter <span class="math inline">\(\theta\)</span>.</p>
<p><strong>Applications and Limitations:</strong></p>
<ul>
<li>Jeffreys Prior is particularly useful for parameters that are
naturally scale-invariant, such as variance and standard deviation.</li>
<li>While it addresses the issue of uniform priors not translating
uniformly over transformations of the parameters, Jeffreys Prior can
sometimes lead to priors that are improper or do not integrate to one,
particularly in complex models or multi-parameter settings.</li>
</ul>
</div>
<div id="reference-prior" class="section level3 unnumbered">
<h3 class="unnumbered">Reference Prior</h3>
<p><strong>Background:</strong></p>
<p>The concept of Reference Priors was developed to address some of the
limitations encountered with Jeffreys Prior, especially in multivariate
contexts where interactions between parameters can complicate the
definition and application of non-informative priors.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Maximization of Information Divergence</strong>: Reference
priors are designed to maximize the Kullback-Leibler divergence between
the prior and the posterior distributions under large sample conditions.
This divergence measures the information gain provided by the data,
relative to the prior.</li>
<li><strong>Minimally Informative</strong>: By maximizing the
divergence, the reference prior aims to minimize its impact on the
posterior, making the results as data-driven as possible. This feature
makes it an ideal choice when seeking to minimize the influence of
subjective assumptions on the analysis.</li>
</ul>
<p><strong>Formula:</strong></p>
<p>While the specific form of a reference prior can depend on the model
and the parameters, its derivation generally involves complex
calculations aimed at maximizing the Kullback-Leibler divergence, which
may not have a closed-form expression and often requires numerical
methods to solve.</p>
<p><strong>Applications and Limitations:</strong></p>
<ul>
<li>Reference Priors are particularly useful in settings involving
multiple parameters where interactions can complicate the analysis.</li>
<li>They are also used in problems where the sample size is large, and
the aim is to make inferences that are as objective as possible.</li>
</ul>
</div>
</div>
<div id="conjugate-priors" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> 2. Conjugate
Priors</h2>
<p>Conjugate priors are a type of prior that, when used with a
particular likelihood function, results in a posterior distribution that
is of the same family as the prior distribution. This property of
conjugacy is particularly valuable because it simplifies the
mathematical operations involved in Bayesian updates.</p>
<p><strong>Key Characteristics of Conjugate Priors:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Mathematical Simplicity</strong>: Conjugate priors
simplify the Bayesian updating process because the posterior
distributions are analytically tractable. This means that one can derive
explicit formulas for updating the parameters of the distribution,
typically referred to as hyperparameters, based on the observed
data.</p></li>
<li><p><strong>Parameterization</strong>: In the context of conjugate
priors, the prior distribution is often characterized by a few key
parameters, known as hyperparameters. For example, in the case of a
normal distribution used as a likelihood, the conjugate prior would also
be normal, characterized by parameters like the mean and variance. These
hyperparameters are updated to form the posterior based on the
data.</p></li>
</ol>
<p>For practical Bayesian analysis, conjugate priors are particularly
prevalent in cases where the likelihood functions belong to the
exponential family, such as:</p>
<ul>
<li><strong>Beta distribution</strong> for binomial data,</li>
<li><strong>Gamma distribution</strong> for Poisson data,</li>
<li><strong>Normal distribution</strong> for normal data.</li>
</ul>
<div class="figure">
<img src="02_Plots/Bayesian/Bayer_Conjugate.png" alt="Conjugate priors for the most common statistical families" width="342" />
<p class="caption">
Conjugate priors for the most common statistical families
</p>
</div>
<p><strong>Advantages of Using Conjugate Priors:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Computational Efficiency</strong>: The algebraic
convenience of conjugate priors allows for straightforward updates of
beliefs in light of new data. This efficiency is particularly
advantageous in iterative processes or when dealing with large
datasets.</p></li>
<li><p><strong>Theoretical Elegance</strong>: The ability to maintain
the same family of distributions before and after observing data offers
a closed-form solution for the posterior, which can be elegantly
described and understood.</p></li>
<li><p><strong>Ease of Interpretation</strong>: Because the form of the
distribution remains constant, the interpretation of the parameters
(such as mean or variance in a normal distribution) remains intuitive
and consistent throughout the Bayesian analysis.</p></li>
</ol>
<p><strong>Drawbacks of Using Conjugate Priors:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Restrictive Assumptions</strong>: The main limitation of
conjugate priors is that they might force one to adopt specific
distributional forms that may not be substantively justified. The need
to maintain conjugacy can impose restrictions on the choice of the prior
that might not align with the actual prior knowledge about the
parameters.</p></li>
<li><p><strong>Limited Flexibility</strong>: While the use of conjugate
priors simplifies calculations, it also reduces flexibility in modeling.
The specific structure required for conjugacy might not adequately
capture the complexities or nuances of the prior beliefs or the
data.</p></li>
<li><p><strong>Hyperparameter Sensitivity</strong>: The process requires
the selection of hyperparameters, which can significantly influence the
posterior. Incorrect or suboptimal choices of these parameters can lead
to biased or misleading results, especially if the prior information is
insufficient or vague.</p></li>
</ol>
</div>
<div id="empirical-bayes-priors" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> 3. Empirical Bayes
Priors</h2>
<p><strong>Concept and Foundation of Empirical Bayes</strong></p>
<p>Empirical Bayes methods are based on the idea of using observed data
to estimate the parameters of the prior distribution in a Bayesian
setup. Unlike traditional Bayesian methods, which require the
specification of a prior based purely on subjective belief or external
information, Empirical Bayes uses an evidence-based approach to
determine the prior. This hybrid method falls between the fully Bayesian
approach (which relies entirely on subjective priors) and the purely
frequentist approach (which does not incorporate prior information at
all).</p>
<p><strong>How Empirical Bayes Methods Work</strong> The process
involves two main steps:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Estimation of Prior Parameters</strong>: First, the
method uses the aggregate data to estimate the parameters of the prior
distribution. This is typically done using maximum likelihood estimation
or another suitable frequentist method. The goal here is to capture the
common characteristics of the parameter across different observations or
experiments.</p></li>
<li><p><strong>Bayesian Updating</strong>: Once the prior parameters are
estimated, each specific instance or data point is analyzed using
Bayesian methods, where the empirically estimated prior is updated with
the actual observed data to produce a posterior distribution.</p></li>
</ol>
<p><strong>Key Features of Empirical Bayes</strong></p>
<ul>
<li><p><strong>Data-Driven Priors</strong>: The priors are not fixed
before seeing the data; instead, they are determined based on the data
itself. This is particularly useful in scenarios where little is known
about the system beforehand, or when subjective priors are hard to
justify.</p></li>
<li><p><strong>Reduction in Variance</strong>: By borrowing strength
from the entire dataset to form the prior, Empirical Bayes methods can
reduce the variance of the estimates compared to purely frequentist
approaches that treat each problem separately.</p></li>
<li><p><strong>Computational Efficiency</strong>: Empirical Bayes can be
more computationally efficient than fully Bayesian methods since it
avoids the need for complex prior specification and the intensive
computations that can entail, especially with large datasets.</p></li>
</ul>
</div>
<div id="expert-elicitation-priors" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> 4. Expert Elicitation
Priors</h2>
<p>Expert elicitation priors are a method in Bayesian statistics where
subjective judgments from experts are formally incorporated into the
Bayesian framework as prior distributions. This approach is particularly
useful in scenarios where empirical data is sparse, but expert knowledge
is abundant and reliable.</p>
<p>Expert elicitation involves systematically gathering opinions from
one or more experts about uncertain quantities and then using these
opinions to form prior distributions in Bayesian analysis. The experts
provide their insights based on experience, existing research, and
intuition, which are then quantified into a statistical format that can
be directly used in the probabilistic models.</p>
<p><strong>Process of Developing Expert Elicitation Priors</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Selection of Experts</strong>: Careful selection of
experts is crucial. Experts should have deep and relevant knowledge
about the subject matter. Diversity in expertise can help capture a
broad range of perspectives and reduce individual bias.</p></li>
<li><p><strong>Elicitation Technique</strong>: Various techniques can be
used to elicit quantitative data from experts, such as interviews,
structured questionnaires, or interactive workshops. Techniques like the
Delphi method, which involves multiple rounds of questioning with
feedback, are commonly used to converge expert opinions towards a
consensus.</p></li>
<li><p><strong>Quantification of Expert Opinions</strong>: The elicited
qualitative assessments are converted into quantitative measures.
Experts might be asked to estimate parameters directly, provide
percentiles for distributions, or express their confidence in different
outcomes.</p></li>
<li><p><strong>Aggregation of Responses</strong>: When multiple experts
are involved, their responses need to be aggregated. This can be done
through mathematical pooling of individual probability distributions or
by using more sophisticated models that weigh expert opinions by their
reliability or coherence with empirical data.</p></li>
</ol>
<p><strong>Advantages of Using Expert Elicitation Priors</strong></p>
<ul>
<li><p><strong>Fills Data Gaps</strong>: In cases where empirical data
is not available or is incomplete, expert opinions can provide valuable
insights that would otherwise be unattainable.</p></li>
<li><p><strong>Improves Model Relevance</strong>: By incorporating
real-world knowledge, the models become more reflective of the actual
phenomena being studied, enhancing the relevance and applicability of
the statistical analyses.</p></li>
<li><p><strong>Facilitates Complex Decision Making</strong>: Expert
elicitation is particularly beneficial in complex decision-making
scenarios, such as policy formulation or risk assessment, where the
stakes are high and the problems are too intricate to be captured fully
by available data.</p></li>
</ul>
</div>
</div>
<div id="distribution" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Distribution</h1>
<div id="bernoulli-distribution" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Bernoulli
Distribution</h2>
<p>This delve into the application of Bayesian statistics for
Poisson-distributed data using a Gamma distribution as a conjugate
prior. This scenario is commonly encountered in settings where the data
consists of counts or events that follow a Poisson process, and the
prior information about the event rate (λ, lambda) is modeled using a
Gamma distribution.</p>
<p><strong>Context and Setup</strong></p>
<ul>
<li><strong>Bernoulli Distribution</strong>: This is used to model
binary data, where each trial has two possible outcomes, typically
represented as 0 or 1. In the context given, each trial (or observation)
can result in success (1) or failure (0).</li>
<li><strong>Beta Distribution for Prior</strong>: The Beta distribution
is commonly used as a prior in Bayesian analysis for binomial and
Bernoulli distributions due to its conjugate properties. The Beta
distribution is parameterized by two positive shape parameters, α
(alpha) and β (beta), which represent prior knowledge about the
probability of success in Bernoulli trials.</li>
</ul>
<p><strong>Mathematical Formulation</strong></p>
<ul>
<li>The likelihood of observing a particular set of Bernoulli data given
a probability of success θ is: <span class="math display">\[
p(X|\theta) = \theta^{\sum x_i} (1-\theta)^{n - \sum x_i}
\]</span> where <span class="math inline">\(\sum x_i\)</span> is the
total number of successes, and <span class="math inline">\(n\)</span> is
the total number of trials.</li>
<li>The conjugate prior for θ in this scenario is a Beta distribution:
<span class="math display">\[
p(\theta) \propto \theta^{\alpha - 1} (1-\theta)^{\beta - 1}
\]</span></li>
<li>The posterior distribution, after observing the data, remains a Beta
distribution: <span class="math display">\[
p(\theta|X) = \text{Beta}(\alpha + \sum x_i, \beta + n - \sum x_i)
\]</span> This formula shows that the parameters of the Beta
distribution are updated by adding the number of successes to α and the
number of failures to β.</li>
</ul>
<p><img
src="02_Plots/Bayesian/Bayer_Distribution_Bernoulli.png" /></p>
<p><strong>Statistical Inference</strong></p>
<ul>
<li><strong>Posterior Mean</strong>: The expectation of the posterior
distribution <span class="math inline">\(\theta|X\)</span> can be
estimated as: <span class="math display">\[
E[\theta|X] = \frac{\alpha + \sum x_i}{\alpha + \beta + n}
\]</span> This represents a weighted average between the prior belief
and the observed data, where the influence of the prior diminishes as
more data is collected.</li>
<li><strong>Practical Example</strong>: Suppose a prior belief models
the probability of success as somewhat uncertain but leaning towards
being less likely (e.g., <span class="math inline">\(\alpha = 2, \beta =
18\)</span>). After observing 15 successes out of 20 trials, the
posterior parameters would be updated to <span
class="math inline">\(\alpha&#39; = 2+15 = 17\)</span> and <span
class="math inline">\(\beta&#39; = 18+5 = 23\)</span>. The posterior
distribution would then be Beta(17, 23).</li>
</ul>
</div>
<div id="poisson-distribution" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Poisson
Distribution</h2>
<p>This delve into the application of Bayesian statistics for
Poisson-distributed data using a Gamma distribution as a conjugate
prior. This scenario is commonly encountered in settings where the data
consists of counts or events that follow a Poisson process, and the
prior information about the event rate (λ, lambda) is modeled using a
Gamma distribution.</p>
<ol style="list-style-type: decimal">
<li><strong>Poisson Distribution</strong>:
<ul>
<li>The Poisson distribution is used to model the probability of a given
number of events happening in a fixed interval of time or space, given
the average number of events (rate λ).</li>
<li>The likelihood function for observing data <span
class="math inline">\(y = (y_1, y_2, \dots, y_n)\)</span> under a
Poisson model is: <span class="math display">\[
p(y|\lambda) = \prod_{i=1}^n \frac{\lambda^{y_i} e^{-\lambda}}{y_i!}
\]</span></li>
</ul></li>
<li><strong>Gamma Distribution as a Conjugate Prior</strong>:
<ul>
<li>The Gamma distribution is a suitable choice as a conjugate prior for
λ in Poisson models because it results in a posterior distribution that
is also a Gamma, facilitating computational ease and analytical
tractability.</li>
<li>The Gamma distribution is parameterized by a shape parameter (α,
alpha) and a rate parameter (β, beta), with the probability density
function given by: <span class="math display">\[
p(\lambda) = \frac{\beta^\alpha}{\Gamma(\alpha)} \lambda^{\alpha-1}
e^{-\beta \lambda}
\]</span></li>
</ul></li>
<li><strong>Posterior Distribution</strong>:
<ul>
<li>By Bayes’ theorem, the posterior distribution of λ after observing
data <span class="math inline">\(y\)</span> combines the prior and the
likelihood, yielding another Gamma distribution: <span
class="math display">\[
p(\lambda|y) \propto p(y|\lambda) p(\lambda) = \text{Gamma}(\alpha +
\sum y_i, \beta + n)
\]</span></li>
<li>Here, <span class="math inline">\(\sum y_i\)</span> is the sum of
the observed counts, and <span class="math inline">\(n\)</span> is the
number of observations or trials.</li>
</ul></li>
</ol>
<p><img src="02_Plots/Bayesian/Bayer_Distribution_Poisson.png" /></p>
<p><strong>Example Illustration</strong></p>
<ul>
<li><p>Suppose we have a set of counts over ten time periods, and we
assume that these counts are Poisson-distributed with an unknown rate λ.
Using a Gamma prior for λ with parameters α = 1 and β = 1, we
incorporate the observed data to update these parameters.</p></li>
<li><p>After observing the data, the posterior parameters become:</p>
<ul>
<li>New alpha (α’): α + sum of observed counts</li>
<li>New beta (β’): β + number of observations</li>
</ul></li>
<li><p>If the observed counts sum to 77 over 10 periods, the posterior
distribution for λ becomes:</p>
<ul>
<li>Alpha: 1 + 77 = 78</li>
<li>Beta: 1 + 10 = 11</li>
<li>Resulting in a posterior distribution Gamma(78, 11).</li>
</ul></li>
</ul>
</div>
<div id="normal-distribution" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Normal
Distribution</h2>
<p>This provided delve into Bayesian inference for normally distributed
data, employing conjugate priors.</p>
<ol style="list-style-type: decimal">
<li><strong>Background and Setup:</strong>
<ul>
<li>The data is assumed to follow a Normal distribution, <span
class="math inline">\(N(\mu, \sigma^2)\)</span>, where both the mean
(<span class="math inline">\(\mu\)</span>) and variance (<span
class="math inline">\(\sigma^2\)</span>) are unknown.</li>
<li>A common approach in Bayesian analysis is to assume conjugate priors
for these parameters because conjugate priors simplify the computation
of the posterior distributions.</li>
</ul></li>
<li><strong>Conjugate Priors Used:</strong>
<ul>
<li>For the mean <span class="math inline">\(\mu\)</span>, when <span
class="math inline">\(\sigma^2\)</span> is known, the conjugate prior is
a Normal distribution, <span class="math inline">\(N(\mu_0,
\tau_0)\)</span>.</li>
<li>For the variance <span class="math inline">\(\sigma^2\)</span>, the
conjugate prior is an inverse-Gamma distribution, which ensures that the
posterior distributions for <span class="math inline">\(\mu\)</span> and
<span class="math inline">\(\sigma^2\)</span> are tractable and remain
within the family of Normal and inverse-Gamma distributions
respectively.</li>
</ul></li>
<li><strong>Mathematical Formulation:</strong>
<ul>
<li><strong>Likelihood Function:</strong> Given the data <span
class="math inline">\(x = (x_1, x_2, ..., x_n)\)</span>, the likelihood
for a normal model is: <span class="math display">\[
p(x | \mu, \sigma^2) \propto \sigma^{-n} \exp\left(-\frac{1}{2\sigma^2}
\sum_{i=1}^n (x_i - \mu)^2\right)
\]</span></li>
<li><strong>Posterior for Mean <span
class="math inline">\(\mu\)</span>:</strong> When <span
class="math inline">\(\sigma^2\)</span> is known, the posterior
distribution of <span class="math inline">\(\mu\)</span> after observing
data is also a Normal distribution: <span class="math display">\[
\mu | x, \sigma^2 \sim N\left(\frac{\tau_0 \mu_0 + n\bar{x}}{\tau_0 +
n}, \frac{\sigma^2}{\tau_0 + n}\right)
\]</span> where <span class="math inline">\(\bar{x}\)</span> is the
sample mean.</li>
<li><strong>Posterior for Variance <span
class="math inline">\(\sigma^2\)</span>:</strong> The posterior for
<span class="math inline">\(\sigma^2\)</span> is an inverse-Gamma
distribution, parameterized by updated shape and scale parameters
derived from the data.</li>
</ul></li>
<li><strong>Updating Process:</strong>
<ul>
<li>Given the priors and the observed data, the parameters of the priors
(<span class="math inline">\(\mu_0, \tau_0\)</span> for the mean and
shape and rate for the variance) are updated to reflect the new evidence
provided by the data.</li>
<li>This Bayesian updating allows continuous learning as new data
becomes available, adjusting the beliefs about the parameters based on
cumulative evidence.</li>
</ul></li>
</ol>
<p><img src="02_Plots/Bayesian/Bayer_Distribution_Normal.png" /></p>
</div>
</div>
<div id="bayesian-inference-algorithm" class="section level1"
number="4">
<h1><span class="header-section-number">4</span> Bayesian Inference
Algorithm</h1>
<div id="maximum-a-posteriori-map-estimation" class="section level2"
number="4.1">
<h2><span class="header-section-number">4.1</span> Maximum A Posteriori
(MAP) Estimation</h2>
<ol style="list-style-type: decimal">
<li><strong>Definition and Formula</strong>:
<ul>
<li>MAP estimation is similar to MLE but incorporates a prior
distribution on the parameters. It modifies the estimation process by
not just considering the likelihood of the observed data but also how
probable parameters are a priori.</li>
<li>The formula for MAP estimation is: <span class="math display">\[
\hat{\theta}_{MAP} = \arg \max_{\theta} p(\theta | x) = \arg
\max_{\theta} \log \left( p(x | \theta) p(\theta) \right)
\]</span></li>
<li>This can be expanded using Bayes’ theorem to: <span
class="math display">\[
\hat{\theta}_{MAP} = \arg \max_{\theta} \log \left( \prod_{i=1}^n p(x_i
| \theta) p(\theta) \right)
\]</span></li>
</ul></li>
<li><strong>Differences from MLE</strong>:
<ul>
<li>While MLE solely focuses on maximizing the likelihood, MAP also
considers the prior distribution of the parameters, which can lead to
different estimates especially when the amount of data is limited.</li>
<li>MAP is a regularization of MLE, incorporating additional information
(or beliefs) about the parameters before observing the data.</li>
</ul></li>
</ol>
</div>
<div id="laplace-approximation" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Laplace
Approximation</h2>
<ol style="list-style-type: decimal">
<li><strong>Purpose and Use</strong>:
<ul>
<li>Laplace approximation is used to simplify the computation of
posterior distributions in Bayesian inference by approximating these
distributions with a Gaussian distribution centered at the MAP
estimate.</li>
<li>This method is particularly advantageous in high-dimensional
settings where the integral over the parameter space becomes
intractable.</li>
</ul></li>
<li><strong>Mathematical Foundation</strong>:
<ul>
<li>Given a posterior distribution <span class="math inline">\(p(\theta
| x)\)</span>, the goal is to approximate it around the point <span
class="math inline">\(\hat{\theta}\)</span> where it reaches its
maximum, i.e., the MAP estimate.</li>
<li>The approximation assumes that the log of the posterior distribution
can be approximated by a second-order Taylor expansion around <span
class="math inline">\(\hat{\theta}\)</span>.</li>
</ul></li>
<li><strong>Procedure</strong>:
<ul>
<li><strong>Find the MAP</strong>: Solve <span
class="math inline">\(\hat{\theta} = \arg \max_{\theta} \log p(\theta |
x)\)</span>, which involves derivatives of the log-posterior to find the
point where it peaks.</li>
<li><strong>Second-Order Taylor Expansion</strong>: Expand <span
class="math inline">\(\log p(\theta | x)\)</span> around <span
class="math inline">\(\hat{\theta}\)</span> using a second-order Taylor
series: <span class="math display">\[
\log p(\theta | x) \approx \log p(\hat{\theta} | x) - \frac{1}{2}
(\theta - \hat{\theta})^T A (\theta - \hat{\theta})
\]</span> where <span class="math inline">\(A\)</span> is the Hessian
matrix of the negative log-posterior evaluated at <span
class="math inline">\(\hat{\theta}\)</span>.</li>
<li><strong>Approximate the Posterior</strong>: The approximate
posterior is then: <span class="math display">\[
q(\theta) \propto \exp\left(-\frac{1}{2} (\theta - \hat{\theta})^T A
(\theta - \hat{\theta})\right)
\]</span> which is the form of a Gaussian distribution with mean <span
class="math inline">\(\hat{\theta}\)</span> and covariance matrix <span
class="math inline">\(A^{-1}\)</span>.</li>
</ul></li>
<li><strong>Implications and Applications</strong></li>
</ol>
<ul>
<li><strong>Efficiency</strong>: The Laplace approximation allows for
more efficient numerical calculations and integrations over the
parameter space by reducing complex posterior distributions to Gaussian
approximations.</li>
<li><strong>Model Comparison</strong>: It facilitates model comparison
and selection using Bayesian model comparison criteria like the Bayesian
Information Criterion (BIC) and Akaike Information Criterion (AIC),
which require the evaluation of the log-posterior or its
approximations.</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li><strong>Limitations</strong></li>
</ol>
<ul>
<li><strong>Accuracy</strong>: The approximation assumes that the
posterior is unimodal and symmetric near the MAP, which may not hold in
cases with multi-modal distributions or significant skewness.</li>
<li><strong>Dimensionality</strong>: In very high-dimensional spaces,
even the computation of the Hessian and its inversion can become
computationally challenging.</li>
</ul>
</div>
<div id="markov-chain-monte-carlo-mcmc" class="section level2"
number="4.3">
<h2><span class="header-section-number">4.3</span> Markov Chain Monte
Carlo (MCMC)</h2>
<p>Markov Chain Monte Carlo (MCMC) is a class of algorithms that allows
for the sampling from a probability distribution based on constructing a
Markov chain that has the desired distribution as its equilibrium
distribution. This approach is particularly useful for obtaining a
sequence of random samples from a multivariate probability distribution
where direct sampling is difficult.</p>
<p><strong>Monte Carlo Simulation</strong>:</p>
<ul>
<li>Named after the Monte Carlo Casino due to the random nature of the
methods, similar to gambling.</li>
<li>These methods involve using randomness to solve problems that might
be deterministic in principle. For example, they can be used to compute
integrals by simulating random draws from a distribution and
approximating sums or integrals.</li>
</ul>
<p><strong>Markov Chains</strong>:</p>
<ul>
<li>A Markov Chain is a stochastic model describing a sequence of
possible events in which the probability of each event depends only on
the state attained in the previous event.</li>
<li>In the context of MCMC, the chain uses transition probabilities that
depend only on the current state, not on how the current state was
reached.</li>
</ul>
<p><img src="02_Plots/Bayesian/Bayer_MCMC1.png" width="416" /></p>
<p><strong>MCMC Process</strong>:</p>
<ol style="list-style-type: decimal">
<li><strong>Initialization</strong>: Start from an arbitrary point in
the support of the distribution.</li>
<li><strong>Iteration</strong>: Move around the state space according to
some probabilistic rules designed so that the chain will eventually
converge to the target distribution.</li>
</ol>
<p><strong>Key Methods within MCMC</strong>:</p>
<ul>
<li><strong>Metropolis-Hastings Algorithm</strong>: Proposes a new state
from a proposal distribution and accepts or rejects the new state based
on an acceptance ratio, which ensures that the detailed balance is
maintained and the stationary distribution of the Markov chain is the
target distribution.</li>
<li><strong>Gibbs Sampling</strong>: A special case of
Metropolis-Hastings used when the joint distribution can be easily
sampled by sequentially sampling from the conditional distributions of
each variable given all other variables. It is particularly useful when
each conditional distribution is easier to sample from than the joint
distribution.</li>
</ul>
<p><strong>Advantages of MCMC</strong>:</p>
<ul>
<li>Enables sampling from complex, multi-dimensional distributions.</li>
<li>Useful in Bayesian inference for obtaining posterior distributions
where analytical solutions are not feasible.</li>
</ul>
<p><strong>Challenges with MCMC</strong>:</p>
<ul>
<li>Requires a large number of iterations to reach convergence, and
determining convergence can be non-trivial.</li>
<li>The samples are correlated, which means that the effective sample
size is less than the total number of samples generated.</li>
</ul>
</div>
<div id="expectation-maximization-em" class="section level2"
number="4.4">
<h2><span class="header-section-number">4.4</span>
Expectation-Maximization (EM)</h2>
<p>The Expectation-Maximization (EM) algorithm is a robust technique
used for parameter estimation in cases where data is incomplete,
missing, or has latent variables. It consists of two main steps repeated
iteratively: the Expectation step (E-step) and the Maximization step
(M-step).</p>
<ol style="list-style-type: decimal">
<li><p><strong>E-step</strong>: In this step, the algorithm calculates
the expected value of the log-likelihood function, with respect to the
conditional distribution of the latent variables given the observed data
and the current estimates of the parameters. This step involves filling
in missing data, estimating latent variables, or more generally,
calculating the expected sufficient statistics that are necessary for
the parameter updates in the next step.</p></li>
<li><p><strong>M-step</strong>: Here, the algorithm finds the parameter
values that maximize the expected log-likelihood found in the E-step.
These parameters are updated to new values that are used in the next
E-step.</p></li>
</ol>
<p>The process repeats with these new parameters until the convergence
criteria are met, which typically involves the change in the
log-likelihood or in the parameter estimates falling below a
threshold.</p>
<p>This iterative process helps in making the EM algorithm particularly
useful for situations where the model depends on unobserved latent data.
The EM algorithm is widely used in various applications like clustering
in machine learning (e.g., Gaussian mixture models), bioinformatics
(e.g., gene expression analysis), and more.</p>
<p><strong>Key Benefits:</strong></p>
<ul>
<li><strong>Handling of Missing Data</strong>: Efficiently deals with
missing or hidden data during model fitting.</li>
<li><strong>Flexibility</strong>: Can be applied to a wide range of
problems including those involving latent variables.</li>
<li><strong>Convergence Guarantee</strong>: Under mild conditions, EM is
guaranteed to converge to a local (sometimes global) maximum of the
likelihood function.</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li><strong>Local Maxima</strong>: The algorithm can converge to local
maxima, which means the initial values of parameters can affect the
final solution.</li>
<li><strong>Computationally Intensive</strong>: The E-step and M-step
can be computationally demanding, especially with large datasets or
complex models.</li>
<li><strong>Sensitivity to Model Specification</strong>: The performance
and convergence of the EM algorithm can be highly sensitive to how well
the model and its assumptions match the underlying data structure.</li>
</ul>
</div>
<div id="variational-inference" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Variational
inference</h2>
<p>Variational inference (VI) is a method used in Bayesian statistics
that approximates probability densities through optimization rather than
sampling, as seen in Markov Chain Monte Carlo (MCMC) methods. It is
particularly useful when dealing with complex models and large datasets,
providing a faster computational alternative.</p>
<p><strong>Process of Variational Inference:</strong></p>
<ol style="list-style-type: decimal">
<li><strong>Setup</strong>: VI transforms the computation of the
posterior distribution into an optimization problem. This involves
selecting a simpler, tractable family of distributions known as the
variational family.</li>
<li><strong>Objective</strong>: The aim is to find a distribution within
this family that most closely approximates the true posterior
distribution. The measure of “closeness” is typically quantified using
the Kullback-Leibler (KL) divergence.</li>
<li><strong>Optimization</strong>: To achieve this, VI minimizes the KL
divergence between the chosen variational distribution and the true
posterior distribution. This is often done using standard optimization
techniques.</li>
<li><strong>Outcome</strong>: The result is a deterministic
approximation of the posterior, which offers insights into parameter
estimates and uncertainties more rapidly than sampling methods.</li>
</ol>
<p><strong>Advantages of Variational Inference:</strong></p>
<ul>
<li><strong>Speed</strong>: Generally faster than MCMC due to its
deterministic nature.</li>
<li><strong>Scalability</strong>: Handles large datasets and complex
models more efficiently by avoiding the computationally intensive
process of drawing samples.</li>
<li><strong>Applicability</strong>: Useful in scenarios with large
parameter spaces where MCMC methods might converge slowly or be
impractical.</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li><strong>Accuracy</strong>: There can be significant discrepancies
between the variational approximation and the true posterior, especially
if the posterior is multi-modal or particularly complex.</li>
<li><strong>Bias</strong>: VI introduces bias because the variational
family may not encompass the true posterior.</li>
<li><strong>Dependency on Form</strong>: The effectiveness of VI depends
greatly on the chosen variational family. If too restrictive, it may not
adequately capture the posterior distribution.</li>
</ul>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
