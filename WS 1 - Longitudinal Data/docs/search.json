[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "s4_sensitivity_analyses.html",
    "href": "s4_sensitivity_analyses.html",
    "title": "Sensitivity Analyses",
    "section": "",
    "text": "Purpose: talk about sensitivity analyses with respect to missing data\n\nMMRM is an appropriate choice for the primary analysis in many longitudinal clinical trials under the missing at random (MAR) assumption.\nMMRM can handle missing values. BUT: need of baseline and at least one post-baseline value.\nNo imputation for individual missing values but missing data is implicitly imputed.\nExploit the correlation between outcomes within subjects.\nMAR: future outcomes for subjects who discontinued are assumed be similar to the future outcomes of subjects who continued if they had the same values of past (observed) outcomes, covariates,…\n\n\n\n\nConsider sensivitiy analyses to check model assumptions e.g. assumption of MAR.\nComparing results from sensitivity analyses: how much inference rely on the assumptions.\nHere, inference with regard to the treatment effect. Thus, investigate how treatment effects vary depending on assumptions (about missing data).\nUncertainty from incompleteness cannot be objectively evaluated from observed data so there is a need for missing data sensitivity analyses.\n\n\n\n\n\nFlexibility in modeling treatment effects over time and the within-patient error correlation structure makes MMRM a widely useful analysis.\nMMRM, MI: two major approaches to missing data with good statistical properties. Both rely on MAR assumption (for MI: standard implementation).\nMMRM: missing values implicitly imputed, MI: missing values explicitly imputed.\nMMRM vs. MI: approximately equivalent provided the variables used in the imputation model are the same as those included in the analysis model (level of equivalence will depend on the number of imputations)\nMI: imputation model with at least those variables from the primary model, additional auxiliary variables can be used in the imputation model to improve the accuracy of the missing data prediction.\nHandling missing not at random (MNAR) possible for MI (e.g. reference-based imputation) but not within MMRM.\nMMRM does not work if missing baseline values are present. Missing baseline values can be imputed first. Additionally, at least one post-baseline value has to be observed. Alternative: LDA where baseline is part of the response vector.\n\nNote that, when implemented in similar manners, MI and MMRM have similar assumptions and yield similar results. Thus, MI implemented similarly to MMRM is not a sensitivity analysis!\n\n\n\n\nMissing baseline value of the outcome (and other covariates) is a common situation\nMMRM not efficient or potential biased estimates as subjects with missing covariates are excluded from the analysis\n(Kayembe and Breukelen 2022) compared different methods e.g. unadjusted analysis, complete case, mean imputation, MI: mean imputation seems to be appropriate as long as the covariates are measured before randomization (produces unbiased treatment effect estimates with good coverage, easy to implement)\n\nNow, we consider the situation as in our data sets: baseline observed, no intermittent missing values, drop-outs = monotone missing pattern\n\n\n\nIn general, these simple approaches are not recommended for use. Methods are of historic interest and provide a useful starting point. Here, we consider two simple approaches. We will apply these two methods in the practical part to compare results.\n\n\nFor each subject, LOCF imputes missing values using the last observed value for that subject. Typically, under LOCF the repeated masures nature of the data is ignored and a single outcome for each subject is analyzed.\nLOCF was used in the past, justified as it was thought that it provides conservative estimates. However, conditions under which LOCF yield conservative estimates and maintain control of Type I error rates are not straightforward and cannot be assured at the beginning of the trial. For example, LOCF is likely to overestimate treatment benefit if dop-out in the control gorup is more frequent.\n\n\n\nOther names: observed case/ completers analysis\nReduce the data set selecting only those subjects with observed outcome value(s).\nCompleters analysis may create selection bias, may cause overestimation of within group effects particularly at the last scheduled visit.\n\n\n\n\n\nAssumption of MAR is often reasonable, but possibility of data missing not at random (MNAR) is difficult to rule out.\nThus, analysis under MNAR needed.\nAnalysis under MNAR: these methods are heavily assumption driven and the assumptions are not testable as we do not have the missing data.\nConsider a sensitivity analysis framework allowing assessment of robustness of results to the various assumptions.\nMNAR methods: different possibilities e.g. class of pattern-mixture models. The pattern-mixture model allows missing outcomes to be imputed under a chosen scenario and in this way can be used to complete the data set and apply the primary analysis to this completed data set.\nMI can be used to explore departures from MAR (for analysis under a MNAR assumption). This is referred to as controlled MI and includes delta-based MI and reference-based MI (belong to the class of pattern mixture models). Data is imputed under an alternative MNAR distribution that reflects a relevant scenario for the unobserved data. The imputed data sets are then analysed as with standard MI.\n\n\n\n\nHas received increasing attention in clinical trials as it provides an attractive approach for a sensitivity analysis because missing data assumptions are framed in an intuitive way. The departure from MAR is captured in a qualitative way, making the formulation of the problem intuitive.\nFor example, a plausible MNAR mechanism in a placebo???controlled trial is to assume that subjects in the experimental arm who dropped out stop taking their treatment and have similar outcomes to those in the placebo arm.\nRemember: MI under MAR assumes that the outcome distribution of patients with missing data is the same as the outcome distribution of patients with complete data, conditional on relevant covariates. However, if most patients withdraw from the study after treatment discontinuation, then this is not plausible, as patients who withdraw from the study treatment are expected to have a worse otucome than patients who stay on study treatment. Thus, addressing missing data under a MAR assumption estimates a hypothetical estimand and not a treatment policy estimand.\nDifferent options to handle missing outcome data for reference-based imputation were described (Carpenter and Kenward 2013): e.g. jump to reference (J2R), copy reference (CR), copy increments in reference (CIR)\n\nJump to reference J2R assumes that after treatment discontinuation, the patient???s mean outcome distribution is that of a reference group, usually the control group. This is a very extreme assumption, as this implies that any efficacy of the drug vanishes immediately after discontinuation - may be plausible for symptomatic treatments.\nCopy reference CR assumes that the patient???s outcome distribution both before and after treatment discontinuation is the same as the distribution of the reference group. This has a milder effect than J2R: If a treatment-group patient has an outcome that is better than the reference group mean before treatment discontinuation, their imputed values after treatment discontinuation will also be better than the reference group mean.\nCopy increments in reference CIR assumes that after treatment discontinuation, the increments are the same as those from the reference group. This is much milder than J2R and CR and implies that benefit gained from the treatment before discontinuation is not lost.\nThe conventional approach to analyse data using these reference based approaches is MI, following the same steps as MI under MAR.\nSoftware, R: e.g. the rbmi package supports reference-based strategies (Gower-Page and Wolbers 2022)\n\n\n\n\nImpute data assuming all unobserved subjects having a poorer or better response than those observed, by adding or subtracting a delta parameter \\(\\delta\\) to the expected value of the e.g. MAR imputed values.\nDelta can be implemented in all treatment groups, or in only one group, or may vary by treatment group or an alternative specified factor.\nChoice of values for the sensitivity parameter \\(\\delta\\): e.g. selection by content experts.\nSteps: 1. missing values are imputed using standard MI procedure e.g. under MAR (but can also be under MNAR e.g. combinded with copy reference approach), 2. imputed values are shifted by adding some fixed value \\(\\delta\\) to reflect the MNAR mechanism, 3. analysis with standard statistical methods including Rubin’s rule to combine results\n\n\n\n\n\n\nTake the (all2) high2 data set\nLook at the MMRM and at the complete case (CC) analysis (refer to section Missing Data for the all2 data set).\nApply additionally LOCF and compare results.\nTry MNAR method reference-based MI with J2R and CIR by using the rbmi package. Compare with the other results.\n\n\n\nHave a short look at the rbmi() package first.\n\nlibrary(rbmi)\n# ?rbmi\nvignette(topic = \"quickstart\", package = \"rbmi\")\n\nstarting httpd help server ... done\n\n\nThe workflow is based on 4 core functions:\n\ndraws() - fits the imputation models, different methods possible, we will use method_bayes() for MI based on Bayesian posterior parameter draws from MCMC sampling\nimpute() - creates multiple imputed data sets\nanalyse() - analyses each of the multiple imputed data sets, default = ancova, other options possible\npool() - combines the results across imputed data sets, for method_bayes (see above) pooling and inference is based on Rubin’s rule\n\nImplemented imputation strategies in rbmi:\n\nMissing at Random (MAR)\nJump to Reference (JR)\nCopy Reference (CR)\nCopy Increments in Reference (CIR)\n\nI will show how it looks like for the all2 data set and you will then explore the methods using the high2 data set.\n\n\n\n\n\nTable: Adjusted means for the complete case data set (all2 data with drop-out, select completer)\n\nmodel_lsmeans_cc\n\n trt avisit emmean   SE df lower.CL upper.CL\n 1   Week 2  -4.33 1.12 34    -6.61    -2.06\n 2   Week 2  -5.47 1.09 34    -7.69    -3.26\n 1   Week 4  -6.98 1.09 34    -9.19    -4.77\n 2   Week 4  -9.12 1.06 34   -11.27    -6.97\n 1   Week 8 -10.17 1.21 34   -12.63    -7.71\n 2   Week 8 -13.10 1.18 34   -15.49   -10.71\n\nConfidence level used: 0.95 \n\n\n\n\n\nTable: Adjusted means for the all2 data set with drop-out analysed with MMRM\n\nmodel_lsmeans_mmrm\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.10 0.900 47.0    -5.91    -2.29\n 2   Week 2  -5.29 0.899 47.0    -7.10    -3.48\n 1   Week 4  -6.42 0.974 46.5    -8.38    -4.46\n 2   Week 4  -8.52 0.951 44.8   -10.43    -6.60\n 1   Week 8  -9.73 1.142 40.4   -12.03    -7.42\n 2   Week 8 -12.62 1.114 40.1   -14.88   -10.37\n\nConfidence level used: 0.95 \n\n\n\n\n\n\nall2.locf &lt;- all2 %&gt;% filter(!is.na(chgdrop)) %&gt;%\n  dplyr::group_by(subject) %&gt;% \n  dplyr::mutate( drop=max(week) )\n\nall2.locf&lt;-all2.locf %&gt;% dplyr::filter(week==drop)\n\nancova &lt;- aov(change ~ basval + trt, data = all2.locf)\nsummary(ancova)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \nbasval       1    1.8    1.82   0.053 0.8185  \ntrt          1  114.2  114.20   3.342 0.0739 .\nResiduals   47 1606.1   34.17                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nancova$coefficients\n\n(Intercept)      basval        trt2 \n-8.69460273  0.02497994 -3.02800963 \n\n\nTable: Mean values for change from baseline of LOCF analysis\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Arm 1, N = 251\n      Arm 2, N = 251\n    \n  \n  \n    change\n-8.20 (5.50)\n-11.24 (6.06)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\n\n\n\n\n# Define the names of key variables in the data set\nset_mi&lt;-set_vars(\n  subjid = \"subject\",\n  visit = \"avisit\",\n  outcome = \"chgdrop\",\n  group = \"group\",\n  covariates = c(\"basval * avisit\", \"group * avisit\")\n)\n\nvars_an&lt;-set_mi\nvars_an$covariates &lt;- \"basval\"\n\n# Define the imputation strategy for each subject with at least one missing observation\ndat_ice &lt;- all2 %&gt;% \n  arrange(subject, avisit) %&gt;% \n  filter(is.na(chgdrop)) %&gt;% \n  group_by(subject) %&gt;% \n  slice(1) %&gt;%\n  ungroup() %&gt;% \n  select(subject, avisit) %&gt;% \n  mutate(strategy = \"JR\")\n\n# Define the imputation method\nmethod &lt;- method_bayes(\n  burn_in = 200,\n  burn_between = 5,\n  n_samples = 100,\n  seed = 072407\n)\n\ndraw_all2&lt;-draws(data=all2, data_ice = dat_ice, vars=set_mi, method=method, ncores = 1, quiet = FALSE)\n\nimputeObj &lt;- rbmi::impute(\n  draw_all2,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\")\n)\n\nimputed_all2 &lt;- extract_imputed_dfs(imputeObj)\n\n\nanaObj &lt;- analyse(\n  imputeObj,\n  vars = vars_an\n)\n\nTable: Estimates from jump to reference J2R imputation\n\npoolObj &lt;- pool(anaObj)\nas.data.frame(poolObj)\n\n       parameter        est        se        lci        uci         pval\n1     trt_Week 2  -1.189928 1.2864325  -3.780746  1.4008900 3.598958e-01\n2 lsm_ref_Week 2  -4.125036 0.9088264  -5.955372 -2.2947002 4.178855e-05\n3 lsm_alt_Week 2  -5.314964 0.9088264  -7.145300 -3.4846279 5.199440e-07\n4     trt_Week 4  -1.891611 1.3620669  -4.640571  0.8573493 1.722385e-01\n5 lsm_ref_Week 4  -6.431208 0.9825242  -8.416838 -4.4455792 8.018843e-08\n6 lsm_alt_Week 4  -8.322819 0.9686135 -10.278514 -6.3671240 9.691334e-11\n7     trt_Week 8  -2.224522 1.6819701  -5.630171  1.1811279 1.939313e-01\n8 lsm_ref_Week 8  -9.635725 1.2325842 -12.138382 -7.1330688 3.578224e-09\n9 lsm_alt_Week 8 -11.860247 1.1666594 -14.219452 -9.5010426 1.465037e-12\n\n\n\n\n\nUse the additional argument update_strategies in the impute function.\n\ndat_ice_CIR &lt;- dat_ice %&gt;% \n  mutate(strategy = ifelse(strategy == \"JR\", \"CIR\", strategy))\n\nimputeObj_CIR &lt;- rbmi::impute(\n  draw_all2,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\"),\n  update_strategy = dat_ice_CIR\n)\n\nanaObj_CIR &lt;- analyse(\n  imputeObj_CIR,\n  vars = vars_an\n)\n\nTable: Estimates from copy increments in reference CIR imputation\n\npoolObj_CIR &lt;- pool(anaObj_CIR)\nas.data.frame(poolObj_CIR)\n\n       parameter        est        se        lci        uci         pval\n1     trt_Week 2  -1.189928 1.2864325  -3.780746  1.4008900 3.598958e-01\n2 lsm_ref_Week 2  -4.125036 0.9088264  -5.955372 -2.2947002 4.178855e-05\n3 lsm_alt_Week 2  -5.314964 0.9088264  -7.145300 -3.4846279 5.199440e-07\n4     trt_Week 4  -2.014066 1.3705302  -4.780689  0.7525565 1.492051e-01\n5 lsm_ref_Week 4  -6.421132 0.9876309  -8.417393 -4.4248703 9.451951e-08\n6 lsm_alt_Week 4  -8.435198 0.9659215 -10.384762 -6.4856335 5.656836e-11\n7     trt_Week 8  -2.623617 1.6330444  -5.927634  0.6803994 1.162804e-01\n8 lsm_ref_Week 8  -9.638166 1.1777005 -12.024453 -7.2518789 8.026285e-10\n9 lsm_alt_Week 8 -12.261783 1.1899788 -14.674825 -9.8487422 2.641684e-12\n\n\n\n\n\nTake the figure from the missingness part to better understand what we have found here.\n\nEstimates for all methods\n\n\n\nMean\nDiff\n\n\n\n\nCompleters, Arm 1\n-10.17\n\n\n\nCompleters, Arm 2\n-13.10\n-2.93\n\n\nMMRM, Arm 1\n-9.73\n\n\n\nMMRM, Arm 2\n-12.62\n-2.89\n\n\nLOCF, Arm 1\n-8.20\n\n\n\nLOCF, Arm 2\n-11.24\n-3.03\n\n\nJ2R , Arm 1\n-9.66\n\n\n\nJ2R , Arm 2\n-11.87\n-2.21\n\n\nCIR , Arm 1\n-9.65\n\n\n\nCIR , Arm 2\n-12.26\n-2.61\n\n\n\n\n\n\n\nNow, you can first of all repeat the analysis on the all2 data set to see if you can manage it. Or you go directly to the next step and apply methods to the high2 data set.\nOne starting point for the high2 data set as the structure is a little bit different:\nFirst, fill in missing visits. This was not necessary in the all2 data set. This can be done with the expand_locf function of the rbmi package. Note, change is the outcome variable and not chgdrop as in all2\n\nhigh2 &lt;- high2 %&gt;% ungroup()\n\nhigh2_expand &lt;- expand_locf(\n  high2,\n  subject = levels(high2$subject),  \n  avisit = levels(high2$avisit),\n  vars = c(\"basval\",\"trt\",\"group\"),\n  group = c(\"subject\"),\n  order = c(\"subject\", \"avisit\")\n)\n\n## Exploring missing data\nvis_miss(high2_expand)\n\n\n\ngg_miss_var(high2_expand %&gt;% filter(group==\"Arm 1\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\ngg_miss_var(high2_expand %&gt;% filter(group==\"Arm 2\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\n\n\n\n\n\n trt avisit emmean    SE  df lower.CL upper.CL\n 1   Week 1  -1.91 0.595 127    -3.08   -0.731\n 2   Week 1  -1.97 0.550 127    -3.06   -0.885\n 1   Week 2  -4.08 0.756 126    -5.58   -2.585\n 2   Week 2  -4.47 0.702 127    -5.86   -3.080\n 1   Week 4  -5.85 0.764 127    -7.36   -4.336\n 2   Week 4  -6.99 0.706 127    -8.38   -5.591\n 1   Week 6  -7.09 0.749 127    -8.57   -5.607\n 2   Week 6  -8.51 0.692 127    -9.88   -7.138\n 1   Week 8  -6.96 0.811 127    -8.56   -5.352\n 2   Week 8  -8.67 0.750 127   -10.16   -7.191\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n trt avisit emmean    SE  df lower.CL upper.CL\n 1   Week 1  -1.61 0.458 197    -2.52   -0.711\n 2   Week 1  -1.66 0.459 197    -2.56   -0.752\n 1   Week 2  -3.24 0.609 191    -4.44   -2.036\n 2   Week 2  -3.89 0.613 193    -5.10   -2.681\n 1   Week 4  -4.52 0.656 182    -5.81   -3.223\n 2   Week 4  -5.98 0.656 182    -7.27   -4.684\n 1   Week 6  -5.12 0.718 168    -6.53   -3.701\n 2   Week 6  -7.48 0.715 166    -8.89   -6.067\n 1   Week 8  -5.24 0.785 149    -6.79   -3.686\n 2   Week 8  -7.76 0.762 139    -9.26   -6.251\n\nConfidence level used: 0.95 \n\n\n\n\n\n\nhigh2_expand.locf &lt;- high2_expand %&gt;% filter(!is.na(change)) %&gt;%\n  dplyr::group_by(subject) %&gt;% \n  dplyr::mutate( drop=max(week) )\n\nhigh2_expand.locf&lt;-high2_expand.locf %&gt;% dplyr::filter(week==drop)\n\nancova &lt;- aov(change ~ basval + trt, data = high2_expand.locf)\nsummary(ancova)\n\n             Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nbasval        1    483   483.3   9.709 0.00211 **\ntrt           1    241   241.4   4.851 0.02880 * \nResiduals   197   9805    49.8                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nancova$coefficients\n\n(Intercept)      basval        trt2 \n  0.3536399  -0.2648315  -2.2086854 \n\n\nTable: Mean values for change from baseline of LOCF analysis\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Arm 1, N = 1001\n      Arm 2, N = 1001\n    \n  \n  \n    change\n-4.22 (6.38)\n-6.72 (7.90)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\n\n\n\n\n# Define the names of key variables in the data set\nset_mi&lt;-set_vars(\n  subjid = \"subject\",\n  visit = \"avisit\",\n  outcome = \"change\",\n  group = \"group\",\n  covariates = c(\"basval * avisit\", \"group * avisit\")\n)\n\nvars_an&lt;-set_mi\nvars_an$covariates &lt;- \"basval\"\n\n# Define the imputation strategy for each subject with at least one missing observation\ndat_ice &lt;- high2_expand %&gt;% \n  arrange(subject, avisit) %&gt;% \n  filter(is.na(change)) %&gt;% \n  group_by(subject) %&gt;% \n  slice(1) %&gt;%\n  ungroup() %&gt;% \n  select(subject, avisit) %&gt;% \n  mutate(strategy = \"JR\")\n\n# Define the imputation method\nmethod &lt;- method_bayes(\n  burn_in = 200,\n  burn_between = 5,\n  n_samples = 100,\n  seed = 072407\n)\n\ndraw_high2_expand&lt;-draws(data=high2_expand, data_ice = dat_ice, vars=set_mi, method=method, ncores = 1, quiet = FALSE)\n\nimputeObj &lt;- rbmi::impute(\n  draw_high2_expand,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\")\n)\n\nimputed_high2_expand &lt;- extract_imputed_dfs(imputeObj)\n\n\nanaObj &lt;- analyse(\n  imputeObj,\n  vars = vars_an\n)\n\nTable: Estimates from jump to reference J2R imputation\n\npoolObj &lt;- pool(anaObj)\nas.data.frame(poolObj)\n\n        parameter         est        se       lci        uci         pval\n1      trt_Week 1 -0.04272539 0.6513099 -1.327240  1.2417894 9.477641e-01\n2  lsm_ref_Week 1 -1.64363730 0.4593710 -2.549610 -0.7376649 4.367614e-04\n3  lsm_alt_Week 1 -1.68636270 0.4593710 -2.592335 -0.7803903 3.118171e-04\n4      trt_Week 2 -0.56992013 0.8733074 -2.293096  1.1532554 5.148426e-01\n5  lsm_ref_Week 2 -3.31268012 0.6131345 -4.522404 -2.1029566 2.023442e-07\n6  lsm_alt_Week 2 -3.88260025 0.6200592 -5.106212 -2.6589881 2.772190e-09\n7      trt_Week 4 -1.24725634 0.9408037 -3.104301  0.6097887 1.866906e-01\n8  lsm_ref_Week 4 -4.55155161 0.6629053 -5.860032 -3.2430717 1.152780e-10\n9  lsm_alt_Week 4 -5.79880795 0.6663404 -7.114195 -4.4834207 2.753285e-15\n10     trt_Week 6 -1.70672432 1.0335987 -3.747568  0.3341192 1.005981e-01\n11 lsm_ref_Week 6 -5.19235287 0.7271162 -6.627972 -3.7567339 2.786779e-11\n12 lsm_alt_Week 6 -6.89907719 0.7562247 -8.393431 -5.4047230 4.832113e-16\n13     trt_Week 8 -1.72142767 1.1185316 -3.931215  0.4883593 1.258714e-01\n14 lsm_ref_Week 8 -5.30861260 0.8134583 -6.916855 -3.7003698 1.147909e-09\n15 lsm_alt_Week 8 -7.03004027 0.8171570 -8.645779 -5.4143020 1.519834e-14\n\n\n\n\n\n\ndat_ice_CR &lt;- dat_ice %&gt;% \n  mutate(strategy = ifelse(strategy == \"JR\", \"CR\", strategy))\n\nimputeObj_CR &lt;- rbmi::impute(\n  draw_high2_expand,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\"),\n  update_strategy = dat_ice_CR\n)\n\nanaObj_CR &lt;- analyse(\n  imputeObj_CR,\n  vars = vars_an\n)\n\nTable: Estimates from copy increments in reference CR imputation\n\npoolObj_CR &lt;- pool(anaObj_CR)\nas.data.frame(poolObj_CR)\n\n        parameter         est        se       lci        uci         pval\n1      trt_Week 1 -0.04272539 0.6513099 -1.327240  1.2417894 9.477641e-01\n2  lsm_ref_Week 1 -1.64363730 0.4593710 -2.549610 -0.7376649 4.367614e-04\n3  lsm_alt_Week 1 -1.68636270 0.4593710 -2.592335 -0.7803903 3.118171e-04\n4      trt_Week 2 -0.56759918 0.8689359 -2.282001  1.1468026 5.144382e-01\n5  lsm_ref_Week 2 -3.29268009 0.6124023 -4.500929 -2.0844308 2.286124e-07\n6  lsm_alt_Week 2 -3.86027926 0.6116150 -5.066951 -2.6536076 2.006222e-09\n7      trt_Week 4 -1.25504934 0.9383983 -3.107106  0.5970075 1.828184e-01\n8  lsm_ref_Week 4 -4.53971218 0.6596020 -5.841448 -3.2379761 9.920190e-11\n9  lsm_alt_Week 4 -5.79476153 0.6613572 -7.100023 -4.4895005 1.620378e-15\n10     trt_Week 6 -1.84350067 1.0284066 -3.874288  0.1872865 7.490327e-02\n11 lsm_ref_Week 6 -5.19290296 0.7322118 -6.639082 -3.7467244 4.162868e-11\n12 lsm_alt_Week 6 -7.03640363 0.7325057 -8.483175 -5.5896322 1.716342e-17\n13     trt_Week 8 -1.89556177 1.1140972 -4.097188  0.3060646 9.096551e-02\n14 lsm_ref_Week 8 -5.34060252 0.8285363 -6.980116 -3.7010886 2.174328e-09\n15 lsm_alt_Week 8 -7.23616429 0.7883131 -8.794109 -5.6782193 3.806874e-16\n\n\n\n\n\nUse the additional argument update_strategies in the impute function.\n\ndat_ice_CIR &lt;- dat_ice %&gt;% \n  mutate(strategy = ifelse(strategy == \"JR\", \"CIR\", strategy))\n\nimputeObj_CIR &lt;- rbmi::impute(\n  draw_high2_expand,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\"),\n  update_strategy = dat_ice_CIR\n)\n\nanaObj_CIR &lt;- analyse(\n  imputeObj_CIR,\n  vars = vars_an\n)\n\nTable: Estimates from copy increments in reference CIR imputation\n\npoolObj_CIR &lt;- pool(anaObj_CIR)\nas.data.frame(poolObj_CIR)\n\n        parameter         est        se       lci         uci         pval\n1      trt_Week 1 -0.04272539 0.6513099 -1.327240  1.24178939 9.477641e-01\n2  lsm_ref_Week 1 -1.64363730 0.4593710 -2.549610 -0.73766488 4.367614e-04\n3  lsm_alt_Week 1 -1.68636270 0.4593710 -2.592335 -0.78039028 3.118171e-04\n4      trt_Week 2 -0.59370495 0.8652051 -2.300688  1.11327818 4.934487e-01\n5  lsm_ref_Week 2 -3.31016751 0.6107925 -4.515231 -2.10510358 1.858699e-07\n6  lsm_alt_Week 2 -3.90387245 0.6131567 -5.113675 -2.69407009 1.525078e-09\n7      trt_Week 4 -1.30521947 0.9399264 -3.160483  0.55004438 1.667362e-01\n8  lsm_ref_Week 4 -4.54415889 0.6612575 -5.849315 -3.23900302 1.094861e-10\n9  lsm_alt_Week 4 -5.84937837 0.6646077 -7.161268 -4.53748825 1.440661e-15\n10     trt_Week 6 -1.95953532 1.0158040 -3.965042  0.04597113 5.542434e-02\n11 lsm_ref_Week 6 -5.17405265 0.7257053 -6.607187 -3.74091840 3.216919e-11\n12 lsm_alt_Week 6 -7.13358797 0.7274177 -8.570175 -5.69700135 4.541636e-18\n13     trt_Week 8 -2.06003358 1.1160556 -4.265940  0.14587245 6.696562e-02\n14 lsm_ref_Week 8 -5.30927178 0.8206544 -6.933036 -3.68550713 1.886190e-09\n15 lsm_alt_Week 8 -7.36930536 0.7879631 -8.926768 -5.81184259 1.535541e-16\n\n\n\n\n\nTake the figure from the missingness part to better understand what we have found here.\n\nEstimates for all methods\n\n\nGroup\nMean\nDiff\n\n\n\n\nCompleters, Arm 1\n-6.96\n\n\n\nCompleters, Arm 2\n-8.67\n-1.71\n\n\nMMRM, Arm 1\n-5.24\n\n\n\nMMRM, Arm 2\n-7.76\n-2.52\n\n\nLOCF, Arm 1\n-4.22\n\n\n\nLOCF, Arm 2\n-6.72\n-2.50\n\n\nJ2R, Arm 1\n-5.31\n\n\n\nJ2R, Arm 2\n-7.03\n-1.72\n\n\nCR, Arm 1\n-5.34\n\n\n\nCR, Arm 2\n-7.24\n-1.90\n\n\nCIR, Arm 1\n-5.31\n\n\n\nCIR, Arm 2\n-7.37\n-2.06"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#purpose-of-sensitivity-analyses",
    "href": "s4_sensitivity_analyses.html#purpose-of-sensitivity-analyses",
    "title": "Sensitivity Analyses",
    "section": "",
    "text": "Consider sensivitiy analyses to check model assumptions e.g. assumption of MAR.\nComparing results from sensitivity analyses: how much inference rely on the assumptions.\nHere, inference with regard to the treatment effect. Thus, investigate how treatment effects vary depending on assumptions (about missing data).\nUncertainty from incompleteness cannot be objectively evaluated from observed data so there is a need for missing data sensitivity analyses."
  },
  {
    "objectID": "s4_sensitivity_analyses.html#mmrm-vs.-mi",
    "href": "s4_sensitivity_analyses.html#mmrm-vs.-mi",
    "title": "Sensitivity Analyses",
    "section": "",
    "text": "Flexibility in modeling treatment effects over time and the within-patient error correlation structure makes MMRM a widely useful analysis.\nMMRM, MI: two major approaches to missing data with good statistical properties. Both rely on MAR assumption (for MI: standard implementation).\nMMRM: missing values implicitly imputed, MI: missing values explicitly imputed.\nMMRM vs. MI: approximately equivalent provided the variables used in the imputation model are the same as those included in the analysis model (level of equivalence will depend on the number of imputations)\nMI: imputation model with at least those variables from the primary model, additional auxiliary variables can be used in the imputation model to improve the accuracy of the missing data prediction.\nHandling missing not at random (MNAR) possible for MI (e.g. reference-based imputation) but not within MMRM.\nMMRM does not work if missing baseline values are present. Missing baseline values can be imputed first. Additionally, at least one post-baseline value has to be observed. Alternative: LDA where baseline is part of the response vector.\n\nNote that, when implemented in similar manners, MI and MMRM have similar assumptions and yield similar results. Thus, MI implemented similarly to MMRM is not a sensitivity analysis!"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#missing-covariates-baseline-data-only",
    "href": "s4_sensitivity_analyses.html#missing-covariates-baseline-data-only",
    "title": "Sensitivity Analyses",
    "section": "",
    "text": "Missing baseline value of the outcome (and other covariates) is a common situation\nMMRM not efficient or potential biased estimates as subjects with missing covariates are excluded from the analysis\n(Kayembe and Breukelen 2022) compared different methods e.g. unadjusted analysis, complete case, mean imputation, MI: mean imputation seems to be appropriate as long as the covariates are measured before randomization (produces unbiased treatment effect estimates with good coverage, easy to implement)\n\nNow, we consider the situation as in our data sets: baseline observed, no intermittent missing values, drop-outs = monotone missing pattern"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#sensitivity-analyses---simple-approaches",
    "href": "s4_sensitivity_analyses.html#sensitivity-analyses---simple-approaches",
    "title": "Sensitivity Analyses",
    "section": "",
    "text": "In general, these simple approaches are not recommended for use. Methods are of historic interest and provide a useful starting point. Here, we consider two simple approaches. We will apply these two methods in the practical part to compare results.\n\n\nFor each subject, LOCF imputes missing values using the last observed value for that subject. Typically, under LOCF the repeated masures nature of the data is ignored and a single outcome for each subject is analyzed.\nLOCF was used in the past, justified as it was thought that it provides conservative estimates. However, conditions under which LOCF yield conservative estimates and maintain control of Type I error rates are not straightforward and cannot be assured at the beginning of the trial. For example, LOCF is likely to overestimate treatment benefit if dop-out in the control gorup is more frequent.\n\n\n\nOther names: observed case/ completers analysis\nReduce the data set selecting only those subjects with observed outcome value(s).\nCompleters analysis may create selection bias, may cause overestimation of within group effects particularly at the last scheduled visit."
  },
  {
    "objectID": "s4_sensitivity_analyses.html#sensitivity-analyses---handling-nonignorable-missingness-mnar",
    "href": "s4_sensitivity_analyses.html#sensitivity-analyses---handling-nonignorable-missingness-mnar",
    "title": "Sensitivity Analyses",
    "section": "",
    "text": "Assumption of MAR is often reasonable, but possibility of data missing not at random (MNAR) is difficult to rule out.\nThus, analysis under MNAR needed.\nAnalysis under MNAR: these methods are heavily assumption driven and the assumptions are not testable as we do not have the missing data.\nConsider a sensitivity analysis framework allowing assessment of robustness of results to the various assumptions.\nMNAR methods: different possibilities e.g. class of pattern-mixture models. The pattern-mixture model allows missing outcomes to be imputed under a chosen scenario and in this way can be used to complete the data set and apply the primary analysis to this completed data set.\nMI can be used to explore departures from MAR (for analysis under a MNAR assumption). This is referred to as controlled MI and includes delta-based MI and reference-based MI (belong to the class of pattern mixture models). Data is imputed under an alternative MNAR distribution that reflects a relevant scenario for the unobserved data. The imputed data sets are then analysed as with standard MI.\n\n\n\n\nHas received increasing attention in clinical trials as it provides an attractive approach for a sensitivity analysis because missing data assumptions are framed in an intuitive way. The departure from MAR is captured in a qualitative way, making the formulation of the problem intuitive.\nFor example, a plausible MNAR mechanism in a placebo???controlled trial is to assume that subjects in the experimental arm who dropped out stop taking their treatment and have similar outcomes to those in the placebo arm.\nRemember: MI under MAR assumes that the outcome distribution of patients with missing data is the same as the outcome distribution of patients with complete data, conditional on relevant covariates. However, if most patients withdraw from the study after treatment discontinuation, then this is not plausible, as patients who withdraw from the study treatment are expected to have a worse otucome than patients who stay on study treatment. Thus, addressing missing data under a MAR assumption estimates a hypothetical estimand and not a treatment policy estimand.\nDifferent options to handle missing outcome data for reference-based imputation were described (Carpenter and Kenward 2013): e.g. jump to reference (J2R), copy reference (CR), copy increments in reference (CIR)\n\nJump to reference J2R assumes that after treatment discontinuation, the patient???s mean outcome distribution is that of a reference group, usually the control group. This is a very extreme assumption, as this implies that any efficacy of the drug vanishes immediately after discontinuation - may be plausible for symptomatic treatments.\nCopy reference CR assumes that the patient???s outcome distribution both before and after treatment discontinuation is the same as the distribution of the reference group. This has a milder effect than J2R: If a treatment-group patient has an outcome that is better than the reference group mean before treatment discontinuation, their imputed values after treatment discontinuation will also be better than the reference group mean.\nCopy increments in reference CIR assumes that after treatment discontinuation, the increments are the same as those from the reference group. This is much milder than J2R and CR and implies that benefit gained from the treatment before discontinuation is not lost.\nThe conventional approach to analyse data using these reference based approaches is MI, following the same steps as MI under MAR.\nSoftware, R: e.g. the rbmi package supports reference-based strategies (Gower-Page and Wolbers 2022)\n\n\n\n\nImpute data assuming all unobserved subjects having a poorer or better response than those observed, by adding or subtracting a delta parameter \\(\\delta\\) to the expected value of the e.g. MAR imputed values.\nDelta can be implemented in all treatment groups, or in only one group, or may vary by treatment group or an alternative specified factor.\nChoice of values for the sensitivity parameter \\(\\delta\\): e.g. selection by content experts.\nSteps: 1. missing values are imputed using standard MI procedure e.g. under MAR (but can also be under MNAR e.g. combinded with copy reference approach), 2. imputed values are shifted by adding some fixed value \\(\\delta\\) to reflect the MNAR mechanism, 3. analysis with standard statistical methods including Rubin’s rule to combine results"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#practical-part",
    "href": "s4_sensitivity_analyses.html#practical-part",
    "title": "Sensitivity Analyses",
    "section": "",
    "text": "Take the (all2) high2 data set\nLook at the MMRM and at the complete case (CC) analysis (refer to section Missing Data for the all2 data set).\nApply additionally LOCF and compare results.\nTry MNAR method reference-based MI with J2R and CIR by using the rbmi package. Compare with the other results.\n\n\n\nHave a short look at the rbmi() package first.\n\nlibrary(rbmi)\n# ?rbmi\nvignette(topic = \"quickstart\", package = \"rbmi\")\n\nstarting httpd help server ... done\n\n\nThe workflow is based on 4 core functions:\n\ndraws() - fits the imputation models, different methods possible, we will use method_bayes() for MI based on Bayesian posterior parameter draws from MCMC sampling\nimpute() - creates multiple imputed data sets\nanalyse() - analyses each of the multiple imputed data sets, default = ancova, other options possible\npool() - combines the results across imputed data sets, for method_bayes (see above) pooling and inference is based on Rubin’s rule\n\nImplemented imputation strategies in rbmi:\n\nMissing at Random (MAR)\nJump to Reference (JR)\nCopy Reference (CR)\nCopy Increments in Reference (CIR)\n\nI will show how it looks like for the all2 data set and you will then explore the methods using the high2 data set.\n\n\n\n\n\nTable: Adjusted means for the complete case data set (all2 data with drop-out, select completer)\n\nmodel_lsmeans_cc\n\n trt avisit emmean   SE df lower.CL upper.CL\n 1   Week 2  -4.33 1.12 34    -6.61    -2.06\n 2   Week 2  -5.47 1.09 34    -7.69    -3.26\n 1   Week 4  -6.98 1.09 34    -9.19    -4.77\n 2   Week 4  -9.12 1.06 34   -11.27    -6.97\n 1   Week 8 -10.17 1.21 34   -12.63    -7.71\n 2   Week 8 -13.10 1.18 34   -15.49   -10.71\n\nConfidence level used: 0.95 \n\n\n\n\n\nTable: Adjusted means for the all2 data set with drop-out analysed with MMRM\n\nmodel_lsmeans_mmrm\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.10 0.900 47.0    -5.91    -2.29\n 2   Week 2  -5.29 0.899 47.0    -7.10    -3.48\n 1   Week 4  -6.42 0.974 46.5    -8.38    -4.46\n 2   Week 4  -8.52 0.951 44.8   -10.43    -6.60\n 1   Week 8  -9.73 1.142 40.4   -12.03    -7.42\n 2   Week 8 -12.62 1.114 40.1   -14.88   -10.37\n\nConfidence level used: 0.95 \n\n\n\n\n\n\nall2.locf &lt;- all2 %&gt;% filter(!is.na(chgdrop)) %&gt;%\n  dplyr::group_by(subject) %&gt;% \n  dplyr::mutate( drop=max(week) )\n\nall2.locf&lt;-all2.locf %&gt;% dplyr::filter(week==drop)\n\nancova &lt;- aov(change ~ basval + trt, data = all2.locf)\nsummary(ancova)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \nbasval       1    1.8    1.82   0.053 0.8185  \ntrt          1  114.2  114.20   3.342 0.0739 .\nResiduals   47 1606.1   34.17                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nancova$coefficients\n\n(Intercept)      basval        trt2 \n-8.69460273  0.02497994 -3.02800963 \n\n\nTable: Mean values for change from baseline of LOCF analysis\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Arm 1, N = 251\n      Arm 2, N = 251\n    \n  \n  \n    change\n-8.20 (5.50)\n-11.24 (6.06)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\n\n\n\n\n# Define the names of key variables in the data set\nset_mi&lt;-set_vars(\n  subjid = \"subject\",\n  visit = \"avisit\",\n  outcome = \"chgdrop\",\n  group = \"group\",\n  covariates = c(\"basval * avisit\", \"group * avisit\")\n)\n\nvars_an&lt;-set_mi\nvars_an$covariates &lt;- \"basval\"\n\n# Define the imputation strategy for each subject with at least one missing observation\ndat_ice &lt;- all2 %&gt;% \n  arrange(subject, avisit) %&gt;% \n  filter(is.na(chgdrop)) %&gt;% \n  group_by(subject) %&gt;% \n  slice(1) %&gt;%\n  ungroup() %&gt;% \n  select(subject, avisit) %&gt;% \n  mutate(strategy = \"JR\")\n\n# Define the imputation method\nmethod &lt;- method_bayes(\n  burn_in = 200,\n  burn_between = 5,\n  n_samples = 100,\n  seed = 072407\n)\n\ndraw_all2&lt;-draws(data=all2, data_ice = dat_ice, vars=set_mi, method=method, ncores = 1, quiet = FALSE)\n\nimputeObj &lt;- rbmi::impute(\n  draw_all2,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\")\n)\n\nimputed_all2 &lt;- extract_imputed_dfs(imputeObj)\n\n\nanaObj &lt;- analyse(\n  imputeObj,\n  vars = vars_an\n)\n\nTable: Estimates from jump to reference J2R imputation\n\npoolObj &lt;- pool(anaObj)\nas.data.frame(poolObj)\n\n       parameter        est        se        lci        uci         pval\n1     trt_Week 2  -1.189928 1.2864325  -3.780746  1.4008900 3.598958e-01\n2 lsm_ref_Week 2  -4.125036 0.9088264  -5.955372 -2.2947002 4.178855e-05\n3 lsm_alt_Week 2  -5.314964 0.9088264  -7.145300 -3.4846279 5.199440e-07\n4     trt_Week 4  -1.891611 1.3620669  -4.640571  0.8573493 1.722385e-01\n5 lsm_ref_Week 4  -6.431208 0.9825242  -8.416838 -4.4455792 8.018843e-08\n6 lsm_alt_Week 4  -8.322819 0.9686135 -10.278514 -6.3671240 9.691334e-11\n7     trt_Week 8  -2.224522 1.6819701  -5.630171  1.1811279 1.939313e-01\n8 lsm_ref_Week 8  -9.635725 1.2325842 -12.138382 -7.1330688 3.578224e-09\n9 lsm_alt_Week 8 -11.860247 1.1666594 -14.219452 -9.5010426 1.465037e-12\n\n\n\n\n\nUse the additional argument update_strategies in the impute function.\n\ndat_ice_CIR &lt;- dat_ice %&gt;% \n  mutate(strategy = ifelse(strategy == \"JR\", \"CIR\", strategy))\n\nimputeObj_CIR &lt;- rbmi::impute(\n  draw_all2,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\"),\n  update_strategy = dat_ice_CIR\n)\n\nanaObj_CIR &lt;- analyse(\n  imputeObj_CIR,\n  vars = vars_an\n)\n\nTable: Estimates from copy increments in reference CIR imputation\n\npoolObj_CIR &lt;- pool(anaObj_CIR)\nas.data.frame(poolObj_CIR)\n\n       parameter        est        se        lci        uci         pval\n1     trt_Week 2  -1.189928 1.2864325  -3.780746  1.4008900 3.598958e-01\n2 lsm_ref_Week 2  -4.125036 0.9088264  -5.955372 -2.2947002 4.178855e-05\n3 lsm_alt_Week 2  -5.314964 0.9088264  -7.145300 -3.4846279 5.199440e-07\n4     trt_Week 4  -2.014066 1.3705302  -4.780689  0.7525565 1.492051e-01\n5 lsm_ref_Week 4  -6.421132 0.9876309  -8.417393 -4.4248703 9.451951e-08\n6 lsm_alt_Week 4  -8.435198 0.9659215 -10.384762 -6.4856335 5.656836e-11\n7     trt_Week 8  -2.623617 1.6330444  -5.927634  0.6803994 1.162804e-01\n8 lsm_ref_Week 8  -9.638166 1.1777005 -12.024453 -7.2518789 8.026285e-10\n9 lsm_alt_Week 8 -12.261783 1.1899788 -14.674825 -9.8487422 2.641684e-12\n\n\n\n\n\nTake the figure from the missingness part to better understand what we have found here.\n\nEstimates for all methods\n\n\n\nMean\nDiff\n\n\n\n\nCompleters, Arm 1\n-10.17\n\n\n\nCompleters, Arm 2\n-13.10\n-2.93\n\n\nMMRM, Arm 1\n-9.73\n\n\n\nMMRM, Arm 2\n-12.62\n-2.89\n\n\nLOCF, Arm 1\n-8.20\n\n\n\nLOCF, Arm 2\n-11.24\n-3.03\n\n\nJ2R , Arm 1\n-9.66\n\n\n\nJ2R , Arm 2\n-11.87\n-2.21\n\n\nCIR , Arm 1\n-9.65\n\n\n\nCIR , Arm 2\n-12.26\n-2.61\n\n\n\n\n\n\n\nNow, you can first of all repeat the analysis on the all2 data set to see if you can manage it. Or you go directly to the next step and apply methods to the high2 data set.\nOne starting point for the high2 data set as the structure is a little bit different:\nFirst, fill in missing visits. This was not necessary in the all2 data set. This can be done with the expand_locf function of the rbmi package. Note, change is the outcome variable and not chgdrop as in all2\n\nhigh2 &lt;- high2 %&gt;% ungroup()\n\nhigh2_expand &lt;- expand_locf(\n  high2,\n  subject = levels(high2$subject),  \n  avisit = levels(high2$avisit),\n  vars = c(\"basval\",\"trt\",\"group\"),\n  group = c(\"subject\"),\n  order = c(\"subject\", \"avisit\")\n)\n\n## Exploring missing data\nvis_miss(high2_expand)\n\n\n\ngg_miss_var(high2_expand %&gt;% filter(group==\"Arm 1\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\ngg_miss_var(high2_expand %&gt;% filter(group==\"Arm 2\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\n\n\n\n\n\n trt avisit emmean    SE  df lower.CL upper.CL\n 1   Week 1  -1.91 0.595 127    -3.08   -0.731\n 2   Week 1  -1.97 0.550 127    -3.06   -0.885\n 1   Week 2  -4.08 0.756 126    -5.58   -2.585\n 2   Week 2  -4.47 0.702 127    -5.86   -3.080\n 1   Week 4  -5.85 0.764 127    -7.36   -4.336\n 2   Week 4  -6.99 0.706 127    -8.38   -5.591\n 1   Week 6  -7.09 0.749 127    -8.57   -5.607\n 2   Week 6  -8.51 0.692 127    -9.88   -7.138\n 1   Week 8  -6.96 0.811 127    -8.56   -5.352\n 2   Week 8  -8.67 0.750 127   -10.16   -7.191\n\nConfidence level used: 0.95 \n\n\n\n\n\n\n\n trt avisit emmean    SE  df lower.CL upper.CL\n 1   Week 1  -1.61 0.458 197    -2.52   -0.711\n 2   Week 1  -1.66 0.459 197    -2.56   -0.752\n 1   Week 2  -3.24 0.609 191    -4.44   -2.036\n 2   Week 2  -3.89 0.613 193    -5.10   -2.681\n 1   Week 4  -4.52 0.656 182    -5.81   -3.223\n 2   Week 4  -5.98 0.656 182    -7.27   -4.684\n 1   Week 6  -5.12 0.718 168    -6.53   -3.701\n 2   Week 6  -7.48 0.715 166    -8.89   -6.067\n 1   Week 8  -5.24 0.785 149    -6.79   -3.686\n 2   Week 8  -7.76 0.762 139    -9.26   -6.251\n\nConfidence level used: 0.95 \n\n\n\n\n\n\nhigh2_expand.locf &lt;- high2_expand %&gt;% filter(!is.na(change)) %&gt;%\n  dplyr::group_by(subject) %&gt;% \n  dplyr::mutate( drop=max(week) )\n\nhigh2_expand.locf&lt;-high2_expand.locf %&gt;% dplyr::filter(week==drop)\n\nancova &lt;- aov(change ~ basval + trt, data = high2_expand.locf)\nsummary(ancova)\n\n             Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nbasval        1    483   483.3   9.709 0.00211 **\ntrt           1    241   241.4   4.851 0.02880 * \nResiduals   197   9805    49.8                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nancova$coefficients\n\n(Intercept)      basval        trt2 \n  0.3536399  -0.2648315  -2.2086854 \n\n\nTable: Mean values for change from baseline of LOCF analysis\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Arm 1, N = 1001\n      Arm 2, N = 1001\n    \n  \n  \n    change\n-4.22 (6.38)\n-6.72 (7.90)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\n\n\n\n\n# Define the names of key variables in the data set\nset_mi&lt;-set_vars(\n  subjid = \"subject\",\n  visit = \"avisit\",\n  outcome = \"change\",\n  group = \"group\",\n  covariates = c(\"basval * avisit\", \"group * avisit\")\n)\n\nvars_an&lt;-set_mi\nvars_an$covariates &lt;- \"basval\"\n\n# Define the imputation strategy for each subject with at least one missing observation\ndat_ice &lt;- high2_expand %&gt;% \n  arrange(subject, avisit) %&gt;% \n  filter(is.na(change)) %&gt;% \n  group_by(subject) %&gt;% \n  slice(1) %&gt;%\n  ungroup() %&gt;% \n  select(subject, avisit) %&gt;% \n  mutate(strategy = \"JR\")\n\n# Define the imputation method\nmethod &lt;- method_bayes(\n  burn_in = 200,\n  burn_between = 5,\n  n_samples = 100,\n  seed = 072407\n)\n\ndraw_high2_expand&lt;-draws(data=high2_expand, data_ice = dat_ice, vars=set_mi, method=method, ncores = 1, quiet = FALSE)\n\nimputeObj &lt;- rbmi::impute(\n  draw_high2_expand,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\")\n)\n\nimputed_high2_expand &lt;- extract_imputed_dfs(imputeObj)\n\n\nanaObj &lt;- analyse(\n  imputeObj,\n  vars = vars_an\n)\n\nTable: Estimates from jump to reference J2R imputation\n\npoolObj &lt;- pool(anaObj)\nas.data.frame(poolObj)\n\n        parameter         est        se       lci        uci         pval\n1      trt_Week 1 -0.04272539 0.6513099 -1.327240  1.2417894 9.477641e-01\n2  lsm_ref_Week 1 -1.64363730 0.4593710 -2.549610 -0.7376649 4.367614e-04\n3  lsm_alt_Week 1 -1.68636270 0.4593710 -2.592335 -0.7803903 3.118171e-04\n4      trt_Week 2 -0.56992013 0.8733074 -2.293096  1.1532554 5.148426e-01\n5  lsm_ref_Week 2 -3.31268012 0.6131345 -4.522404 -2.1029566 2.023442e-07\n6  lsm_alt_Week 2 -3.88260025 0.6200592 -5.106212 -2.6589881 2.772190e-09\n7      trt_Week 4 -1.24725634 0.9408037 -3.104301  0.6097887 1.866906e-01\n8  lsm_ref_Week 4 -4.55155161 0.6629053 -5.860032 -3.2430717 1.152780e-10\n9  lsm_alt_Week 4 -5.79880795 0.6663404 -7.114195 -4.4834207 2.753285e-15\n10     trt_Week 6 -1.70672432 1.0335987 -3.747568  0.3341192 1.005981e-01\n11 lsm_ref_Week 6 -5.19235287 0.7271162 -6.627972 -3.7567339 2.786779e-11\n12 lsm_alt_Week 6 -6.89907719 0.7562247 -8.393431 -5.4047230 4.832113e-16\n13     trt_Week 8 -1.72142767 1.1185316 -3.931215  0.4883593 1.258714e-01\n14 lsm_ref_Week 8 -5.30861260 0.8134583 -6.916855 -3.7003698 1.147909e-09\n15 lsm_alt_Week 8 -7.03004027 0.8171570 -8.645779 -5.4143020 1.519834e-14\n\n\n\n\n\n\ndat_ice_CR &lt;- dat_ice %&gt;% \n  mutate(strategy = ifelse(strategy == \"JR\", \"CR\", strategy))\n\nimputeObj_CR &lt;- rbmi::impute(\n  draw_high2_expand,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\"),\n  update_strategy = dat_ice_CR\n)\n\nanaObj_CR &lt;- analyse(\n  imputeObj_CR,\n  vars = vars_an\n)\n\nTable: Estimates from copy increments in reference CR imputation\n\npoolObj_CR &lt;- pool(anaObj_CR)\nas.data.frame(poolObj_CR)\n\n        parameter         est        se       lci        uci         pval\n1      trt_Week 1 -0.04272539 0.6513099 -1.327240  1.2417894 9.477641e-01\n2  lsm_ref_Week 1 -1.64363730 0.4593710 -2.549610 -0.7376649 4.367614e-04\n3  lsm_alt_Week 1 -1.68636270 0.4593710 -2.592335 -0.7803903 3.118171e-04\n4      trt_Week 2 -0.56759918 0.8689359 -2.282001  1.1468026 5.144382e-01\n5  lsm_ref_Week 2 -3.29268009 0.6124023 -4.500929 -2.0844308 2.286124e-07\n6  lsm_alt_Week 2 -3.86027926 0.6116150 -5.066951 -2.6536076 2.006222e-09\n7      trt_Week 4 -1.25504934 0.9383983 -3.107106  0.5970075 1.828184e-01\n8  lsm_ref_Week 4 -4.53971218 0.6596020 -5.841448 -3.2379761 9.920190e-11\n9  lsm_alt_Week 4 -5.79476153 0.6613572 -7.100023 -4.4895005 1.620378e-15\n10     trt_Week 6 -1.84350067 1.0284066 -3.874288  0.1872865 7.490327e-02\n11 lsm_ref_Week 6 -5.19290296 0.7322118 -6.639082 -3.7467244 4.162868e-11\n12 lsm_alt_Week 6 -7.03640363 0.7325057 -8.483175 -5.5896322 1.716342e-17\n13     trt_Week 8 -1.89556177 1.1140972 -4.097188  0.3060646 9.096551e-02\n14 lsm_ref_Week 8 -5.34060252 0.8285363 -6.980116 -3.7010886 2.174328e-09\n15 lsm_alt_Week 8 -7.23616429 0.7883131 -8.794109 -5.6782193 3.806874e-16\n\n\n\n\n\nUse the additional argument update_strategies in the impute function.\n\ndat_ice_CIR &lt;- dat_ice %&gt;% \n  mutate(strategy = ifelse(strategy == \"JR\", \"CIR\", strategy))\n\nimputeObj_CIR &lt;- rbmi::impute(\n  draw_high2_expand,\n  references = c(\"Arm 1\" = \"Arm 1\", \"Arm 2\" = \"Arm 1\"),\n  update_strategy = dat_ice_CIR\n)\n\nanaObj_CIR &lt;- analyse(\n  imputeObj_CIR,\n  vars = vars_an\n)\n\nTable: Estimates from copy increments in reference CIR imputation\n\npoolObj_CIR &lt;- pool(anaObj_CIR)\nas.data.frame(poolObj_CIR)\n\n        parameter         est        se       lci         uci         pval\n1      trt_Week 1 -0.04272539 0.6513099 -1.327240  1.24178939 9.477641e-01\n2  lsm_ref_Week 1 -1.64363730 0.4593710 -2.549610 -0.73766488 4.367614e-04\n3  lsm_alt_Week 1 -1.68636270 0.4593710 -2.592335 -0.78039028 3.118171e-04\n4      trt_Week 2 -0.59370495 0.8652051 -2.300688  1.11327818 4.934487e-01\n5  lsm_ref_Week 2 -3.31016751 0.6107925 -4.515231 -2.10510358 1.858699e-07\n6  lsm_alt_Week 2 -3.90387245 0.6131567 -5.113675 -2.69407009 1.525078e-09\n7      trt_Week 4 -1.30521947 0.9399264 -3.160483  0.55004438 1.667362e-01\n8  lsm_ref_Week 4 -4.54415889 0.6612575 -5.849315 -3.23900302 1.094861e-10\n9  lsm_alt_Week 4 -5.84937837 0.6646077 -7.161268 -4.53748825 1.440661e-15\n10     trt_Week 6 -1.95953532 1.0158040 -3.965042  0.04597113 5.542434e-02\n11 lsm_ref_Week 6 -5.17405265 0.7257053 -6.607187 -3.74091840 3.216919e-11\n12 lsm_alt_Week 6 -7.13358797 0.7274177 -8.570175 -5.69700135 4.541636e-18\n13     trt_Week 8 -2.06003358 1.1160556 -4.265940  0.14587245 6.696562e-02\n14 lsm_ref_Week 8 -5.30927178 0.8206544 -6.933036 -3.68550713 1.886190e-09\n15 lsm_alt_Week 8 -7.36930536 0.7879631 -8.926768 -5.81184259 1.535541e-16\n\n\n\n\n\nTake the figure from the missingness part to better understand what we have found here.\n\nEstimates for all methods\n\n\nGroup\nMean\nDiff\n\n\n\n\nCompleters, Arm 1\n-6.96\n\n\n\nCompleters, Arm 2\n-8.67\n-1.71\n\n\nMMRM, Arm 1\n-5.24\n\n\n\nMMRM, Arm 2\n-7.76\n-2.52\n\n\nLOCF, Arm 1\n-4.22\n\n\n\nLOCF, Arm 2\n-6.72\n-2.50\n\n\nJ2R, Arm 1\n-5.31\n\n\n\nJ2R, Arm 2\n-7.03\n-1.72\n\n\nCR, Arm 1\n-5.34\n\n\n\nCR, Arm 2\n-7.24\n-1.90\n\n\nCIR, Arm 1\n-5.31\n\n\n\nCIR, Arm 2\n-7.37\n-2.06"
  },
  {
    "objectID": "s2_inference_continuous.html",
    "href": "s2_inference_continuous.html",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "This section will focus on the application of Mixed Model with Repeated Measures (MMRMs). Our main focus will be the modeling of the means of the data. MMRMs are generalizations of standard linear models in the way that data is allowed to be correlated between subsequent measurements from the same subject and exhibit non-constant variability. A nice summary can be found in the user manual for the MIXED Procedure SAS, or the vignette for the mmrm package (Sabanes Bove et al. 2024).\nThe primary assumptions for MMRMs are:\n\nThe data are normally distributed\nThe means (expected values) of the data are linear in terms of a certain set of parameters.\nThe variances and covariances of the data are in terms of a different set of parameters, and they exhibit a structure matching one of those outlined in the former chapter.\n\nThe mixed linear model can be described via the following formula\n\\[\ny_i = X_i\\beta\\,+\\,Z_i\\gamma_i\\,+\\,\\varepsilon_i\\,,\\, i = 1,\\ldots,N\n\\]\nwhere \\(y\\) is the vector of responses (observed data, dependent variable), \\(\\beta\\) is an unknown vector of fixed effects with known design matrix \\(X\\), \\(\\gamma\\) is an unknown vector of random effects with known design matrix \\(Z\\), and \\(\\varepsilon\\) is an unknown random error vector. Furthermore \\(N\\) denotes the total number of subjects in our analysis. For the sake of readability, we will omit the subject index and simplify the above formula to\n\\[\ny = X\\beta\\,+\\,Z\\gamma\\,+\\,\\varepsilon\\,.\n\\]\nWe will further assume that \\(\\gamma\\) and \\(\\varepsilon\\) are uncorrelated Gaussian random variables with expectation \\(0\\) and variances \\(G\\) and \\(R\\), respectively. Then the variance-covariance matrix of \\(y\\) is given by\n\\[\n\\text{Var}(y) := V = ZGZ' + R\\,.\n\\] In this case \\(ZGZ'\\) comprises the random effects component, and \\(R\\) is the within-subject component.\nIn this workshop we will focus on the case where only the within-subject component is accounted for, via modeling of the \\(R\\) matrix. The random effects component \\(Z\\gamma\\) will be omitted. In this case we will have \\(\\text{Var}(y) = V = R\\), resulting in a model given by\n\\[\ny = X\\beta\\,+\\,\\varepsilon\\,.\n\\]\n\n\nThe key difference between MMRM (Mixed Model for Repeated Measures) and the more general Mixed Model lies in how they handle repeated measurements and the assumptions they make about the data.\nMMRM is specifically designed for longitudinal or repeated measures data, such as clinical trials where the same subjects are measured multiple times over different time points. It allows for flexible covariance structures that model the within-subject correlation over time, making it especially useful for analyzing treatment effects that change over time.\nIn contrast, the general mixed model can be used for a wider range of data, including nested or hierarchical structures, and is not limited to longitudinal data. While mixed models also handle repeated measures, they are often applied in contexts where the focus is on individual-level variability through random effects (e.g., random intercepts and slopes), whereas MMRM focuses on the treatment effect over time without including random slopes or intercepts.\nWhen it comes to handling missing data, MMRM assumes the data is missing at random (MAR) and can produce unbiased estimates without the need for data imputation. This makes it particularly advantageous in clinical trials where patients may drop out over time. Mixed models also handle missing data but are not specifically tailored for time-dependent missingness.\nIn terms of covariance structure, MMRM is more flexible and allows modeling of timepoint correlations using an unstructured covariance matrix, providing a more detailed understanding of how outcomes change over time. In comparison, general mixed models are typically less focused on modeling timepoint-specific covariance and more focused on individual-level random effects.\nLastly, MMRM mainly deals with fixed effects, especially treatment and time, while handling within-subject correlations via covariance structures. It typically does not include random intercepts or slopes, unlike general mixed models, which often include both fixed and random effects to account for individual-level variability and differences in baseline or rates of change. This makes MMRM simpler and more focused on treatment effects over time, whereas general mixed models provide more flexibility in modeling variability between individuals.\nIn summary, MMRM is a specialized form of mixed model used primarily for repeated measures in longitudinal data, particularly in clinical settings, with a focus on time-varying treatment effects and handling missing data effectively. General mixed models are more versatile and used in broader contexts, often including random effects to account for variability between subjects or nested data structures.\n\n\n\nIn the following sections we will use the package mmrm (Sabanes Bove et al. 2024). You can start and familiarise yourself with the main function mmrm() using the command\nTwo inputs are strictly required to get mmrm() to work:\n\nA model formula\nThe dataset, containing the response, as well as all fixed effects and variables in the covariance matrix.\n\nExercise: Fit a model fit_cat_time using the dataset all2, with change as dependent variable, baseline value, visit, baseline by visit interaction and treatment by visit interaction as fixed effects and an unstructured covariance matrix for visits within each subject.\n\nHow do different choices for covariance matrices change the results? What is the difference on the estimation procedure?\nYou can obtain a summary of the fit results via summary(fit_cat_time). How do you interpret the fit summary?\nLook at the structure of the fit summary and try to extract the estimate of the \\(R\\) matrix.\nHow do other choices of covariance structures influence the estimation?\n\nSolution\n\nfit_cat_time_un &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_toep &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + toep(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_toeph &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + toeph(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_sp &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + sp_exp(week | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\n## https://cran.r-project.org/web/packages/mmrm/mmrm.pdf\n# summary(fit_cat_time_un)\n# summary(fit_cat_time_toep)\n# summary(fit_cat_time_toeph)\n# summary(fit_cat_time_sp)\n\n## Covariance Matrix\nfit_cat_time_un$cov\n\n         Week 2   Week 4   Week 8\nWeek 2 20.61191 15.30474 12.27830\nWeek 4 15.30474 21.35801 17.66644\nWeek 8 12.27830 17.66644 27.61440\n\n# Extract AIC and BIC values for the models\naic_values &lt;- c(\n  AIC(fit_cat_time_un),\n  AIC(fit_cat_time_toep),\n  AIC(fit_cat_time_toeph),\n  AIC(fit_cat_time_sp)\n)\n\nbic_values &lt;- c(\n  BIC(fit_cat_time_un),\n  BIC(fit_cat_time_toep),\n  BIC(fit_cat_time_toeph),\n  BIC(fit_cat_time_sp)\n)\n\n# Extract fixed effect coefficients from each model\ncoef_un &lt;- summary(fit_cat_time_un)$coefficients\ncoef_toep &lt;- summary(fit_cat_time_toep)$coefficients\ncoef_toeph &lt;- summary(fit_cat_time_toeph)$coefficients\ncoef_sp &lt;- summary(fit_cat_time_sp)$coefficients\n\n# Combine AIC, BIC, and coefficients into a summary table\ncomparison_table &lt;- data.frame(\n  Model = c(\"Unstructured\", \"Toeplitz\", \"Heterogeneous Toeplitz\", \"Spatial Power\"),\n  AIC = aic_values,\n  BIC = bic_values\n)\n\n# Display the summary of goodness of fit (AIC and BIC)\ncomparison_table %&gt;%\n  kable(caption = \"Goodness of Fit Comparison (AIC, BIC)\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nGoodness of Fit Comparison (AIC, BIC)\n\n\nModel\nAIC\nBIC\n\n\n\n\nUnstructured\n822.4105\n833.8826\n\n\nToeplitz\n818.5753\n824.3114\n\n\nHeterogeneous Toeplitz\n820.4111\n829.9712\n\n\nSpatial Power\n818.5262\n822.3503\n\n\n\n\n\n\n# Extract the Estimate (fixed effect coefficients) from each model\nestimates_un &lt;- summary(fit_cat_time_un)$coefficients[, \"Estimate\"]\nestimates_toep &lt;- summary(fit_cat_time_toep)$coefficients[, \"Estimate\"]\nestimates_toeph &lt;- summary(fit_cat_time_toeph)$coefficients[, \"Estimate\"]\n\n# Combine the estimates into a data frame for comparison\nestimate_comparison &lt;- data.frame(\n  Term = names(estimates_un),  # Assuming all models have the same terms\n  Unstructured = estimates_un,\n  Toeplitz = estimates_toep,\n  Heterogeneous_Toeplitz = estimates_toeph\n)\n\n# Display the table of estimates\nestimate_comparison %&gt;%\n  kable(caption = \"Comparison of Estimates for the Three Models\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nComparison of Estimates for the Three Models\n\n\n\nTerm\nUnstructured\nToeplitz\nHeterogeneous_Toeplitz\n\n\n\n\n(Intercept)\n(Intercept)\n1.9845205\n1.9845205\n1.9845205\n\n\nbasval\nbasval\n-0.3123495\n-0.3123495\n-0.3123495\n\n\navisitWeek 4\navisitWeek 4\n-0.9086176\n-0.9086176\n-0.9086176\n\n\navisitWeek 8\navisitWeek 8\n-10.5863002\n-10.5863002\n-10.5863002\n\n\ngroupArm 2\ngroupArm 2\n-1.1899278\n-1.1899278\n-1.1899278\n\n\nbasval:avisitWeek 4\nbasval:avisitWeek 4\n-0.0854234\n-0.0854234\n-0.0854234\n\n\nbasval:avisitWeek 8\nbasval:avisitWeek 8\n0.2477929\n0.2477929\n0.2477929\n\n\navisitWeek 4:groupArm 2\navisitWeek 4:groupArm 2\n-0.8010032\n-0.8010032\n-0.8010032\n\n\navisitWeek 8:groupArm 2\navisitWeek 8:groupArm 2\n-2.2010594\n-2.2010594\n-2.2010594\n\n\n\n\n\n\ntab_model(fit_cat_time_un,fit_cat_time_sp)\n\nWarning: The `full` argument of `model.frame.mmrm_tmb()` is deprecated as of mmrm 0.3.\nℹ The deprecated feature was likely used in the mmrm package.\n  Please report the issue at &lt;https://github.com/openpharma/mmrm/issues&gt;.\n\n\n\n\n\n \nchange\nchange\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n1.98\n-4.60 – 8.57\n0.547\n1.98\n-5.07 – 9.04\n0.577\n\n\nbasval\n-0.31\n-0.63 – 0.01\n0.055\n-0.31\n-0.65 – 0.03\n0.073\n\n\navisit [Week 4]\n-0.91\n-5.73 – 3.92\n0.707\n-0.91\n-5.38 – 3.57\n0.687\n\n\navisit [Week 8]\n-10.59\n-17.55 – -3.63\n0.004\n-10.59\n-17.57 – -3.60\n0.003\n\n\ngroup [Arm 2]\n-1.19\n-3.75 – 1.37\n0.355\n-1.19\n-3.93 – 1.55\n0.390\n\n\nbasval × avisit [Week 4]\n-0.09\n-0.32 – 0.15\n0.467\n-0.09\n-0.30 – 0.13\n0.437\n\n\nbasval × avisit [Week 8]\n0.25\n-0.09 – 0.59\n0.147\n0.25\n-0.09 – 0.59\n0.151\n\n\navisit [Week 4] × group[Arm 2]\n-0.80\n-2.68 – 1.07\n0.395\n-0.80\n-2.54 – 0.94\n0.362\n\n\navisit [Week 8] × group[Arm 2]\n-2.20\n-4.91 – 0.50\n0.108\n-2.20\n-4.91 – 0.51\n0.111\n\n\n\nN\n50 subject\n50 subject\n\n\n\n\n\n\n\n\nStructure\nDescription\n\n\n\n\nad\nAnte-dependence\n\n\nadh\nHeterogeneous ante-dependence\n\n\nar1\nFirst-order auto-regressive\n\n\nar1h\nHeterogeneous first-order auto-regressive\n\n\ncs\nCompound symmetry\n\n\ncsh\nHeterogeneous compound symmetry\n\n\ntoep\nToeplitz\n\n\ntoeph\nHeterogeneous Toeplitz\n\n\nus\nUnstructured\n\n\n\n\n\n\nTime as continuous effect -&gt; single df for time and trt-by-time interaction\nModeling: - Need avisit for structure of covariance matrix - Implicit assumption is for the covariance between values for two timepoints to be equal, regardless of the specific timing\n\nfit_cont_time &lt;- mmrm::mmrm(\n  formula = change ~ basval*week + trt*week + us(avisit | subject),\n  ## Treat time as continuously\n  weights = all2$week,\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nsummary (fit_cont_time)\n\nmmrm fit\n\nFormula:     change ~ basval * week + trt * week + us(avisit | subject)\nData:        all2 (used 150 observations from 50 subjects with maximum 3 \ntimepoints)\nWeights:     all2$week\nCovariance:  unstructured (6 variance parameters)\nMethod:      Kenward-Roger\nVcov Method: Kenward-Roger\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n   838.0    849.5   -413.0    826.0 \n\nCoefficients: \n            Estimate Std. Error       df t value Pr(&gt;|t|)   \n(Intercept)  6.83666    3.82960 47.00000   1.785  0.08068 . \nbasval      -0.47981    0.18600 47.00000  -2.580  0.01308 * \nweek        -1.94296    0.57420 47.00000  -3.384  0.00145 **\ntrt2        -0.49024    1.48826 47.00000  -0.329  0.74331   \nbasval:week  0.05275    0.02789 47.00000   1.892  0.06472 . \nweek:trt2   -0.36226    0.22315 47.00000  -1.623  0.11119   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        Week 2   Week 4   Week 8\nWeek 2 41.3658  42.8600  49.0752\nWeek 4 42.8600  86.6690 100.0141\nWeek 8 49.0752 100.0141 220.9000\n\n\nCan also apply non-linear transformations of time variable, in case the anticipated effect is not necessarily linear in time:\n\nall2$timesq &lt;- all2$week^2\n\nfit_cont_timesq &lt;- mmrm::mmrm(\n  formula = change ~ basval*timesq + trt*timesq + us(avisit | subject),\n  weights = all2$week,\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nsummary(fit_cont_timesq)\n\nmmrm fit\n\nFormula:     change ~ basval * timesq + trt * timesq + us(avisit | subject)\nData:        all2 (used 150 observations from 50 subjects with maximum 3 \ntimepoints)\nWeights:     all2$week\nCovariance:  unstructured (6 variance parameters)\nMethod:      Kenward-Roger\nVcov Method: Kenward-Roger\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n   861.8    873.3   -424.9    849.8 \n\nCoefficients: \n               Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)    3.298095   3.300323 47.000000   0.999  0.32275    \nbasval        -0.396751   0.160290 47.000000  -2.475  0.01698 *  \ntimesq        -0.191395   0.053074 47.000000  -3.606  0.00075 ***\ntrt2          -1.224631   1.282574 47.000000  -0.955  0.34455    \nbasval:timesq  0.005800   0.002578 47.000000   2.250  0.02916 *  \ntimesq:trt2   -0.032220   0.020626 47.000000  -1.562  0.12497    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        Week 2   Week 4   Week 8\nWeek 2 42.2220  41.1223  47.8394\nWeek 4 41.1223  90.1270 102.6988\nWeek 8 47.8394 102.6988 222.5403\n\n\n\n\n\nLS Means are means of the dependent variable adjusted for covariates in the statistical model. We can obtain LS Means estimates and contrasts allowing for a treatment comparison using the emmeans package.\nExample: Calculate the observed (raw) means of changes along with number of patients by treatment group from the dataset all2 overall and by visit. Then take the model fit_cat_time and derive the respective LS Means from the model. What do you observe?\n\n# Raw means\nall2 %&gt;% \n  dplyr::group_by(group) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n(),\n    Mean = mean(change),\n    .groups = \"drop\"\n  )\n\n# A tibble: 2 × 3\n  group     N  Mean\n  &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1 Arm 1    75 -6.96\n2 Arm 2    75 -9.03\n\nall2 %&gt;% \n  dplyr::group_by(group, avisit) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n(),\n    Mean = mean(change),\n    .groups = \"drop\"\n  )\n\n# A tibble: 6 × 4\n  group avisit     N   Mean\n  &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 Arm 1 Week 2    25  -4.2 \n2 Arm 1 Week 4    25  -6.8 \n3 Arm 1 Week 8    25  -9.88\n4 Arm 2 Week 2    25  -5.24\n5 Arm 2 Week 4    25  -8.6 \n6 Arm 2 Week 8    25 -13.2 \n\n\nThe respective LS Means from the model with time as a fixed factor yields the following estimates:\n\n\n'emmGrid' object with variables:\n    basval = 19.56\n    avisit = Week 2, Week 4, Week 8\n    trt = 1, 2\n\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n trt emmean    SE df lower.CL upper.CL\n 1    -6.90 0.836 47    -8.58    -5.22\n 2    -9.09 0.836 47   -10.77    -7.41\n\nResults are averaged over the levels of: avisit \nConfidence level used: 0.95 \n\n\n trt avisit emmean    SE df lower.CL upper.CL\n 1   Week 2  -4.13 0.899 47    -5.93    -2.32\n 2   Week 2  -5.31 0.899 47    -7.12    -3.51\n 1   Week 4  -6.70 0.916 47    -8.55    -4.86\n 2   Week 4  -8.70 0.916 47   -10.54    -6.85\n 1   Week 8  -9.86 1.033 47   -11.94    -7.79\n 2   Week 8 -13.26 1.033 47   -15.33   -11.18\n\nConfidence level used: 0.95 \n\n\n\n\nIn the example above we have used the standard option for the weights in the calculation of LS Means. We will delve deeper into the following two options and will try to understand the difference:\n\nweights = \"equal\": Each stratum induced by covariate levels is assigned the same weight in the calculation of the LS Means. This is the default option.\nweights = \"proportional\": Each stratum induced by covariate levels is assigned a weight according to their observed proportion in the calculation of the LS Mean. This option gives each stratum a weight corresponding to its size. Estimates using this option are reflective of the balance of covariates in the data.\n\nExercise: Based on the fit_cat_time model, compare the LS Means for the change in the response variable by treatment overall and treatment by visit interaction using the different options for weight. Compare the results for the two LS Means options to the observed means and to one another.\nDiscuss the following points:\n\nWhy is there no difference between LS Means estimates for the overall treatment effect and the treatment by visit interaction? (Hint: Create a frequency table)\n\nSolution: Balanced Data: If the data is perfectly balanced (e.g., equal sample sizes across visits, no missing data), then the LS Means estimates of the treatment effect at each visit might aggregate to the same result as the overall treatment effect. The overall treatment effect is simply an average of the effects at each visit.\n\n## LS Means estimates for the overall treatment effect\nemmeans(fit_cat_time, ~trt)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n trt emmean    SE df lower.CL upper.CL\n 1    -6.90 0.836 47    -8.58    -5.22\n 2    -9.09 0.836 47   -10.77    -7.41\n\nResults are averaged over the levels of: avisit \nConfidence level used: 0.95 \n\nemmeans(fit_cat_time, ~trt*avisit)\n\n trt avisit emmean    SE df lower.CL upper.CL\n 1   Week 2  -4.13 0.899 47    -5.93    -2.32\n 2   Week 2  -5.31 0.899 47    -7.12    -3.51\n 1   Week 4  -6.70 0.916 47    -8.55    -4.86\n 2   Week 4  -8.70 0.916 47   -10.54    -6.85\n 1   Week 8  -9.86 1.033 47   -11.94    -7.79\n 2   Week 8 -13.26 1.033 47   -15.33   -11.18\n\nConfidence level used: 0.95 \n\n(-4.13-6.70-9.86)/3\n\n[1] -6.896667\n\n(-5.31-8.70-13.26)/3\n\n[1] -9.09\n\n # trt emmean    SE df lower.CL upper.CL\n # 1    -6.90 0.836 47    -8.58    -5.22\n # 2    -9.09 0.836 47   -10.77    -7.41\n \n### Work with code chunks to find the solution to the exercises\nall2 %&gt;% \n  dplyr::group_by(group,avisit) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n(),\n    Mean = mean(change),\n    .groups = \"drop\"\n  )\n\n# A tibble: 6 × 4\n  group avisit     N   Mean\n  &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 Arm 1 Week 2    25  -4.2 \n2 Arm 1 Week 4    25  -6.8 \n3 Arm 1 Week 8    25  -9.88\n4 Arm 2 Week 2    25  -5.24\n5 Arm 2 Week 4    25  -8.6 \n6 Arm 2 Week 8    25 -13.2 \n\nemmeans(fit_cat_time, ~trt, weights = \"equal\")\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n trt emmean    SE df lower.CL upper.CL\n 1    -6.90 0.836 47    -8.58    -5.22\n 2    -9.09 0.836 47   -10.77    -7.41\n\nResults are averaged over the levels of: avisit \nConfidence level used: 0.95 \n\nemmeans(fit_cat_time, ~trt, weights = \"proportional\")\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n trt emmean    SE df lower.CL upper.CL\n 1    -6.90 0.836 47    -8.58    -5.22\n 2    -9.09 0.836 47   -10.77    -7.41\n\nResults are averaged over the levels of: avisit \nConfidence level used: 0.95 \n\n\nNow update the fit_cat_time model to fit_cat_time2, and include the covariate gender. Estimate the same LS Means for the change in the response variable by treatment (overall) and treatment by visit interaction.\n\n\n'emmGrid' object with variables:\n    basval = 19.56\n    avisit = Week 2, Week 4, Week 8\n    trt = 1, 2\n    gender = F, M\n\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.36 0.869 45.7    -6.11    -2.61\n 2   Week 2  -4.71 0.923 46.8    -6.57    -2.85\n 1   Week 4  -6.94 0.920 46.4    -8.79    -5.09\n 2   Week 4  -8.09 0.972 48.1   -10.04    -6.13\n 1   Week 8 -10.10 1.063 45.5   -12.24    -7.96\n 2   Week 8 -12.65 1.108 48.2   -14.88   -10.42\n\nResults are averaged over the levels of: gender \nConfidence level used: 0.95 \n\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.55 0.890 46.2    -6.34    -2.75\n 2   Week 2  -4.89 0.890 46.2    -6.69    -3.10\n 1   Week 4  -7.13 0.941 47.1    -9.02    -5.23\n 2   Week 4  -8.27 0.941 47.1   -10.17    -6.38\n 1   Week 8 -10.29 1.081 46.6   -12.46    -8.11\n 2   Week 8 -12.83 1.081 46.6   -15.01   -10.66\n\nResults are averaged over the levels of: gender \nConfidence level used: 0.95 \n\n\n\nWhy is there a difference now between results from the different LS Means options? (Hint: another frequency table can help)\n\nSolution: In-Balanced Data by Gender\n\nall2 %&gt;% \n  dplyr::group_by(group,avisit,gender) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n(),\n    Mean = mean(change),\n    .groups = \"drop\"\n  )\n\n# A tibble: 12 × 5\n   group avisit gender     N    Mean\n   &lt;fct&gt; &lt;fct&gt;  &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;\n 1 Arm 1 Week 2 F         10  -4.7  \n 2 Arm 1 Week 2 M         15  -3.87 \n 3 Arm 1 Week 4 F         10  -6.9  \n 4 Arm 1 Week 4 M         15  -6.73 \n 5 Arm 1 Week 8 F         10  -8.9  \n 6 Arm 1 Week 8 M         15 -10.5  \n 7 Arm 2 Week 2 F         19  -6.79 \n 8 Arm 2 Week 2 M          6  -0.333\n 9 Arm 2 Week 4 F         19  -9.53 \n10 Arm 2 Week 4 M          6  -5.67 \n11 Arm 2 Week 8 F         19 -13.9  \n12 Arm 2 Week 8 M          6 -11    \n\n\n\nWhat effect could missing data have on the estimation, even in the case of fit_cat_time? I.e. what would happen if this data was not complete but subject to missingness, with the degree of missing data increasing over time and being disproportionate between treatment arms?\nImbalanced Representation Over Time: If the degree of missingness increases over time, estimates of later visits will be based on fewer patients, reducing the reliability of treatment effects at those time points. The treatment-by-visit interaction estimates could become unstable.\nMissing Not at Random (MNAR): If missingness is related to unobserved outcomes (e.g., patients drop out because of worsening symptoms in one treatment group), this could bias the estimation. In particular, the treatment effect estimates could be skewed, either exaggerating or underestimating the true treatment difference.\n\n\n\n\nMost of the times, the quantity we are truly interested in when reading out a study, is the contrast between treatment arms. This contrast can be built either based on LS Means at some landmark time point, or as a longitudinal (linear) combination of LS Means from multiple time points.\nWe can use the pairs() or the contrast() functions, where the latter provides more flexibility for the calculation of linear combinations from multiple timepoints.\n\nlsmns &lt;- emmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\")\npairs(lsmns, reverse = TRUE, adjust = NULL)\n\n contrast                  estimate    SE   df t.ratio p.value\n trt2 Week 2 - trt1 Week 2    -1.19 1.273 47.0  -0.935  0.3546\n trt1 Week 4 - trt1 Week 2    -2.58 0.659 47.0  -3.917  0.0003\n trt1 Week 4 - trt2 Week 2    -1.39 1.284 61.3  -1.082  0.2835\n trt2 Week 4 - trt1 Week 2    -4.57 1.284 61.3  -3.559  0.0007\n trt2 Week 4 - trt2 Week 2    -3.38 0.659 47.0  -5.133  &lt;.0001\n trt2 Week 4 - trt1 Week 4    -1.99 1.296 47.0  -1.536  0.1313\n trt1 Week 8 - trt1 Week 2    -5.74 0.950 47.0  -6.043  &lt;.0001\n trt1 Week 8 - trt2 Week 2    -4.55 1.370 73.3  -3.321  0.0014\n trt1 Week 8 - trt1 Week 4    -3.16 0.716 47.0  -4.416  0.0001\n trt1 Week 8 - trt2 Week 4    -1.17 1.381 61.1  -0.846  0.4007\n trt2 Week 8 - trt1 Week 2    -9.13 1.370 73.3  -6.664  &lt;.0001\n trt2 Week 8 - trt2 Week 2    -7.94 0.950 47.0  -8.361  &lt;.0001\n trt2 Week 8 - trt1 Week 4    -6.55 1.381 61.1  -4.742  &lt;.0001\n trt2 Week 8 - trt2 Week 4    -4.56 0.716 47.0  -6.373  &lt;.0001\n trt2 Week 8 - trt1 Week 8    -3.39 1.462 47.0  -2.319  0.0248\n\n### This is the same as the following\nprs &lt;- contrast(lsmns, method = \"revpairwise\", adjust = NULL)\nprs &lt;- contrast(lsmns, method = \"revpairwise\", adjust = \"tukey\")\n\n\n\n\n\n\n\n\nAdjustment Method\nDescription\n\n\n\n\n“tukey”\nUses the Studentized range distribution with the number of means in the family. (Available for two-sided cases only.)\n\n\n“scheffe”\nComputes p-values from the F distribution, according to the Scheffe critical value of rF(α; r, d), where d is the error degrees of freedom and r is the rank of the set of linear functions under consideration. By default, r is computed from object@linfct for each group. If there are k means involved, r = k - 1 for a full set of contrasts, and r = k for the means themselves. (Available for two-sided cases only.)\n\n\n“sidak”\nMakes adjustments as if the estimates were independent (a conservative adjustment in many cases).\n\n\n“bonferroni”\nMultiplies p-values or divides significance levels by the number of estimates. This is a conservative adjustment.\n\n\n“dunnettx”\nUses an ad hoc approximation to the Dunnett distribution for a family of estimates with pairwise correlations of 0.5 (common when comparing treatments with a control with equal sample sizes). This method is faster than “mvt” and the approximation improves with the number of estimates. (Available for two-sided cases only.)\n\n\n“mvt”\nUses the multivariate t distribution to assess the probability or critical value for the maximum of k estimates. Produces the same p-values and intervals as the default methods in as.glht. Monte Carlo simulation is used, so results may vary unless the same random-number seed is used. Computation time increases with family size, making “tukey” or “dunnettx” more attractive alternatives for large families.\n\n\n“none”\nNo adjustments are made to the p-values.\n\n\n\nNote that both pairs() and contrast() provide multiple options for fine-tuning. We chose adjust = NULL in order to not perform any multiplicity adjustment (default method would have been the Tukey method). We also chose reverse = TRUE to reverse the order of comparisons performed by pairs(), as the default would have given us the contrast for Treatment 1 - Treatment 2. Consequently, we applied method = \"revpairwise\" in the contrast() function.\nWe can obtain the coefficients in the calculation of the contrasts via coef():\n\ncoef(prs)\n\n            trt avisit c.1 c.2 c.3 c.4 c.5 c.6 c.7 c.8 c.9 c.10 c.11 c.12 c.13\ntrt1 Week 2   1 Week 2  -1  -1   0  -1   0   0  -1   0   0    0   -1    0    0\ntrt2 Week 2   2 Week 2   1   0  -1   0  -1   0   0  -1   0    0    0   -1    0\ntrt1 Week 4   1 Week 4   0   1   1   0   0  -1   0   0  -1    0    0    0   -1\ntrt2 Week 4   2 Week 4   0   0   0   1   1   1   0   0   0   -1    0    0    0\ntrt1 Week 8   1 Week 8   0   0   0   0   0   0   1   1   1    1    0    0    0\ntrt2 Week 8   2 Week 8   0   0   0   0   0   0   0   0   0    0    1    1    1\n            c.14 c.15\ntrt1 Week 2    0    0\ntrt2 Week 2    0    0\ntrt1 Week 4    0    0\ntrt2 Week 4   -1    0\ntrt1 Week 8    0   -1\ntrt2 Week 8    1    1\n\n\nThe output above is probably more than we wanted. We are only interested in contrasts between Treatments 1 and 2 at the same time points. Here contrast() provides more flexibility. Instead of parsing a string with the name of a method to the method argument, we provide a named list of coefficients. These coefficients are identical with the onces we can see in the coefficient matrix above. We can use it as a guide.\n\ncontrast(\n  lsmns, \n  method = list(\n    \"Difference Trt 2 - Trt 1 at Week 4\" = c(0, 0, -1, 1, 0, 0),\n    \"Difference Trt 2 - Trt 1 at Week 8\" = c(0, 0, 0, 0, -1, 1)\n  ), \n  adjust = NULL)\n\n contrast                           estimate   SE df t.ratio p.value\n Difference Trt 2 - Trt 1 at Week 4    -1.99 1.30 47  -1.536  0.1313\n Difference Trt 2 - Trt 1 at Week 8    -3.39 1.46 47  -2.319  0.0248\n\n\nThis way of computing LS Means from our MMRM allows us to calculate all kinds of linear combinations of LS Means. Assume we were interested in the longitudinal mean of changes from baseline averaged over Weeks 2, 4 and 8. This would look like this:\n\ncontrast(\n  lsmns, \n  method = list(\n    \"Difference Trt 2 - Trt 1 Averaged over Weeks 2, 4 and 8\" = c(-1, 1, -1, 1, -1, 1)/3\n  ), \n  adjust = NULL)\n\n contrast                                                estimate   SE df\n Difference Trt 2 - Trt 1 Averaged over Weeks 2, 4 and 8    -2.19 1.18 47\n t.ratio p.value\n  -1.850  0.0705\n\n\n\n\n\n\nThe following section closely follows the content in Chapter 10 in (Fitzmaurice 2011).\nOur analysis should be concluded with a look into the fit diagnostics, more specifically, the residuals. Residuals are defined by the difference between the true responses and the fitted values from the model:\n\\[\nr := y - X\\hat\\beta\\,,\n\\]\nwhere \\(\\hat\\beta\\) are the estimated coefficients from our model. Residuals provide an estimate of the true vector of random errors\n\\[\n\\varepsilon = y - X\\beta\\,.\n\\]\nAs per our modeling assumptions, \\(\\varepsilon\\) should follow a normal distribution with mean zero. The mean of the residuals is zero and therefore identical with the mean of the error term. For the covariance of the residuals however, the variance-covariance matrix of \\(\\varepsilon\\) only serves us as an approximation (as suggested by (Fitzmaurice 2011) for all ‘practical applications’):\n\\[\nCov(r) \\approx Cov(\\varepsilon) = R\\,.\n\\]\nThis assumption has several implications on the residual diagnostics:\n\nThe variance is not necessarily constant. Plotting the fitted values versus the residuals might therefore lead to a non-constant range. An examination of the residual variance or autocorrelation among residuals is therefore not very meaningful.\nResiduals from analyses of longitudinal data can exhibit correlation with the covariates. Scatterplots of residuals versus selected covariates can therefore reveal systematic trends (which normally should not be the case).\n\nA transformation of residuals to achieve constant variance and zero correlation is therefore often useful. This transformation uses the so-called Cholesky decomposition of the variance-covariance matrix \\(R\\). Let \\(L\\) be a lower triangular matrix, such that\n\\[\nR = L\\,L'\\,,\n\\]\nthen the transformed residuals are given by\n\\[\nr^* =  L^{-1}(y - X\\beta)\\,.\n\\]\nIn the mmrm package, transformed residuals can be derived using the type = \"normalized\" option.\nExercise: Which visualisations can you think of that make sense to assess the goodness of fit here? Create a new tibble (or data.frame) containing the variables of importance and try plotting them in a meaningful way. Discuss the results within your group.\nSolution:\n\n\n\nresiduals(fit, type = “response”), Response or raw residuals - the difference between the observed and fitted or predicted value.\nresiduals(fit, type = “pearson”), Pearson residuals - the raw residuals scaled by the estimated standard deviation of the response.\nresiduals(fit, type = “normalized”), Normalized or scaled residuals - the raw residuals are ‘de-correlated’ based on the Cholesky decomposition of the variance-covariance matrix.\n\nTo avoid repetition, let us first save the important variables to perform fit diagnostics in a tibble.\n\ndf_residuals &lt;- dplyr::tibble(\n  residuals = residuals(fit_cat_time, type = \"normalized\"),\n  predictions = fitted(fit_cat_time),\n  all2\n)\n\n\n\n\nWe can firstly look into a histogram of transformed residuals. The shape should resemble the density function of normal distribution with mean zero and positive variance. Superimposing the density function with mean and SD derived from the model residuals, let’s us see that this is indeed the case. We can also detect a slight skewness to the right.\n\ndf_residuals %&gt;% \n  ggplot(aes(x = residuals)) +\n  geom_histogram(aes(y = after_stat(density)), fill='lightgray', col='black') +\n  stat_function(fun = dnorm, args = list(mean=mean(df_residuals$residuals), sd=sd(df_residuals$residuals)), col='red', lwd=1) +\n  ggtitle(\n    label = \"Histogram of transformed residuals\",\n    subtitle = \"Normal density with mean and SD of residuals superimposed\"\n  )\n\n\n\n\n\n\n\nAlternatively, we can create a Q-Q-Plot.\n\ndf_residuals %&gt;% \n  ggplot(aes(sample = residuals)) +\n  stat_qq(color = \"blue\") +\n  stat_qq_line() +\n  labs(\n    x = \"Quantiles (Normal distribution)\",\n    y = \"Transformed Residuals\"\n  ) +\n  ggtitle(\n    label = \"Q-Q Plot Transformed Residuals Plot\"\n  )\n\n\n\n\nHow to interprete the Q-Q plot:\nWe can use the following fourfold table to assess the shape characteristics derivable from this plot, depending on where the data on which end of the plot is bend compared to the linear trend line:\n\n\n\n\n\n\n  \n    \n    \n       \n       \n      \n        Upper right corner\n      \n    \n    \n      Above\n      Below\n    \n  \n  \n    Lower left corner\nAbove\nSkewed to the right\nLight-tailed\n    Lower left corner\nBelow\nHeavy-tailed\nSkewed to the left\n  \n  \n  \n\n\n\n\nWe can see that our data is skewed to the right, as the data in the upper right corner and data in the lower left corner of the plot bend above the linear trend line. This is also a trend we can observe from the histogram.\n\n\n\n\ndf_residuals %&gt;% \n  ggplot(aes(x = predictions, y = residuals)) +\n  geom_point() +\n  geom_smooth(method = lm, color = \"blue\") +\n  geom_hline(yintercept = 0, show.legend = FALSE, linetype = 2) +\n  ggtitle(\n    label = \"Residual Plot of predicted values vs. transformed residuals\"\n  )\n\n\n\n\nWhat do we see?\n\nThe points in the plot look well dispersed and symmetric around zero. The fitted line shows no departure from zero.\nThere is no systematic trend, but a rather random scatter.\nWe can spot a couple of outliers.\n\n\ndf_residuals %&gt;% \n  ggplot(aes(x = predictions, y = change)) +\n  geom_point() +\n  geom_smooth(method = lm, color = \"blue\")\n\n\n\n\n\n\n\n\nIn the former examples we used baseline severity as a continuous covariate, which is the most common approach. In this case we treat baseval as a fixed effect and used changes from baseline as response variable in our model formula. This approach comes with a couple of caveats:\n\nOnly subjects with a non-missing baseline and at least one non-missing follow-up response contribute to the analysis (i.e. at least one non-missing change from baseline value).\nOnly subjects with complete covariate data contribute to the analysis.\n\nHence, if baseval is missing for a subject, this subject will not be included in our model. (Liang and Zeger 2000) introduced the so-called LDA (longitudinal data analysis) and cLDA (constrained longitudinal data analysis) models. The basic idea behind these models is that baseline can be regarded as a response at Time 0, and can therefore be included in the vector of responses.\nIn order to fit the model, we need to apply some data wrangling upfront and add baseline to the response column (aval). Note that this step is usually not required when dealing with CDISC compliant datasets, such as ADaM or SDTM.\n\nbase &lt;- dplyr::distinct(all2, subject, trt, basval, group, gender) %&gt;% \n  dplyr::mutate(\n    time = 0,\n    aval = basval,\n    avisit = \"Baseline\"\n  )\n\nall2_lda &lt;- dplyr::bind_rows(all2, base) %&gt;% \n  dplyr::mutate(\n    avisit = forcats::fct_reorder(avisit, time)\n  )\n\n### Check Order of avisit levels:\nlevels(all2_lda$avisit)\n\n[1] \"Baseline\" \"Week 2\"   \"Week 4\"   \"Week 8\"  \n\n\nWe can now fit a model, including aval as a response variable, treatment (group), visit (avisit) and a treatment-by-time interaction term:\n\nlda &lt;- mmrm(\n  formula = aval ~ group*avisit + us(avisit | subject),\n  data = all2_lda,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nThe LS Mean estimates per treatment arm for mean changes to Week 8 (Time 3) are now obtained via contrasts between Week 3 and Baseline:\n\nlsmns &lt;- emmeans(lda, ~group*avisit, weights = \"proportional\")\ncontrast(\n  lsmns,\n  method = list(\n    \"LS Means for Change from Baseline to Week 8 Treatment 1\" = c(-1, 0, 0, 0, 0, 0, 1, 0),\n    \"LS Means for Change from Baseline to Week 8 Treatment 2\" = c(0, -1, 0, 0, 0, 0, 0, 1),\n    \"LS Means for Difference in Changes to Week 8 btw. Treatment 2 and Treatment 1\" = c(1, -1, 0, 0, 0, 0, -1, 1)\n  ), \n  adjust = NULL\n)\n\n contrast                                                                     \n LS Means for Change from Baseline to Week 8 Treatment 1                      \n LS Means for Change from Baseline to Week 8 Treatment 2                      \n LS Means for Difference in Changes to Week 8 btw. Treatment 2 and Treatment 1\n estimate   SE df t.ratio p.value\n    -9.88 1.01 48  -9.768  &lt;.0001\n   -13.24 1.01 48 -13.089  &lt;.0001\n    -3.36 1.43 48  -2.349  0.0230\n\n\nA note on caveats associated with LDA models:\n\nIn cases where the treatment effect has a rapid onset, the linearity assumption underlying the model is violated.\nUse of baseline as a response, as opposed to a covariate, ignores the predictive nature of baseline severity as an explanatory factor in the residual error.\n\nGenerally, LDA models can be very useful in trials with only very few visits per patient due to the additional response value being included. In longer trials however, it is recommended to refrain from their use for the disadvantages stated above. In this case, a decent data quality is key to avoid missing baseline data (if possible completely) and reduce the degree of missingness with regards to follow-up data as much as possible.\n\n\n\nIn this chapter we have dealt with models where the response is modeled as a linear combination of fixed effect parameters \\(\\beta\\) and a random error \\(\\varepsilon\\)\n\\[\ny = X\\beta\\,+\\,\\varepsilon\\,.\n\\]\nThe fixed effects in this model represent the population effects and we used the random error to model the subject-specific influences. Although we used the term mixed model for repeated measures (MMRM), this nomenclature is misleading in the way that our model does not truly deserve the term mixed. A true mixed model would require the involvement of fixed and random effects. The latter have previously been omitted.\nWhile we will not cover random coefficient models (also known as random slope and intercept models or RS&I models) in depth in this class, we would like to point to couple of useful features. For further reading, one can refer to Chapter 8 in (Fitzmaurice 2011).\nThe distinction between fixed and random effects in linear mixed effect models allows for modeling of both between-subject and within-subject variations. In random coefficient models (i.e. MMRMs with a non-trivial random effect) each subject is assumed to have their own (linear) rate of response over time, expressed as random slopes and intercepts.\n“In addition it is not only possible to estimate parameters that describe how the mean response changes in the population of interest, it is also possible to predict how individual response trajectories change over time. For example, linear mixed effects models can be used to obtain predictions of individual growth trajectories over time.” (Fitzmaurice 2011)\nLinear mixed effects models therefore allow for inferences on the individual (subject) basis rather than the entirety of individuals (population).\nAnother advantage of linear mixed models is their flexibility with respect to imbalances in longitudinal data. We are no longer bound by the restriction to have (approximately) the same number of observations per subject, i.e. the approximately the same length of follow-up, or even for the visits to be taken at the same times. This feature is especially useful whenever we are dealing with parallel design studies, involving the comparison of interventions with different dosing/ assessment frequencies.\nNote that the mmrm package so far does not allow for fitting of linear mixed effect models, in the sense that an actual random effects term is included in the model formula. For these kind of models, we point to the package lme4 (Bates et al. 2015)."
  },
  {
    "objectID": "s2_inference_continuous.html#categorical-time",
    "href": "s2_inference_continuous.html#categorical-time",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "In the following sections we will use the package mmrm (Sabanes Bove et al. 2024). You can start and familiarise yourself with the main function mmrm() using the command\nTwo inputs are strictly required to get mmrm() to work:\n\nA model formula\nThe dataset, containing the response, as well as all fixed effects and variables in the covariance matrix.\n\nExercise: Fit a model fit_cat_time using the dataset all2, with change as dependent variable, baseline value, visit, baseline by visit interaction and treatment by visit interaction as fixed effects and an unstructured covariance matrix for visits within each subject.\n\nHow do different choices for covariance matrices change the results? What is the difference on the estimation procedure?\nYou can obtain a summary of the fit results via summary(fit_cat_time). How do you interpret the fit summary?\nLook at the structure of the fit summary and try to extract the estimate of the \\(R\\) matrix.\nHow do other choices of covariance structures influence the estimation?\n\nSolution\n\nfit_cat_time_un &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_toep &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + toep(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_toeph &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + toeph(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_sp &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + sp_exp(week | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\n\n## https://cran.r-project.org/web/packages/mmrm/mmrm.pdf\n# summary(fit_cat_time_un)\n# summary(fit_cat_time_toep)\n# summary(fit_cat_time_toeph)\n# summary(fit_cat_time_sp)\n\n## Covariance Matrix\nfit_cat_time_un$cov\n\n         Week 2   Week 4   Week 8\nWeek 2 20.61191 15.30474 12.27830\nWeek 4 15.30474 21.35801 17.66644\nWeek 8 12.27830 17.66644 27.61440\n\n# Extract AIC and BIC values for the models\naic_values &lt;- c(\n  AIC(fit_cat_time_un),\n  AIC(fit_cat_time_toep),\n  AIC(fit_cat_time_toeph),\n  AIC(fit_cat_time_sp)\n)\n\nbic_values &lt;- c(\n  BIC(fit_cat_time_un),\n  BIC(fit_cat_time_toep),\n  BIC(fit_cat_time_toeph),\n  BIC(fit_cat_time_sp)\n)\n\n# Extract fixed effect coefficients from each model\ncoef_un &lt;- summary(fit_cat_time_un)$coefficients\ncoef_toep &lt;- summary(fit_cat_time_toep)$coefficients\ncoef_toeph &lt;- summary(fit_cat_time_toeph)$coefficients\ncoef_sp &lt;- summary(fit_cat_time_sp)$coefficients\n\n# Combine AIC, BIC, and coefficients into a summary table\ncomparison_table &lt;- data.frame(\n  Model = c(\"Unstructured\", \"Toeplitz\", \"Heterogeneous Toeplitz\", \"Spatial Power\"),\n  AIC = aic_values,\n  BIC = bic_values\n)\n\n# Display the summary of goodness of fit (AIC and BIC)\ncomparison_table %&gt;%\n  kable(caption = \"Goodness of Fit Comparison (AIC, BIC)\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nGoodness of Fit Comparison (AIC, BIC)\n\n\nModel\nAIC\nBIC\n\n\n\n\nUnstructured\n822.4105\n833.8826\n\n\nToeplitz\n818.5753\n824.3114\n\n\nHeterogeneous Toeplitz\n820.4111\n829.9712\n\n\nSpatial Power\n818.5262\n822.3503\n\n\n\n\n\n\n# Extract the Estimate (fixed effect coefficients) from each model\nestimates_un &lt;- summary(fit_cat_time_un)$coefficients[, \"Estimate\"]\nestimates_toep &lt;- summary(fit_cat_time_toep)$coefficients[, \"Estimate\"]\nestimates_toeph &lt;- summary(fit_cat_time_toeph)$coefficients[, \"Estimate\"]\n\n# Combine the estimates into a data frame for comparison\nestimate_comparison &lt;- data.frame(\n  Term = names(estimates_un),  # Assuming all models have the same terms\n  Unstructured = estimates_un,\n  Toeplitz = estimates_toep,\n  Heterogeneous_Toeplitz = estimates_toeph\n)\n\n# Display the table of estimates\nestimate_comparison %&gt;%\n  kable(caption = \"Comparison of Estimates for the Three Models\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nComparison of Estimates for the Three Models\n\n\n\nTerm\nUnstructured\nToeplitz\nHeterogeneous_Toeplitz\n\n\n\n\n(Intercept)\n(Intercept)\n1.9845205\n1.9845205\n1.9845205\n\n\nbasval\nbasval\n-0.3123495\n-0.3123495\n-0.3123495\n\n\navisitWeek 4\navisitWeek 4\n-0.9086176\n-0.9086176\n-0.9086176\n\n\navisitWeek 8\navisitWeek 8\n-10.5863002\n-10.5863002\n-10.5863002\n\n\ngroupArm 2\ngroupArm 2\n-1.1899278\n-1.1899278\n-1.1899278\n\n\nbasval:avisitWeek 4\nbasval:avisitWeek 4\n-0.0854234\n-0.0854234\n-0.0854234\n\n\nbasval:avisitWeek 8\nbasval:avisitWeek 8\n0.2477929\n0.2477929\n0.2477929\n\n\navisitWeek 4:groupArm 2\navisitWeek 4:groupArm 2\n-0.8010032\n-0.8010032\n-0.8010032\n\n\navisitWeek 8:groupArm 2\navisitWeek 8:groupArm 2\n-2.2010594\n-2.2010594\n-2.2010594\n\n\n\n\n\n\n\n\n\n\nStructure\nDescription\n\n\n\n\nad\nAnte-dependence\n\n\nadh\nHeterogeneous ante-dependence\n\n\nar1\nFirst-order auto-regressive\n\n\nar1h\nHeterogeneous first-order auto-regressive\n\n\ncs\nCompound symmetry\n\n\ncsh\nHeterogeneous compound symmetry\n\n\ntoep\nToeplitz\n\n\ntoeph\nHeterogeneous Toeplitz\n\n\nus\nUnstructured"
  },
  {
    "objectID": "s2_inference_continuous.html#continuous-time",
    "href": "s2_inference_continuous.html#continuous-time",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "Time as continuous effect -&gt; single df for time and trt-by-time interaction\nModeling: - Need avisit for structure of covariance matrix - Implicit assumption is for the covariance between values for two timepoints to be equal, regardless of the specific timing\n\nfit_cont_time &lt;- mmrm::mmrm(\n  formula = change ~ basval*week + trt*week + us(avisit | subject),\n  ## Treat time as continuously\n  weights = all2$week,\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nsummary (fit_cont_time)\n\nmmrm fit\n\nFormula:     change ~ basval * week + trt * week + us(avisit | subject)\nData:        all2 (used 150 observations from 50 subjects with maximum 3 \ntimepoints)\nWeights:     all2$week\nCovariance:  unstructured (6 variance parameters)\nMethod:      Kenward-Roger\nVcov Method: Kenward-Roger\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n   838.0    849.5   -413.0    826.0 \n\nCoefficients: \n            Estimate Std. Error       df t value Pr(&gt;|t|)   \n(Intercept)  6.83666    3.82960 47.00000   1.785  0.08068 . \nbasval      -0.47981    0.18600 47.00000  -2.580  0.01308 * \nweek        -1.94296    0.57420 47.00000  -3.384  0.00145 **\ntrt2        -0.49024    1.48826 47.00000  -0.329  0.74331   \nbasval:week  0.05275    0.02789 47.00000   1.892  0.06472 . \nweek:trt2   -0.36226    0.22315 47.00000  -1.623  0.11119   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        Week 2   Week 4   Week 8\nWeek 2 41.3658  42.8600  49.0752\nWeek 4 42.8600  86.6690 100.0141\nWeek 8 49.0752 100.0141 220.9000\n\n\nCan also apply non-linear transformations of time variable, in case the anticipated effect is not necessarily linear in time:\n\nall2$timesq &lt;- all2$week^2\n\nfit_cont_timesq &lt;- mmrm::mmrm(\n  formula = change ~ basval*timesq + trt*timesq + us(avisit | subject),\n  weights = all2$week,\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nsummary(fit_cont_timesq)\n\nmmrm fit\n\nFormula:     change ~ basval * timesq + trt * timesq + us(avisit | subject)\nData:        all2 (used 150 observations from 50 subjects with maximum 3 \ntimepoints)\nWeights:     all2$week\nCovariance:  unstructured (6 variance parameters)\nMethod:      Kenward-Roger\nVcov Method: Kenward-Roger\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n   861.8    873.3   -424.9    849.8 \n\nCoefficients: \n               Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)    3.298095   3.300323 47.000000   0.999  0.32275    \nbasval        -0.396751   0.160290 47.000000  -2.475  0.01698 *  \ntimesq        -0.191395   0.053074 47.000000  -3.606  0.00075 ***\ntrt2          -1.224631   1.282574 47.000000  -0.955  0.34455    \nbasval:timesq  0.005800   0.002578 47.000000   2.250  0.02916 *  \ntimesq:trt2   -0.032220   0.020626 47.000000  -1.562  0.12497    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        Week 2   Week 4   Week 8\nWeek 2 42.2220  41.1223  47.8394\nWeek 4 41.1223  90.1270 102.6988\nWeek 8 47.8394 102.6988 222.5403"
  },
  {
    "objectID": "s2_inference_continuous.html#adjusted-ls-means-from-mmrms",
    "href": "s2_inference_continuous.html#adjusted-ls-means-from-mmrms",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "LS Means are means of the dependent variable adjusted for covariates in the statistical model. We can obtain LS Means estimates and contrasts allowing for a treatment comparison using the emmeans package.\nExample: Calculate the observed (raw) means of changes along with number of patients by treatment group from the dataset all2 overall and by visit. Then take the model fit_cat_time and derive the respective LS Means from the model. What do you observe?\n\n# Raw means\nall2 %&gt;% \n  dplyr::group_by(group) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n(),\n    Mean = mean(change),\n    .groups = \"drop\"\n  )\n\n# A tibble: 2 × 3\n  group     N  Mean\n  &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n1 Arm 1    75 -6.96\n2 Arm 2    75 -9.03\n\nall2 %&gt;% \n  dplyr::group_by(group, avisit) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n(),\n    Mean = mean(change),\n    .groups = \"drop\"\n  )\n\n# A tibble: 6 × 4\n  group avisit     N   Mean\n  &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 Arm 1 Week 2    25  -4.2 \n2 Arm 1 Week 4    25  -6.8 \n3 Arm 1 Week 8    25  -9.88\n4 Arm 2 Week 2    25  -5.24\n5 Arm 2 Week 4    25  -8.6 \n6 Arm 2 Week 8    25 -13.2 \n\n\nThe respective LS Means from the model with time as a fixed factor yields the following estimates:\n\n\n'emmGrid' object with variables:\n    basval = 19.56\n    avisit = Week 2, Week 4, Week 8\n    trt = 1, 2\n\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n trt emmean    SE df lower.CL upper.CL\n 1    -6.90 0.836 47    -8.58    -5.22\n 2    -9.09 0.836 47   -10.77    -7.41\n\nResults are averaged over the levels of: avisit \nConfidence level used: 0.95 \n\n\n trt avisit emmean    SE df lower.CL upper.CL\n 1   Week 2  -4.13 0.899 47    -5.93    -2.32\n 2   Week 2  -5.31 0.899 47    -7.12    -3.51\n 1   Week 4  -6.70 0.916 47    -8.55    -4.86\n 2   Week 4  -8.70 0.916 47   -10.54    -6.85\n 1   Week 8  -9.86 1.033 47   -11.94    -7.79\n 2   Week 8 -13.26 1.033 47   -15.33   -11.18\n\nConfidence level used: 0.95 \n\n\n\n\nIn the example above we have used the standard option for the weights in the calculation of LS Means. We will delve deeper into the following two options and will try to understand the difference:\n\nweights = \"equal\": Each stratum induced by covariate levels is assigned the same weight in the calculation of the LS Means. This is the default option.\nweights = \"proportional\": Each stratum induced by covariate levels is assigned a weight according to their observed proportion in the calculation of the LS Mean. This option gives each stratum a weight corresponding to its size. Estimates using this option are reflective of the balance of covariates in the data.\n\nExercise: Based on the fit_cat_time model, compare the LS Means for the change in the response variable by treatment overall and treatment by visit interaction using the different options for weight. Compare the results for the two LS Means options to the observed means and to one another.\nDiscuss the following points:\n\nWhy is there no difference between LS Means estimates for the overall treatment effect and the treatment by visit interaction? (Hint: Create a frequency table)\n\nSolution: Balanced Data: If the data is perfectly balanced (e.g., equal sample sizes across visits, no missing data), then the LS Means estimates of the treatment effect at each visit might aggregate to the same result as the overall treatment effect. The overall treatment effect is simply an average of the effects at each visit.\n\n## LS Means estimates for the overall treatment effect\nemmeans(fit_cat_time, ~trt)\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n trt emmean    SE df lower.CL upper.CL\n 1    -6.90 0.836 47    -8.58    -5.22\n 2    -9.09 0.836 47   -10.77    -7.41\n\nResults are averaged over the levels of: avisit \nConfidence level used: 0.95 \n\nemmeans(fit_cat_time, ~trt*avisit)\n\n trt avisit emmean    SE df lower.CL upper.CL\n 1   Week 2  -4.13 0.899 47    -5.93    -2.32\n 2   Week 2  -5.31 0.899 47    -7.12    -3.51\n 1   Week 4  -6.70 0.916 47    -8.55    -4.86\n 2   Week 4  -8.70 0.916 47   -10.54    -6.85\n 1   Week 8  -9.86 1.033 47   -11.94    -7.79\n 2   Week 8 -13.26 1.033 47   -15.33   -11.18\n\nConfidence level used: 0.95 \n\n(-4.13-6.70-9.86)/3\n\n[1] -6.896667\n\n(-5.31-8.70-13.26)/3\n\n[1] -9.09\n\n # trt emmean    SE df lower.CL upper.CL\n # 1    -6.90 0.836 47    -8.58    -5.22\n # 2    -9.09 0.836 47   -10.77    -7.41\n \n### Work with code chunks to find the solution to the exercises\nall2 %&gt;% \n  dplyr::group_by(group,avisit) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n(),\n    Mean = mean(change),\n    .groups = \"drop\"\n  )\n\n# A tibble: 6 × 4\n  group avisit     N   Mean\n  &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 Arm 1 Week 2    25  -4.2 \n2 Arm 1 Week 4    25  -6.8 \n3 Arm 1 Week 8    25  -9.88\n4 Arm 2 Week 2    25  -5.24\n5 Arm 2 Week 4    25  -8.6 \n6 Arm 2 Week 8    25 -13.2 \n\nemmeans(fit_cat_time, ~trt, weights = \"equal\")\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n trt emmean    SE df lower.CL upper.CL\n 1    -6.90 0.836 47    -8.58    -5.22\n 2    -9.09 0.836 47   -10.77    -7.41\n\nResults are averaged over the levels of: avisit \nConfidence level used: 0.95 \n\nemmeans(fit_cat_time, ~trt, weights = \"proportional\")\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n trt emmean    SE df lower.CL upper.CL\n 1    -6.90 0.836 47    -8.58    -5.22\n 2    -9.09 0.836 47   -10.77    -7.41\n\nResults are averaged over the levels of: avisit \nConfidence level used: 0.95 \n\n\nNow update the fit_cat_time model to fit_cat_time2, and include the covariate gender. Estimate the same LS Means for the change in the response variable by treatment (overall) and treatment by visit interaction.\n\n\n'emmGrid' object with variables:\n    basval = 19.56\n    avisit = Week 2, Week 4, Week 8\n    trt = 1, 2\n    gender = F, M\n\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.36 0.869 45.7    -6.11    -2.61\n 2   Week 2  -4.71 0.923 46.8    -6.57    -2.85\n 1   Week 4  -6.94 0.920 46.4    -8.79    -5.09\n 2   Week 4  -8.09 0.972 48.1   -10.04    -6.13\n 1   Week 8 -10.10 1.063 45.5   -12.24    -7.96\n 2   Week 8 -12.65 1.108 48.2   -14.88   -10.42\n\nResults are averaged over the levels of: gender \nConfidence level used: 0.95 \n\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.55 0.890 46.2    -6.34    -2.75\n 2   Week 2  -4.89 0.890 46.2    -6.69    -3.10\n 1   Week 4  -7.13 0.941 47.1    -9.02    -5.23\n 2   Week 4  -8.27 0.941 47.1   -10.17    -6.38\n 1   Week 8 -10.29 1.081 46.6   -12.46    -8.11\n 2   Week 8 -12.83 1.081 46.6   -15.01   -10.66\n\nResults are averaged over the levels of: gender \nConfidence level used: 0.95 \n\n\n\nWhy is there a difference now between results from the different LS Means options? (Hint: another frequency table can help)\n\nSolution: In-Balanced Data by Gender\n\nall2 %&gt;% \n  dplyr::group_by(group,avisit,gender) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n(),\n    Mean = mean(change),\n    .groups = \"drop\"\n  )\n\n# A tibble: 12 × 5\n   group avisit gender     N    Mean\n   &lt;fct&gt; &lt;fct&gt;  &lt;chr&gt;  &lt;int&gt;   &lt;dbl&gt;\n 1 Arm 1 Week 2 F         10  -4.7  \n 2 Arm 1 Week 2 M         15  -3.87 \n 3 Arm 1 Week 4 F         10  -6.9  \n 4 Arm 1 Week 4 M         15  -6.73 \n 5 Arm 1 Week 8 F         10  -8.9  \n 6 Arm 1 Week 8 M         15 -10.5  \n 7 Arm 2 Week 2 F         19  -6.79 \n 8 Arm 2 Week 2 M          6  -0.333\n 9 Arm 2 Week 4 F         19  -9.53 \n10 Arm 2 Week 4 M          6  -5.67 \n11 Arm 2 Week 8 F         19 -13.9  \n12 Arm 2 Week 8 M          6 -11    \n\n\n\nWhat effect could missing data have on the estimation, even in the case of fit_cat_time? I.e. what would happen if this data was not complete but subject to missingness, with the degree of missing data increasing over time and being disproportionate between treatment arms?\nImbalanced Representation Over Time: If the degree of missingness increases over time, estimates of later visits will be based on fewer patients, reducing the reliability of treatment effects at those time points. The treatment-by-visit interaction estimates could become unstable.\nMissing Not at Random (MNAR): If missingness is related to unobserved outcomes (e.g., patients drop out because of worsening symptoms in one treatment group), this could bias the estimation. In particular, the treatment effect estimates could be skewed, either exaggerating or underestimating the true treatment difference.\n\n\n\n\nMost of the times, the quantity we are truly interested in when reading out a study, is the contrast between treatment arms. This contrast can be built either based on LS Means at some landmark time point, or as a longitudinal (linear) combination of LS Means from multiple time points.\nWe can use the pairs() or the contrast() functions, where the latter provides more flexibility for the calculation of linear combinations from multiple timepoints.\n\nlsmns &lt;- emmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\")\npairs(lsmns, reverse = TRUE, adjust = NULL)\n\n contrast                  estimate    SE   df t.ratio p.value\n trt2 Week 2 - trt1 Week 2    -1.19 1.273 47.0  -0.935  0.3546\n trt1 Week 4 - trt1 Week 2    -2.58 0.659 47.0  -3.917  0.0003\n trt1 Week 4 - trt2 Week 2    -1.39 1.284 61.3  -1.082  0.2835\n trt2 Week 4 - trt1 Week 2    -4.57 1.284 61.3  -3.559  0.0007\n trt2 Week 4 - trt2 Week 2    -3.38 0.659 47.0  -5.133  &lt;.0001\n trt2 Week 4 - trt1 Week 4    -1.99 1.296 47.0  -1.536  0.1313\n trt1 Week 8 - trt1 Week 2    -5.74 0.950 47.0  -6.043  &lt;.0001\n trt1 Week 8 - trt2 Week 2    -4.55 1.370 73.3  -3.321  0.0014\n trt1 Week 8 - trt1 Week 4    -3.16 0.716 47.0  -4.416  0.0001\n trt1 Week 8 - trt2 Week 4    -1.17 1.381 61.1  -0.846  0.4007\n trt2 Week 8 - trt1 Week 2    -9.13 1.370 73.3  -6.664  &lt;.0001\n trt2 Week 8 - trt2 Week 2    -7.94 0.950 47.0  -8.361  &lt;.0001\n trt2 Week 8 - trt1 Week 4    -6.55 1.381 61.1  -4.742  &lt;.0001\n trt2 Week 8 - trt2 Week 4    -4.56 0.716 47.0  -6.373  &lt;.0001\n trt2 Week 8 - trt1 Week 8    -3.39 1.462 47.0  -2.319  0.0248\n\n### This is the same as the following\nprs &lt;- contrast(lsmns, method = \"revpairwise\", adjust = NULL)\nprs &lt;- contrast(lsmns, method = \"revpairwise\", adjust = \"tukey\")\n\n\n\n\n\n\n\n\nAdjustment Method\nDescription\n\n\n\n\n“tukey”\nUses the Studentized range distribution with the number of means in the family. (Available for two-sided cases only.)\n\n\n“scheffe”\nComputes p-values from the F distribution, according to the Scheffe critical value of rF(α; r, d), where d is the error degrees of freedom and r is the rank of the set of linear functions under consideration. By default, r is computed from object@linfct for each group. If there are k means involved, r = k - 1 for a full set of contrasts, and r = k for the means themselves. (Available for two-sided cases only.)\n\n\n“sidak”\nMakes adjustments as if the estimates were independent (a conservative adjustment in many cases).\n\n\n“bonferroni”\nMultiplies p-values or divides significance levels by the number of estimates. This is a conservative adjustment.\n\n\n“dunnettx”\nUses an ad hoc approximation to the Dunnett distribution for a family of estimates with pairwise correlations of 0.5 (common when comparing treatments with a control with equal sample sizes). This method is faster than “mvt” and the approximation improves with the number of estimates. (Available for two-sided cases only.)\n\n\n“mvt”\nUses the multivariate t distribution to assess the probability or critical value for the maximum of k estimates. Produces the same p-values and intervals as the default methods in as.glht. Monte Carlo simulation is used, so results may vary unless the same random-number seed is used. Computation time increases with family size, making “tukey” or “dunnettx” more attractive alternatives for large families.\n\n\n“none”\nNo adjustments are made to the p-values.\n\n\n\nNote that both pairs() and contrast() provide multiple options for fine-tuning. We chose adjust = NULL in order to not perform any multiplicity adjustment (default method would have been the Tukey method). We also chose reverse = TRUE to reverse the order of comparisons performed by pairs(), as the default would have given us the contrast for Treatment 1 - Treatment 2. Consequently, we applied method = \"revpairwise\" in the contrast() function.\nWe can obtain the coefficients in the calculation of the contrasts via coef():\n\ncoef(prs)\n\n            trt avisit c.1 c.2 c.3 c.4 c.5 c.6 c.7 c.8 c.9 c.10 c.11 c.12 c.13\ntrt1 Week 2   1 Week 2  -1  -1   0  -1   0   0  -1   0   0    0   -1    0    0\ntrt2 Week 2   2 Week 2   1   0  -1   0  -1   0   0  -1   0    0    0   -1    0\ntrt1 Week 4   1 Week 4   0   1   1   0   0  -1   0   0  -1    0    0    0   -1\ntrt2 Week 4   2 Week 4   0   0   0   1   1   1   0   0   0   -1    0    0    0\ntrt1 Week 8   1 Week 8   0   0   0   0   0   0   1   1   1    1    0    0    0\ntrt2 Week 8   2 Week 8   0   0   0   0   0   0   0   0   0    0    1    1    1\n            c.14 c.15\ntrt1 Week 2    0    0\ntrt2 Week 2    0    0\ntrt1 Week 4    0    0\ntrt2 Week 4   -1    0\ntrt1 Week 8    0   -1\ntrt2 Week 8    1    1\n\n\nThe output above is probably more than we wanted. We are only interested in contrasts between Treatments 1 and 2 at the same time points. Here contrast() provides more flexibility. Instead of parsing a string with the name of a method to the method argument, we provide a named list of coefficients. These coefficients are identical with the onces we can see in the coefficient matrix above. We can use it as a guide.\n\ncontrast(\n  lsmns, \n  method = list(\n    \"Difference Trt 2 - Trt 1 at Week 4\" = c(0, 0, -1, 1, 0, 0),\n    \"Difference Trt 2 - Trt 1 at Week 8\" = c(0, 0, 0, 0, -1, 1)\n  ), \n  adjust = NULL)\n\n contrast                           estimate   SE df t.ratio p.value\n Difference Trt 2 - Trt 1 at Week 4    -1.99 1.30 47  -1.536  0.1313\n Difference Trt 2 - Trt 1 at Week 8    -3.39 1.46 47  -2.319  0.0248\n\n\nThis way of computing LS Means from our MMRM allows us to calculate all kinds of linear combinations of LS Means. Assume we were interested in the longitudinal mean of changes from baseline averaged over Weeks 2, 4 and 8. This would look like this:\n\ncontrast(\n  lsmns, \n  method = list(\n    \"Difference Trt 2 - Trt 1 Averaged over Weeks 2, 4 and 8\" = c(-1, 1, -1, 1, -1, 1)/3\n  ), \n  adjust = NULL)\n\n contrast                                                estimate   SE df\n Difference Trt 2 - Trt 1 Averaged over Weeks 2, 4 and 8    -2.19 1.18 47\n t.ratio p.value\n  -1.850  0.0705"
  },
  {
    "objectID": "s2_inference_continuous.html#fit-diagnostics",
    "href": "s2_inference_continuous.html#fit-diagnostics",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "The following section closely follows the content in Chapter 10 in (Fitzmaurice 2011).\nOur analysis should be concluded with a look into the fit diagnostics, more specifically, the residuals. Residuals are defined by the difference between the true responses and the fitted values from the model:\n\\[\nr := y - X\\hat\\beta\\,,\n\\]\nwhere \\(\\hat\\beta\\) are the estimated coefficients from our model. Residuals provide an estimate of the true vector of random errors\n\\[\n\\varepsilon = y - X\\beta\\,.\n\\]\nAs per our modeling assumptions, \\(\\varepsilon\\) should follow a normal distribution with mean zero. The mean of the residuals is zero and therefore identical with the mean of the error term. For the covariance of the residuals however, the variance-covariance matrix of \\(\\varepsilon\\) only serves us as an approximation (as suggested by (Fitzmaurice 2011) for all ‘practical applications’):\n\\[\nCov(r) \\approx Cov(\\varepsilon) = R\\,.\n\\]\nThis assumption has several implications on the residual diagnostics:\n\nThe variance is not necessarily constant. Plotting the fitted values versus the residuals might therefore lead to a non-constant range. An examination of the residual variance or autocorrelation among residuals is therefore not very meaningful.\nResiduals from analyses of longitudinal data can exhibit correlation with the covariates. Scatterplots of residuals versus selected covariates can therefore reveal systematic trends (which normally should not be the case).\n\nA transformation of residuals to achieve constant variance and zero correlation is therefore often useful. This transformation uses the so-called Cholesky decomposition of the variance-covariance matrix \\(R\\). Let \\(L\\) be a lower triangular matrix, such that\n\\[\nR = L\\,L'\\,,\n\\]\nthen the transformed residuals are given by\n\\[\nr^* =  L^{-1}(y - X\\beta)\\,.\n\\]\nIn the mmrm package, transformed residuals can be derived using the type = \"normalized\" option.\nExercise: Which visualisations can you think of that make sense to assess the goodness of fit here? Create a new tibble (or data.frame) containing the variables of importance and try plotting them in a meaningful way. Discuss the results within your group.\nSolution:\n\n\n\nresiduals(fit, type = “response”), Response or raw residuals - the difference between the observed and fitted or predicted value.\nresiduals(fit, type = “pearson”), Pearson residuals - the raw residuals scaled by the estimated standard deviation of the response.\nresiduals(fit, type = “normalized”), Normalized or scaled residuals - the raw residuals are ‘de-correlated’ based on the Cholesky decomposition of the variance-covariance matrix.\n\nTo avoid repetition, let us first save the important variables to perform fit diagnostics in a tibble.\n\ndf_residuals &lt;- dplyr::tibble(\n  residuals = residuals(fit_cat_time, type = \"normalized\"),\n  predictions = fitted(fit_cat_time),\n  all2\n)\n\n\n\n\nWe can firstly look into a histogram of transformed residuals. The shape should resemble the density function of normal distribution with mean zero and positive variance. Superimposing the density function with mean and SD derived from the model residuals, let’s us see that this is indeed the case. We can also detect a slight skewness to the right.\n\ndf_residuals %&gt;% \n  ggplot(aes(x = residuals)) +\n  geom_histogram(aes(y = after_stat(density)), fill='lightgray', col='black') +\n  stat_function(fun = dnorm, args = list(mean=mean(df_residuals$residuals), sd=sd(df_residuals$residuals)), col='red', lwd=1) +\n  ggtitle(\n    label = \"Histogram of transformed residuals\",\n    subtitle = \"Normal density with mean and SD of residuals superimposed\"\n  )\n\n\n\n\n\n\n\nAlternatively, we can create a Q-Q-Plot.\n\ndf_residuals %&gt;% \n  ggplot(aes(sample = residuals)) +\n  stat_qq(color = \"blue\") +\n  stat_qq_line() +\n  labs(\n    x = \"Quantiles (Normal distribution)\",\n    y = \"Transformed Residuals\"\n  ) +\n  ggtitle(\n    label = \"Q-Q Plot Transformed Residuals Plot\"\n  )\n\n\n\n\nHow to interprete the Q-Q plot:\nWe can use the following fourfold table to assess the shape characteristics derivable from this plot, depending on where the data on which end of the plot is bend compared to the linear trend line:\n\n\n\n\n\n\n  \n    \n    \n       \n       \n      \n        Upper right corner\n      \n    \n    \n      Above\n      Below\n    \n  \n  \n    Lower left corner\nAbove\nSkewed to the right\nLight-tailed\n    Lower left corner\nBelow\nHeavy-tailed\nSkewed to the left\n  \n  \n  \n\n\n\n\nWe can see that our data is skewed to the right, as the data in the upper right corner and data in the lower left corner of the plot bend above the linear trend line. This is also a trend we can observe from the histogram.\n\n\n\n\ndf_residuals %&gt;% \n  ggplot(aes(x = predictions, y = residuals)) +\n  geom_point() +\n  geom_smooth(method = lm, color = \"blue\") +\n  geom_hline(yintercept = 0, show.legend = FALSE, linetype = 2) +\n  ggtitle(\n    label = \"Residual Plot of predicted values vs. transformed residuals\"\n  )\n\n\n\n\nWhat do we see?\n\nThe points in the plot look well dispersed and symmetric around zero. The fitted line shows no departure from zero.\nThere is no systematic trend, but a rather random scatter.\nWe can spot a couple of outliers.\n\n\ndf_residuals %&gt;% \n  ggplot(aes(x = predictions, y = change)) +\n  geom_point() +\n  geom_smooth(method = lm, color = \"blue\")"
  },
  {
    "objectID": "s2_inference_continuous.html#baseline-as-a-response-clda-lda",
    "href": "s2_inference_continuous.html#baseline-as-a-response-clda-lda",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "In the former examples we used baseline severity as a continuous covariate, which is the most common approach. In this case we treat baseval as a fixed effect and used changes from baseline as response variable in our model formula. This approach comes with a couple of caveats:\n\nOnly subjects with a non-missing baseline and at least one non-missing follow-up response contribute to the analysis (i.e. at least one non-missing change from baseline value).\nOnly subjects with complete covariate data contribute to the analysis.\n\nHence, if baseval is missing for a subject, this subject will not be included in our model. (Liang and Zeger 2000) introduced the so-called LDA (longitudinal data analysis) and cLDA (constrained longitudinal data analysis) models. The basic idea behind these models is that baseline can be regarded as a response at Time 0, and can therefore be included in the vector of responses.\nIn order to fit the model, we need to apply some data wrangling upfront and add baseline to the response column (aval). Note that this step is usually not required when dealing with CDISC compliant datasets, such as ADaM or SDTM.\n\nbase &lt;- dplyr::distinct(all2, subject, trt, basval, group, gender) %&gt;% \n  dplyr::mutate(\n    time = 0,\n    aval = basval,\n    avisit = \"Baseline\"\n  )\n\nall2_lda &lt;- dplyr::bind_rows(all2, base) %&gt;% \n  dplyr::mutate(\n    avisit = forcats::fct_reorder(avisit, time)\n  )\n\n### Check Order of avisit levels:\nlevels(all2_lda$avisit)\n\n[1] \"Baseline\" \"Week 2\"   \"Week 4\"   \"Week 8\"  \n\n\nWe can now fit a model, including aval as a response variable, treatment (group), visit (avisit) and a treatment-by-time interaction term:\n\nlda &lt;- mmrm(\n  formula = aval ~ group*avisit + us(avisit | subject),\n  data = all2_lda,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nThe LS Mean estimates per treatment arm for mean changes to Week 8 (Time 3) are now obtained via contrasts between Week 3 and Baseline:\n\nlsmns &lt;- emmeans(lda, ~group*avisit, weights = \"proportional\")\ncontrast(\n  lsmns,\n  method = list(\n    \"LS Means for Change from Baseline to Week 8 Treatment 1\" = c(-1, 0, 0, 0, 0, 0, 1, 0),\n    \"LS Means for Change from Baseline to Week 8 Treatment 2\" = c(0, -1, 0, 0, 0, 0, 0, 1),\n    \"LS Means for Difference in Changes to Week 8 btw. Treatment 2 and Treatment 1\" = c(1, -1, 0, 0, 0, 0, -1, 1)\n  ), \n  adjust = NULL\n)\n\n contrast                                                                     \n LS Means for Change from Baseline to Week 8 Treatment 1                      \n LS Means for Change from Baseline to Week 8 Treatment 2                      \n LS Means for Difference in Changes to Week 8 btw. Treatment 2 and Treatment 1\n estimate   SE df t.ratio p.value\n    -9.88 1.01 48  -9.768  &lt;.0001\n   -13.24 1.01 48 -13.089  &lt;.0001\n    -3.36 1.43 48  -2.349  0.0230\n\n\nA note on caveats associated with LDA models:\n\nIn cases where the treatment effect has a rapid onset, the linearity assumption underlying the model is violated.\nUse of baseline as a response, as opposed to a covariate, ignores the predictive nature of baseline severity as an explanatory factor in the residual error.\n\nGenerally, LDA models can be very useful in trials with only very few visits per patient due to the additional response value being included. In longer trials however, it is recommended to refrain from their use for the disadvantages stated above. In this case, a decent data quality is key to avoid missing baseline data (if possible completely) and reduce the degree of missingness with regards to follow-up data as much as possible."
  },
  {
    "objectID": "s2_inference_continuous.html#addendum-on-linear-mixed-effect-models",
    "href": "s2_inference_continuous.html#addendum-on-linear-mixed-effect-models",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "In this chapter we have dealt with models where the response is modeled as a linear combination of fixed effect parameters \\(\\beta\\) and a random error \\(\\varepsilon\\)\n\\[\ny = X\\beta\\,+\\,\\varepsilon\\,.\n\\]\nThe fixed effects in this model represent the population effects and we used the random error to model the subject-specific influences. Although we used the term mixed model for repeated measures (MMRM), this nomenclature is misleading in the way that our model does not truly deserve the term mixed. A true mixed model would require the involvement of fixed and random effects. The latter have previously been omitted.\nWhile we will not cover random coefficient models (also known as random slope and intercept models or RS&I models) in depth in this class, we would like to point to couple of useful features. For further reading, one can refer to Chapter 8 in (Fitzmaurice 2011).\nThe distinction between fixed and random effects in linear mixed effect models allows for modeling of both between-subject and within-subject variations. In random coefficient models (i.e. MMRMs with a non-trivial random effect) each subject is assumed to have their own (linear) rate of response over time, expressed as random slopes and intercepts.\n“In addition it is not only possible to estimate parameters that describe how the mean response changes in the population of interest, it is also possible to predict how individual response trajectories change over time. For example, linear mixed effects models can be used to obtain predictions of individual growth trajectories over time.” (Fitzmaurice 2011)\nLinear mixed effects models therefore allow for inferences on the individual (subject) basis rather than the entirety of individuals (population).\nAnother advantage of linear mixed models is their flexibility with respect to imbalances in longitudinal data. We are no longer bound by the restriction to have (approximately) the same number of observations per subject, i.e. the approximately the same length of follow-up, or even for the visits to be taken at the same times. This feature is especially useful whenever we are dealing with parallel design studies, involving the comparison of interventions with different dosing/ assessment frequencies.\nNote that the mmrm package so far does not allow for fitting of linear mixed effect models, in the sense that an actual random effects term is included in the model formula. For these kind of models, we point to the package lme4 (Bates et al. 2015)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "Authors\n\nDr. Marietta Kirchner, Institute of Medical Biometry, Heidelberg University\nDr. Alexandra Lauer, Boehringer Ingelheim Pharma GmbH & Co. KG\n\nPublished\n\nSys.Date()\n\n[1] \"2024-09-28\"\n\n\n\n\nThis class focuses on the longitudinal modeling of data from Patient Reported Outcomes (PROs). It is meant to be hands-on class with applications in R.\nContent and structure follow the book by (Mallinckrodt and Lipkovich 2016). We would like to extend our warmest gratitude towards Dr. Mallinckrodt for providing the example data for the workshop.\nThe following topics will be covered:\n\nWelcome and Introduction (WS session 1)\nExploration and visualization of longitudinal data (WS session 1/2)\nInferences from longitudinal data (WS session 3 + 4)\nAssessment of missingness patterns (WS session 5)\nSensitivity analyses to assess the impact of missingness (WS session 6)\nAnnex: Inferences from longitudinal binary data (WS session 7)\n\n\n\n\nThis workshop focuses on the analysis of data observed in randomized clinical trials (RCTs). Here, patients have assessments taken at the start of their treatment and then subsequently throughout the course of the trial based on a pre-specified schedule of assessments. The measurement at the start of the treatment is usually referred to as the baseline.\nResearchers can be interested in\n\nthe occurrence of a certain event during the course of the trial, e.g. death or a cardiac event, or the time to the occurrence of such an event, or\nthe longitudinal profile from multiple repeated measurements taken, with a focus on either estimates at a landmark visit or across several time points.\n\nThe outcomes under point 1 can be handled via a comparison of the percentages of patients with events between treatment arms, or a time-to-event analysis. Both are out of scope of this workshop.\n\n\n\nIf you are not used to working with R and RStudio so far, we recommend for you to familiarize yourself with the following useful content:\n\nRStudio User Guide\nRStudio Cheatsheet\nThe following two cheatsheets for dplyr (data wrangling) and ggplot2 (plotting and visualizations)\nThis video about Quarto"
  },
  {
    "objectID": "index.html#workshop-structure",
    "href": "index.html#workshop-structure",
    "title": "Introduction",
    "section": "",
    "text": "This class focuses on the longitudinal modeling of data from Patient Reported Outcomes (PROs). It is meant to be hands-on class with applications in R.\nContent and structure follow the book by (Mallinckrodt and Lipkovich 2016). We would like to extend our warmest gratitude towards Dr. Mallinckrodt for providing the example data for the workshop.\nThe following topics will be covered:\n\nWelcome and Introduction (WS session 1)\nExploration and visualization of longitudinal data (WS session 1/2)\nInferences from longitudinal data (WS session 3 + 4)\nAssessment of missingness patterns (WS session 5)\nSensitivity analyses to assess the impact of missingness (WS session 6)\nAnnex: Inferences from longitudinal binary data (WS session 7)"
  },
  {
    "objectID": "index.html#longitudinal-data",
    "href": "index.html#longitudinal-data",
    "title": "Introduction",
    "section": "",
    "text": "This workshop focuses on the analysis of data observed in randomized clinical trials (RCTs). Here, patients have assessments taken at the start of their treatment and then subsequently throughout the course of the trial based on a pre-specified schedule of assessments. The measurement at the start of the treatment is usually referred to as the baseline.\nResearchers can be interested in\n\nthe occurrence of a certain event during the course of the trial, e.g. death or a cardiac event, or the time to the occurrence of such an event, or\nthe longitudinal profile from multiple repeated measurements taken, with a focus on either estimates at a landmark visit or across several time points.\n\nThe outcomes under point 1 can be handled via a comparison of the percentages of patients with events between treatment arms, or a time-to-event analysis. Both are out of scope of this workshop."
  },
  {
    "objectID": "index.html#basics-about-rstudio-pre-read",
    "href": "index.html#basics-about-rstudio-pre-read",
    "title": "Introduction",
    "section": "",
    "text": "If you are not used to working with R and RStudio so far, we recommend for you to familiarize yourself with the following useful content:\n\nRStudio User Guide\nRStudio Cheatsheet\nThe following two cheatsheets for dplyr (data wrangling) and ggplot2 (plotting and visualizations)\nThis video about Quarto"
  },
  {
    "objectID": "s1_visualization.html",
    "href": "s1_visualization.html",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "",
    "text": "Data on individuals followed over time with information collected at several time points.\nClusters are the individuals who are followed over time.\nRepeated observations may or may not be taken at regular times (balanced, fixed occasions, do not differ between subjects).\nOur interest is in the change from baseline.\n\nDatasets used in this course:\n\nExample data is taken from (Mallinckrodt and Lipkovich 2016). The authors generated data sets based on two nearly identically designed antidepressant clinical trials by randomly selecting subjects from the original data.\nContain data on the continuous variable HAMD17 (Hamilton 17-item rating scale for depression).\nTwo treatement arms are included: placebo (arm 1) vs. drug (arm 2).\nAssessments were taken at baseline and weeks 1, 2, 4, 6, and 8.\n\nThere are 3 data sets created from the original data:\n\nData all2 = Subsample of the large dataset with n=50, visits: weeks 2, 4, 8.\nData high2 = Large dataset with n=100, high dropout = 70% (drug), 60% (placebo).\nData low2 = Large dataset with n=100, low dropout = 18%.\n\nWe are mainly working with the all2 data set in the following. There is one application on the high2 data set. We are not considering the low2 data set.\n\n\n\n\nSmall data set with n=50 subjects.\n1st version: complete data where all subjects adhered to the originally assigend study medication, variable change\n2nd version = missing data: identical to the first except some data were missing (drop-out), variable chgdrop\n\nLooking at the variables in the data set\n\nhead(all2)\n\n# A tibble: 6 × 14\n  subject  time chgdrop trt   basval change pgiimp gender chgrescue dropout_grp \n  &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n1 1           1     -11 2         24    -11      3 F            -11 Week 2 Drop…\n2 1           2      NA 2         24    -16      2 F            -26 Week 2 Drop…\n3 1           3      NA 2         24    -24      2 F            -34 Week 2 Drop…\n4 2           1      -6 1         20     -6      4 F             -6 Week 2 Drop…\n5 2           2      NA 1         20     -8      4 F            -18 Week 2 Drop…\n6 2           3      NA 1         20     -5      5 F            -15 Week 2 Drop…\n# ℹ 4 more variables: aval &lt;dbl&gt;, avisit &lt;fct&gt;, week &lt;dbl&gt;, group &lt;fct&gt;\n\n\n\n\nOnly consider the complete data, variable change\n\nAre the data balanced and equally spaced?\nNumber of observations by week? - Summary statistics for HAMD17 (change from baseline) by week.\nPlot trajectories for each individual, different colors for each treatment group (or panels).\nAdd mean to your plot or generate new plot with mean change from baseline by treatment group.\nPlot mean change from baseline for each treatment group stratified by sex. Comment on the plot.\n\n\n\n\ndescribe(all2)\n\nall2 \n\n 14  Variables      150  Observations\n--------------------------------------------------------------------------------\nsubject \n       n  missing distinct \n     150        0       50 \n\nlowest : 1  2  3  4  5 , highest: 46 47 48 49 50\n--------------------------------------------------------------------------------\ntime \n       n  missing distinct     Info     Mean      Gmd \n     150        0        3    0.889        2   0.8949 \n                            \nValue          1     2     3\nFrequency     50    50    50\nProportion 0.333 0.333 0.333\n\nFor the frequency table, variable is rounded to the nearest 0.02\n--------------------------------------------------------------------------------\nchgdrop \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     129       21       26    0.996    -7.62     6.43      -17      -15 \n     .25      .50      .75      .90      .95 \n     -12       -7       -3       -1        0 \n\nlowest : -22 -20 -19 -18 -17, highest:   0   1   4   5   9\n--------------------------------------------------------------------------------\ntrt \n       n  missing distinct \n     150        0        2 \n                  \nValue        1   2\nFrequency   75  75\nProportion 0.5 0.5\n--------------------------------------------------------------------------------\nbasval \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     150        0       16    0.968    19.56    3.925     12.0     14.9 \n     .25      .50      .75      .90      .95 \n    19.0     20.0     21.0     23.1     24.0 \n                                                                            \nValue       8.00  9.89 11.78 12.86 13.94 14.75 16.91 17.99 18.80 19.88 20.96\nFrequency      3     3     3     3     3     3     6    12    30    42    12\nProportion  0.02  0.02  0.02  0.02  0.02  0.02  0.04  0.08  0.20  0.28  0.08\n                                        \nValue      21.77 22.85 23.93 25.82 35.00\nFrequency      6     9     9     3     3\nProportion  0.04  0.06  0.06  0.02  0.02\n\nFor the frequency table, variable is rounded to the nearest 0.27\n--------------------------------------------------------------------------------\nchange \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     150        0       27    0.996   -7.993    6.448   -17.55   -15.00 \n     .25      .50      .75      .90      .95 \n  -12.00    -8.00    -3.25    -1.00     0.00 \n\nlowest : -24 -22 -20 -19 -18, highest:   0   1   4   5   9\n--------------------------------------------------------------------------------\npgiimp : PGI IMPROVEMENT \n       n  missing distinct     Info     Mean      Gmd \n     149        1        7    0.924    2.859    1.206 \n                                                    \nValue       1.00  1.96  2.98  4.00  4.96  5.98  7.00\nFrequency     13    50    41    38     5     1     1\nProportion 0.087 0.336 0.275 0.255 0.034 0.007 0.007\n\nFor the frequency table, variable is rounded to the nearest 0.06\n--------------------------------------------------------------------------------\ngender : PATIENT SEX  Format:$ \n       n  missing distinct \n     150        0        2 \n                    \nValue         F    M\nFrequency    87   63\nProportion 0.58 0.42\n--------------------------------------------------------------------------------\nchgrescue \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     150        0       32    0.997   -9.393    8.003   -21.55   -19.00 \n     .25      .50      .75      .90      .95 \n  -14.00    -9.00    -4.00    -1.00     0.00 \n\nlowest : -34 -29 -26 -25 -23, highest:   0   1   4   5   9\n--------------------------------------------------------------------------------\ndropout_grp \n       n  missing distinct \n     150        0        3 \n                                                       \nValue           Completer Week 2 Dropout Week 4 Dropout\nFrequency             111             24             15\nProportion           0.74           0.16           0.10\n--------------------------------------------------------------------------------\naval \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     150        0       26    0.997    11.57    7.214     1.45     3.00 \n     .25      .50      .75      .90      .95 \n    7.00    11.00    16.75    19.00    21.00 \n\nlowest :  0  1  2  3  4, highest: 21 22 25 27 36\n--------------------------------------------------------------------------------\navisit \n       n  missing distinct \n     150        0        3 \n                               \nValue      Week 2 Week 4 Week 8\nFrequency      50     50     50\nProportion  0.333  0.333  0.333\n--------------------------------------------------------------------------------\nweek \n       n  missing distinct     Info     Mean      Gmd \n     150        0        3    0.889    4.667    2.685 \n                            \nValue       2.00  3.98  8.00\nFrequency     50    50    50\nProportion 0.333 0.333 0.333\n\nFor the frequency table, variable is rounded to the nearest 0.06\n--------------------------------------------------------------------------------\ngroup \n       n  missing distinct \n     150        0        2 \n                      \nValue      Arm 1 Arm 2\nFrequency     75    75\nProportion   0.5   0.5\n--------------------------------------------------------------------------------\n\n\n\n\n\n\nall2 %&gt;%\n  # group_by(Month) %&gt;%\n  miss_var_summary() %&gt;%\n  kable(caption = \"Missing data among variables\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nMissing data among variables\n\n\nvariable\nn_miss\npct_miss\n\n\n\n\nchgdrop\n21\n14.0000000\n\n\npgiimp\n1\n0.6666667\n\n\nsubject\n0\n0.0000000\n\n\ntime\n0\n0.0000000\n\n\ntrt\n0\n0.0000000\n\n\nbasval\n0\n0.0000000\n\n\nchange\n0\n0.0000000\n\n\ngender\n0\n0.0000000\n\n\nchgrescue\n0\n0.0000000\n\n\ndropout_grp\n0\n0.0000000\n\n\naval\n0\n0.0000000\n\n\navisit\n0\n0.0000000\n\n\nweek\n0\n0.0000000\n\n\ngroup\n0\n0.0000000\n\n\n\n\n\n\ngg_miss_var(all2 %&gt;% filter(group==\"Arm 1\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\ngg_miss_var(all2 %&gt;% filter(group==\"Arm 2\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\n\n\n\n\n\n# Plot individual lines for each patient\nggplot(data = all2, aes(x = factor(week), y = change, group = subject)) +  \n  geom_line(aes(colour = factor(group)), alpha = 0.5) +  # Individual lines for each patient\n  facet_wrap(~group) +\n  ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name = \"Visit [week]\", breaks = c(2, 4, 8)) +\n  scale_x_discrete(name = \"Visit [week]\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\nall2 %&gt;%\n  select(aval, group, avisit) %&gt;%\n  tbl_strata(strata=group, \n             ~.x %&gt;% \n               tbl_summary(by = avisit,\n                           statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"), \n      digits = all_continuous() ~ 2 ) %&gt;%\n      modify_header(label = \"**Variable**\")\n)\n\n\n\n\n\n  \n    \n    \n      Variable\n      \n        Arm 1\n      \n      \n        Arm 2\n      \n    \n    \n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n    \n  \n  \n    aval\n15.60 (5.06)\n13.00 (5.24)\n9.92 (5.50)\n14.08 (5.52)\n10.72 (5.14)\n6.08 (7.27)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\nall2 %&gt;%\n  select(change, group, avisit) %&gt;%\n  tbl_strata(strata=group, \n             ~.x %&gt;% \n               tbl_summary(by = avisit,\n                           statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"), \n      digits = all_continuous() ~ 2 ) %&gt;%\n      modify_header(label = \"**Variable**\")\n)\n\n\n\n\n\n  \n    \n    \n      Variable\n      \n        Arm 1\n      \n      \n        Arm 2\n      \n    \n    \n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n    \n  \n  \n    change\n-4.20 (3.66)\n-6.80 (4.25)\n-9.88 (4.85)\n-5.24 (5.49)\n-8.60 (5.39)\n-13.24 (5.54)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\nggplot(data = all2, aes(x = factor(week), y = change)) +  \n  geom_boxplot(aes(colour = factor(group))) + \n  ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2, 4, 8)) +\n  scale_x_discrete(name = \"Visit [week]\") +\n  theme_minimal()\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n# Calculate mean and standard deviation by group and week\nsummary_stats &lt;- all2 %&gt;%\n  group_by(week, group) %&gt;%\n  summarise(mean = mean(change, na.rm = TRUE),\n            sd = sd(change, na.rm = TRUE))\n\n`summarise()` has grouped output by 'week'. You can override using the\n`.groups` argument.\n\n# Plot with boxplot and labels for mean and SD by group\nggplot(data = all2, aes(x = factor(week), y = change, colour = factor(group))) +  \n  geom_boxplot() + \n  ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2, 4, 8)) +\n  scale_x_discrete(name = \"Visit [week]\") +\n  theme_minimal() +\n  # Add text labels for mean and SD by group and week\n  geom_text(data = summary_stats, aes(x = factor(week), y = mean + sd, \n                                      label = paste0(\"Mean: \", round(mean, 2), \n                                                     \"\\nSD: \", round(sd, 2)), \n                                      colour = factor(group)), \n            vjust = -0.5, size = 3, position = position_dodge(width = 0.75))\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\nggplot(data = all2, aes(x = week, y = change)) +  \n  geom_point(aes(colour=factor(group))) + ylab(\"Change from baseline HAMD17\") +\n  facet_wrap(~gender) +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2,4,8)) +\n  stat_summary(aes(group = group, colour=factor(group)), geom = \"line\", fun.y = mean,\n               size = 1) +\n  stat_summary(aes(group = group, colour=factor(group)), geom = \"point\", fun.y = mean,\n               shape=17,size = 2)\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\nall2 %&gt;% dplyr::select(gender, group) %&gt;% \n  tbl_summary(by=group,\n              type = all_continuous() ~ \"continuous2\", \n              label = list(Sex = \"Gender\", missing = \"no\")) %&gt;%\n  modify_header(label ~ \"Variable\") %&gt;%\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"Subgroup\") %&gt;%\n  bold_labels() %&gt;%\n  add_overall() \n\n\n\n\n\n  \n    \n    \n      Variable\n      Overall, N = 1501\n      \n        Subgroup\n      \n    \n    \n      Arm 1, N = 751\n      Arm 2, N = 751\n    \n  \n  \n    PATIENT SEX\n\n\n\n        F\n87 (58%)\n30 (40%)\n57 (76%)\n        M\n63 (42%)\n45 (60%)\n18 (24%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\nggplot(data = all2, aes(x = factor(week), y = change)) +  \n  geom_boxplot(aes(colour = factor(group))) + \n  facet_wrap(~gender) +\n  ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2, 4, 8)) +\n  scale_x_discrete(name = \"Visit [week]\") +\n  theme_minimal()\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n2nd version = missing data: identical to the first except some data were missing (drop-out), variable chgdrop\nThis version is later relevant when considering missing data. Thus, have a short look at the data.\n\nTable: Summary statistics for HAMD17 by treatment and week in the all2 data set with drop-outs\n\nall2 %&gt;%\n  select(chgdrop, group, avisit) %&gt;%\n  tbl_strata(strata=group, \n             ~.x %&gt;% \n               tbl_summary(by = avisit,\n                           statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"), \n      digits = all_continuous() ~ 2 ) %&gt;%\n      modify_header(label = \"**Variable**\")\n)\n\n\n\n\n\n  \n    \n    \n      Variable\n      \n        Arm 1\n      \n      \n        Arm 2\n      \n    \n    \n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n    \n  \n  \n    chgdrop\n-4.20 (3.66)\n-6.80 (4.63)\n-10.17 (4.88)\n-5.24 (5.49)\n-8.14 (5.27)\n-13.11 (5.44)\n        Unknown\n0\n5\n7\n0\n3\n6\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\nFigure: Mean change from baseline for each treatment group in the all2 data set with drop-outs\n\nggplot(data = all2, aes(x = week, y = chgdrop)) +  \n  geom_point(aes(colour=factor(group))) + ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2,4,8)) +\n  stat_summary(aes(group = group, colour=factor(group)), geom = \"line\", fun.y = mean,\n               size = 1) +\n  stat_summary(aes(group = group, colour=factor(group)), geom = \"point\", fun.y = mean,\n               shape=17,size = 2)\n\n\n\n\nFigure 1: Mean HAMD17 change from baseline by treatment group\n\n\n\n\n\n\n\n\n\n\nLarge data set with n=100 subjects.\nNote that we have no intermittent missing values but drop-outs.\n\nLooking at the variables in the data set.\n\nhead(high2)\n\n# A tibble: 6 × 16\n# Groups:   patient [2]\n  patient trt   poolinv basval  week change pgiimp   age gender  drop .groups\n    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;  \n1    1401 1     005         19     1     -7      3  44.5 F          2 drop   \n2    1401 1     005         19     2     -4      3  44.5 F          2 drop   \n3    1411 2     005         17     1      0      3  35.7 F          8 drop   \n4    1411 2     005         17     2     -2      3  35.7 F          8 drop   \n5    1411 2     005         17     4      2      3  35.7 F          8 drop   \n6    1411 2     005         17     6     -3      2  35.7 F          8 drop   \n# ℹ 5 more variables: aval &lt;dbl&gt;, group &lt;fct&gt;, avisit &lt;fct&gt;, dropout_grp &lt;fct&gt;,\n#   subject &lt;fct&gt;\n\n\n\n\n\nExplore the drop-outs e.g. number of observations by week.\nSummary statistics for HAMD17 change.\nGenerate and interpret the group-wise boxplots of the change from baseline.\nMean change from baseline for different drop-out groups (by treatment). Comment on the plot."
  },
  {
    "objectID": "s1_visualization.html#introduction",
    "href": "s1_visualization.html#introduction",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "",
    "text": "Data on individuals followed over time with information collected at several time points.\nClusters are the individuals who are followed over time.\nRepeated observations may or may not be taken at regular times (balanced, fixed occasions, do not differ between subjects).\nOur interest is in the change from baseline.\n\nDatasets used in this course:\n\nExample data is taken from (Mallinckrodt and Lipkovich 2016). The authors generated data sets based on two nearly identically designed antidepressant clinical trials by randomly selecting subjects from the original data.\nContain data on the continuous variable HAMD17 (Hamilton 17-item rating scale for depression).\nTwo treatement arms are included: placebo (arm 1) vs. drug (arm 2).\nAssessments were taken at baseline and weeks 1, 2, 4, 6, and 8.\n\nThere are 3 data sets created from the original data:\n\nData all2 = Subsample of the large dataset with n=50, visits: weeks 2, 4, 8.\nData high2 = Large dataset with n=100, high dropout = 70% (drug), 60% (placebo).\nData low2 = Large dataset with n=100, low dropout = 18%.\n\nWe are mainly working with the all2 data set in the following. There is one application on the high2 data set. We are not considering the low2 data set."
  },
  {
    "objectID": "s1_visualization.html#data-set-all2",
    "href": "s1_visualization.html#data-set-all2",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "",
    "text": "Small data set with n=50 subjects.\n1st version: complete data where all subjects adhered to the originally assigend study medication, variable change\n2nd version = missing data: identical to the first except some data were missing (drop-out), variable chgdrop\n\nLooking at the variables in the data set\n\nhead(all2)\n\n# A tibble: 6 × 14\n  subject  time chgdrop trt   basval change pgiimp gender chgrescue dropout_grp \n  &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n1 1           1     -11 2         24    -11      3 F            -11 Week 2 Drop…\n2 1           2      NA 2         24    -16      2 F            -26 Week 2 Drop…\n3 1           3      NA 2         24    -24      2 F            -34 Week 2 Drop…\n4 2           1      -6 1         20     -6      4 F             -6 Week 2 Drop…\n5 2           2      NA 1         20     -8      4 F            -18 Week 2 Drop…\n6 2           3      NA 1         20     -5      5 F            -15 Week 2 Drop…\n# ℹ 4 more variables: aval &lt;dbl&gt;, avisit &lt;fct&gt;, week &lt;dbl&gt;, group &lt;fct&gt;\n\n\n\n\nOnly consider the complete data, variable change\n\nAre the data balanced and equally spaced?\nNumber of observations by week? - Summary statistics for HAMD17 (change from baseline) by week.\nPlot trajectories for each individual, different colors for each treatment group (or panels).\nAdd mean to your plot or generate new plot with mean change from baseline by treatment group.\nPlot mean change from baseline for each treatment group stratified by sex. Comment on the plot.\n\n\n\n\ndescribe(all2)\n\nall2 \n\n 14  Variables      150  Observations\n--------------------------------------------------------------------------------\nsubject \n       n  missing distinct \n     150        0       50 \n\nlowest : 1  2  3  4  5 , highest: 46 47 48 49 50\n--------------------------------------------------------------------------------\ntime \n       n  missing distinct     Info     Mean      Gmd \n     150        0        3    0.889        2   0.8949 \n                            \nValue          1     2     3\nFrequency     50    50    50\nProportion 0.333 0.333 0.333\n\nFor the frequency table, variable is rounded to the nearest 0.02\n--------------------------------------------------------------------------------\nchgdrop \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     129       21       26    0.996    -7.62     6.43      -17      -15 \n     .25      .50      .75      .90      .95 \n     -12       -7       -3       -1        0 \n\nlowest : -22 -20 -19 -18 -17, highest:   0   1   4   5   9\n--------------------------------------------------------------------------------\ntrt \n       n  missing distinct \n     150        0        2 \n                  \nValue        1   2\nFrequency   75  75\nProportion 0.5 0.5\n--------------------------------------------------------------------------------\nbasval \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     150        0       16    0.968    19.56    3.925     12.0     14.9 \n     .25      .50      .75      .90      .95 \n    19.0     20.0     21.0     23.1     24.0 \n                                                                            \nValue       8.00  9.89 11.78 12.86 13.94 14.75 16.91 17.99 18.80 19.88 20.96\nFrequency      3     3     3     3     3     3     6    12    30    42    12\nProportion  0.02  0.02  0.02  0.02  0.02  0.02  0.04  0.08  0.20  0.28  0.08\n                                        \nValue      21.77 22.85 23.93 25.82 35.00\nFrequency      6     9     9     3     3\nProportion  0.04  0.06  0.06  0.02  0.02\n\nFor the frequency table, variable is rounded to the nearest 0.27\n--------------------------------------------------------------------------------\nchange \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     150        0       27    0.996   -7.993    6.448   -17.55   -15.00 \n     .25      .50      .75      .90      .95 \n  -12.00    -8.00    -3.25    -1.00     0.00 \n\nlowest : -24 -22 -20 -19 -18, highest:   0   1   4   5   9\n--------------------------------------------------------------------------------\npgiimp : PGI IMPROVEMENT \n       n  missing distinct     Info     Mean      Gmd \n     149        1        7    0.924    2.859    1.206 \n                                                    \nValue       1.00  1.96  2.98  4.00  4.96  5.98  7.00\nFrequency     13    50    41    38     5     1     1\nProportion 0.087 0.336 0.275 0.255 0.034 0.007 0.007\n\nFor the frequency table, variable is rounded to the nearest 0.06\n--------------------------------------------------------------------------------\ngender : PATIENT SEX  Format:$ \n       n  missing distinct \n     150        0        2 \n                    \nValue         F    M\nFrequency    87   63\nProportion 0.58 0.42\n--------------------------------------------------------------------------------\nchgrescue \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     150        0       32    0.997   -9.393    8.003   -21.55   -19.00 \n     .25      .50      .75      .90      .95 \n  -14.00    -9.00    -4.00    -1.00     0.00 \n\nlowest : -34 -29 -26 -25 -23, highest:   0   1   4   5   9\n--------------------------------------------------------------------------------\ndropout_grp \n       n  missing distinct \n     150        0        3 \n                                                       \nValue           Completer Week 2 Dropout Week 4 Dropout\nFrequency             111             24             15\nProportion           0.74           0.16           0.10\n--------------------------------------------------------------------------------\naval \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n     150        0       26    0.997    11.57    7.214     1.45     3.00 \n     .25      .50      .75      .90      .95 \n    7.00    11.00    16.75    19.00    21.00 \n\nlowest :  0  1  2  3  4, highest: 21 22 25 27 36\n--------------------------------------------------------------------------------\navisit \n       n  missing distinct \n     150        0        3 \n                               \nValue      Week 2 Week 4 Week 8\nFrequency      50     50     50\nProportion  0.333  0.333  0.333\n--------------------------------------------------------------------------------\nweek \n       n  missing distinct     Info     Mean      Gmd \n     150        0        3    0.889    4.667    2.685 \n                            \nValue       2.00  3.98  8.00\nFrequency     50    50    50\nProportion 0.333 0.333 0.333\n\nFor the frequency table, variable is rounded to the nearest 0.06\n--------------------------------------------------------------------------------\ngroup \n       n  missing distinct \n     150        0        2 \n                      \nValue      Arm 1 Arm 2\nFrequency     75    75\nProportion   0.5   0.5\n--------------------------------------------------------------------------------\n\n\n\n\n\n\nall2 %&gt;%\n  # group_by(Month) %&gt;%\n  miss_var_summary() %&gt;%\n  kable(caption = \"Missing data among variables\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nMissing data among variables\n\n\nvariable\nn_miss\npct_miss\n\n\n\n\nchgdrop\n21\n14.0000000\n\n\npgiimp\n1\n0.6666667\n\n\nsubject\n0\n0.0000000\n\n\ntime\n0\n0.0000000\n\n\ntrt\n0\n0.0000000\n\n\nbasval\n0\n0.0000000\n\n\nchange\n0\n0.0000000\n\n\ngender\n0\n0.0000000\n\n\nchgrescue\n0\n0.0000000\n\n\ndropout_grp\n0\n0.0000000\n\n\naval\n0\n0.0000000\n\n\navisit\n0\n0.0000000\n\n\nweek\n0\n0.0000000\n\n\ngroup\n0\n0.0000000\n\n\n\n\n\n\ngg_miss_var(all2 %&gt;% filter(group==\"Arm 1\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\ngg_miss_var(all2 %&gt;% filter(group==\"Arm 2\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\n\n\n\n\n\n# Plot individual lines for each patient\nggplot(data = all2, aes(x = factor(week), y = change, group = subject)) +  \n  geom_line(aes(colour = factor(group)), alpha = 0.5) +  # Individual lines for each patient\n  facet_wrap(~group) +\n  ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name = \"Visit [week]\", breaks = c(2, 4, 8)) +\n  scale_x_discrete(name = \"Visit [week]\") +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\nall2 %&gt;%\n  select(aval, group, avisit) %&gt;%\n  tbl_strata(strata=group, \n             ~.x %&gt;% \n               tbl_summary(by = avisit,\n                           statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"), \n      digits = all_continuous() ~ 2 ) %&gt;%\n      modify_header(label = \"**Variable**\")\n)\n\n\n\n\n\n  \n    \n    \n      Variable\n      \n        Arm 1\n      \n      \n        Arm 2\n      \n    \n    \n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n    \n  \n  \n    aval\n15.60 (5.06)\n13.00 (5.24)\n9.92 (5.50)\n14.08 (5.52)\n10.72 (5.14)\n6.08 (7.27)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\nall2 %&gt;%\n  select(change, group, avisit) %&gt;%\n  tbl_strata(strata=group, \n             ~.x %&gt;% \n               tbl_summary(by = avisit,\n                           statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"), \n      digits = all_continuous() ~ 2 ) %&gt;%\n      modify_header(label = \"**Variable**\")\n)\n\n\n\n\n\n  \n    \n    \n      Variable\n      \n        Arm 1\n      \n      \n        Arm 2\n      \n    \n    \n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n    \n  \n  \n    change\n-4.20 (3.66)\n-6.80 (4.25)\n-9.88 (4.85)\n-5.24 (5.49)\n-8.60 (5.39)\n-13.24 (5.54)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\nggplot(data = all2, aes(x = factor(week), y = change)) +  \n  geom_boxplot(aes(colour = factor(group))) + \n  ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2, 4, 8)) +\n  scale_x_discrete(name = \"Visit [week]\") +\n  theme_minimal()\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n# Calculate mean and standard deviation by group and week\nsummary_stats &lt;- all2 %&gt;%\n  group_by(week, group) %&gt;%\n  summarise(mean = mean(change, na.rm = TRUE),\n            sd = sd(change, na.rm = TRUE))\n\n`summarise()` has grouped output by 'week'. You can override using the\n`.groups` argument.\n\n# Plot with boxplot and labels for mean and SD by group\nggplot(data = all2, aes(x = factor(week), y = change, colour = factor(group))) +  \n  geom_boxplot() + \n  ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2, 4, 8)) +\n  scale_x_discrete(name = \"Visit [week]\") +\n  theme_minimal() +\n  # Add text labels for mean and SD by group and week\n  geom_text(data = summary_stats, aes(x = factor(week), y = mean + sd, \n                                      label = paste0(\"Mean: \", round(mean, 2), \n                                                     \"\\nSD: \", round(sd, 2)), \n                                      colour = factor(group)), \n            vjust = -0.5, size = 3, position = position_dodge(width = 0.75))\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\nggplot(data = all2, aes(x = week, y = change)) +  \n  geom_point(aes(colour=factor(group))) + ylab(\"Change from baseline HAMD17\") +\n  facet_wrap(~gender) +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2,4,8)) +\n  stat_summary(aes(group = group, colour=factor(group)), geom = \"line\", fun.y = mean,\n               size = 1) +\n  stat_summary(aes(group = group, colour=factor(group)), geom = \"point\", fun.y = mean,\n               shape=17,size = 2)\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\nall2 %&gt;% dplyr::select(gender, group) %&gt;% \n  tbl_summary(by=group,\n              type = all_continuous() ~ \"continuous2\", \n              label = list(Sex = \"Gender\", missing = \"no\")) %&gt;%\n  modify_header(label ~ \"Variable\") %&gt;%\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"Subgroup\") %&gt;%\n  bold_labels() %&gt;%\n  add_overall() \n\n\n\n\n\n  \n    \n    \n      Variable\n      Overall, N = 1501\n      \n        Subgroup\n      \n    \n    \n      Arm 1, N = 751\n      Arm 2, N = 751\n    \n  \n  \n    PATIENT SEX\n\n\n\n        F\n87 (58%)\n30 (40%)\n57 (76%)\n        M\n63 (42%)\n45 (60%)\n18 (24%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\nggplot(data = all2, aes(x = factor(week), y = change)) +  \n  geom_boxplot(aes(colour = factor(group))) + \n  facet_wrap(~gender) +\n  ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2, 4, 8)) +\n  scale_x_discrete(name = \"Visit [week]\") +\n  theme_minimal()\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\n\n\n\n\n\n\n\n\n2nd version = missing data: identical to the first except some data were missing (drop-out), variable chgdrop\nThis version is later relevant when considering missing data. Thus, have a short look at the data.\n\nTable: Summary statistics for HAMD17 by treatment and week in the all2 data set with drop-outs\n\nall2 %&gt;%\n  select(chgdrop, group, avisit) %&gt;%\n  tbl_strata(strata=group, \n             ~.x %&gt;% \n               tbl_summary(by = avisit,\n                           statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"), \n      digits = all_continuous() ~ 2 ) %&gt;%\n      modify_header(label = \"**Variable**\")\n)\n\n\n\n\n\n  \n    \n    \n      Variable\n      \n        Arm 1\n      \n      \n        Arm 2\n      \n    \n    \n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n    \n  \n  \n    chgdrop\n-4.20 (3.66)\n-6.80 (4.63)\n-10.17 (4.88)\n-5.24 (5.49)\n-8.14 (5.27)\n-13.11 (5.44)\n        Unknown\n0\n5\n7\n0\n3\n6\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\nFigure: Mean change from baseline for each treatment group in the all2 data set with drop-outs\n\nggplot(data = all2, aes(x = week, y = chgdrop)) +  \n  geom_point(aes(colour=factor(group))) + ylab(\"Change from baseline HAMD17\") +\n  scale_x_continuous(name=\"Visit [week]\", breaks=c(2,4,8)) +\n  stat_summary(aes(group = group, colour=factor(group)), geom = \"line\", fun.y = mean,\n               size = 1) +\n  stat_summary(aes(group = group, colour=factor(group)), geom = \"point\", fun.y = mean,\n               shape=17,size = 2)\n\n\n\n\nFigure 1: Mean HAMD17 change from baseline by treatment group"
  },
  {
    "objectID": "s1_visualization.html#data-set-high2",
    "href": "s1_visualization.html#data-set-high2",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "",
    "text": "Large data set with n=100 subjects.\nNote that we have no intermittent missing values but drop-outs.\n\nLooking at the variables in the data set.\n\nhead(high2)\n\n# A tibble: 6 × 16\n# Groups:   patient [2]\n  patient trt   poolinv basval  week change pgiimp   age gender  drop .groups\n    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;  \n1    1401 1     005         19     1     -7      3  44.5 F          2 drop   \n2    1401 1     005         19     2     -4      3  44.5 F          2 drop   \n3    1411 2     005         17     1      0      3  35.7 F          8 drop   \n4    1411 2     005         17     2     -2      3  35.7 F          8 drop   \n5    1411 2     005         17     4      2      3  35.7 F          8 drop   \n6    1411 2     005         17     6     -3      2  35.7 F          8 drop   \n# ℹ 5 more variables: aval &lt;dbl&gt;, group &lt;fct&gt;, avisit &lt;fct&gt;, dropout_grp &lt;fct&gt;,\n#   subject &lt;fct&gt;\n\n\n\n\n\nExplore the drop-outs e.g. number of observations by week.\nSummary statistics for HAMD17 change.\nGenerate and interpret the group-wise boxplots of the change from baseline.\nMean change from baseline for different drop-out groups (by treatment). Comment on the plot."
  },
  {
    "objectID": "s1_visualization.html#overview---different-covariance-matrices",
    "href": "s1_visualization.html#overview---different-covariance-matrices",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "Overview - different covariance matrices",
    "text": "Overview - different covariance matrices\n\nVariance components (VC) independence structure\nCompound symmetry (CS) also known as exchangeable\nToeplitz (TOEP)\nFirst order auto regressive (AR(1))\nUnstructured (UN)\n\nSelected covariance structures for data with three assessment times (t=3) are shown below. Note that with three assessment times, the number of parameters estimated for the various structures did not differ as much as would be the case with more assessment times. Thus, results from different covariance structures are more similar than would be the case with more assessment times.\n\nIndependence structure (VC)\nConstant variance. It is assumed to be no correlation between assessments (residuals are independent across time). \\[ R = \\begin{bmatrix}\n   \\sigma^2   & 0  & 0  \\\\\n   0  & \\sigma^2   & 0 \\\\\n   0  & 0  & \\sigma^2\n   \\end{bmatrix}\\]\n\n\nCompound symmetry (CS)\nConstant variance and constant covariance across all assessments. Also known as exchangeable. It requires two parameter estimates. Most simplest repeated measures (i.e., correlated errors) structure.\n\\[ R = \\begin{bmatrix}\n   \\sigma^2 + \\sigma_1 & \\sigma_1  & \\sigma_1  \\\\\n   \\sigma_1  & \\sigma^2 + \\sigma_1  & \\sigma_1  \\\\\n   \\sigma_1  & \\sigma_1  & \\sigma^2 + \\sigma_1\n   \\end{bmatrix}\\]\n\n\nUnstructured (UN)\nThis is the most general (saturated) model. It has t + [t(t-1)/2] parameters to be estimated. Here it is 3 + 3 = 6 parameters.\n\\[ R = \\begin{bmatrix}\n   \\sigma_1^2 & \\sigma_{21}  & \\sigma_{31}  \\\\\n   \\sigma_{21}  & \\sigma_2^2   & \\sigma_{32}  \\\\\n   \\sigma_{31}  & \\sigma_{32}  & \\sigma_3^2\n   \\end{bmatrix}\\]\n\n\nToeplitz structure (TOEP)\nHomogenous variances and heterogenous correlations. Same correlation value is used whenever the degree of adjacency is the same e.g. correlation between times 1 and 2 = correlation between times 2 and 3. Repeated measurements are assumed to be equally spaced. TOEP requries t parameter estimates so here we have t=3 parameter.\n\\[ R = \\begin{bmatrix}\n   \\sigma^2  & \\sigma_1^2 & \\sigma_2^2 \\  \\\\\n   \\sigma_1^2 & \\sigma^2  & \\sigma_1^2  \\\\\n   \\sigma_2^2  & \\sigma_1^2 & \\sigma^2\n   \\end{bmatrix}\\]\n\n\nAutoregressive structure (AR(1))\nCorrelation decreases as time between observations increases. Assumtpion of equal spacing between each repeated measurement must be reasonably applicable. This structure requires the estimation of two parameters.\n\\[ R = \\begin{bmatrix}\n   \\sigma^2  & \\sigma^2 \\rho  & \\sigma^2 \\rho^2  \\\\\n   \\sigma^2 \\rho & \\sigma^2   & \\sigma^2 \\rho  \\\\\n  \\sigma^2 \\rho^2  & \\sigma^2 \\rho  & \\sigma^2\n   \\end{bmatrix}\\]\n\n\nSpatial Power (SP)\nSpatial covariance structures does not require equal spacing between measurements. Instead, as long as the distance between visits can be quantified in terms of time and/or other coordinates, the spatial covariance structure can be applied. Covariances are mathematical functions of Euclidean distances between observed measurements. Again, two parameters need to be estimated.\nFor spatial exponential, the covariance structure is defined as follows:\n\\[ R = \\begin{bmatrix}\n   \\sigma^2  & \\sigma^2 \\rho_{12}  & \\sigma^2 \\rho_{13}  \\\\\n   \\sigma^2 \\rho_{21} & \\sigma^2   & \\sigma^2 \\rho_{23}  \\\\\n  \\sigma^2 \\rho_{31}  & \\sigma^2 \\rho_{32}  & \\sigma^2\n   \\end{bmatrix}\\]\nwith \\[ \\rho_{ij}=\\rho^{d_{ij}} \\] where \\[d_{ij} \\] is the distance between time point i and time point j e.g. distance in weeks."
  },
  {
    "objectID": "s1_visualization.html#selecting-the-covariance-structure",
    "href": "s1_visualization.html#selecting-the-covariance-structure",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "Selecting the covariance structure",
    "text": "Selecting the covariance structure\nThere are a variety of considerations when selecting the covariance structure:\n\nnumber of parameters\ninterpretation of the structure\nmodel fit\n\nUN is the most flexible (complex) structure and can fail to run especially if one has many repeated measures. Choose a reasonable covaraiance structure which is the best compromise between model fit and complexity. E.g. use AIC as it penalises more complex models."
  },
  {
    "objectID": "s1_visualization.html#task-3---exploration-of-correlation-in-the-data",
    "href": "s1_visualization.html#task-3---exploration-of-correlation-in-the-data",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "Task 3 - Exploration of correlation in the data",
    "text": "Task 3 - Exploration of correlation in the data\n\nCompute the empirical correlations between measurement timepoints in the all2 data set (e.g. correlation between baseline and post-baseline changes, variable change).\nLooking at these correlations + using your knowledge of the experiment (e.g., spacing of measurements), comment on the suitability of the correlation structures VC, CS, UN, AR(1).\n\n\nCompute the correlation matrix\n\n# Reshape data from long to wide format\nwide_base &lt;- all2 %&gt;%\n  select(subject, week, basval) %&gt;%\n  pivot_wider(names_from = week, values_from = basval, names_prefix = \"Base_\") %&gt;%\n  select(Base_2)\n\n\nwide_data &lt;- all2 %&gt;%\n  select(subject, week, change) %&gt;%\n  pivot_wider(names_from = week, values_from = change, names_prefix = \"week_\")\n\nwide_new &lt;- cbind(wide_data,wide_base) \nwide_new &lt;- wide_new %&gt;%\n  select(subject,Base_2,week_2,week_4,week_8)\n \n\n# Compute the correlation matrix for the wide data (excluding the 'subject' column)\ncor_matrix &lt;- cor(wide_new[ , -1], use = \"complete.obs\")\n# Print the correlation matrix\nprint(cor_matrix)\n\n            Base_2     week_2     week_4      week_8\nBase_2  1.00000000 -0.2636447 -0.3165711 -0.02915138\nweek_2 -0.26364471  1.0000000  0.7557078  0.51502724\nweek_4 -0.31657106  0.7557078  1.0000000  0.71298768\nweek_8 -0.02915138  0.5150272  0.7129877  1.00000000\n\nlibrary(\"ggcorrplot\")\n# Plot the correlation matrix\nggcorrplot(cor_matrix, \n           type = \"full\",       \n           lab = TRUE,          # Add correlation coefficient labels\n           lab_size = 3,        # Size of the labels\n           colors = c(\"red\", \"white\", \"blue\"),  \n           title = \"Correlation Matrix\",\n           ggtheme = theme_minimal())  \n\n\n\ncov(wide_new[ , -1], use = \"complete.obs\")\n\n           Base_2    week_2    week_4     week_8\nBase_2 16.3330612 -4.955918 -6.253061 -0.6391837\nweek_2 -4.9559184 21.634286 17.179592 12.9967347\nweek_4 -6.2530612 17.179592 23.887755 18.9061224\nweek_8 -0.6391837 12.996735 18.906122 29.4351020"
  },
  {
    "objectID": "s1_visualization.html#task-3---discussion-and-possible-solution",
    "href": "s1_visualization.html#task-3---discussion-and-possible-solution",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "Task 3 - Discussion and possible solution",
    "text": "Task 3 - Discussion and possible solution\nTable: Correlation and covariance matrix\n\nall2.w &lt;- all2 %&gt;% \n  pivot_wider(id_cols=subject,names_from = time, values_from = c(basval,change)) %&gt;% \n  select(-c(basval_2,basval_3))\n\ncor(all2.w[-1]) \n\n            basval_1   change_1   change_2    change_3\nbasval_1  1.00000000 -0.2636447 -0.3165711 -0.02915138\nchange_1 -0.26364471  1.0000000  0.7557078  0.51502724\nchange_2 -0.31657106  0.7557078  1.0000000  0.71298768\nchange_3 -0.02915138  0.5150272  0.7129877  1.00000000\n\ncov(all2.w[-1])\n\n           basval_1  change_1  change_2   change_3\nbasval_1 16.3330612 -4.955918 -6.253061 -0.6391837\nchange_1 -4.9559184 21.634286 17.179592 12.9967347\nchange_2 -6.2530612 17.179592 23.887755 18.9061224\nchange_3 -0.6391837 12.996735 18.906122 29.4351020"
  },
  {
    "objectID": "s1_visualization.html#taking-a-step-back-consequences-of-ignoring-correlation-among-longitudinal-data",
    "href": "s1_visualization.html#taking-a-step-back-consequences-of-ignoring-correlation-among-longitudinal-data",
    "title": "Longitudinal Data Exploration and Visualization",
    "section": "Taking a step back: Consequences of Ignoring Correlation among Longitudinal Data",
    "text": "Taking a step back: Consequences of Ignoring Correlation among Longitudinal Data\nThis technical detour is motivated by (Fitzmaurice 2011). Let us assume we are only interested in the first two responses in a clinical study, say Visit 1 (Baseline) and Visit 2. Our interest lies in an assessment of mean changes over time (for the sake of simplicity in a single treatment group only), i.e. we wish to estimate\n\\[\n\\hat\\delta := \\hat\\mu_2 - \\hat\\mu_1 = \\frac{1}{N} \\sum_{i=1}^N (Y_{i2} - Y_{i1})\\,,\n\\]\nwhere \\(Y_{i1}\\) and \\(Y_{i2}\\) are observations from subject \\(i\\) at Visit 1 and Visit 2, respectively. To obtain the standard error (SE) and get a notion of variability, we compute the variance of \\(\\hat\\delta\\) and see that\n\\[\n\\text{Var}(\\hat\\delta) = \\text{Var}\\left(\\frac{1}{N} \\sum_{i=1}^N (Y_{i2} - Y_{i1})\\right) = \\frac{1}{N} (\\sigma_1^2 + \\sigma_2^2 - 2\\sigma_{12})\\,.\n\\]\nThe inclusion of the term \\(- 2\\sigma_{12}\\) accounts for the correlation between responses at Visit 1 and Visit 2. As data from adjacent visits is usually positively correlated, the omission of the correlation term leads to an overestimation of the variance and thus the SE associated with the treatment effect."
  },
  {
    "objectID": "s3_missingness.html",
    "href": "s3_missingness.html",
    "title": "Missing Data",
    "section": "",
    "text": "## get the wd path\n# setwd(dirname(rstudioapi::getSourceEditorContext()$path))\n# getwd()\nsource(\"setup.R\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nmmrm() registered as emmeans extension\n\n\nWarning: package 'rbmi' was built under R version 4.3.3\n\n\n\nAttaching package: 'rbmi'\n\nThe following object is masked from 'package:tidyr':\n\n    expand\n\n\nAttaching package: 'Hmisc'\n\nThe following object is masked from 'package:gt':\n\n    html\n\nThe following object is masked from 'package:rbmi':\n\n    impute\n\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\nSo far, we conducted all our analyses on the basis of complete data. This is a blissful, yet highly unusual setting.\nWe use the following definition for missing data, borrowed from (Roderick JA Little 2019):\n“Missing data are unobserved values that would be meaningful for analysis if observed; in other words, a missing value hides a meaningful value.”\nWe distinguish the following patterns of missingness:\n\nMonotonic missingness/ dropout: All values by a subject after a certain time are missing. More specifically, if responses are missing at visit \\(n \\in \\mathbb{N}\\), then responses are also missing for every subsequent visit \\(n + m\\), for all \\(m \\in \\mathbb{N}\\). Example: Subject drop-out from the clinical study.\nIntermittend missingness: Subjects miss one or several visits, but return for later visits. Example: A subject with data collected at baseline and Time 1 (Week 2), a missing value at Time 2 (Week 4) and a non-missing value at Time 3 (Week 8).\n\nNote that, following the nomenclature introduced by (Roderick JA Little 2019), we use the term missing data pattern, to describe which data are missing in the data matrix of subject responses, and the term missing data mechanism, which describes the relationship between missing and observed values in the subject responses.\nOur dataset contains a second variable chgdrop, which is subject to missingness. Let’s rerun our initial MMRM with chgdrop as dependent variable, baseline value, visit, baseline by visit interaction and treatment by visit interaction as fixed effects and an unstructured covariance matrix for visits within each subject.\nThis formulation is very similar to the one at the beginning of the former chapter. How do the results differ in terms of LS Means of change from baseline by treatment arm over time?\n\nfit_cat_time &lt;- mmrm::mmrm(\n  formula = chgdrop ~ basval*avisit + trt*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\n# summary(fit_cat_time)\n\nmodel_lsmeans &lt;- emmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\")\nmodel_lsmeans\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.10 0.900 47.0    -5.91    -2.29\n 2   Week 2  -5.29 0.899 47.0    -7.10    -3.48\n 1   Week 4  -6.42 0.974 46.5    -8.38    -4.46\n 2   Week 4  -8.52 0.951 44.8   -10.43    -6.60\n 1   Week 8  -9.73 1.142 40.4   -12.03    -7.42\n 2   Week 8 -12.62 1.114 40.1   -14.88   -10.37\n\nConfidence level used: 0.95 \n\nemmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\") %&gt;% \n  contrast(\n    list(\n      \"Difference in LS Means at Week 8\" = c(0, 0, 0, 0, -1, 1),\n      \"Difference in longitudinal LS Means to Week 8\" = c(-1, 1, -1, 1, -1, 1)/3\n    )\n  )\n\n contrast                                      estimate   SE   df t.ratio\n Difference in LS Means at Week 8                 -2.90 1.60 40.3  -1.814\n Difference in longitudinal LS Means to Week 8    -2.06 1.23 46.8  -1.671\n p.value\n  0.0771\n  0.1014\n\n\nTo understand the nature of the differences between the model using change as a response variable and the one with chgdrop, we need to look closer into the extent of missing data and understand its nature.\n\n\nTo understand the nature of missing data in our clinical trial, we consider the following taxonomy, introduced by (Roderick JA Little 2019). We differentiate between the following three types of missing data:\n\nMissing Completely at Random (MCAR): Conditional on all covariates in our analysis, the probability of missingness does not depend on either observed or unobserved values of the response variable.\nMissing at Random (MAR): Conditional on all covariates and observed response values in our analysis, the probability of missingness does not depend on the unobserved values of the response variable.\nMissing not at Random (MNAR): Conditional on all covariates and observed response values in our analysis, the probability of missingness does depend on the unobserved values of the response variable.\n\n(Mallinckrodt and Lipkovich 2016) give the following interpretation around the three types of missingness:\n“With MCAR, the outcome variable is not related to the probability of dropout (after taking into account covariates). In MAR, the observed values of the outcome variable are related to the probability of dropout, but the unobserved outcomes are not (after taking into account covariates and observed outcomes). In MNAR the unobserved outcomes are related to the probability of dropout even after the observed outcomes and covariates have been taken into account.”\nThe following two sections outline handling strategies for missing data. However, the best approach to handle missing data is to minimise its extent. While the occurence of missing data can rarely be avoided at all (think about the collection of questionnaire data in oncology studies and the missing data after subjects die), it is important to pursue an “as complete as can be” data collection.\nBaseline and screening data are of utmost importance in a pursuit of data completeness. If a screening value is missing, but was meant to be used as a covariate, this subjects’ whole data will be dropped from the analysis even if all responses were observed. If the baseline response variable was missing we are unable to compute a change from baseline, which also leads to the loss of this subjects’ data in the model (although LDA models are still able to provide an estimate) even if all post-baseline values were observed.\n\n\n\nTo gain an understanding of the impact of missingness on the average response trajectories, we can plot the mean changes from baseline by visit for each drop-out group. The three drop-out groups (variable dropout_grp) are:\n\nDrop-outs at Week 2: Subjects who completed baseline and Week 2, but discontinued from the study prior to Week 4.\nDrop-outs at Week 4: Subjects who completed baseline, Week 2 and Week 4, but discontinued from the study prior to Week 8.\nCompleters: Subjects who completed all visits in the study.\n\n\n\n\n\n\nExercise: Try to interpret the plot above and discuss the following topics around missingness:\n\n\n\nQ1&gt; Look into the data. Which missing data pattern is present in this dataset?\n\nFrom the plot, we can infer that there is a monotone missing data pattern. This is characterized by participants dropping out of the study at specific points (Weeks 2 and 4), and then no further data is collected for them. The plot shows how participants who drop out at different weeks (Week 2 and Week 4) exhibit a decline in their measured outcome prior to dropping out. We can observe distinct trajectories for those who complete the study versus those who drop out.\n\nall2 %&gt;%\n  # group_by(Month) %&gt;%\n  miss_var_summary() %&gt;%\n  kable(caption = \"Missing data among variables\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nMissing data among variables\n\n\nvariable\nn_miss\npct_miss\n\n\n\n\nchgdrop\n21\n14.0000000\n\n\npgiimp\n1\n0.6666667\n\n\nsubject\n0\n0.0000000\n\n\ntime\n0\n0.0000000\n\n\ntrt\n0\n0.0000000\n\n\nbasval\n0\n0.0000000\n\n\nchange\n0\n0.0000000\n\n\ngender\n0\n0.0000000\n\n\nchgrescue\n0\n0.0000000\n\n\ndropout_grp\n0\n0.0000000\n\n\naval\n0\n0.0000000\n\n\navisit\n0\n0.0000000\n\n\nweek\n0\n0.0000000\n\n\ngroup\n0\n0.0000000\n\n\n\n\n\n\n## Exploring missing data\nvis_miss(all2)\n\n\n\ngg_miss_var(all2 %&gt;% filter(group==\"Arm 1\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\ngg_miss_var(all2 %&gt;% filter(group==\"Arm 2\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\n\n\nQ2&gt; What can be seen in the plot? How does the drop-out time affect the observed mean response trajectories?\n\nDropout Trajectories\n\nParticipants who drop out at Week 2 or Week 4 show a different mean change from baseline compared to completers. For example, those dropping out earlier seem to have a more abrupt or flatter decline, indicating that their treatment response may be different from completers.\n\nCompleter Trajectories\n\nThe completers in both treatment groups exhibit a smoother and more sustained decline, suggesting better outcomes than the dropouts.\n\nEffect of Dropout Time\n\nThe earlier the dropout, the less steep the observed decline from baseline. This could be due to several factors, such as treatment inefficacy for those participants or increased adverse effects, leading to their dropout.\nDropouts at Week 4 have trajectories closer to the completers but are still distinct, indicating some level of divergence in treatment response.\nQ3&gt; What other aspects, apart from response, could influence a subjects’ likelihood to drop-out from the study?\n\nOther Factors Influencing Dropout Likelihood Apart from the measured response (mean change from baseline), several other factors could influence a subject’s likelihood of dropping out from the study:\n\nAdverse effects: Participants experiencing more severe side effects may drop out earlier.\nPersonal circumstances: Life events unrelated to the study (e.g., work, family issues) may cause participants to discontinue participation.\nLack of perceived treatment efficacy: Participants who feel the treatment is not working may lose motivation to continue.\nQ4&gt; Which other summaries/ visualizations can be useful to characterize and monitor the degree of missingness in clinical study data?\n\nOther Summaries/Visualizations to Characterize Missingness To better characterize and monitor missingness in clinical study data, the following summaries and visualizations could be useful:\n\nMissing Data Patterns Table: A summary table showing the number of subjects missing data at each time point.\nKaplan-Meier Plot for Time-to-Dropout: This would allow us to examine the dropout pattern over time, showing how many participants remain in the study at each time point.\nProportional Missingness Plot: A bar chart showing the proportion of missing data for each variable at each time point.\nCorrelation Heatmap: Showing correlations between missingness patterns and other variables (e.g., baseline characteristics, adverse events).\nTrajectory Plots for Subgroups: Similar to the plot provided, but stratified by potential confounders (e.g., age, gender) to see if missingness varies across subgroups.\n\n\n\n\nA look into the data shows that all missing values stem from a monotinic missingness pattern.\nThe figure above shows a notable difference between mean response trajectories per drop-out group. The completers in both treatment arms show a steady decrease of HAMD17 scores over time, which is equivalent to an increase in depression symptoms.\nWeek 4 drop-outs under treatment 2 only showed a moderate change from baseline, while the treatment 1 subjects experienced an increase in HAMD17 scores. A possible explanation could be that changes under treatment 2 were not regarded meaningful by patients, while the increase in scores under treatment 1 made subjects drop out of the study.\nWeek 2 drop-outs under treatment 2 showed notable improvements of HAMD17 scores compared to treatment 1, yet the drop-out could potentially be linked to the occurrence of adverse events.\nAlthough the extent of missing data should be reduced to the bare minimum, it can never be avoided completely, especially with Patient-Reported Outcomes (PRO) data. In the reporting of PRO clinical trial data, it is therefore important to transparently summarize the extent of missingness. This is usually done via so-called compliance tables.\nCompliance tables summarize three key components to characterize missingness in our data:\n\nThe number of subjects initially randomized in the trial.\nThe number of subjects for whom data is expected. This is the number of patients who are still ongoing in the study (alive and not discontinued) and for whom an assessment is scheduled following the schedule of assessments in the clinical trial protocol.\nThe number of subjects by whom the assessment has been completed.\n\nFrom these numbers, we can derive the available data rate and the compliance for visit \\(i\\) as follows:\n\\[\n\\begin{aligned}\n\\text{Available Data Rate}_{\\,i} &:= 100\\,\\frac{\\#\\{\\text{Subj. with assessment i completed}\\}}{\\#\\{\\text{Subj. randomized}\\}}\\,,\\\\\n\\text{Compliance Rate}_{\\,i} &:= 100\\,\\frac{\\#\\{\\text{Subj. with assessment i completed}\\}}{\\#\\{\\text{Subj. assessment i expected}\\}}\\,.\n\\end{aligned}\n\\]\n\n\n\n\nThis section provides an overview of simple and most of the times overly naive methods to deal with missing data. Although we will introduce more suitable methods in the next chapter, the approaches introduced in this section have gained questionable popularity in the past, which is why we introduce them here. The following methods to compute or completely ignore missing data exist:\n\nComplete Case Analysis: Discard all subjects with missing observations and only conduct the analysis on subjects with complete follow-up data.\nLast observation carried forward (LOCF): Handling of monotonic missing data. The missing visits are imputed with the last non-missing value. This approach assumes a constant trend of observations after drop-out from the study, i.e. the response level remains the same as the last response under the study drug.\nBaseline observation carried forward (BOCF): Handling of monotonic missing data. The missing visits are imputed with the baseline value. This approach assumes that subjects’ symptom severity or functioning (whichever was measured in the study) bounce back to the baseline state, prior to the intiation of the study drug.\n\n\n\nLet us run a complete case analysis on the all2 dataset.\nExercise: Fit an MMRM with response variable chgdrop, with baseline severity, treatment and visit as fixed effects, as well as baseline-by-visit and treatment-by-visit interaction, using an unstructured variance-covariance matrix on the all2 completers.\n\nHow do the results differ from the results obtained in the former chapter (response variable change, no missing data)?\nHow do the results differ from the results obtained at the beginning of this chapter (response variable chgdrop with missing data)?\nDiscuss the limitations of the complete case analysis. Which sources of bias can you identify?\n\nSignificant Impact in Multivariate Analysis: In complex multivariate analyses, list-wise deletion can lead to substantial loss of statistical information due to a reduction in the effective sample size.\nThe varying sample size due to list-wise deletion makes it difficult to maintain a consistent set of inputs across analyses.\nPotential for Bias in Estimations: CCA assumes that the data are Missing Completely at Random (MCAR)—i.e., the probability of missingness is independent of both observed and unobserved data. However, in most real-world scenarios, data are more likely Missing at Random (MAR) or Missing Not at Random (MNAR).\nSelection Bias\n\n\nSolution:\nWe firstly select our completers dataset. As this is a filtering exercise based on post-baseline characteristics, we first look into the distribution of subjects per treatment arm (note that we lost our randomization effect):\n\nall2_comp &lt;- dplyr::filter(all2, dropout_grp == \"Completer\")\n\nall2_comp %&gt;% \n  dplyr::group_by(group) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n_distinct(subject),\n    .groups = \"drop\"\n  )\n\n# A tibble: 2 × 2\n  group     N\n  &lt;fct&gt; &lt;int&gt;\n1 Arm 1    18\n2 Arm 2    19\n\n### Work with code chunks to find the solution to the exercises\nall2_cca &lt;- all2 %&gt;%\n  group_by(subject) %&gt;%                    \n  filter(all(!is.na(chgdrop))) %&gt;%          \n  ungroup()    \n\nIn this case, we are left with 18 and 19 subjects per arm, which reduced our sample size notably, but at least left us with close to equal sizes of our treatment groups. This is not normal. Usually the stratification of data based on post-baseline assessments can lead to imbalances (it might still have, as we only checked the distribution of the treatment arms).\n\n### Complete Case Analysis\nfit_cat_time_compl &lt;- mmrm::mmrm(\n  formula = chgdrop ~ basval*avisit + trt*avisit + us(avisit | subject),\n  data = all2_comp,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nsummary(fit_cat_time_compl)\n\nmmrm fit\n\nFormula:     chgdrop ~ basval * avisit + trt * avisit + us(avisit | subject)\nData:        all2_comp (used 111 observations from 37 subjects with maximum 3 \ntimepoints)\nCovariance:  unstructured (6 variance parameters)\nMethod:      Kenward-Roger\nVcov Method: Kenward-Roger\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n   608.8    618.5   -298.4    596.8 \n\nCoefficients: \n                     Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)           1.89223    3.60558  33.99000   0.525 0.603124    \nbasval               -0.31950    0.17281  33.99000  -1.849 0.073201 .  \navisitWeek 4         -1.63943    2.46046  34.00000  -0.666 0.509708    \navisitWeek 8        -12.36928    3.39084  34.00000  -3.648 0.000877 ***\ntrt2                 -1.13978    1.56623  33.99000  -0.728 0.471768    \nbasval:avisitWeek 4  -0.05179    0.11793  34.00000  -0.439 0.663301    \nbasval:avisitWeek 8   0.33515    0.16252  34.00000   2.062 0.046899 *  \navisitWeek 4:trt2    -0.99990    1.06880  34.00000  -0.936 0.356113    \navisitWeek 8:trt2    -1.78825    1.47295  34.00000  -1.214 0.233089    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        Week 2  Week 4  Week 8\nWeek 2 23.2319 16.8721 14.6422\nWeek 4 16.8721 21.7589 17.9166\nWeek 8 14.6422 17.9166 27.5347\n\nmodel_lsmeans &lt;- emmeans::emmeans(fit_cat_time_compl, ~trt*avisit, weights = \"proportional\")\nmodel_lsmeans\n\n trt avisit emmean   SE df lower.CL upper.CL\n 1   Week 2  -4.33 1.12 34    -6.61    -2.06\n 2   Week 2  -5.47 1.09 34    -7.69    -3.26\n 1   Week 4  -6.98 1.09 34    -9.19    -4.77\n 2   Week 4  -9.12 1.06 34   -11.27    -6.97\n 1   Week 8 -10.17 1.21 34   -12.63    -7.71\n 2   Week 8 -13.10 1.18 34   -15.49   -10.71\n\nConfidence level used: 0.95 \n\nemmeans::emmeans(fit_cat_time_compl, ~trt*avisit, weights = \"proportional\") %&gt;% \n  contrast(\n    list(\n      \"Difference in LS Means at Week 8\" = c(0, 0, 0, 0, -1, 1),\n      \"Difference in longitudinal LS Means to Week 8\" = c(-1, 1, -1, 1, -1, 1)/3\n    )\n  )\n\n contrast                                      estimate   SE df t.ratio p.value\n Difference in LS Means at Week 8                 -2.93 1.69 34  -1.733  0.0922\n Difference in longitudinal LS Means to Week 8    -2.07 1.42 34  -1.455  0.1548\n\n\nA comparison to the results using the full response trajectories for all randomized subjects (response variable change) yields:\n\n### complete response trajectory on all randomized subjects\n\nfit_cat_time &lt;- mmrm::mmrm(\n  formula = change ~ basval*avisit + trt*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nmodel_lsmeans &lt;- emmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\")\nmodel_lsmeans\n\n trt avisit emmean    SE df lower.CL upper.CL\n 1   Week 2  -4.13 0.899 47    -5.93    -2.32\n 2   Week 2  -5.31 0.899 47    -7.12    -3.51\n 1   Week 4  -6.70 0.916 47    -8.55    -4.86\n 2   Week 4  -8.70 0.916 47   -10.54    -6.85\n 1   Week 8  -9.86 1.033 47   -11.94    -7.79\n 2   Week 8 -13.26 1.033 47   -15.33   -11.18\n\nConfidence level used: 0.95 \n\nemmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\") %&gt;% \n  contrast(\n    list(\n      \"Difference in LS Means at Week 8\" = c(0, 0, 0, 0, -1, 1),\n      \"Difference in longitudinal LS Means to Week 8\" = c(-1, 1, -1, 1, -1, 1)/3\n    )\n  )\n\n contrast                                      estimate   SE df t.ratio p.value\n Difference in LS Means at Week 8                 -3.39 1.46 47  -2.319  0.0248\n Difference in longitudinal LS Means to Week 8    -2.19 1.18 47  -1.850  0.0705\n\n\nWe can see that the mean change from baseline to Week 8 using the complete response trajectory is actually lower (i.e. better) under Treatment 2 than the ones from the complete case analysis. For Treatment 1 the mean change from baseline to Week 8 is a little higher (i.e. worse) for the complete response trajectory on all randomized subjects as compared to the complete case analysis. A possible explanation could be that the favorable treatment effect of Treatment 2 came at the cost of adverse events, which made subjects drop out from the study, while the lack of early efficacy under Treatment 1 made subjects drop out, which lead them to not experience the favorable effects in the longer term.\nA comparison to the analysis results based on the incomplete response trajectory (data as is), yields:\n\n### Response data as is (including missings)\n\nfit_cat_time &lt;- mmrm::mmrm(\n  formula = chgdrop ~ basval*avisit + trt*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nemmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\")\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.10 0.900 47.0    -5.91    -2.29\n 2   Week 2  -5.29 0.899 47.0    -7.10    -3.48\n 1   Week 4  -6.42 0.974 46.5    -8.38    -4.46\n 2   Week 4  -8.52 0.951 44.8   -10.43    -6.60\n 1   Week 8  -9.73 1.142 40.4   -12.03    -7.42\n 2   Week 8 -12.62 1.114 40.1   -14.88   -10.37\n\nConfidence level used: 0.95 \n\nemmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\") %&gt;% \n  contrast(\n    list(\n      \"Difference in LS Means at Week 8\" = c(0, 0, 0, 0, -1, 1),\n      \"Difference in longitudinal LS Means to Week 8\" = c(-1, 1, -1, 1, -1, 1)/3\n    )\n  )\n\n contrast                                      estimate   SE   df t.ratio\n Difference in LS Means at Week 8                 -2.90 1.60 40.3  -1.814\n Difference in longitudinal LS Means to Week 8    -2.06 1.23 46.8  -1.671\n p.value\n  0.0772\n  0.1014\n\n\nWe can see that mean changes from baseline to Week 8 are higher (i.e. worse) under both treatment arms using the data as is, as compared to the complete case analysis. In this case, the complete case analysis overestimates the treatment effect in both arms. This effect is often observed with complete case analyses, due to the inherent selection bias that arises from the inclusion of completers only.\n\n\n\nComplete Case Analysis is subject to selection bias, as the analysis is only conducted on subjects who complete the study and therefore did not drop out due to the experience of adverse events of the lack of efficacy. Selection of subjects based on post-baseline events can lead to notable imbalances between our treatment arms and the distribution of covariates. Results from the Complete Case Analysis can therefore be hard to interpret (due to the loss of randomization), and are frequently overestimating the true treatment effect.\nIn principle, this method should be avoided."
  },
  {
    "objectID": "s3_missingness.html#missing-data-mechanisms",
    "href": "s3_missingness.html#missing-data-mechanisms",
    "title": "Missing Data",
    "section": "",
    "text": "To understand the nature of missing data in our clinical trial, we consider the following taxonomy, introduced by (Roderick JA Little 2019). We differentiate between the following three types of missing data:\n\nMissing Completely at Random (MCAR): Conditional on all covariates in our analysis, the probability of missingness does not depend on either observed or unobserved values of the response variable.\nMissing at Random (MAR): Conditional on all covariates and observed response values in our analysis, the probability of missingness does not depend on the unobserved values of the response variable.\nMissing not at Random (MNAR): Conditional on all covariates and observed response values in our analysis, the probability of missingness does depend on the unobserved values of the response variable.\n\n(Mallinckrodt and Lipkovich 2016) give the following interpretation around the three types of missingness:\n“With MCAR, the outcome variable is not related to the probability of dropout (after taking into account covariates). In MAR, the observed values of the outcome variable are related to the probability of dropout, but the unobserved outcomes are not (after taking into account covariates and observed outcomes). In MNAR the unobserved outcomes are related to the probability of dropout even after the observed outcomes and covariates have been taken into account.”\nThe following two sections outline handling strategies for missing data. However, the best approach to handle missing data is to minimise its extent. While the occurence of missing data can rarely be avoided at all (think about the collection of questionnaire data in oncology studies and the missing data after subjects die), it is important to pursue an “as complete as can be” data collection.\nBaseline and screening data are of utmost importance in a pursuit of data completeness. If a screening value is missing, but was meant to be used as a covariate, this subjects’ whole data will be dropped from the analysis even if all responses were observed. If the baseline response variable was missing we are unable to compute a change from baseline, which also leads to the loss of this subjects’ data in the model (although LDA models are still able to provide an estimate) even if all post-baseline values were observed."
  },
  {
    "objectID": "s3_missingness.html#missing-data-handling-i-descriptive-stats-visualisations",
    "href": "s3_missingness.html#missing-data-handling-i-descriptive-stats-visualisations",
    "title": "Missing Data",
    "section": "",
    "text": "To gain an understanding of the impact of missingness on the average response trajectories, we can plot the mean changes from baseline by visit for each drop-out group. The three drop-out groups (variable dropout_grp) are:\n\nDrop-outs at Week 2: Subjects who completed baseline and Week 2, but discontinued from the study prior to Week 4.\nDrop-outs at Week 4: Subjects who completed baseline, Week 2 and Week 4, but discontinued from the study prior to Week 8.\nCompleters: Subjects who completed all visits in the study.\n\n\n\n\n\n\nExercise: Try to interpret the plot above and discuss the following topics around missingness:\n\n\n\nQ1&gt; Look into the data. Which missing data pattern is present in this dataset?\n\nFrom the plot, we can infer that there is a monotone missing data pattern. This is characterized by participants dropping out of the study at specific points (Weeks 2 and 4), and then no further data is collected for them. The plot shows how participants who drop out at different weeks (Week 2 and Week 4) exhibit a decline in their measured outcome prior to dropping out. We can observe distinct trajectories for those who complete the study versus those who drop out.\n\nall2 %&gt;%\n  # group_by(Month) %&gt;%\n  miss_var_summary() %&gt;%\n  kable(caption = \"Missing data among variables\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nMissing data among variables\n\n\nvariable\nn_miss\npct_miss\n\n\n\n\nchgdrop\n21\n14.0000000\n\n\npgiimp\n1\n0.6666667\n\n\nsubject\n0\n0.0000000\n\n\ntime\n0\n0.0000000\n\n\ntrt\n0\n0.0000000\n\n\nbasval\n0\n0.0000000\n\n\nchange\n0\n0.0000000\n\n\ngender\n0\n0.0000000\n\n\nchgrescue\n0\n0.0000000\n\n\ndropout_grp\n0\n0.0000000\n\n\naval\n0\n0.0000000\n\n\navisit\n0\n0.0000000\n\n\nweek\n0\n0.0000000\n\n\ngroup\n0\n0.0000000\n\n\n\n\n\n\n## Exploring missing data\nvis_miss(all2)\n\n\n\ngg_miss_var(all2 %&gt;% filter(group==\"Arm 1\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\ngg_miss_var(all2 %&gt;% filter(group==\"Arm 2\"), \n            facet = avisit, \n            show_pct = TRUE)\n\n\n\n\n\nQ2&gt; What can be seen in the plot? How does the drop-out time affect the observed mean response trajectories?\n\nDropout Trajectories\n\nParticipants who drop out at Week 2 or Week 4 show a different mean change from baseline compared to completers. For example, those dropping out earlier seem to have a more abrupt or flatter decline, indicating that their treatment response may be different from completers.\n\nCompleter Trajectories\n\nThe completers in both treatment groups exhibit a smoother and more sustained decline, suggesting better outcomes than the dropouts.\n\nEffect of Dropout Time\n\nThe earlier the dropout, the less steep the observed decline from baseline. This could be due to several factors, such as treatment inefficacy for those participants or increased adverse effects, leading to their dropout.\nDropouts at Week 4 have trajectories closer to the completers but are still distinct, indicating some level of divergence in treatment response.\nQ3&gt; What other aspects, apart from response, could influence a subjects’ likelihood to drop-out from the study?\n\nOther Factors Influencing Dropout Likelihood Apart from the measured response (mean change from baseline), several other factors could influence a subject’s likelihood of dropping out from the study:\n\nAdverse effects: Participants experiencing more severe side effects may drop out earlier.\nPersonal circumstances: Life events unrelated to the study (e.g., work, family issues) may cause participants to discontinue participation.\nLack of perceived treatment efficacy: Participants who feel the treatment is not working may lose motivation to continue.\nQ4&gt; Which other summaries/ visualizations can be useful to characterize and monitor the degree of missingness in clinical study data?\n\nOther Summaries/Visualizations to Characterize Missingness To better characterize and monitor missingness in clinical study data, the following summaries and visualizations could be useful:\n\nMissing Data Patterns Table: A summary table showing the number of subjects missing data at each time point.\nKaplan-Meier Plot for Time-to-Dropout: This would allow us to examine the dropout pattern over time, showing how many participants remain in the study at each time point.\nProportional Missingness Plot: A bar chart showing the proportion of missing data for each variable at each time point.\nCorrelation Heatmap: Showing correlations between missingness patterns and other variables (e.g., baseline characteristics, adverse events).\nTrajectory Plots for Subgroups: Similar to the plot provided, but stratified by potential confounders (e.g., age, gender) to see if missingness varies across subgroups.\n\n\n\n\nA look into the data shows that all missing values stem from a monotinic missingness pattern.\nThe figure above shows a notable difference between mean response trajectories per drop-out group. The completers in both treatment arms show a steady decrease of HAMD17 scores over time, which is equivalent to an increase in depression symptoms.\nWeek 4 drop-outs under treatment 2 only showed a moderate change from baseline, while the treatment 1 subjects experienced an increase in HAMD17 scores. A possible explanation could be that changes under treatment 2 were not regarded meaningful by patients, while the increase in scores under treatment 1 made subjects drop out of the study.\nWeek 2 drop-outs under treatment 2 showed notable improvements of HAMD17 scores compared to treatment 1, yet the drop-out could potentially be linked to the occurrence of adverse events.\nAlthough the extent of missing data should be reduced to the bare minimum, it can never be avoided completely, especially with Patient-Reported Outcomes (PRO) data. In the reporting of PRO clinical trial data, it is therefore important to transparently summarize the extent of missingness. This is usually done via so-called compliance tables.\nCompliance tables summarize three key components to characterize missingness in our data:\n\nThe number of subjects initially randomized in the trial.\nThe number of subjects for whom data is expected. This is the number of patients who are still ongoing in the study (alive and not discontinued) and for whom an assessment is scheduled following the schedule of assessments in the clinical trial protocol.\nThe number of subjects by whom the assessment has been completed.\n\nFrom these numbers, we can derive the available data rate and the compliance for visit \\(i\\) as follows:\n\\[\n\\begin{aligned}\n\\text{Available Data Rate}_{\\,i} &:= 100\\,\\frac{\\#\\{\\text{Subj. with assessment i completed}\\}}{\\#\\{\\text{Subj. randomized}\\}}\\,,\\\\\n\\text{Compliance Rate}_{\\,i} &:= 100\\,\\frac{\\#\\{\\text{Subj. with assessment i completed}\\}}{\\#\\{\\text{Subj. assessment i expected}\\}}\\,.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "s3_missingness.html#missing-data-handling-ii-naive-analytic-approaches",
    "href": "s3_missingness.html#missing-data-handling-ii-naive-analytic-approaches",
    "title": "Missing Data",
    "section": "",
    "text": "This section provides an overview of simple and most of the times overly naive methods to deal with missing data. Although we will introduce more suitable methods in the next chapter, the approaches introduced in this section have gained questionable popularity in the past, which is why we introduce them here. The following methods to compute or completely ignore missing data exist:\n\nComplete Case Analysis: Discard all subjects with missing observations and only conduct the analysis on subjects with complete follow-up data.\nLast observation carried forward (LOCF): Handling of monotonic missing data. The missing visits are imputed with the last non-missing value. This approach assumes a constant trend of observations after drop-out from the study, i.e. the response level remains the same as the last response under the study drug.\nBaseline observation carried forward (BOCF): Handling of monotonic missing data. The missing visits are imputed with the baseline value. This approach assumes that subjects’ symptom severity or functioning (whichever was measured in the study) bounce back to the baseline state, prior to the intiation of the study drug.\n\n\n\nLet us run a complete case analysis on the all2 dataset.\nExercise: Fit an MMRM with response variable chgdrop, with baseline severity, treatment and visit as fixed effects, as well as baseline-by-visit and treatment-by-visit interaction, using an unstructured variance-covariance matrix on the all2 completers.\n\nHow do the results differ from the results obtained in the former chapter (response variable change, no missing data)?\nHow do the results differ from the results obtained at the beginning of this chapter (response variable chgdrop with missing data)?\nDiscuss the limitations of the complete case analysis. Which sources of bias can you identify?\n\nSignificant Impact in Multivariate Analysis: In complex multivariate analyses, list-wise deletion can lead to substantial loss of statistical information due to a reduction in the effective sample size.\nThe varying sample size due to list-wise deletion makes it difficult to maintain a consistent set of inputs across analyses.\nPotential for Bias in Estimations: CCA assumes that the data are Missing Completely at Random (MCAR)—i.e., the probability of missingness is independent of both observed and unobserved data. However, in most real-world scenarios, data are more likely Missing at Random (MAR) or Missing Not at Random (MNAR).\nSelection Bias\n\n\nSolution:\nWe firstly select our completers dataset. As this is a filtering exercise based on post-baseline characteristics, we first look into the distribution of subjects per treatment arm (note that we lost our randomization effect):\n\nall2_comp &lt;- dplyr::filter(all2, dropout_grp == \"Completer\")\n\nall2_comp %&gt;% \n  dplyr::group_by(group) %&gt;% \n  dplyr::summarise(\n    N = dplyr::n_distinct(subject),\n    .groups = \"drop\"\n  )\n\n# A tibble: 2 × 2\n  group     N\n  &lt;fct&gt; &lt;int&gt;\n1 Arm 1    18\n2 Arm 2    19\n\n### Work with code chunks to find the solution to the exercises\nall2_cca &lt;- all2 %&gt;%\n  group_by(subject) %&gt;%                    \n  filter(all(!is.na(chgdrop))) %&gt;%          \n  ungroup()    \n\nIn this case, we are left with 18 and 19 subjects per arm, which reduced our sample size notably, but at least left us with close to equal sizes of our treatment groups. This is not normal. Usually the stratification of data based on post-baseline assessments can lead to imbalances (it might still have, as we only checked the distribution of the treatment arms).\n\n### Complete Case Analysis\nfit_cat_time_compl &lt;- mmrm::mmrm(\n  formula = chgdrop ~ basval*avisit + trt*avisit + us(avisit | subject),\n  data = all2_comp,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nsummary(fit_cat_time_compl)\n\nmmrm fit\n\nFormula:     chgdrop ~ basval * avisit + trt * avisit + us(avisit | subject)\nData:        all2_comp (used 111 observations from 37 subjects with maximum 3 \ntimepoints)\nCovariance:  unstructured (6 variance parameters)\nMethod:      Kenward-Roger\nVcov Method: Kenward-Roger\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n   608.8    618.5   -298.4    596.8 \n\nCoefficients: \n                     Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept)           1.89223    3.60558  33.99000   0.525 0.603124    \nbasval               -0.31950    0.17281  33.99000  -1.849 0.073201 .  \navisitWeek 4         -1.63943    2.46046  34.00000  -0.666 0.509708    \navisitWeek 8        -12.36928    3.39084  34.00000  -3.648 0.000877 ***\ntrt2                 -1.13978    1.56623  33.99000  -0.728 0.471768    \nbasval:avisitWeek 4  -0.05179    0.11793  34.00000  -0.439 0.663301    \nbasval:avisitWeek 8   0.33515    0.16252  34.00000   2.062 0.046899 *  \navisitWeek 4:trt2    -0.99990    1.06880  34.00000  -0.936 0.356113    \navisitWeek 8:trt2    -1.78825    1.47295  34.00000  -1.214 0.233089    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        Week 2  Week 4  Week 8\nWeek 2 23.2319 16.8721 14.6422\nWeek 4 16.8721 21.7589 17.9166\nWeek 8 14.6422 17.9166 27.5347\n\nmodel_lsmeans &lt;- emmeans::emmeans(fit_cat_time_compl, ~trt*avisit, weights = \"proportional\")\nmodel_lsmeans\n\n trt avisit emmean   SE df lower.CL upper.CL\n 1   Week 2  -4.33 1.12 34    -6.61    -2.06\n 2   Week 2  -5.47 1.09 34    -7.69    -3.26\n 1   Week 4  -6.98 1.09 34    -9.19    -4.77\n 2   Week 4  -9.12 1.06 34   -11.27    -6.97\n 1   Week 8 -10.17 1.21 34   -12.63    -7.71\n 2   Week 8 -13.10 1.18 34   -15.49   -10.71\n\nConfidence level used: 0.95 \n\nemmeans::emmeans(fit_cat_time_compl, ~trt*avisit, weights = \"proportional\") %&gt;% \n  contrast(\n    list(\n      \"Difference in LS Means at Week 8\" = c(0, 0, 0, 0, -1, 1),\n      \"Difference in longitudinal LS Means to Week 8\" = c(-1, 1, -1, 1, -1, 1)/3\n    )\n  )\n\n contrast                                      estimate   SE df t.ratio p.value\n Difference in LS Means at Week 8                 -2.93 1.69 34  -1.733  0.0922\n Difference in longitudinal LS Means to Week 8    -2.07 1.42 34  -1.455  0.1548\n\n\nA comparison to the results using the full response trajectories for all randomized subjects (response variable change) yields:\n\n### complete response trajectory on all randomized subjects\n\nfit_cat_time &lt;- mmrm::mmrm(\n  formula = change ~ basval*avisit + trt*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nmodel_lsmeans &lt;- emmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\")\nmodel_lsmeans\n\n trt avisit emmean    SE df lower.CL upper.CL\n 1   Week 2  -4.13 0.899 47    -5.93    -2.32\n 2   Week 2  -5.31 0.899 47    -7.12    -3.51\n 1   Week 4  -6.70 0.916 47    -8.55    -4.86\n 2   Week 4  -8.70 0.916 47   -10.54    -6.85\n 1   Week 8  -9.86 1.033 47   -11.94    -7.79\n 2   Week 8 -13.26 1.033 47   -15.33   -11.18\n\nConfidence level used: 0.95 \n\nemmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\") %&gt;% \n  contrast(\n    list(\n      \"Difference in LS Means at Week 8\" = c(0, 0, 0, 0, -1, 1),\n      \"Difference in longitudinal LS Means to Week 8\" = c(-1, 1, -1, 1, -1, 1)/3\n    )\n  )\n\n contrast                                      estimate   SE df t.ratio p.value\n Difference in LS Means at Week 8                 -3.39 1.46 47  -2.319  0.0248\n Difference in longitudinal LS Means to Week 8    -2.19 1.18 47  -1.850  0.0705\n\n\nWe can see that the mean change from baseline to Week 8 using the complete response trajectory is actually lower (i.e. better) under Treatment 2 than the ones from the complete case analysis. For Treatment 1 the mean change from baseline to Week 8 is a little higher (i.e. worse) for the complete response trajectory on all randomized subjects as compared to the complete case analysis. A possible explanation could be that the favorable treatment effect of Treatment 2 came at the cost of adverse events, which made subjects drop out from the study, while the lack of early efficacy under Treatment 1 made subjects drop out, which lead them to not experience the favorable effects in the longer term.\nA comparison to the analysis results based on the incomplete response trajectory (data as is), yields:\n\n### Response data as is (including missings)\n\nfit_cat_time &lt;- mmrm::mmrm(\n  formula = chgdrop ~ basval*avisit + trt*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nemmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\")\n\n trt avisit emmean    SE   df lower.CL upper.CL\n 1   Week 2  -4.10 0.900 47.0    -5.91    -2.29\n 2   Week 2  -5.29 0.899 47.0    -7.10    -3.48\n 1   Week 4  -6.42 0.974 46.5    -8.38    -4.46\n 2   Week 4  -8.52 0.951 44.8   -10.43    -6.60\n 1   Week 8  -9.73 1.142 40.4   -12.03    -7.42\n 2   Week 8 -12.62 1.114 40.1   -14.88   -10.37\n\nConfidence level used: 0.95 \n\nemmeans::emmeans(fit_cat_time, ~trt*avisit, weights = \"proportional\") %&gt;% \n  contrast(\n    list(\n      \"Difference in LS Means at Week 8\" = c(0, 0, 0, 0, -1, 1),\n      \"Difference in longitudinal LS Means to Week 8\" = c(-1, 1, -1, 1, -1, 1)/3\n    )\n  )\n\n contrast                                      estimate   SE   df t.ratio\n Difference in LS Means at Week 8                 -2.90 1.60 40.3  -1.814\n Difference in longitudinal LS Means to Week 8    -2.06 1.23 46.8  -1.671\n p.value\n  0.0772\n  0.1014\n\n\nWe can see that mean changes from baseline to Week 8 are higher (i.e. worse) under both treatment arms using the data as is, as compared to the complete case analysis. In this case, the complete case analysis overestimates the treatment effect in both arms. This effect is often observed with complete case analyses, due to the inherent selection bias that arises from the inclusion of completers only.\n\n\n\nComplete Case Analysis is subject to selection bias, as the analysis is only conducted on subjects who complete the study and therefore did not drop out due to the experience of adverse events of the lack of efficacy. Selection of subjects based on post-baseline events can lead to notable imbalances between our treatment arms and the distribution of covariates. Results from the Complete Case Analysis can therefore be hard to interpret (due to the loss of randomization), and are frequently overestimating the true treatment effect.\nIn principle, this method should be avoided."
  },
  {
    "objectID": "s5_inferences_binary.html",
    "href": "s5_inferences_binary.html",
    "title": "Inferences from binary longitudinal data",
    "section": "",
    "text": "In the previous chapters we focused on modeling the means over time from a continuous response vector. In clinical trials we often encounter cases, where our response is however not continuous, but rather discrete. Discrete data can stem from either count data, such that values are taken in (a subset) of the natural numbers, or ordinal data, where values represent distinct categories, or binary data. In the latter case only values 0 and 1 are taken and represent the presence or absence of a clinical status, such as alive or dead at time X, hospitalized or not hospitalized at time X or response or non-response on a specific scale at time X.\nAdditionally, we can rarely assume a linear relationship between the discrete response variable and the independent variables.\nIn this case we use generalized linear models for the analysis of discrete longitudinal data. Generalized linear models (GLMs) apply a suitable link function to deal with the nonlinearity problem and necessitate the choice of an appropriate distributional assumption on the errors.\nGLMs differ from the linear models for continuous data in terms of their interpretation. Modeling approaches include marginal, random effects, and conditional models.\n\n\nA marginal model for binary data can be written as\n\\[\nlogit\\left(\\,\\text{E}[\\,Y_{i,j}\\,|\\, X\\,]\\,\\right) = x_{i,j}'\\,\\beta\\,,\n\\] where \\(Y_{i,j}\\) is the binary response of subject \\(i\\) at visit \\(j\\), \\(X\\) is a set of predictor variables and \\(x_{i,j}\\) a covariate vector. Furthermore, the link function \\(logit(.)\\) is used. It is defined as\n\\[\nlogit(p) := \\ln\\left(\\frac{p}{1-p}\\right),\\hspace{.1in} p\\in(0,1).\n\\] The model is called a marginal model, as it uses the marginal distribution of an outcome vector \\(Y\\) given a set of predictor variables \\(X\\). Models of this type are usually handled via Generalized Estimating Equations (GEEs). In R, the packages gee and geepack can be used.\n\n\n\nWe can add a vector of random effects to the predictor variables in \\(X\\) to obtain\n\\[\nlogit\\left(\\,\\text{E}[\\,Y_{i,j}\\,|\\, X, b_i\\,]\\,\\right) = x_{i,j}'\\,\\beta\\,+\\,z_{i,j}'b_i\\,.\n\\] This model is often referred to as a generalized linear mixed-effects model. In the random effects model all fixed effects estimates are conditional upon the random effects vector \\(b_i\\), hence its inclusion on the left-hand side of the equation. In R, the package glmm can be used to fit random effects models for binary data.\n\n\n\nConditional models are models of the type\n\\[\nlogit\\left(\\,\\text{E}[\\,Y_{i,j}\\,|\\, Y_{i,1},\\ldots, Y_{i, j-1}, x_{i,j}\\,]\\,\\right) = x_{i,j}'\\,\\beta\\,+\\,\\alpha\\,Y_{i, j-1}.\n\\] Here no random effects are added, but expectations are based on earlier observations. As stated by (Mallinckrodt and Lipkovich 2016) “In clinical trials, interest is often on an overall, or population average treatment effect, not on a treatment effect associated with specific outcome histories”. This limits the applicability of conditional models in the clinical trials context.\n\n\n\nFor an in-depth discussion, refer to Chapter 10 in (Mallinckrodt and Lipkovich 2016) or Part III in (Fitzmaurice 2011)."
  },
  {
    "objectID": "s2_inference_continuous.html#mixed-model-vs-mmrm",
    "href": "s2_inference_continuous.html#mixed-model-vs-mmrm",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "The key difference between MMRM (Mixed Model for Repeated Measures) and the more general Mixed Model lies in how they handle repeated measurements and the assumptions they make about the data.\nMMRM is specifically designed for longitudinal or repeated measures data, such as clinical trials where the same subjects are measured multiple times over different time points. It allows for flexible covariance structures that model the within-subject correlation over time, making it especially useful for analyzing treatment effects that change over time.\nIn contrast, the general mixed model can be used for a wider range of data, including nested or hierarchical structures, and is not limited to longitudinal data. While mixed models also handle repeated measures, they are often applied in contexts where the focus is on individual-level variability through random effects (e.g., random intercepts and slopes), whereas MMRM focuses on the treatment effect over time without including random slopes or intercepts.\nWhen it comes to handling missing data, MMRM assumes the data is missing at random (MAR) and can produce unbiased estimates without the need for data imputation. This makes it particularly advantageous in clinical trials where patients may drop out over time. Mixed models also handle missing data but are not specifically tailored for time-dependent missingness.\nIn terms of covariance structure, MMRM is more flexible and allows modeling of timepoint correlations using an unstructured covariance matrix, providing a more detailed understanding of how outcomes change over time. In comparison, general mixed models are typically less focused on modeling timepoint-specific covariance and more focused on individual-level random effects.\nLastly, MMRM mainly deals with fixed effects, especially treatment and time, while handling within-subject correlations via covariance structures. It typically does not include random intercepts or slopes, unlike general mixed models, which often include both fixed and random effects to account for individual-level variability and differences in baseline or rates of change. This makes MMRM simpler and more focused on treatment effects over time, whereas general mixed models provide more flexibility in modeling variability between individuals.\nIn summary, MMRM is a specialized form of mixed model used primarily for repeated measures in longitudinal data, particularly in clinical settings, with a focus on time-varying treatment effects and handling missing data effectively. General mixed models are more versatile and used in broader contexts, often including random effects to account for variability between subjects or nested data structures."
  },
  {
    "objectID": "s2_inference_continuous.html#categorical-time-not-using-time-from-randomization",
    "href": "s2_inference_continuous.html#categorical-time-not-using-time-from-randomization",
    "title": "Inference from Longitudinal Data",
    "section": "",
    "text": "In the following sections we will use the package mmrm (Sabanes Bove et al. 2024). You can start and familiarise yourself with the main function mmrm() using the command\nTwo inputs are strictly required to get mmrm() to work:\n\nA model formula\nThe dataset, containing the response, as well as all fixed effects and variables in the covariance matrix.\n\nExercise: Fit a model fit_cat_time using the dataset all2, with change as dependent variable, baseline value, visit, baseline by visit interaction and treatment by visit interaction as fixed effects and an unstructured covariance matrix for visits within each subject.\n\nHow do different choices for covariance matrices change the results? What is the difference on the estimation procedure?\nYou can obtain a summary of the fit results via summary(fit_cat_time). How do you interpret the fit summary?\nLook at the structure of the fit summary and try to extract the estimate of the \\(R\\) matrix.\nHow do other choices of covariance structures influence the estimation?\n\nSolution\n\nfit_cat_time_un &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_toep &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + toep(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_toeph &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + toeph(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nfit_cat_time_sp &lt;- mmrm::mmrm(\n  formula = change ~ basval + avisit + basval*avisit + group*avisit + sp_exp(week | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\n## https://cran.r-project.org/web/packages/mmrm/mmrm.pdf\n# summary(fit_cat_time_un)\n# summary(fit_cat_time_toep)\n# summary(fit_cat_time_toeph)\n# summary(fit_cat_time_sp)\n\n## Covariance Matrix\nfit_cat_time_un$cov\n\n         Week 2   Week 4   Week 8\nWeek 2 20.61191 15.30474 12.27830\nWeek 4 15.30474 21.35801 17.66644\nWeek 8 12.27830 17.66644 27.61440\n\n# Extract AIC and BIC values for the models\naic_values &lt;- c(\n  AIC(fit_cat_time_un),\n  AIC(fit_cat_time_toep),\n  AIC(fit_cat_time_toeph),\n  AIC(fit_cat_time_sp)\n)\n\nbic_values &lt;- c(\n  BIC(fit_cat_time_un),\n  BIC(fit_cat_time_toep),\n  BIC(fit_cat_time_toeph),\n  BIC(fit_cat_time_sp)\n)\n\n# Extract fixed effect coefficients from each model\ncoef_un &lt;- summary(fit_cat_time_un)$coefficients\ncoef_toep &lt;- summary(fit_cat_time_toep)$coefficients\ncoef_toeph &lt;- summary(fit_cat_time_toeph)$coefficients\ncoef_sp &lt;- summary(fit_cat_time_sp)$coefficients\n\n# Combine AIC, BIC, and coefficients into a summary table\ncomparison_table &lt;- data.frame(\n  Model = c(\"Unstructured\", \"Toeplitz\", \"Heterogeneous Toeplitz\", \"Spatial Power\"),\n  AIC = aic_values,\n  BIC = bic_values\n)\n\n# Display the summary of goodness of fit (AIC and BIC)\ncomparison_table %&gt;%\n  kable(caption = \"Goodness of Fit Comparison (AIC, BIC)\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nGoodness of Fit Comparison (AIC, BIC)\n\n\nModel\nAIC\nBIC\n\n\n\n\nUnstructured\n822.4105\n833.8826\n\n\nToeplitz\n818.5753\n824.3114\n\n\nHeterogeneous Toeplitz\n820.4111\n829.9712\n\n\nSpatial Power\n818.5262\n822.3503\n\n\n\n\n\n\n# Extract the Estimate (fixed effect coefficients) from each model\nestimates_un &lt;- summary(fit_cat_time_un)$coefficients[, \"Estimate\"]\nestimates_toep &lt;- summary(fit_cat_time_toep)$coefficients[, \"Estimate\"]\nestimates_toeph &lt;- summary(fit_cat_time_toeph)$coefficients[, \"Estimate\"]\n\n# Combine the estimates into a data frame for comparison\nestimate_comparison &lt;- data.frame(\n  Term = names(estimates_un),  # Assuming all models have the same terms\n  Unstructured = estimates_un,\n  Toeplitz = estimates_toep,\n  Heterogeneous_Toeplitz = estimates_toeph\n)\n\n# Display the table of estimates\nestimate_comparison %&gt;%\n  kable(caption = \"Comparison of Estimates for the Three Models\", format = \"html\") %&gt;%\n  kable_styling(latex_options = \"striped\")\n\n\nComparison of Estimates for the Three Models\n\n\n\nTerm\nUnstructured\nToeplitz\nHeterogeneous_Toeplitz\n\n\n\n\n(Intercept)\n(Intercept)\n1.9845205\n1.9845205\n1.9845205\n\n\nbasval\nbasval\n-0.3123495\n-0.3123495\n-0.3123495\n\n\navisitWeek 4\navisitWeek 4\n-0.9086176\n-0.9086176\n-0.9086176\n\n\navisitWeek 8\navisitWeek 8\n-10.5863002\n-10.5863002\n-10.5863002\n\n\ngroupArm 2\ngroupArm 2\n-1.1899278\n-1.1899278\n-1.1899278\n\n\nbasval:avisitWeek 4\nbasval:avisitWeek 4\n-0.0854234\n-0.0854234\n-0.0854234\n\n\nbasval:avisitWeek 8\nbasval:avisitWeek 8\n0.2477929\n0.2477929\n0.2477929\n\n\navisitWeek 4:groupArm 2\navisitWeek 4:groupArm 2\n-0.8010032\n-0.8010032\n-0.8010032\n\n\navisitWeek 8:groupArm 2\navisitWeek 8:groupArm 2\n-2.2010594\n-2.2010594\n-2.2010594\n\n\n\n\n\n\ntab_model(fit_cat_time_un,fit_cat_time_sp)\n\nWarning: The `full` argument of `model.frame.mmrm_tmb()` is deprecated as of mmrm 0.3.\nℹ The deprecated feature was likely used in the mmrm package.\n  Please report the issue at &lt;https://github.com/openpharma/mmrm/issues&gt;.\n\n\n\n\n\n \nchange\nchange\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n1.98\n-4.60 – 8.57\n0.547\n1.98\n-5.07 – 9.04\n0.577\n\n\nbasval\n-0.31\n-0.63 – 0.01\n0.055\n-0.31\n-0.65 – 0.03\n0.073\n\n\navisit [Week 4]\n-0.91\n-5.73 – 3.92\n0.707\n-0.91\n-5.38 – 3.57\n0.687\n\n\navisit [Week 8]\n-10.59\n-17.55 – -3.63\n0.004\n-10.59\n-17.57 – -3.60\n0.003\n\n\ngroup [Arm 2]\n-1.19\n-3.75 – 1.37\n0.355\n-1.19\n-3.93 – 1.55\n0.390\n\n\nbasval × avisit [Week 4]\n-0.09\n-0.32 – 0.15\n0.467\n-0.09\n-0.30 – 0.13\n0.437\n\n\nbasval × avisit [Week 8]\n0.25\n-0.09 – 0.59\n0.147\n0.25\n-0.09 – 0.59\n0.151\n\n\navisit [Week 4] × group[Arm 2]\n-0.80\n-2.68 – 1.07\n0.395\n-0.80\n-2.54 – 0.94\n0.362\n\n\navisit [Week 8] × group[Arm 2]\n-2.20\n-4.91 – 0.50\n0.108\n-2.20\n-4.91 – 0.51\n0.111\n\n\n\nN\n50 subject\n50 subject\n\n\n\n\n\n\n\n\nStructure\nDescription\n\n\n\n\nad\nAnte-dependence\n\n\nadh\nHeterogeneous ante-dependence\n\n\nar1\nFirst-order auto-regressive\n\n\nar1h\nHeterogeneous first-order auto-regressive\n\n\ncs\nCompound symmetry\n\n\ncsh\nHeterogeneous compound symmetry\n\n\ntoep\nToeplitz\n\n\ntoeph\nHeterogeneous Toeplitz\n\n\nus\nUnstructured"
  },
  {
    "objectID": "s5_inferences_binary.html#marginal-models",
    "href": "s5_inferences_binary.html#marginal-models",
    "title": "Inferences from binary longitudinal data",
    "section": "",
    "text": "A marginal model for binary data can be written as\n\\[\nlogit\\left(\\,\\text{E}[\\,Y_{i,j}\\,|\\, X\\,]\\,\\right) = x_{i,j}'\\,\\beta\\,,\n\\] where \\(Y_{i,j}\\) is the binary response of subject \\(i\\) at visit \\(j\\), \\(X\\) is a set of predictor variables and \\(x_{i,j}\\) a covariate vector. Furthermore, the link function \\(logit(.)\\) is used. It is defined as\n\\[\nlogit(p) := \\ln\\left(\\frac{p}{1-p}\\right),\\hspace{.1in} p\\in(0,1).\n\\] The model is called a marginal model, as it uses the marginal distribution of an outcome vector \\(Y\\) given a set of predictor variables \\(X\\). Models of this type are usually handled via Generalized Estimating Equations (GEEs). In R, the packages gee and geepack can be used."
  },
  {
    "objectID": "s5_inferences_binary.html#random-effect-models",
    "href": "s5_inferences_binary.html#random-effect-models",
    "title": "Inferences from binary longitudinal data",
    "section": "",
    "text": "We can add a vector of random effects to the predictor variables in \\(X\\) to obtain\n\\[\nlogit\\left(\\,\\text{E}[\\,Y_{i,j}\\,|\\, X, b_i\\,]\\,\\right) = x_{i,j}'\\,\\beta\\,+\\,z_{i,j}'b_i\\,.\n\\] This model is often referred to as a generalized linear mixed-effects model. In the random effects model all fixed effects estimates are conditional upon the random effects vector \\(b_i\\), hence its inclusion on the left-hand side of the equation. In R, the package glmm can be used to fit random effects models for binary data."
  },
  {
    "objectID": "s5_inferences_binary.html#conditional-models",
    "href": "s5_inferences_binary.html#conditional-models",
    "title": "Inferences from binary longitudinal data",
    "section": "",
    "text": "Conditional models are models of the type\n\\[\nlogit\\left(\\,\\text{E}[\\,Y_{i,j}\\,|\\, Y_{i,1},\\ldots, Y_{i, j-1}, x_{i,j}\\,]\\,\\right) = x_{i,j}'\\,\\beta\\,+\\,\\alpha\\,Y_{i, j-1}.\n\\] Here no random effects are added, but expectations are based on earlier observations. As stated by (Mallinckrodt and Lipkovich 2016) “In clinical trials, interest is often on an overall, or population average treatment effect, not on a treatment effect associated with specific outcome histories”. This limits the applicability of conditional models in the clinical trials context."
  },
  {
    "objectID": "s5_inferences_binary.html#further-reading",
    "href": "s5_inferences_binary.html#further-reading",
    "title": "Inferences from binary longitudinal data",
    "section": "",
    "text": "For an in-depth discussion, refer to Chapter 10 in (Mallinckrodt and Lipkovich 2016) or Part III in (Fitzmaurice 2011)."
  }
]