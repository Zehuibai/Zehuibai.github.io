<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Tree models | ML Project Using bookdown</title>
  <meta name="description" content="A book example for a Chapman &amp; Hall book." />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Tree models | ML Project Using bookdown" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A book example for a Chapman &amp; Hall book." />
  <meta name="github-repo" content="yihui/bookdown-crc" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Tree models | ML Project Using bookdown" />
  
  <meta name="twitter:description" content="A book example for a Chapman &amp; Hall book." />
  

<meta name="author" content="Zehui Bai" />


<meta name="date" content="2023-12-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="svm.html"/>
<link rel="next" href="pca.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<script src="libs/d3-3.5.17/d3.min.js"></script>
<link href="libs/markmap-0.3.3/view.mindmap.css" rel="stylesheet" />
<script src="libs/markmap-0.3.3/view.mindmap.js"></script>
<script src="libs/markmap-0.3.3/plugins/parsemd.min.js"></script>
<script src="libs/markmap-binding-1.3.2/markmap.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ML Project</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-read-this-book"><i class="fa fa-check"></i>Why read this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-information-and-conventions"><i class="fa fa-check"></i>Software information and conventions</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html"><i class="fa fa-check"></i><b>1</b> Regularization Penalized Regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#motivation"><i class="fa fa-check"></i><b>1.1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.1.2" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#data-preparation"><i class="fa fa-check"></i><b>1.1.2</b> Data preparation</a></li>
<li class="chapter" data-level="1.1.3" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#best-subset-regression"><i class="fa fa-check"></i><b>1.1.3</b> Best subset regression</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#ridge-regression"><i class="fa fa-check"></i><b>1.2</b> Ridge Regression</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#modeling"><i class="fa fa-check"></i><b>1.2.1</b> Modeling</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#lasso-regression"><i class="fa fa-check"></i><b>1.3</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#modelling"><i class="fa fa-check"></i><b>1.3.1</b> Modelling</a></li>
<li class="chapter" data-level="1.3.2" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#glmnet-cross-validation"><i class="fa fa-check"></i><b>1.3.2</b> glmnet cross validation</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#elasticnet"><i class="fa fa-check"></i><b>1.4</b> ElasticNet</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#modelling-1"><i class="fa fa-check"></i><b>1.4.1</b> Modelling</a></li>
<li class="chapter" data-level="1.4.2" data-path="regularization-penalized-regression.html"><a href="regularization-penalized-regression.html#classification"><i class="fa fa-check"></i><b>1.4.2</b> Classification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>2</b> Smoothing</a>
<ul>
<li class="chapter" data-level="2.1" data-path="smoothing.html"><a href="smoothing.html#smoothing-1"><i class="fa fa-check"></i><b>2.1</b> Smoothing</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="smoothing.html"><a href="smoothing.html#bin-smoothing"><i class="fa fa-check"></i><b>2.1.1</b> Bin smoothing</a></li>
<li class="chapter" data-level="2.1.2" data-path="smoothing.html"><a href="smoothing.html#kernels"><i class="fa fa-check"></i><b>2.1.2</b> Kernels</a></li>
<li class="chapter" data-level="2.1.3" data-path="smoothing.html"><a href="smoothing.html#local-weighted-regression-loess"><i class="fa fa-check"></i><b>2.1.3</b> Local weighted regression (loess)</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="smoothing.html"><a href="smoothing.html#loess-regression"><i class="fa fa-check"></i><b>2.2</b> Loess Regression</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="knn.html"><a href="knn.html"><i class="fa fa-check"></i><b>3</b> KNN</a>
<ul>
<li class="chapter" data-level="3.1" data-path="knn.html"><a href="knn.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="knn.html"><a href="knn.html#idee"><i class="fa fa-check"></i><b>3.1.1</b> Idee</a></li>
<li class="chapter" data-level="3.1.2" data-path="knn.html"><a href="knn.html#加权最近邻法"><i class="fa fa-check"></i><b>3.1.2</b> 加权最近邻法</a></li>
<li class="chapter" data-level="3.1.3" data-path="knn.html"><a href="knn.html#knn算法三要素"><i class="fa fa-check"></i><b>3.1.3</b> KNN算法三要素</a></li>
<li class="chapter" data-level="3.1.4" data-path="knn.html"><a href="knn.html#优缺点"><i class="fa fa-check"></i><b>3.1.4</b> 优缺点</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="knn.html"><a href="knn.html#knn算法的实现方式"><i class="fa fa-check"></i><b>3.2</b> KNN算法的实现方式</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="knn.html"><a href="knn.html#brute-force"><i class="fa fa-check"></i><b>3.2.1</b> Brute-force</a></li>
<li class="chapter" data-level="3.2.2" data-path="knn.html"><a href="knn.html#kd树实现"><i class="fa fa-check"></i><b>3.2.2</b> KD树实现</a></li>
<li class="chapter" data-level="3.2.3" data-path="knn.html"><a href="knn.html#球树实现"><i class="fa fa-check"></i><b>3.2.3</b> 球树实现</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="knn.html"><a href="knn.html#application"><i class="fa fa-check"></i><b>3.3</b> Application</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="knn.html"><a href="knn.html#data-preparation-1"><i class="fa fa-check"></i><b>3.3.1</b> Data Preparation</a></li>
<li class="chapter" data-level="3.3.2" data-path="knn.html"><a href="knn.html#knn-modelling"><i class="fa fa-check"></i><b>3.3.2</b> KNN Modelling</a></li>
<li class="chapter" data-level="3.3.3" data-path="knn.html"><a href="knn.html#加权最近邻法-1"><i class="fa fa-check"></i><b>3.3.3</b> 加权最近邻法</a></li>
<li class="chapter" data-level="3.3.4" data-path="knn.html"><a href="knn.html#over-training"><i class="fa fa-check"></i><b>3.3.4</b> Over-training</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>4</b> SVM</a>
<ul>
<li class="chapter" data-level="4.1" data-path="svm.html"><a href="svm.html#introduction-2"><i class="fa fa-check"></i><b>4.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="svm.html"><a href="svm.html#perceptron"><i class="fa fa-check"></i><b>4.1.1</b> Perceptron</a></li>
<li class="chapter" data-level="4.1.2" data-path="svm.html"><a href="svm.html#函数间隔与几何间隔"><i class="fa fa-check"></i><b>4.1.2</b> 函数间隔与几何间隔</a></li>
<li class="chapter" data-level="4.1.3" data-path="svm.html"><a href="svm.html#svm支持向量"><i class="fa fa-check"></i><b>4.1.3</b> SVM支持向量</a></li>
<li class="chapter" data-level="4.1.4" data-path="svm.html"><a href="svm.html#svm模型目标函数与优化"><i class="fa fa-check"></i><b>4.1.4</b> SVM模型目标函数与优化</a></li>
<li class="chapter" data-level="4.1.5" data-path="svm.html"><a href="svm.html#线性可分svm的算法过程"><i class="fa fa-check"></i><b>4.1.5</b> 线性可分SVM的算法过程</a></li>
<li class="chapter" data-level="4.1.6" data-path="svm.html"><a href="svm.html#线性svm的软间隔最大化"><i class="fa fa-check"></i><b>4.1.6</b> 线性SVM的软间隔最大化</a></li>
<li class="chapter" data-level="4.1.7" data-path="svm.html"><a href="svm.html#线性不可分支持向量机与核函数"><i class="fa fa-check"></i><b>4.1.7</b> 线性不可分支持向量机与核函数</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="svm.html"><a href="svm.html#application-1"><i class="fa fa-check"></i><b>4.2</b> Application</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="svm.html"><a href="svm.html#data-preparation-2"><i class="fa fa-check"></i><b>4.2.1</b> Data Preparation</a></li>
<li class="chapter" data-level="4.2.2" data-path="svm.html"><a href="svm.html#svm-modelling"><i class="fa fa-check"></i><b>4.2.2</b> SVM Modelling</a></li>
<li class="chapter" data-level="4.2.3" data-path="svm.html"><a href="svm.html#model-selection"><i class="fa fa-check"></i><b>4.2.3</b> Model Selection</a></li>
<li class="chapter" data-level="4.2.4" data-path="svm.html"><a href="svm.html#character-selection"><i class="fa fa-check"></i><b>4.2.4</b> Character selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="tree-models.html"><a href="tree-models.html"><i class="fa fa-check"></i><b>5</b> Tree models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="tree-models.html"><a href="tree-models.html#decision-tree-model"><i class="fa fa-check"></i><b>5.1</b> Decision Tree Model</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="tree-models.html"><a href="tree-models.html#decision-tree-algorithm"><i class="fa fa-check"></i><b>5.1.1</b> Decision tree algorithm</a></li>
<li class="chapter" data-level="5.1.2" data-path="tree-models.html"><a href="tree-models.html#id3-algorithm"><i class="fa fa-check"></i><b>5.1.2</b> ID3 Algorithm</a></li>
<li class="chapter" data-level="5.1.3" data-path="tree-models.html"><a href="tree-models.html#c4.5-algorithm"><i class="fa fa-check"></i><b>5.1.3</b> C4.5 Algorithm</a></li>
<li class="chapter" data-level="5.1.4" data-path="tree-models.html"><a href="tree-models.html#cart-algorithm"><i class="fa fa-check"></i><b>5.1.4</b> CART Algorithm</a></li>
<li class="chapter" data-level="5.1.5" data-path="tree-models.html"><a href="tree-models.html#pruning"><i class="fa fa-check"></i><b>5.1.5</b> Pruning</a></li>
<li class="chapter" data-level="5.1.6" data-path="tree-models.html"><a href="tree-models.html#package-rpart"><i class="fa fa-check"></i><b>5.1.6</b> Package ‘rpart’</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="tree-models.html"><a href="tree-models.html#random-forest"><i class="fa fa-check"></i><b>5.2</b> Random Forest</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="tree-models.html"><a href="tree-models.html#bootstrap-bagging"><i class="fa fa-check"></i><b>5.2.1</b> Bootstrap (Bagging)</a></li>
<li class="chapter" data-level="5.2.2" data-path="tree-models.html"><a href="tree-models.html#bagging算法流程"><i class="fa fa-check"></i><b>5.2.2</b> bagging算法流程</a></li>
<li class="chapter" data-level="5.2.3" data-path="tree-models.html"><a href="tree-models.html#random-forest-algorithm"><i class="fa fa-check"></i><b>5.2.3</b> Random Forest Algorithm</a></li>
<li class="chapter" data-level="5.2.4" data-path="tree-models.html"><a href="tree-models.html#random-forest-promotion"><i class="fa fa-check"></i><b>5.2.4</b> Random forest promotion</a></li>
<li class="chapter" data-level="5.2.5" data-path="tree-models.html"><a href="tree-models.html#package-randomforest"><i class="fa fa-check"></i><b>5.2.5</b> Package ‘randomForest’</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="tree-models.html"><a href="tree-models.html#modelling-2"><i class="fa fa-check"></i><b>5.3</b> Modelling</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="tree-models.html"><a href="tree-models.html#data-preparation-3"><i class="fa fa-check"></i><b>5.3.1</b> Data preparation</a></li>
<li class="chapter" data-level="5.3.2" data-path="tree-models.html"><a href="tree-models.html#regression-tree-1"><i class="fa fa-check"></i><b>5.3.2</b> Regression tree</a></li>
<li class="chapter" data-level="5.3.3" data-path="tree-models.html"><a href="tree-models.html#classification-tree-1"><i class="fa fa-check"></i><b>5.3.3</b> Classification tree</a></li>
<li class="chapter" data-level="5.3.4" data-path="tree-models.html"><a href="tree-models.html#random-forest-for-regression"><i class="fa fa-check"></i><b>5.3.4</b> Random forest for regression</a></li>
<li class="chapter" data-level="5.3.5" data-path="tree-models.html"><a href="tree-models.html#random-forest-for-classification"><i class="fa fa-check"></i><b>5.3.5</b> Random forest for classification</a></li>
<li class="chapter" data-level="5.3.6" data-path="tree-models.html"><a href="tree-models.html#皮玛印第安人糖尿病数据集"><i class="fa fa-check"></i><b>5.3.6</b> 皮玛印第安人糖尿病数据集</a></li>
<li class="chapter" data-level="5.3.7" data-path="tree-models.html"><a href="tree-models.html#使用随机森林进行特征选择"><i class="fa fa-check"></i><b>5.3.7</b> 使用随机森林进行特征选择</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tree-models.html"><a href="tree-models.html#gradient-boosting"><i class="fa fa-check"></i><b>5.4</b> Gradient Boosting</a></li>
<li class="chapter" data-level="5.5" data-path="tree-models.html"><a href="tree-models.html#gradient-descent"><i class="fa fa-check"></i><b>5.5</b> Gradient Descent</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="tree-models.html"><a href="tree-models.html#gradient"><i class="fa fa-check"></i><b>5.5.1</b> Gradient</a></li>
<li class="chapter" data-level="5.5.2" data-path="tree-models.html"><a href="tree-models.html#gradient-descent-1"><i class="fa fa-check"></i><b>5.5.2</b> Gradient Descent</a></li>
<li class="chapter" data-level="5.5.3" data-path="tree-models.html"><a href="tree-models.html#gradient-descent-algorithm"><i class="fa fa-check"></i><b>5.5.3</b> Gradient Descent Algorithm</a></li>
<li class="chapter" data-level="5.5.4" data-path="tree-models.html"><a href="tree-models.html#gradient-descent-familiy"><i class="fa fa-check"></i><b>5.5.4</b> Gradient Descent Familiy</a></li>
<li class="chapter" data-level="5.5.5" data-path="tree-models.html"><a href="tree-models.html#gbdt分类算法"><i class="fa fa-check"></i><b>5.5.5</b> GBDT分类算法</a></li>
<li class="chapter" data-level="5.5.6" data-path="tree-models.html"><a href="tree-models.html#package-gbm"><i class="fa fa-check"></i><b>5.5.6</b> Package ‘gbm’</a></li>
<li class="chapter" data-level="5.5.7" data-path="tree-models.html"><a href="tree-models.html#极限梯度提升分类"><i class="fa fa-check"></i><b>5.5.7</b> 极限梯度提升——分类</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="tree-models.html"><a href="tree-models.html#cubist-model"><i class="fa fa-check"></i><b>5.6</b> Cubist Model</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="tree-models.html"><a href="tree-models.html#introduction-3"><i class="fa fa-check"></i><b>5.6.1</b> Introduction</a></li>
<li class="chapter" data-level="5.6.2" data-path="tree-models.html"><a href="tree-models.html#application-data-preparation"><i class="fa fa-check"></i><b>5.6.2</b> Application Data Preparation</a></li>
<li class="chapter" data-level="5.6.3" data-path="tree-models.html"><a href="tree-models.html#fit-continious-outcome"><i class="fa fa-check"></i><b>5.6.3</b> Fit Continious Outcome</a></li>
<li class="chapter" data-level="5.6.4" data-path="tree-models.html"><a href="tree-models.html#variable-importance"><i class="fa fa-check"></i><b>5.6.4</b> Variable Importance</a></li>
<li class="chapter" data-level="5.6.5" data-path="tree-models.html"><a href="tree-models.html#summary-display"><i class="fa fa-check"></i><b>5.6.5</b> Summary display</a></li>
<li class="chapter" data-level="5.6.6" data-path="tree-models.html"><a href="tree-models.html#specific-parts"><i class="fa fa-check"></i><b>5.6.6</b> specific parts</a></li>
<li class="chapter" data-level="5.6.7" data-path="tree-models.html"><a href="tree-models.html#ensembles-by-committees"><i class="fa fa-check"></i><b>5.6.7</b> Ensembles By Committees</a></li>
<li class="chapter" data-level="5.6.8" data-path="tree-models.html"><a href="tree-models.html#nearestneighbors-adjustmemt"><i class="fa fa-check"></i><b>5.6.8</b> Nearest–neighbors Adjustmemt</a></li>
<li class="chapter" data-level="5.6.9" data-path="tree-models.html"><a href="tree-models.html#optimize-parameters"><i class="fa fa-check"></i><b>5.6.9</b> Optimize parameters</a></li>
<li class="chapter" data-level="5.6.10" data-path="tree-models.html"><a href="tree-models.html#logistic-cv"><i class="fa fa-check"></i><b>5.6.10</b> Logistic CV</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>6</b> PCA</a>
<ul>
<li class="chapter" data-level="6.1" data-path="pca.html"><a href="pca.html#introduction-4"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="pca.html"><a href="pca.html#component"><i class="fa fa-check"></i><b>6.1.1</b> Component</a></li>
<li class="chapter" data-level="6.1.2" data-path="pca.html"><a href="pca.html#pca算法"><i class="fa fa-check"></i><b>6.1.2</b> PCA算法</a></li>
<li class="chapter" data-level="6.1.3" data-path="pca.html"><a href="pca.html#主成分旋转"><i class="fa fa-check"></i><b>6.1.3</b> 主成分旋转</a></li>
<li class="chapter" data-level="6.1.4" data-path="pca.html"><a href="pca.html#kernelized-pca"><i class="fa fa-check"></i><b>6.1.4</b> Kernelized PCA</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="pca.html"><a href="pca.html#application-2"><i class="fa fa-check"></i><b>6.2</b> Application</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="pca.html"><a href="pca.html#data-preparation-4"><i class="fa fa-check"></i><b>6.2.1</b> Data preparation</a></li>
<li class="chapter" data-level="6.2.2" data-path="pca.html"><a href="pca.html#modeling-1"><i class="fa fa-check"></i><b>6.2.2</b> Modeling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>7</b> Cluster Analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hierarchical-clustering"><i class="fa fa-check"></i><b>7.1</b> Hierarchical Clustering</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#introduction-5"><i class="fa fa-check"></i><b>7.1.1</b> Introduction</a></li>
<li class="chapter" data-level="7.1.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hierarchical-clustering-algorithms"><i class="fa fa-check"></i><b>7.1.2</b> Hierarchical clustering algorithms</a></li>
<li class="chapter" data-level="7.1.3" data-path="cluster-analysis.html"><a href="cluster-analysis.html#measure-the-dissimilarity-between-two-clusters-of-observations"><i class="fa fa-check"></i><b>7.1.3</b> Measure the dissimilarity between two clusters of observations</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#k-means-clustering"><i class="fa fa-check"></i><b>7.2</b> K-means Clustering</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#algorithm"><i class="fa fa-check"></i><b>7.2.1</b> Algorithm</a></li>
<li class="chapter" data-level="7.2.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#k-means"><i class="fa fa-check"></i><b>7.2.2</b> K-Means++</a></li>
<li class="chapter" data-level="7.2.3" data-path="cluster-analysis.html"><a href="cluster-analysis.html#elkan-k-means"><i class="fa fa-check"></i><b>7.2.3</b> elkan K-Means</a></li>
<li class="chapter" data-level="7.2.4" data-path="cluster-analysis.html"><a href="cluster-analysis.html#mini-batch-k-means"><i class="fa fa-check"></i><b>7.2.4</b> Mini Batch K-Means</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="cluster-analysis.html"><a href="cluster-analysis.html#gowers-coefficient-and-pam"><i class="fa fa-check"></i><b>7.3</b> Gower’s coefficient and PAM</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#gowers-coefficient"><i class="fa fa-check"></i><b>7.3.1</b> Gower’s coefficient</a></li>
<li class="chapter" data-level="7.3.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#不同数据类型的相异度计算-距离法"><i class="fa fa-check"></i><b>7.3.2</b> 不同数据类型的相异度计算 (距离法)</a></li>
<li class="chapter" data-level="7.3.3" data-path="cluster-analysis.html"><a href="cluster-analysis.html#pam"><i class="fa fa-check"></i><b>7.3.3</b> PAM</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="cluster-analysis.html"><a href="cluster-analysis.html#birch-clustering"><i class="fa fa-check"></i><b>7.4</b> BIRCH Clustering</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#birch-introduction"><i class="fa fa-check"></i><b>7.4.1</b> BIRCH Introduction</a></li>
<li class="chapter" data-level="7.4.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#聚类特征cf与聚类特征树cf-tree"><i class="fa fa-check"></i><b>7.4.2</b> 聚类特征CF与聚类特征树CF Tree</a></li>
<li class="chapter" data-level="7.4.3" data-path="cluster-analysis.html"><a href="cluster-analysis.html#cf-tree的生成"><i class="fa fa-check"></i><b>7.4.3</b> CF Tree的生成</a></li>
<li class="chapter" data-level="7.4.4" data-path="cluster-analysis.html"><a href="cluster-analysis.html#birch算法"><i class="fa fa-check"></i><b>7.4.4</b> BIRCH算法</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="cluster-analysis.html"><a href="cluster-analysis.html#application-3"><i class="fa fa-check"></i><b>7.5</b> Application</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#data-preparation-5"><i class="fa fa-check"></i><b>7.5.1</b> Data preparation</a></li>
<li class="chapter" data-level="7.5.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hierarchical-clustering-1"><i class="fa fa-check"></i><b>7.5.2</b> Hierarchical Clustering</a></li>
<li class="chapter" data-level="7.5.3" data-path="cluster-analysis.html"><a href="cluster-analysis.html#k-means-clustering-1"><i class="fa fa-check"></i><b>7.5.3</b> K-means Clustering</a></li>
<li class="chapter" data-level="7.5.4" data-path="cluster-analysis.html"><a href="cluster-analysis.html#gowers-coefficient-and-pam-1"><i class="fa fa-check"></i><b>7.5.4</b> Gower’s coefficient and PAM</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html"><i class="fa fa-check"></i><b>8</b> linear discriminant analysis (LDA)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#introduction-6"><i class="fa fa-check"></i><b>8.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#naive-bayes"><i class="fa fa-check"></i><b>8.1.1</b> Naive Bayes</a></li>
<li class="chapter" data-level="8.1.2" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#controlling-prevalence"><i class="fa fa-check"></i><b>8.1.2</b> Controlling prevalence</a></li>
<li class="chapter" data-level="8.1.3" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#qda"><i class="fa fa-check"></i><b>8.1.3</b> QDA</a></li>
<li class="chapter" data-level="8.1.4" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#lda"><i class="fa fa-check"></i><b>8.1.4</b> LDA</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#discriminant-analysis-algorithm"><i class="fa fa-check"></i><b>8.2</b> Discriminant analysis algorithm</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#idee-1"><i class="fa fa-check"></i><b>8.2.1</b> Idee</a></li>
<li class="chapter" data-level="8.2.2" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#瑞利商rayleigh-quotient"><i class="fa fa-check"></i><b>8.2.2</b> 瑞利商（Rayleigh quotient）</a></li>
<li class="chapter" data-level="8.2.3" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#广义瑞利商-genralized-rayleigh-quotient"><i class="fa fa-check"></i><b>8.2.3</b> 广义瑞利商 genralized Rayleigh quotient</a></li>
<li class="chapter" data-level="8.2.4" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#lda算法流程"><i class="fa fa-check"></i><b>8.2.4</b> LDA算法流程</a></li>
<li class="chapter" data-level="8.2.5" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#lda-application"><i class="fa fa-check"></i><b>8.2.5</b> LDA Application</a></li>
<li class="chapter" data-level="8.2.6" data-path="linear-discriminant-analysis-lda.html"><a href="linear-discriminant-analysis-lda.html#qda-1"><i class="fa fa-check"></i><b>8.2.6</b> QDA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="neural-network.html"><a href="neural-network.html"><i class="fa fa-check"></i><b>9</b> Neural Network</a>
<ul>
<li class="chapter" data-level="9.1" data-path="neural-network.html"><a href="neural-network.html#introduction-7"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="neural-network.html"><a href="neural-network.html#反向传播方法进行训练的前馈神经网络"><i class="fa fa-check"></i><b>9.2</b> 反向传播方法进行训练的前馈神经网络</a></li>
<li class="chapter" data-level="9.3" data-path="neural-network.html"><a href="neural-network.html#application-4"><i class="fa fa-check"></i><b>9.3</b> Application</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="neural-network.html"><a href="neural-network.html#数据准备"><i class="fa fa-check"></i><b>9.3.1</b> 数据准备</a></li>
<li class="chapter" data-level="9.3.2" data-path="neural-network.html"><a href="neural-network.html#模型构建"><i class="fa fa-check"></i><b>9.3.2</b> 模型构建</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="more-to-say.html"><a href="more-to-say.html"><i class="fa fa-check"></i><b>A</b> More to Say</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ML Project Using bookdown</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tree-models" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Tree models<a href="tree-models.html#tree-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div class="markmap html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-a935a9e9f8d2a0f70c23" style="width:672px;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-a935a9e9f8d2a0f70c23">{"x":{"data":"# \n## Tree models\n### Decision Tree Model\n#### Decision tree algorithm\n#### ID3 Algorithm \n##### 举例: \n##### Algorithm process\n##### 不足\n#### C4.5 Algorithm \n##### 不足\n#### CART Algorithm \n##### Classification tree\n##### 分类树建立算法的具体流程\n##### Regression tree\n##### 回归树建立算法的具体流程\n#### Pruning\n##### 剪枝的损失函数度量\n##### 算法主要过程如下\n#### Package ‘rpart’\n### Random Forest\n#### Bootstrap (Bagging)\n#### bagging算法流程\n#### Random Forest Algorithm\n##### RF算法\n#### Random forest promotion\n##### Extra trees\n##### Totally Random Trees Embedding\n##### Isolation Forest\n#### Package ‘randomForest’\n### Modelling\n#### Data preparation \n#### Regression tree\n#### Classification tree\n#### Random forest for regression\n#### Random forest for classification\n#### 皮玛印第安人糖尿病数据集\n#### 使用随机森林进行特征选择\n### Gradient Boosting\n### Gradient Descent\n#### Gradient\n#### Gradient Descent\n#### Gradient Descent Algorithm\n#### Gradient Descent Familiy\n##### 批量梯度下降法（BGD, Batch Gradient Descent)\n##### 随机梯度下降法（SGD, Stochastic Gradient Descent）\n##### 小批量梯度下降法（MBGD, Mini-batch Gradient Descent）\n#### GBDT分类算法\n#### Package ‘gbm’\n#### 极限梯度提升——分类\n### Cubist Model\n#### Introduction\n#### Application Data Preparation\n#### Fit Continious Outcome\n#### Variable Importance\n#### Summary display\n#### specific parts \n#### Ensembles By Committees \n#### Nearest–neighbors Adjustmemt\n#### Optimize parameters\n#### Logistic CV","options":{"preset":"colorful","autoFit":true}},"evals":[],"jsHooks":[]}</script>
<div id="decision-tree-model" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Decision Tree Model<a href="tree-models.html#decision-tree-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="decision-tree-algorithm" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Decision tree algorithm<a href="tree-models.html#decision-tree-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Tree-based models are a class of nonparametric algorithms that work by partitioning the feature space into a number of smaller (non-overlapping) regions with similar response values using a set of splitting rules. Predictions are obtained by fitting a simpler model (e.g., a constant like the average response value) in each region.</p>
<blockquote>
<p>基于树的模型是一类非参数算法，其通过使用一组拆分规则将特征空间划分为具有相似响应值的多个较小（非重叠）区域来工作。 通过在每个区域中拟合更简单的模型（例如，类似于平均响应值的常数）来获得预测。</p>
</blockquote>
<p>{% embed url=“<a href="https://www.cnblogs.com/pinard/p/6050306.html" class="uri">https://www.cnblogs.com/pinard/p/6050306.html</a>” %}</p>
<p>{% embed url=“<a href="https://www.cnblogs.com/pinard/p/6053344.html" class="uri">https://www.cnblogs.com/pinard/p/6053344.html</a>” %}</p>
</div>
<div id="id3-algorithm" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> ID3 Algorithm<a href="tree-models.html#id3-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>1970年代，一个叫昆兰的大牛找到了用信息论中的熵来度量决策树的决策选择过程，方法一出，它的简洁和高效就引起了轰动，昆兰把这个算法叫做ID3。熵度量了事物的不确定性，<strong>越不确定的事物，它的熵就越大</strong>。具体的，随机变量X的熵的表达式如下：</p>
<p><span class="math display">\[
H(X) = -\sum\limits_{i=1}^{n}p_i logp_i
\]</span></p>
<ul>
<li>其中n代表X的n种不同的离散取值</li>
<li><span class="math display">\[p_i\]</span>代表了X取值为i的概率</li>
<li>log为以2或者e为底的对数。</li>
</ul>
<p>熟悉了一个变量X的熵，很容易推广到多个个变量的联合熵，这里给出两个变量X和Y的联合熵表达式：</p>
<p><span class="math display">\[
H(X,Y) = -\sum\limits_{x_i \in X}\sum\limits_{y_i \in Y}p(x_i,y_i)logp(x_i,y_i)
\]</span></p>
<p>有了联合熵，又可以得到条件熵的表达式H(X|Y)，条件熵类似于条件概率,它度量了我们的X在知道Y以后剩下的不确定性。表达式如下：</p>
<p><span class="math display">\[
H(X|Y) = -\sum\limits_{x_i \in X}\sum\limits_{y_i \in Y}p(x_i,y_i)logp(x_i|y_i) = \sum\limits_{j=1}^{n}p(y_j)H(X|y_j)
\]</span></p>
<ul>
<li>H(X)度量了X的不确定性</li>
<li>条件熵H(X|Y)度量了我们在知道Y以后X剩下的不确定性</li>
<li><strong>H(X)-H(X|Y): </strong>度量了X在知道Y以后不确定性减少程度，这个度量我们在信息论中称为互信息，，记为I(X,Y)。在决策树ID3算法中叫做<strong>信息增益 </strong>information divergence。ID3算法就是用信息增益来判断当前节点应该用什么特征来构建决策树。信息增益大，则越适合用<del>来</del>分类。</li>
</ul>
<p>ID3算法就是用信息增益大小来判断当前节点应该用什么特征来构建决策树，用<strong>计算出的信息增益最大的特征来建立决策树的当前节点</strong>。</p>
<div id="举例" class="section level4 hasAnchor" number="5.1.2.1">
<h4><span class="header-section-number">5.1.2.1</span> 举例:<a href="tree-models.html#举例" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>有15个样本D，输出为0或者1。其中有9个输出为1， 6个输出为0。 样本中有个特征A，取值为A1，A2和A3。在取值为A1的样本的输出中，有3个输出为1， 2个输出为0，取值为A2的样本输出中,2个输出为1,3个输出为0， 在取值为A3的样本中，4个输出为1，1个输出为0.</p>
<ul>
<li>样本D的熵为： <span class="math display">\[H(D) = -(\frac{9}{15}log_2\frac{9}{15} + \frac{6}{15}log_2\frac{6}{15}) = 0.971\]</span></li>
<li>样本D在特征下的条件熵为： <span class="math display">\[H(D|A) = \frac{5}{15}H(D1) + \frac{5}{15}H(D2) + \frac{5}{15}H(D3)\]</span> <span class="math display">\[= -\frac{5}{15}(\frac{3}{5}log_2\frac{3}{5} + \frac{2}{5}log_2\frac{2}{5}) - \frac{5}{15}(\frac{2}{5}log_2\frac{2}{5} + \frac{3}{5}log_2\frac{3}{5}) -\frac{5}{15}(\frac{4}{5}log_2\frac{4}{5} + \frac{1}{5}log_2\frac{1}{5}) = 0.888\]</span></li>
<li>对应的信息增益为 <span class="math display">\[I(D,A) = H(D) - H(D|A) = 0.083\]</span></li>
</ul>
</div>
<div id="algorithm-process" class="section level4 hasAnchor" number="5.1.2.2">
<h4><span class="header-section-number">5.1.2.2</span> Algorithm process<a href="tree-models.html#algorithm-process" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>输入的是m个样本，样本输出集合为D，每个样本有n个离散特征，特征集合即为A，输出为决策树T。</p>
<ol style="list-style-type: decimal">
<li>初始化信息增益的间值 <span class="math display">\[\epsilon\]</span></li>
<li>判断样本是否为同一类输出 <span class="math display">\[D_{i},\]</span> 如果是则返回单节点树T。标记类别为 <span class="math display">\[D_{i}\]</span></li>
<li>判断特征是否为空, 如果是则返回单节点树T， 标记类别为样本中输出类别D实例数最多的类别。</li>
<li>计算A中的各个特征 (一共n个) 对输出D的信息增益, 选择信息增益最大的特征 <span class="math display">\[A_{g}\]</span></li>
<li>如果 <span class="math display">\[A_{g}\]</span> 的信息增益小于间值 <span class="math display">\[\epsilon,\]</span> 则返回单节点树T，标记类别为样本中输出类别D实例数最多的类别。</li>
<li>如果 <span class="math display">\[A_{g}\]</span> 的信息增益小于间值 <span class="math display">\[\epsilon,\]</span> , 按特征 <span class="math display">\[A_{g}\]</span> 的不同取值 <span class="math display">\[A_{g i}\]</span> 将对应的样本输出D分成不同的类别 <span class="math display">\[D_{i 。}\]</span> 每个类别产生一个子节点。对应特征值为 <span class="math display">\[A_{g i}\]</span> 返回增加了节点的数T。</li>
<li>对于所有的子节点, 令 <span class="math display">\[D=D_{i}, A=A-\left\{A_{g}\right\}\]</span> 递归调用2-6步, 得到子树 <span class="math display">\[T_{i}\]</span> 并返回。</li>
</ol>
</div>
<div id="不足" class="section level4 hasAnchor" number="5.1.2.3">
<h4><span class="header-section-number">5.1.2.3</span> 不足<a href="tree-models.html#不足" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>ID3没有考虑连续特征，比如长度，密度都是连续值，无法在ID3运用。</li>
<li>ID3采用信息增益大的特征优先建立决策树的节点。很快就被人发现，在相同条件下，<strong>取值比较多的特征比取值少的特征信息增益大</strong>。</li>
<li>ID3算法对于缺失值的情况没有做考虑</li>
<li>没有考虑过拟合的问题 Overfitting</li>
</ol>
</div>
</div>
<div id="c4.5-algorithm" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> C4.5 Algorithm<a href="tree-models.html#c4.5-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>ID3算法有四个主要的不足，一是不能处理连续特征，第二个就是用信息增益作为标准容易偏向于取值较多的特征，最后两个是缺失值处理的问和过拟合问题。昆兰在C4.5算法中改进了上述4个问题. ID3 算法的作者昆兰基于上述不足，对ID3算法做了改进，这就是C4.5算法</p>
<p>第一个问题，不能处理连续特征， C4.5的思路是将连续的特征离散化。比如m个样本的连续特征A有m个，从小到大排列为a1,a2,…,am,则C4.5取相邻两样本值的平均数，一共取得m-1个划分点. 其中第i个划分点<span class="math display">\[T_i\]</span>表示为 <span class="math display">\[T_i = \frac{a_i+a_{i+1}}{2}\]</span> 。对于这m-1个点，分别计算以该点作为二元分类点时的信息增益。选择信息增益最大的点作为该连续特征的二元离散分类点。比如取到的增益最大的点为at,则小于at的值为类别1，大于at的值为类别2，这样我们就做到了连续特征的离散化。</p>
<p>第二个问题，信息增益作为标准容易偏向于取值较多的特征的问题。我们引入一个信息增益比的变量 <span class="math display">\[I_R(X,Y)\]</span> ，它是信息增益和特征熵的比值。表达式如下</p>
<p><span class="math display">\[
I_R(D,A) = \frac{I(A,D)}{H_A(D)}
\]</span></p>
<p>其中D为样本特征输出的集合，A为样本特征，对于特征熵<span class="math display">\[H_A(D)\]</span></p>
<p><span class="math display">\[
H_A(D) = -\sum\limits_{i=1}^{n}\frac{|D_i|}{|D|}log_2\frac{|D_i|}{|D|}
\]</span></p>
<p>其中n为特征A的类别数， Di为特征A的第i个取值对应的样本个数。|D|为样本个数。<strong>特征数越多的特征对应的特征熵越大，它作为分母，可以校正信息增益容易偏向于取值较多的特征的问题</strong>。</p>
<p>第三个缺失值处理的问题，主要需要解决的是两个问题，</p>
<ul>
<li>一是在样本某些特征缺失的情况下选择划分的属性，
<ul>
<li>对于某一个有缺失特征值的特征A。C4.5的思路是将数据分成两部分，对每个样本设置一个权重（初始可以都为1），然后划分数据，一部分是有特征值A的数据D1，另一部分是没有特征A的数据D2. 然后对于没有缺失特征A的数据集D1来和对应的A特征的各个特征值一起计算加权重后的信息增益比，最后乘上一个系数，这个系数是无特征A缺失的样本加权后所占加权总样本的比例。</li>
</ul></li>
<li>二是选定了划分属性，对于在该属性上缺失特征的样本的处理。
<ul>
<li>将缺失特征的样本同时划分入所有的子节点，不过将该样本的权重按各个子节点样本的数量比例来分配。比如缺失特征A的样本a之前权重为1，特征A有3个特征值A1,A2,A3。 3个特征值对应的无缺失A特征的样本个数为2,3,4.则a同时划分入A1，A2，A3。对应权重调节为2/9,3/9, 4/9。</li>
</ul></li>
</ul>
<p>第四个问题，C4.5引入了正则化系数进行初步的剪枝。</p>
<div id="不足-1" class="section level4 hasAnchor" number="5.1.3.1">
<h4><span class="header-section-number">5.1.3.1</span> 不足<a href="tree-models.html#不足-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>由于决策树算法非常容易过拟合，因此对于生成的决策树必须要进行剪枝。剪枝的算法有非常多，C4.5的剪枝方法有优化的空间。思路主要是两种，一种是预剪枝，即在生成决策树的时候就决定是否剪枝。另一个是后剪枝，即先生成决策树，再通过交叉验证来剪枝。(CART树: 主要采用的是后剪枝加上交叉验证选择最合适的决策树)</li>
<li>C4.5生成的是多叉树，即一个父节点可以有多个节点。很多时候，在计算机中二叉树模型会比多叉树运算效率高。如果采用二叉树，可以提高效率。</li>
<li>C4.5只能用于分类，如果能将决策树用于回归的话可以扩大它的使用范围。</li>
<li>C4.5由于使用了熵模型，里面有大量的耗时的对数运算,如果是连续值还有大量的排序运算。如果能够加以模型简化可以减少运算强度但又不牺牲太多准确性的话，那就更好了。</li>
</ol>
</div>
</div>
<div id="cart-algorithm" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> CART Algorithm<a href="tree-models.html#cart-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>对于C4.5算法的不足，比如模型是用较为复杂的熵来度量，使用了相对较为复杂的多叉树，只能处理分类不能处理回归等。对于这些问题， CART算法大部分做了改进。</p>
<ul>
<li>在ID3算法中我们使用了信息增益来选择特征，信息增益大的优先选择。</li>
<li>在C4.5算法中，采用了信息增益比来选择特征，以减少信息增益容易选择特征值多的特征的问题。</li>
<li>CART分类树算法使用基尼系数来代替信息增益比，基尼系数代表了模型的不纯度，基尼系数越小，则不纯度越低，特征越好。这和信息增益(比)是相反的。</li>
</ul>
<p>具体的，在分类问题中，假设有K个类别，第k个类别的概率为 <span class="math display">\[p_k\]</span> , 则基尼系数的表达式为：</p>
<p><span class="math display">\[
Gini(p) = \sum\limits_{k=1}^{K}p_k(1-p_k) = 1- \sum\limits_{k=1}^{K}p_k^2
\]</span></p>
<p>如果是二类分类问题，计算就更加简单了，如果属于第一个样本输出的概率是p，则基尼系数的表达式为：</p>
<p><span class="math display">\[
Gini(p) = 2p(1-p)
\]</span></p>
<p>对于个给定的样本D,假设有K个类别, 第k个类别的数量为<span class="math display">\[C_k\]</span>,则样本D的基尼系数表达式为：</p>
<p><span class="math display">\[
Gini(D) = 1-\sum\limits_{k=1}^{K}(\frac{|C_k|}{|D|})^2
\]</span></p>
<p>对于样本D,如果根据特征A的某个值a,把D分成D1和D2两部分，则在特征A的条件下，D的基尼系数表达式为：</p>
<p><span class="math display">\[
Gini(D,A) = \frac{|D_1|}{|D|}Gini(D_1) + \frac{|D_2|}{|D|}Gini(D_2)
\]</span></p>
<p>对于CART分类树连续值的处理问题，其思想和C4.5是相同的，都是将连续的特征离散化。唯一的区别在于在选择划分点时的度量方式不同，C4.5使用的是信息增益比，则CART分类树使用的是基尼系数。将连续的特征离散化。比如m个样本的连续特征A有m个，从小到大排列为a1,a2,…,am,则C4.5取相邻两样本值的平均数，一共取得m-1个划分点. 其中第i个划分点<span class="math display">\[T_i\]</span>表示为 <span class="math display">\[T_i = \frac{a_i+a_{i+1}}{2}\]</span> 。对于这m-1个点，分别计算以该点作为二元分类点时的基尼系数。选择基尼系数最小的点作为该连续特征的二元离散分类点。比如取到的基尼系数最小的点为<span class="math display">\[a_t\]</span>则小于<span class="math display">\[a_t\]</span>的值为类别1，大于<span class="math display">\[a_t\]</span>的值为类别2，这样我们就做到了连续特征的离散化。</p>
<div id="classification-tree" class="section level4 hasAnchor" number="5.1.4.1">
<h4><span class="header-section-number">5.1.4.1</span> Classification tree<a href="tree-models.html#classification-tree" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>分类树与回归树的运行原理是一样的，区别在于决定分裂过程的不是RSS，而是<strong>误差率</strong>。误差率不是简单地由误分类的观测数除以总观测数算出。实际上，进行树分裂 时，误分类率本身可能会导致这样一种情况: 可以从下次分裂中获得一些有用信息，但误分类率却没有改善。</p>
<ul>
<li>假设有一个节点N0，节点中有7个标号为No的观测和3个标号为Yes的观测，我们就可以说误 分类率为30%</li>
<li>另一种误差测量方式进行计算，这种方式称为<strong>基尼指数</strong>。 单个节点的基尼指数计算公式如下:<br />
基尼指数=1-(类别1的概率)<sup>2-(类别的概率)</sup>2<br />
在此：对于N0，基尼指数为1 - (0.7)2 - (0.3)2，等于0.42</li>
</ul>
<p>假设将节点N0分裂成两个节点N1和N2，N1中有3个观测属于 类别1，没有属于类别2的观测; N2中有4个观测属于类别1，3个属于类别2。现在，树的这个分支 的整体的误分类率还是30% 整体的基尼指数：</p>
<ul>
<li>基尼指数(N1) = 1 - (3/3)^2 - (0/3)^2= 0</li>
<li>基尼指数(N2) = 1 - (4/7)^2 - (3/7)^2= 0.49</li>
<li>新基尼指数 = (N1比例×基尼指数(N1))+(N2比例×基尼指数(N2)) = (0.3×0) + (0.7×0.49)=0.343. 改善了模型的不纯度，将其从原来的0.42减小到0.343，误分类率却没有变化。rpart()包就是使用Gini指数测量误差的</li>
</ul>
</div>
<div id="分类树建立算法的具体流程" class="section level4 hasAnchor" number="5.1.4.2">
<h4><span class="header-section-number">5.1.4.2</span> 分类树建立算法的具体流程<a href="tree-models.html#分类树建立算法的具体流程" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>算法输入是训练集D，基尼系数的阈值，样本个数阈值。算法从根节点开始，用训练集递归的建立CART树。</p>
<ol style="list-style-type: decimal">
<li>对于当前节点的数据集为D，如果样本个数小于阈值或者没有特征，则返回决策子树，当前节点停止递归。</li>
<li>计算样本集D的基尼系数，如果基尼系数小于阈值，则返回决策树子树，当前节点停止递归。</li>
<li>计算当前节点现有的各个特征的各个特征值对数据集D的基尼系数，缺失值的处理方法和C4.5算法里描述的相同。</li>
<li>在计算出来的各个特征的各个特征值对数据集D的基尼系数中，选择基尼系数最小的特征A和对应的特征值a。根据这个最优特征和最优特征值，把数据集划分成两部分D1和D2，同时建立当前节点的左右节点，做节点的数据集D为D1，右节点的数据集D为D2.</li>
<li>对左右的子节点递归的调用1-4步，生成决策树。</li>
</ol>
</div>
<div id="regression-tree" class="section level4 hasAnchor" number="5.1.4.3">
<h4><span class="header-section-number">5.1.4.3</span> Regression tree<a href="tree-models.html#regression-tree" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>树方法的精髓就是划分特征，从第一次分裂开始就要考虑如何最大程度改善RSS，然 后持续进行二叉分裂，直到树结束。后面的划分并不作用于全体数据集，而仅作用于上次划分时 落到这个分支之下的那部分数据。这个自顶向下的过程被称为“递归划分”。这个过程是贪婪的:</p>
<blockquote>
<p>Greed 贪婪的含义是，<strong>算法在每次分裂中都追求最大程度减少RSS，而不管以后的划分中表现如何</strong>。这样做的结果是，你可能会生成一个带有无效分支的 树，尽管偏差很小，但是方差很大。为了避免这个问题，生成完整的树之后，你要<strong>对树进行剪枝</strong>， 得到最优的规模。</p>
</blockquote>
<ul>
<li>优点是可以处理高度非线性关系</li>
<li>首要的问题就是，一个观测被赋予所属终端节点的平均值，这会损害整体预测效果(高偏差)</li>
<li>如果你一直对数据进行划分，树的层次越来越深，这样可以达到低偏差的效果，但是高方差又成了问题 (可以用交叉验证来选择合适的深度)</li>
</ul>
</div>
<div id="回归树建立算法的具体流程" class="section level4 hasAnchor" number="5.1.4.4">
<h4><span class="header-section-number">5.1.4.4</span> 回归树建立算法的具体流程<a href="tree-models.html#回归树建立算法的具体流程" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>CART回归树和CART分类树的建立和预测的区别主要有下面两点：</p>
<p>　　　　1)连续值的处理方法不同</p>
<p>　　　　2)决策树建立后做预测的方式不同。</p>
<p>对于连续值的处理，我们知道CART分类树采用的是用基尼系数的大小来度量特征的各个划分点的优劣情况。这比较适合分类模型，但是对于回归模型，我们使用了常见的和方差的度量方式，CART回归树的度量目标是，对于任意划分特征A，对应的任意划分点s两边划分成的数据集D1和D2，求出使D1和D2各自集合的均方差最小，同时D1和D2的均方差之和最小所对应的特征和特征值划分点。表达式为：(其中，c1为D1数据集的样本输出均值，c2为D2数据集的样本输出均值。)</p>
<p><span class="math display">\[
\begin{equation}
SSE = \sum_{i \in R_1}\left(y_i - c_1\right)^2 + \sum_{i \in R_2}\left(y_i - c_2\right)^2
\end{equation}
\]</span></p>
<p><span class="math display">\[
\underbrace{min}_{A,s}\Bigg[\underbrace{min}_{c_1}\sum\limits_{x_i \in D_1(A,s)}(y_i - c_1)^2 + \underbrace{min}_{c_2}\sum\limits_{x_i \in D_2(A,s)}(y_i - c_2)^2\Bigg]
\]</span></p>
<p>对于决策树建立后做预测的方式，CART分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。</p>
</div>
</div>
<div id="pruning" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Pruning<a href="tree-models.html#pruning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>CART回归树和CART分类树的剪枝策略除了在度量损失的时候一个使用均方差，一个使用基尼系数。由于决策时算法很容易对训练集过拟合，而导致泛化能力差，为了解决这个问题，我们需要对CART树进行剪枝，即类似于线性回归的正则化，来增加决策树的泛化能力。</p>
<p>有很多的剪枝方法，我们应该这么选择呢？CART采用的办法是<strong>后剪枝法</strong>，即先生成决策树，然后<strong>产生所有可能的剪枝后的CART树，然后使用交叉验证来检验各种剪枝的效果</strong>，选择泛化能力最好的剪枝策略。也就是说，CART树的剪枝算法可以概括为两步，</p>
<ol style="list-style-type: decimal">
<li>从原始决策树生成各种剪枝效果的决策树</li>
<li>用交叉验证来检验剪枝后的预测能力，选择泛化预测能力最好的剪枝后的数作为最终的CART树</li>
</ol>
<div id="剪枝的损失函数度量" class="section level4 hasAnchor" number="5.1.5.1">
<h4><span class="header-section-number">5.1.5.1</span> 剪枝的损失函数度量<a href="tree-models.html#剪枝的损失函数度量" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>在剪枝的过程中，对于任意的一刻子树<span class="math display">\[T_,\]</span>其损失函数为：</p>
<p><span class="math display">\[
C_{\alpha}(T_t) = C(T_t) + \alpha |T_t|
\]</span></p>
<p>其中，α为正则化参数，这和线性回归的正则化一样。 <span class="math display">\[C(T_t)\]</span> 为训练数据的预测误差，分类树是用基尼系数度量，回归树是均方差度量。|Tt|是子树T的叶子节点的数量.</p>
<ul>
<li>当 <span class="math display">\[\alpha = 0\]</span> 时，即没有正则化，原始的生成的CART树即为最优子树。</li>
<li>当 <span class="math display">\[\alpha = \infty\]</span> ，即正则化强度达到最大，此时由原始的生成的CART树的根节点组成的单节点树为最优子树。当然，这是两种极端情况。</li>
<li>一般来说，<span class="math display">\[\alpha\]</span><strong>越大，则剪枝剪的越厉害，生成的最优子树相比原生决策树就越偏小</strong>。对于固定的<span class="math display">\[\alpha\]</span>，一定存在使损失函数Cα(T)最小的唯一子树。</li>
</ul>
<p>看过剪枝的损失函数度量后，我们再来看看剪枝的思路，对于位于节点t的任意一颗子树<span class="math display">\[T_t\]</span>，如果没有剪枝，它的损失是 <span class="math display">\[C_{\alpha}(T_t) = C(T_t) + \alpha |T_t|\]</span>, 如果将其剪掉，仅仅保留根节点，则损失是 <span class="math display">\[C_{\alpha}(T) = C(T) + \alpha\]</span> . 当 <span class="math display">\[\alpha = 0\]</span> 或者<span class="math display">\[\alpha\]</span>很小时， <span class="math display">\[C_{\alpha}(T_t) &lt; C_{\alpha}(T)\]</span> , 当<span class="math display">\[\alpha\]</span>增大到一定的程度时 <span class="math display">\[C_{\alpha}(T_t) = C_{\alpha}(T)\]</span></p>
</div>
<div id="算法主要过程如下" class="section level4 hasAnchor" number="5.1.5.2">
<h4><span class="header-section-number">5.1.5.2</span> 算法主要过程如下<a href="tree-models.html#算法主要过程如下" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>输入是CART树建立算法得到的原始决策树 <span class="math display">\[T_{0}\]</span> 输出是最优决策子树 <span class="math display">\[T_{\alpha 。}\]</span></p>
<ol style="list-style-type: decimal">
<li>初始化 <span class="math display">\[k=0, T=T_{0},\]</span> 最优子树集合 <span class="math display">\[\omega=\{T\}_{\circ}\]</span></li>
<li><span class="math display">\[\alpha_{\min }=\infty\]</span></li>
<li>从叶子节点开始自下而上计算各内部节点t的训练误差损失函数 <span class="math display">\[C_{\alpha}\left(T_{t}\right)\]</span> (回归树为均方差, 分类树为基尼系数)，叶子节点数 <span class="math display">\[\left|T_{t}\right|,\]</span> 以及正则化间值 <span class="math display">\[\alpha=\min \left\{\frac{C(T)-C\left(T_{t}\right)}{\left|T_{t}\right|-1}, \alpha_{\min }\right\},\]</span> 更新 <span class="math display">\[\alpha_{\min }=\alpha\]</span></li>
<li><span class="math display">\[\alpha_{k}=\alpha_{\min }\]</span></li>
<li>自上而下的访问子树的内部节点, 如果 <span class="math display">\[\frac{C(T)-C\left(T_{t}\right)}{\left|T_{t}\right|-1} \leq \alpha_{k}\]</span> 时, 进行剪枝。并决定叶节点<span class="math display">\[t\]</span>的值。如果是分类树, 则是概率最高的类别, 如果是回归树，则是所有样本输出的均值。这样得到 <span class="math display">\[\alpha_{k}\]</span> 对应的最优子树 <span class="math display">\[T_{k}\]</span></li>
<li>最优子树集合 <span class="math display">\[\omega=\omega \cup T_{k}\]</span></li>
<li><span class="math display">\[k=k+1, T=T_{k},\]</span> 如果<span class="math display">\[T\]</span>不是由根节点单独组成的树, 则回到步骤2继续递归执行。否则就已经得到了所有的可选最优子树集合 <span class="math display">\[\omega .\]</span></li>
<li>采用交叉验证在 <span class="math display">\[\omega\]</span> 选择最优子树 <span class="math display">\[T_{\alpha}\]</span></li>
</ol>
</div>
</div>
<div id="package-rpart" class="section level3 hasAnchor" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Package ‘rpart’<a href="tree-models.html#package-rpart" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recursive partitioning for classification, regression and survival trees: <a href="https://cran.r-project.org/web/packages/rpart/rpart.pdf">https://cran.r-project.org/web/packages/rpart/rpart.pdf</a></p>
</div>
</div>
<div id="random-forest" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Random Forest<a href="tree-models.html#random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>为了显著提高模型的预测能力，我们可以生成多个树，然后将这些树的结果组合起来。
随机 森林技术在模型构建过程中使用两种奇妙的方法，以实现这个构想。</p>
<pre><code>第一个方法称为自助聚集，或称装袋。在装袋法中，使用数据集的一次随机抽样建立一个独立树，抽样的数量大概为全部观测的2/3(请记住，剩下的1/3被称为袋外数据，out-of-bag)。这个过程重复几十次或上百次，最后取平均结果。其中每个树都任其生长，不进行任何基于误差测量的剪枝，这意味着每个独立树的方差都很大。但是，通过对结果的平均化处理可以降低方差，同时又不增加偏差。

另一个在随机森林中使用的方法是，对数据进行随机抽样(装袋)的同时，独立树每次分裂时对输入特征也进行随机抽样。在randomForest包中，我们使用随机抽样数的默认值来对预测特征进行抽样。对于分类问题，默认值为所有预测特征数量的平方根;对于回归问题，默认值为所有预测 特征数量除以3。</code></pre>
<p>通过每次分裂时对特征的随机抽样以及由此形成的一套方法，你可以减轻高度相关的预测特 征的影响，这种预测特征在由装袋法生成的独立树中往往起主要作用。这种方法还使你不必思索 如何减少装袋导致的高方差。独立树彼此之间的相关性减少之后，对结果的平均化可以使泛化效 果更好，对于异常值的影响也更加不敏感，比仅进行装袋的效果要好。</p>
<p>在随机森林方法中，创建了大量的决策树。每个观察结果都被送入每个决策树。 每个观察结果最常用作最终输出。对所有决策树进行新的观察，并对每个分类模型进行多数投票。
对于在构建树时未使用的情况进行错误估计。 这被称为OOB(Out-of-bag)错误估计，以百分比表示</p>
<div id="bootstrap-bagging" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Bootstrap (Bagging)<a href="tree-models.html#bootstrap-bagging" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>随机采样(bootstrap)就是从我们的训练集里面采集固定个数的样本，但是每采集一个样本后，都将样本放回。也就是说，之前采集到的样本在放回后有可能继续被采集到。Bagging算法，一般会随机采集和训练集样本数m一样个数的样本。</p>
<ul>
<li>Gradient Boosting Decision Tree Algorithm GBDT的子采样是无放回采样</li>
<li>Bagging的子采样是放回采样。</li>
</ul>
<p>对于一个样本，它在某一次含m个样本的训练集的随机采样中，每次被采集到的概率是 <span class="math display">\[\frac{1}{m}\]</span> 。不被采集到的概率为<span class="math display">\[1-\frac{1}{m}\]</span>。如果m次采样都没有被采集中的概率是 <span class="math display">\[(1-\frac{1}{m})^m\]</span> . 当 <span class="math display">\[m \to \infty\]</span> <span class="math display">\[(1-\frac{1}{m})^m \to \frac{1}{e} \simeq 0.368\]</span> 。</p>
<p>也就是说，在bagging的每轮随机采样中，训练集中大约有36.8%的数据没有被采样集采集中。对于这部分大约36.8%的没有被采样到的数据，我们常常称之为<strong>袋外数据(Out Of Bag, 简称OOB)</strong>。这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="tree-models.html#cb2-1" tabindex="-1"></a><span class="co"># Helper packages</span></span>
<span id="cb2-2"><a href="tree-models.html#cb2-2" tabindex="-1"></a><span class="fu">library</span>(dplyr)       <span class="co"># for data wrangling</span></span>
<span id="cb2-3"><a href="tree-models.html#cb2-3" tabindex="-1"></a><span class="fu">library</span>(ggplot2)     <span class="co"># for awesome plotting</span></span>
<span id="cb2-4"><a href="tree-models.html#cb2-4" tabindex="-1"></a><span class="fu">library</span>(doParallel)  <span class="co"># for parallel backend to foreach</span></span>
<span id="cb2-5"><a href="tree-models.html#cb2-5" tabindex="-1"></a><span class="fu">library</span>(foreach)     <span class="co"># for parallel processing with for loops</span></span>
<span id="cb2-6"><a href="tree-models.html#cb2-6" tabindex="-1"></a><span class="co"># Modeling packages</span></span>
<span id="cb2-7"><a href="tree-models.html#cb2-7" tabindex="-1"></a><span class="fu">library</span>(caret)       <span class="co"># for general model fitting</span></span>
<span id="cb2-8"><a href="tree-models.html#cb2-8" tabindex="-1"></a><span class="fu">library</span>(rpart)       <span class="co"># for fitting decision trees</span></span>
<span id="cb2-9"><a href="tree-models.html#cb2-9" tabindex="-1"></a><span class="fu">library</span>(ipred)       <span class="co"># for fitting bagged decision trees</span></span>
<span id="cb2-10"><a href="tree-models.html#cb2-10" tabindex="-1"></a><span class="co"># make bootstrapping reproducible</span></span>
<span id="cb2-11"><a href="tree-models.html#cb2-11" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb2-12"><a href="tree-models.html#cb2-12" tabindex="-1"></a><span class="co"># train bagged model</span></span>
<span id="cb2-13"><a href="tree-models.html#cb2-13" tabindex="-1"></a>prostate <span class="ot">&lt;-</span> <span class="fu">read.delim</span>(<span class="st">&quot;./01_Datasets/prostate.txt&quot;</span>, <span class="at">header=</span>T)</span>
<span id="cb2-14"><a href="tree-models.html#cb2-14" tabindex="-1"></a>ames_bag1 <span class="ot">&lt;-</span> <span class="fu">bagging</span>(</span>
<span id="cb2-15"><a href="tree-models.html#cb2-15" tabindex="-1"></a>  <span class="at">formula =</span> lpsa <span class="sc">~</span> .,</span>
<span id="cb2-16"><a href="tree-models.html#cb2-16" tabindex="-1"></a>  <span class="at">data =</span> prostate,</span>
<span id="cb2-17"><a href="tree-models.html#cb2-17" tabindex="-1"></a>  <span class="at">nbagg =</span> <span class="dv">100</span>,  </span>
<span id="cb2-18"><a href="tree-models.html#cb2-18" tabindex="-1"></a>  <span class="at">coob =</span> <span class="cn">TRUE</span>,</span>
<span id="cb2-19"><a href="tree-models.html#cb2-19" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">2</span>, <span class="at">cp =</span> <span class="dv">0</span>)</span>
<span id="cb2-20"><a href="tree-models.html#cb2-20" tabindex="-1"></a>)</span>
<span id="cb2-21"><a href="tree-models.html#cb2-21" tabindex="-1"></a>ames_bag1</span></code></pre></div>
<pre><code>## 
## Bagging regression trees with 100 bootstrap replications 
## 
## Call: bagging.data.frame(formula = lpsa ~ ., data = prostate, nbagg = 100, 
##     coob = TRUE, control = rpart.control(minsplit = 2, cp = 0))
## 
## Out-of-bag estimate of root mean squared error:  0.1204</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="tree-models.html#cb4-1" tabindex="-1"></a><span class="do">## Apply bagging within caret and use 10-fold CV</span></span>
<span id="cb4-2"><a href="tree-models.html#cb4-2" tabindex="-1"></a>ames_bag2 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb4-3"><a href="tree-models.html#cb4-3" tabindex="-1"></a>  lpsa <span class="sc">~</span> .,</span>
<span id="cb4-4"><a href="tree-models.html#cb4-4" tabindex="-1"></a>  <span class="at">data =</span> prostate,</span>
<span id="cb4-5"><a href="tree-models.html#cb4-5" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;treebag&quot;</span>,</span>
<span id="cb4-6"><a href="tree-models.html#cb4-6" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb4-7"><a href="tree-models.html#cb4-7" tabindex="-1"></a>  <span class="at">nbagg =</span> <span class="dv">200</span>,  </span>
<span id="cb4-8"><a href="tree-models.html#cb4-8" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">2</span>, <span class="at">cp =</span> <span class="dv">0</span>)</span>
<span id="cb4-9"><a href="tree-models.html#cb4-9" tabindex="-1"></a>)</span>
<span id="cb4-10"><a href="tree-models.html#cb4-10" tabindex="-1"></a>ames_bag2</span></code></pre></div>
<pre><code>## Bagged CART 
## 
## 97 samples
## 10 predictors
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 89, 86, 86, 88, 88, 87, ... 
## Resampling results:
## 
##   RMSE       Rsquared   MAE       
##   0.1096005  0.9952868  0.05980665</code></pre>
</div>
<div id="bagging算法流程" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> bagging算法流程<a href="tree-models.html#bagging算法流程" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>输入为样本集 <span class="math display">\[D=\left\{\left(x, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots\left(x_{m}, y_{m}\right)\right\},\]</span> 弱学习器算法, 弱分类器迭代次数 。 输出为最终的强分类器 <span class="math display">\[f(x)\]</span></p>
<ol style="list-style-type: decimal">
<li>对于t <span class="math display">\[=1,2 \ldots, T:\]</span>
<ul>
<li>a 对训练集进行第t次随机采样, 共采集m次, 得到包含m个样本的采样集 <span class="math display">\[D_{t}\]</span></li>
<li>b 用采样集 <span class="math display">\[D_{t}\]</span> 训练第t个弱学习器 <span class="math display">\[G_{t}(x)\]</span></li>
</ul></li>
<li>如果是分类算法预测, 则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法, T个弱学习器得到的回归结果进行算术平均得 到的值为最终的模型输出。</li>
</ol>
</div>
<div id="random-forest-algorithm" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Random Forest Algorithm<a href="tree-models.html#random-forest-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>随机森林是Bagging算法的进化版, 首先，RF使用了CART决策树作为弱学习器. 第二，在使用决策树的基础上，RF对决策树的建立做了改进，对于普通的决策树，我们会在节点上所有的n个样本特征中选择一个最优的特征来做决策树的左右子树划分，但是RF通过随机选择节点上的一部分样本特征，这个数字小于n，假设为 <span class="math display">\[n_{sub}\]</span> 个样本特征中，选择一个最优的特征来做决策树的左右子树划分。这样进一步增强了模型的泛化能力。</p>
<ul>
<li><span class="math display">\[n_{sub}\]</span>越小，则模型约健壮，当然此时对于训练集的拟合程度会变差。也就是说模型的方差会减小，但是偏倚会增大。</li>
<li>在实际案例中，一般会通过交叉验证调参获取一个合适的<span class="math display">\[n_{sub}\]</span></li>
</ul>
<p>随机森林技术在模型构建过程中使用两种奇妙的方法</p>
<ol style="list-style-type: decimal">
<li>第一个方法称为自助聚集，或称装袋。在装袋法中，使用数据集的一次随机抽样建立一个独立树，抽样的数量大概为全部观测的2/3(请记住，剩下的1/3被称为袋外数据，out-of-bag)。这个过程重复几十次或上百次，最后取平均结果。其中每个树都任其生长，不进行任何基于误差测量的剪枝，这意味着每个独立树的方差都很大。但是，通过对结果的平均化处理可以降低方差，同时又不增加偏差。</li>
<li>另一个在随机森林中使用的方法是，对数据进行随机抽样(装袋)的同时，独立树每次分裂时对输入特征也进行随机抽样。在randomForest包中，我们使用随机抽样数的默认值来对预测特征进行抽样。对于分类问题，默认值为所有预测特征数量的平方根;对于回归问题，默认值为所有预测 特征数量除以3。</li>
</ol>
<p>通过每次分裂时对特征的随机抽样以及由此形成的一套方法，你可以减轻高度相关的预测特 征的影响，这种预测特征在由装袋法生成的独立树中往往起主要作用。这种方法还使你不必思索 如何减少装袋导致的高方差。独立树彼此之间的相关性减少之后，对结果的平均化可以使泛化效 果更好，对于异常值的影响也更加不敏感，比仅进行装袋的效果要好。</p>
<div id="rf算法" class="section level4 hasAnchor" number="5.2.3.1">
<h4><span class="header-section-number">5.2.3.1</span> RF算法<a href="tree-models.html#rf算法" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>输入为样本集 <span class="math display">\[D=\left\{\left(x, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots\left(x_{m}, y_{m}\right)\right\},\]</span> 弱分类器迭代次数T。</p>
<p>输出为最终的强分类器 <span class="math display">\[f(x)\]</span></p>
<ol style="list-style-type: decimal">
<li>对于t <span class="math display">\[=1,2 \ldots, T:\]</span>
<ul>
<li><p>a)对训练集进行第t次随机采样，共采集m次, 得到包含m个样本的采样集 <span class="math display">\[D_{t}\]</span></p></li>
<li><p>b)用采样集 <span class="math display">\[D_{t}\]</span> 训练第t个决策树模型 <span class="math display">\[G_{t}(x),\]</span> 在训练决策树模型的节点的时候, 在节点上所有的样本特征中选择一部分样本特征, 在这些随机选</p>
<p>择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分</p></li>
</ul></li>
<li>如果是分类算法预测, 则T个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法, T个弱学习器得到的回归结果进行算术平均得 到的值为最终的模型输出。</li>
</ol>
</div>
</div>
<div id="random-forest-promotion" class="section level3 hasAnchor" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Random forest promotion<a href="tree-models.html#random-forest-promotion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>RF在实际应用中的良好特性，基于RF，有很多变种算法，应用也很广泛，不光可以用于分类回归，还可以用于特征转换，异常点检测等。</p>
<div id="extra-trees" class="section level4 hasAnchor" number="5.2.4.1">
<h4><span class="header-section-number">5.2.4.1</span> Extra trees<a href="tree-models.html#extra-trees" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>extra trees是RF的一个变种, 原理几乎和RF一模一样，仅有区别有：</p>
<p>　　　　1） 对于每个决策树的训练集，RF采用的是随机采样bootstrap来选择采样集作为每个决策树的训练集，而extra trees一般不采用随机采样，即每个决策树采用原始训练集。</p>
<p>　　　　2） 在选定了划分特征后，RF的决策树会基于基尼系数，均方差之类的原则，选择一个最优的特征值划分点，这和传统的决策树相同。但是extra trees比较的激进，他会随机的选择一个特征值来划分决策树。</p>
<p>从第二点可以看出，由于随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于RF所生成的决策树。也就是说，模型的方差相对于RF进一步减少，但是偏倚相对于RF进一步增大。在某些时候，extra trees的泛化能力比RF更好。</p>
</div>
<div id="totally-random-trees-embedding" class="section level4 hasAnchor" number="5.2.4.2">
<h4><span class="header-section-number">5.2.4.2</span> Totally Random Trees Embedding<a href="tree-models.html#totally-random-trees-embedding" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Totally Random Trees Embedding(以下简称 TRTE)是一种非监督学习的数据转化方法。它将低维的数据集映射到高维，从而让映射到高维的数据更好的运用于分类回归模型。我们知道，在支持向量机中运用了核方法来将低维的数据集映射到高维，此处TRTE提供了另外一种方法。</p>
<p>TRTE在数据转化的过程也使用了类似于RF的方法，建立T个决策树来拟合数据。当决策树建立完毕以后，数据集里的每个数据在T个决策树中叶子节点的位置也定下来了。比如我们有3颗决策树，每个决策树有5个叶子节点，某个数据特征xx划分到第一个决策树的第2个叶子节点，第二个决策树的第3个叶子节点，第三个决策树的第5个叶子节点。则x映射后的特征编码为(0,1,0,0,0, 0,0,1,0,0, 0,0,0,0,1), 有15维的高维特征。这里特征维度之间加上空格是为了强调三颗决策树各自的子编码。</p>
<p>映射到高维特征后，可以继续使用监督学习的各种分类回归算法了。</p>
</div>
<div id="isolation-forest" class="section level4 hasAnchor" number="5.2.4.3">
<h4><span class="header-section-number">5.2.4.3</span> Isolation Forest<a href="tree-models.html#isolation-forest" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Isolation Forest（以下简称IForest）是一种异常点检测的方法。它也使用了类似于RF的方法来检测异常点。对于在T个决策树的样本集，IForest也会对训练集进行随机采样,但是采样个数不需要和RF一样，对于RF，需要采样到采样集样本个数等于训练集个数。但是IForest不需要采样这么多，一般来说，采样个数要远远小于训练集个数？为什么呢？因为我们的目的是异常点检测，只需要部分的样本我们一般就可以将异常点区别出来了。</p>
<p>对于每一个决策树的建立， IForest采用随机选择一个划分特征，对划分特征随机选择一个划分阈值。这点也和RF不同。另外，IForest一般会选择一个比较小的最大决策树深度max_depth,原因同样本采集，用少量的异常点检测一般不需要这么大规模的决策树。</p>
<p>对于异常点的判断, 则是将测试样本点 <span class="math display">\[x\]</span> 拟合到T颗决策树。计算在每颗决策树上该样本的早子节点的深度 <span class="math display">\[h_{t}(x)\]</span> 。, 从而可以计算出平均高度h <span class="math display">\[(\mathrm{x})\]</span> 。此 时我们用下面的公式计算样本点x的异常概率：</p>
<p><span class="math display">\[
s(x, m)=2^{-\frac{h(x)}{c(m)}}
\]</span></p>
<p>其中， m为样本个数。 <span class="math display">\[c(m)\]</span> 的表达式为： <span class="math display">\[c(m)=2 \ln (m-1)+\xi-2 \frac{m-1}{m},\]</span> <span class="math display">\[\xi\]</span>为欧拉常数 <span class="math display">\[s(x, m)\]</span> 的取值范围是 <span class="math display">\[[0,1],\]</span> 取值越接近于1，则是异常点的概率也越大。</p>
</div>
</div>
<div id="package-randomforest" class="section level3 hasAnchor" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> Package ‘randomForest’<a href="tree-models.html#package-randomforest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Source: <a href="https://cran.r-project.org/web/packages/randomForest/randomForest.pdf">https://cran.r-project.org/web/packages/randomForest/randomForest.pdf</a></p>
</div>
</div>
<div id="modelling-2" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Modelling<a href="tree-models.html#modelling-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-preparation-3" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Data preparation<a href="tree-models.html#data-preparation-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>准备数据：前列腺癌数据集。使用ifelse()函数将gleason评分编码为指标变量，划分训练数据集和测试数据集，训练数据集为pros.train，测试数据集为pros.test</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="tree-models.html#cb6-1" tabindex="-1"></a><span class="do">## Load dataset</span></span>
<span id="cb6-2"><a href="tree-models.html#cb6-2" tabindex="-1"></a>prostate <span class="ot">&lt;-</span> <span class="fu">read.delim</span>(<span class="st">&quot;./01_Datasets/prostate.txt&quot;</span>, <span class="at">header=</span>T)</span>
<span id="cb6-3"><a href="tree-models.html#cb6-3" tabindex="-1"></a>prostate<span class="sc">$</span>gleason <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(prostate<span class="sc">$</span>gleason <span class="sc">==</span> <span class="dv">6</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb6-4"><a href="tree-models.html#cb6-4" tabindex="-1"></a>pros.train <span class="ot">&lt;-</span> <span class="fu">subset</span>(prostate, train <span class="sc">==</span> <span class="cn">TRUE</span>)[, <span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>]</span>
<span id="cb6-5"><a href="tree-models.html#cb6-5" tabindex="-1"></a>pros.test <span class="ot">=</span> <span class="fu">subset</span>(prostate, train <span class="sc">==</span> <span class="cn">FALSE</span>)[, <span class="dv">2</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
</div>
<div id="regression-tree-1" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Regression tree<a href="tree-models.html#regression-tree-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="tree-models.html#cb7-1" tabindex="-1"></a><span class="do">## 在训练数据集上建立回归树，使用party包中的rpart()函数</span></span>
<span id="cb7-2"><a href="tree-models.html#cb7-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb7-3"><a href="tree-models.html#cb7-3" tabindex="-1"></a>tree.pros <span class="ot">&lt;-</span> <span class="fu">rpart</span>(lpsa <span class="sc">~</span> ., <span class="at">data =</span> pros.train)</span>
<span id="cb7-4"><a href="tree-models.html#cb7-4" tabindex="-1"></a>tree.pros<span class="sc">$</span>cptable     <span class="do">## 检查每次分裂的误差，以决定最优的树分裂次数</span></span></code></pre></div>
<pre><code>##           CP nsplit rel error    xerror       xstd
## 1 0.35852251      0 1.0000000 1.0195606 0.17963802
## 2 0.12295687      1 0.6414775 0.8742500 0.12878275
## 3 0.11639953      2 0.5185206 0.7949473 0.10419946
## 4 0.05350873      3 0.4021211 0.7904898 0.09821670
## 5 0.01032838      4 0.3486124 0.7044000 0.09115510
## 6 0.01000000      5 0.3382840 0.7321671 0.09381916</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="tree-models.html#cb9-1" tabindex="-1"></a>                      <span class="do">## CP的第一列是成本复杂性参数</span></span>
<span id="cb9-2"><a href="tree-models.html#cb9-2" tabindex="-1"></a>                      <span class="do">## 第二列nsplit是树 分裂的次数，</span></span>
<span id="cb9-3"><a href="tree-models.html#cb9-3" tabindex="-1"></a>                      <span class="do">## rel error列表示相对误差，即某次分裂的RSS除以不分裂的RSS(RSS(k)/RSS(0))</span></span>
<span id="cb9-4"><a href="tree-models.html#cb9-4" tabindex="-1"></a>                      <span class="do">## xerror和xstd都是基于10折交叉验证的</span></span>
<span id="cb9-5"><a href="tree-models.html#cb9-5" tabindex="-1"></a>                      <span class="do">## xerror是平均误差，xstd是交叉验证过程的标准差</span></span>
<span id="cb9-6"><a href="tree-models.html#cb9-6" tabindex="-1"></a><span class="do">## 可以 看出，5次分裂在整个数据集上产生的误差最小，但使用交叉验证时，4次分裂产生的误差略微更 小。</span></span>
<span id="cb9-7"><a href="tree-models.html#cb9-7" tabindex="-1"></a><span class="do">## 可以使用plotcp()函数查看统计图,使用误差条表示树的规模和相对误差之间的关系，误差条和树规模是对应的</span></span>
<span id="cb9-8"><a href="tree-models.html#cb9-8" tabindex="-1"></a><span class="fu">plotcp</span>(tree.pros)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="tree-models.html#cb10-1" tabindex="-1"></a><span class="do">## 树的xerror可以通过剪枝达到最 小化。</span></span>
<span id="cb10-2"><a href="tree-models.html#cb10-2" tabindex="-1"></a><span class="do">## 剪枝的方法是先建立一个cp对象，将这个对象和表中第5行相关联，然后使用prune()函 数完成剩下的工作</span></span>
<span id="cb10-3"><a href="tree-models.html#cb10-3" tabindex="-1"></a>cp <span class="ot">&lt;-</span> <span class="fu">min</span>(tree.pros<span class="sc">$</span>cptable[<span class="dv">5</span>, ])</span>
<span id="cb10-4"><a href="tree-models.html#cb10-4" tabindex="-1"></a>prune.tree.pros <span class="ot">&lt;-</span> <span class="fu">prune</span>(tree.pros, <span class="at">cp =</span> cp)</span>
<span id="cb10-5"><a href="tree-models.html#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="tree-models.html#cb10-6" tabindex="-1"></a><span class="do">## 可以用统计图比较完整树和剪枝树。</span></span>
<span id="cb10-7"><a href="tree-models.html#cb10-7" tabindex="-1"></a><span class="do">## 由partykit包生成的树图明显优于party包生成的，在plot()函数中，可使用as.party()函数作为包装器函数, 它们显示了树的分裂、节点、每节点观测数，以及预测结果的箱线图</span></span>
<span id="cb10-8"><a href="tree-models.html#cb10-8" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.party</span>(tree.pros))</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-3-2.png" width="672" /></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="tree-models.html#cb11-1" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.party</span>(prune.tree.pros))     <span class="do">## 使用as.party()函数处理剪枝树</span></span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-3-3.png" width="672" /></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="tree-models.html#cb12-1" tabindex="-1"></a>                                    <span class="do">## 除了最后一次分裂(完整树包含变量age)，两个树是完全一样的</span></span>
<span id="cb12-2"><a href="tree-models.html#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="tree-models.html#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="tree-models.html#cb12-4" tabindex="-1"></a><span class="do">## Predict</span></span>
<span id="cb12-5"><a href="tree-models.html#cb12-5" tabindex="-1"></a><span class="do">## 剪枝树在测试集上表现如何。在测试数据上使用predict()函数进行预测，并建立一个对象保存这些预测值。然后用预测值减去实际值，得到误差，最后算出误差平方的平均值</span></span>
<span id="cb12-6"><a href="tree-models.html#cb12-6" tabindex="-1"></a>party.pros.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.tree.pros, </span>
<span id="cb12-7"><a href="tree-models.html#cb12-7" tabindex="-1"></a>                           <span class="at">newdata =</span> pros.test)</span>
<span id="cb12-8"><a href="tree-models.html#cb12-8" tabindex="-1"></a>rpart.resid <span class="ot">&lt;-</span> party.pros.test <span class="sc">-</span> pros.test<span class="sc">$</span>lpsa    <span class="do">## calculate residual</span></span>
<span id="cb12-9"><a href="tree-models.html#cb12-9" tabindex="-1"></a><span class="fu">mean</span>(rpart.resid<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.5267748</code></pre>
</div>
<div id="classification-tree-1" class="section level3 hasAnchor" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Classification tree<a href="tree-models.html#classification-tree-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="tree-models.html#cb14-1" tabindex="-1"></a><span class="do">## CART breast cancer 乳腺癌数据</span></span>
<span id="cb14-2"><a href="tree-models.html#cb14-2" tabindex="-1"></a><span class="do">## 删除患者ID，对特征进行重新命名，删除一些缺失值，然后建立训练数据集和测试数据集</span></span>
<span id="cb14-3"><a href="tree-models.html#cb14-3" tabindex="-1"></a><span class="fu">data</span>(biopsy)</span>
<span id="cb14-4"><a href="tree-models.html#cb14-4" tabindex="-1"></a>biopsy <span class="ot">&lt;-</span> biopsy[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb14-5"><a href="tree-models.html#cb14-5" tabindex="-1"></a><span class="fu">names</span>(biopsy) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;thick&quot;</span>, <span class="st">&quot;u.size&quot;</span>, <span class="st">&quot;u.shape&quot;</span>, <span class="st">&quot;adhsn&quot;</span>, <span class="st">&quot;s.size&quot;</span>, <span class="st">&quot;nucl&quot;</span>, <span class="st">&quot;chrom&quot;</span>, <span class="st">&quot;n.nuc&quot;</span>, <span class="st">&quot;mit&quot;</span>, <span class="st">&quot;class&quot;</span>)</span>
<span id="cb14-6"><a href="tree-models.html#cb14-6" tabindex="-1"></a>biopsy.v2 <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(biopsy)</span>
<span id="cb14-7"><a href="tree-models.html#cb14-7" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)                       <span class="co"># random number generator</span></span>
<span id="cb14-8"><a href="tree-models.html#cb14-8" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">2</span>, <span class="fu">nrow</span>(biopsy.v2), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.3</span>))</span>
<span id="cb14-9"><a href="tree-models.html#cb14-9" tabindex="-1"></a>biop.train <span class="ot">&lt;-</span> biopsy.v2[ind <span class="sc">==</span> <span class="dv">1</span>, ] <span class="co"># the training data set</span></span>
<span id="cb14-10"><a href="tree-models.html#cb14-10" tabindex="-1"></a>biop.test <span class="ot">&lt;-</span> biopsy.v2[ind <span class="sc">==</span> <span class="dv">2</span>, ]  <span class="co"># the test data set</span></span>
<span id="cb14-11"><a href="tree-models.html#cb14-11" tabindex="-1"></a><span class="fu">str</span>(biop.test)                      <span class="co"># 建立分类树之前，要确保结果变量是一个因子</span></span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    209 obs. of  10 variables:
##  $ thick  : int  5 6 4 2 1 7 6 7 1 3 ...
##  $ u.size : int  4 8 1 1 1 4 1 3 1 2 ...
##  $ u.shape: int  4 8 1 2 1 6 1 2 1 1 ...
##  $ adhsn  : int  5 1 3 1 1 4 1 10 1 1 ...
##  $ s.size : int  7 3 2 2 1 6 2 5 2 1 ...
##  $ nucl   : int  10 4 1 1 1 1 1 10 1 1 ...
##  $ chrom  : int  3 3 3 3 3 4 3 5 3 2 ...
##  $ n.nuc  : int  2 7 1 1 1 3 1 4 1 1 ...
##  $ mit    : int  1 1 1 1 1 1 1 4 1 1 ...
##  $ class  : Factor w/ 2 levels &quot;benign&quot;,&quot;malignant&quot;: 1 1 1 1 1 2 1 2 1 1 ...
##  - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:16] 24 41 140 146 159 165 236 250 276 293 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:16] &quot;24&quot; &quot;41&quot; &quot;140&quot; &quot;146&quot; ...</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="tree-models.html#cb16-1" tabindex="-1"></a><span class="do">## 生成树，然后检查输出中的表格，找到最优分裂次数</span></span>
<span id="cb16-2"><a href="tree-models.html#cb16-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb16-3"><a href="tree-models.html#cb16-3" tabindex="-1"></a>tree.biop <span class="ot">&lt;-</span> <span class="fu">rpart</span>(class <span class="sc">~</span> ., <span class="at">data =</span> biop.train)</span>
<span id="cb16-4"><a href="tree-models.html#cb16-4" tabindex="-1"></a>tree.biop<span class="sc">$</span>cptable</span></code></pre></div>
<pre><code>##           CP nsplit rel error    xerror       xstd
## 1 0.79651163      0 1.0000000 1.0000000 0.06086254
## 2 0.07558140      1 0.2034884 0.2616279 0.03710371
## 3 0.01162791      2 0.1279070 0.1511628 0.02882093
## 4 0.01000000      3 0.1162791 0.1511628 0.02882093</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="tree-models.html#cb18-1" tabindex="-1"></a><span class="do">## 交叉验证误差仅在两次分裂后就达到了最小值(第3行)。现在可以对树进行剪枝，再在图中绘制剪枝树</span></span>
<span id="cb18-2"><a href="tree-models.html#cb18-2" tabindex="-1"></a>cp <span class="ot">&lt;-</span> <span class="fu">min</span>(tree.biop<span class="sc">$</span>cptable[<span class="dv">3</span>, ])</span>
<span id="cb18-3"><a href="tree-models.html#cb18-3" tabindex="-1"></a>prune.tree.biop <span class="ot">=</span> <span class="fu">prune</span>(tree.biop, cp <span class="ot">&lt;-</span> cp)</span>
<span id="cb18-4"><a href="tree-models.html#cb18-4" tabindex="-1"></a><span class="do">## plot(as.party(tree.biop))</span></span>
<span id="cb18-5"><a href="tree-models.html#cb18-5" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">as.party</span>(prune.tree.biop))</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="tree-models.html#cb19-1" tabindex="-1"></a><span class="do">## 在测试集上的表现</span></span>
<span id="cb19-2"><a href="tree-models.html#cb19-2" tabindex="-1"></a>rparty.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(prune.tree.biop, <span class="at">newdata =</span> biop.test,</span>
<span id="cb19-3"><a href="tree-models.html#cb19-3" tabindex="-1"></a>                       <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb19-4"><a href="tree-models.html#cb19-4" tabindex="-1"></a><span class="fu">table</span>(rparty.test, biop.test<span class="sc">$</span>class)</span></code></pre></div>
<pre><code>##            
## rparty.test benign malignant
##   benign       136         3
##   malignant      6        64</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="tree-models.html#cb21-1" tabindex="-1"></a><span class="do">## 只有两个分支的基本树模型给出了差不多96%的正确率</span></span>
<span id="cb21-2"><a href="tree-models.html#cb21-2" tabindex="-1"></a>(<span class="dv">136</span><span class="sc">+</span><span class="dv">64</span>)<span class="sc">/</span><span class="dv">209</span></span></code></pre></div>
<pre><code>## [1] 0.9569378</code></pre>
</div>
<div id="random-forest-for-regression" class="section level3 hasAnchor" number="5.3.4">
<h3><span class="header-section-number">5.3.4</span> Random forest for regression<a href="tree-models.html#random-forest-for-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>建立一个随机森林对象的通用语法是使用 randomForest()函数，指定模型公式和数据集这两个基本参数。回想一下每次树迭代默认的变 量抽样数，对于回归问题，是p/3;对于分类问题，是p的平方根，p为数据集中预测变量的个数。 对于大规模数据集，就p而言，你可以调整mtry参数，它可以确定每次迭代的变量抽样数值。如 果p小于10，可以省略上面的调整过程。想在多特征数据集中优化mtry参数时，可以使用caret包， 或使用randomForest包中的tuneRF()函数。</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="tree-models.html#cb23-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb23-2"><a href="tree-models.html#cb23-2" tabindex="-1"></a>rf.pros <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(lpsa <span class="sc">~</span> ., <span class="at">data =</span> pros.train)</span>
<span id="cb23-3"><a href="tree-models.html#cb23-3" tabindex="-1"></a>rf.pros        <span class="do">## 生成了500个不同的树(默认设置)，并且在每次树分裂时随机抽出两个变量。</span></span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = lpsa ~ ., data = pros.train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##           Mean of squared residuals: 0.6936697
##                     % Var explained: 51.73</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="tree-models.html#cb25-1" tabindex="-1"></a>               <span class="do">## 结果的MSE为0.68，差不多53%的方差得到了解释</span></span>
<span id="cb25-2"><a href="tree-models.html#cb25-2" tabindex="-1"></a>               <span class="do">## 改善。过多的树会导致过拟合,“多大的数量是‘过多’”依赖于数据规模。</span></span>
<span id="cb25-3"><a href="tree-models.html#cb25-3" tabindex="-1"></a>               <span class="do">## 第一是做出rf.pros的统计图，另一件是求出最小的MSE</span></span>
<span id="cb25-4"><a href="tree-models.html#cb25-4" tabindex="-1"></a></span>
<span id="cb25-5"><a href="tree-models.html#cb25-5" tabindex="-1"></a><span class="do">## 图表示MSE与模型中树的数量之间的关系。可以看出，树的数量增加时，一开始MSE会有显著改善，当森林中大约建立了100棵树之后，改善几乎停滞</span></span>
<span id="cb25-6"><a href="tree-models.html#cb25-6" tabindex="-1"></a><span class="fu">plot</span>(rf.pros)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="tree-models.html#cb26-1" tabindex="-1"></a><span class="fu">which.min</span>(rf.pros<span class="sc">$</span>mse)   <span class="do">## 具体的最优树数量</span></span></code></pre></div>
<pre><code>## [1] 80</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="tree-models.html#cb28-1" tabindex="-1"></a>                         <span class="do">## 指定ntree =</span></span>
<span id="cb28-2"><a href="tree-models.html#cb28-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb28-3"><a href="tree-models.html#cb28-3" tabindex="-1"></a>rf.pros<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(lpsa <span class="sc">~</span> ., <span class="at">data =</span> pros.train, <span class="at">ntree =</span> <span class="fu">which.min</span>(rf.pros<span class="sc">$</span>mse))</span>
<span id="cb28-4"><a href="tree-models.html#cb28-4" tabindex="-1"></a>rf.pros<span class="fl">.2</span></span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = lpsa ~ ., data = pros.train, ntree = which.min(rf.pros$mse)) 
##                Type of random forest: regression
##                      Number of trees: 80
## No. of variables tried at each split: 2
## 
##           Mean of squared residuals: 0.6566502
##                     % Var explained: 54.31</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="tree-models.html#cb30-1" tabindex="-1"></a><span class="do">## 对模型进行检验之前，先看看另一张统计图。如果使用自助抽样和两个随机预测变量建立了80棵不同的树，要想将树的结果组合起来，需 要一种方法确定哪些变量驱动着结果。</span></span>
<span id="cb30-2"><a href="tree-models.html#cb30-2" tabindex="-1"></a><span class="do">## 做出变量重要性统计图及相应的列表。 Y轴是按重要性降序排列的变量列表，X轴是MSE改善百分比。</span></span>
<span id="cb30-3"><a href="tree-models.html#cb30-3" tabindex="-1"></a><span class="do">## 在分类问题中，X轴应 该是基尼指数的改善</span></span>
<span id="cb30-4"><a href="tree-models.html#cb30-4" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.pros<span class="fl">.2</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>,</span>
<span id="cb30-5"><a href="tree-models.html#cb30-5" tabindex="-1"></a>           <span class="at">main =</span> <span class="st">&quot;Variable Importance Plot - PSA Score&quot;</span>)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="tree-models.html#cb31-1" tabindex="-1"></a><span class="do">## 查看具体数据，可以 使用importance()函数</span></span>
<span id="cb31-2"><a href="tree-models.html#cb31-2" tabindex="-1"></a><span class="fu">importance</span>(rf.pros<span class="fl">.2</span>)    </span></code></pre></div>
<pre><code>##         IncNodePurity
## lcavol      25.011557
## lweight     15.822110
## age          7.167320
## lbph         5.471032
## svi          8.497838
## lcp          8.113947
## gleason      4.990213
## pgg45        6.663911</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="tree-models.html#cb33-1" tabindex="-1"></a><span class="do">## 看看模型在测试数据上的表现:</span></span>
<span id="cb33-2"><a href="tree-models.html#cb33-2" tabindex="-1"></a>rf.pros.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.pros<span class="fl">.2</span>, <span class="at">newdata =</span> pros.test)</span>
<span id="cb33-3"><a href="tree-models.html#cb33-3" tabindex="-1"></a><span class="do">## plot(rf.pros.test, pros.test$lpsa)</span></span>
<span id="cb33-4"><a href="tree-models.html#cb33-4" tabindex="-1"></a>rf.resid <span class="ot">&lt;-</span> rf.pros.test <span class="sc">-</span> pros.test<span class="sc">$</span>lpsa </span>
<span id="cb33-5"><a href="tree-models.html#cb33-5" tabindex="-1"></a><span class="do">## calculate residual</span></span>
<span id="cb33-6"><a href="tree-models.html#cb33-6" tabindex="-1"></a><span class="fu">mean</span>(rf.resid<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.5512549</code></pre>
</div>
<div id="random-forest-for-classification" class="section level3 hasAnchor" number="5.3.5">
<h3><span class="header-section-number">5.3.5</span> Random forest for classification<a href="tree-models.html#random-forest-for-classification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="tree-models.html#cb35-1" tabindex="-1"></a><span class="do">## 乳腺癌诊断数据</span></span>
<span id="cb35-2"><a href="tree-models.html#cb35-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb35-3"><a href="tree-models.html#cb35-3" tabindex="-1"></a>rf.biop <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(class <span class="sc">~</span> ., <span class="at">data =</span> biop.train)</span>
<span id="cb35-4"><a href="tree-models.html#cb35-4" tabindex="-1"></a>rf.biop         <span class="do">## OOB(袋外数据)误差率</span></span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = class ~ ., data = biop.train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 3.38%
## Confusion matrix:
##           benign malignant class.error
## benign       294         8  0.02649007
## malignant      8       164  0.04651163</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="tree-models.html#cb37-1" tabindex="-1"></a><span class="fu">plot</span>(rf.biop)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="tree-models.html#cb38-1" tabindex="-1"></a><span class="do">## 找出具体值。和前面不同的一点是，需要指定第一列来得到误差率，这是整体误差率</span></span>
<span id="cb38-2"><a href="tree-models.html#cb38-2" tabindex="-1"></a><span class="fu">which.min</span>(rf.biop<span class="sc">$</span>err.rate[, <span class="dv">1</span>])</span></code></pre></div>
<pre><code>## [1] 125</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="tree-models.html#cb40-1" tabindex="-1"></a><span class="do">## 使模型正确率达到最优</span></span>
<span id="cb40-2"><a href="tree-models.html#cb40-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb40-3"><a href="tree-models.html#cb40-3" tabindex="-1"></a>rf.biop<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(class <span class="sc">~</span> ., <span class="at">data =</span> biop.train, <span class="at">ntree =</span> <span class="dv">125</span>)</span>
<span id="cb40-4"><a href="tree-models.html#cb40-4" tabindex="-1"></a>rf.biop<span class="fl">.2</span></span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = class ~ ., data = biop.train, ntree = 125) 
##                Type of random forest: classification
##                      Number of trees: 125
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 2.95%
## Confusion matrix:
##           benign malignant class.error
## benign       294         8  0.02649007
## malignant      6       166  0.03488372</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="tree-models.html#cb42-1" tabindex="-1"></a><span class="do">## predict</span></span>
<span id="cb42-2"><a href="tree-models.html#cb42-2" tabindex="-1"></a>rf.biop.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.biop<span class="fl">.2</span>, </span>
<span id="cb42-3"><a href="tree-models.html#cb42-3" tabindex="-1"></a>                        <span class="at">newdata =</span> biop.test, </span>
<span id="cb42-4"><a href="tree-models.html#cb42-4" tabindex="-1"></a>                        <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb42-5"><a href="tree-models.html#cb42-5" tabindex="-1"></a><span class="fu">table</span>(rf.biop.test, biop.test<span class="sc">$</span>class)</span></code></pre></div>
<pre><code>##             
## rf.biop.test benign malignant
##    benign       138         0
##    malignant      4        67</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="tree-models.html#cb44-1" tabindex="-1"></a><span class="do">## 训练集上的误差率还不到3%</span></span>
<span id="cb44-2"><a href="tree-models.html#cb44-2" tabindex="-1"></a>(<span class="dv">138</span> <span class="sc">+</span> <span class="dv">67</span>) <span class="sc">/</span> <span class="dv">209</span></span></code></pre></div>
<pre><code>## [1] 0.9808612</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="tree-models.html#cb46-1" tabindex="-1"></a><span class="do">## 变量重要性统计图</span></span>
<span id="cb46-2"><a href="tree-models.html#cb46-2" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf.biop<span class="fl">.2</span>)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="tree-models.html#cb47-1" tabindex="-1"></a><span class="do">## 变量重要性是指每个变量对基尼指数平均减少量的贡献，此处的变量重要性与单个树分裂时有很大区别。回忆一下，单个树是在细胞大小均匀度开始分裂的(与随机森林一致)，然后是nuclei，接着是细胞密度。这揭示了随机森林技术具有非常大的潜力，不但可以提高模 型预测能力，还可以改善特征选择的结果</span></span></code></pre></div>
</div>
<div id="皮玛印第安人糖尿病数据集" class="section level3 hasAnchor" number="5.3.6">
<h3><span class="header-section-number">5.3.6</span> 皮玛印第安人糖尿病数据集<a href="tree-models.html#皮玛印第安人糖尿病数据集" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="tree-models.html#cb48-1" tabindex="-1"></a><span class="do">## 皮玛印第安人糖尿病模型:数据准备</span></span>
<span id="cb48-2"><a href="tree-models.html#cb48-2" tabindex="-1"></a><span class="fu">data</span>(Pima.tr)</span>
<span id="cb48-3"><a href="tree-models.html#cb48-3" tabindex="-1"></a><span class="fu">data</span>(Pima.te)</span>
<span id="cb48-4"><a href="tree-models.html#cb48-4" tabindex="-1"></a>pima <span class="ot">&lt;-</span> <span class="fu">rbind</span>(Pima.tr, Pima.te)</span>
<span id="cb48-5"><a href="tree-models.html#cb48-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">502</span>)</span>
<span id="cb48-6"><a href="tree-models.html#cb48-6" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">2</span>, <span class="fu">nrow</span>(pima), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.3</span>))</span>
<span id="cb48-7"><a href="tree-models.html#cb48-7" tabindex="-1"></a>pima.train <span class="ot">&lt;-</span> pima[ind <span class="sc">==</span> <span class="dv">1</span>, ]</span>
<span id="cb48-8"><a href="tree-models.html#cb48-8" tabindex="-1"></a>pima.test <span class="ot">&lt;-</span> pima[ind <span class="sc">==</span> <span class="dv">2</span>, ]</span>
<span id="cb48-9"><a href="tree-models.html#cb48-9" tabindex="-1"></a></span>
<span id="cb48-10"><a href="tree-models.html#cb48-10" tabindex="-1"></a><span class="do">## 建立模型</span></span>
<span id="cb48-11"><a href="tree-models.html#cb48-11" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb48-12"><a href="tree-models.html#cb48-12" tabindex="-1"></a>rf.pima <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(type <span class="sc">~</span> ., <span class="at">data =</span> pima.train)</span>
<span id="cb48-13"><a href="tree-models.html#cb48-13" tabindex="-1"></a>rf.pima</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = type ~ ., data = pima.train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 20.26%
## Confusion matrix:
##      No Yes class.error
## No  235  27   0.1030534
## Yes  51  72   0.4146341</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="tree-models.html#cb50-1" tabindex="-1"></a><span class="co"># plot(rf.pima)</span></span>
<span id="cb50-2"><a href="tree-models.html#cb50-2" tabindex="-1"></a></span>
<span id="cb50-3"><a href="tree-models.html#cb50-3" tabindex="-1"></a><span class="do">## 对树的数目 进行优化</span></span>
<span id="cb50-4"><a href="tree-models.html#cb50-4" tabindex="-1"></a><span class="fu">which.min</span>(rf.pima<span class="sc">$</span>err.rate[,<span class="dv">1</span>])</span></code></pre></div>
<pre><code>## [1] 88</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="tree-models.html#cb52-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb52-2"><a href="tree-models.html#cb52-2" tabindex="-1"></a>rf.pima<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(type <span class="sc">~</span> ., <span class="at">data =</span> pima.train, <span class="at">ntree =</span> <span class="fu">which.min</span>(rf.pima<span class="sc">$</span>err.rate[,<span class="dv">1</span>]))</span>
<span id="cb52-3"><a href="tree-models.html#cb52-3" tabindex="-1"></a>rf.pima<span class="fl">.2</span>         <span class="do">## OOB误差有些许改善</span></span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = type ~ ., data = pima.train, ntree = which.min(rf.pima$err.rate[,      1])) 
##                Type of random forest: classification
##                      Number of trees: 88
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 19.74%
## Confusion matrix:
##      No Yes class.error
## No  236  26  0.09923664
## Yes  50  73  0.40650407</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="tree-models.html#cb54-1" tabindex="-1"></a>rf.pima.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.pima<span class="fl">.2</span>, </span>
<span id="cb54-2"><a href="tree-models.html#cb54-2" tabindex="-1"></a>                        <span class="at">newdata =</span> pima.test, </span>
<span id="cb54-3"><a href="tree-models.html#cb54-3" tabindex="-1"></a>                        <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb54-4"><a href="tree-models.html#cb54-4" tabindex="-1"></a><span class="fu">table</span>(rf.pima.test, pima.test<span class="sc">$</span>type)</span></code></pre></div>
<pre><code>##             
## rf.pima.test No Yes
##          No  74  17
##          Yes 19  37</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="tree-models.html#cb56-1" tabindex="-1"></a>(<span class="dv">75</span><span class="sc">+</span><span class="dv">33</span>)<span class="sc">/</span><span class="dv">147</span></span></code></pre></div>
<pre><code>## [1] 0.7346939</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="tree-models.html#cb58-1" tabindex="-1"></a><span class="co">#varImpPlot(rf.pima.2)</span></span></code></pre></div>
</div>
<div id="使用随机森林进行特征选择" class="section level3 hasAnchor" number="5.3.7">
<h3><span class="header-section-number">5.3.7</span> 使用随机森林进行特征选择<a href="tree-models.html#使用随机森林进行特征选择" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Boruta包:[Kursa M., Rudnicki W. (2010), Feature Selection with the Boruta Package, Journal of Statistical Software, 36(11), 1 - 13]</p>
<pre><code>1. 算法会复制所有输入特征，并对特征中的观测顺序进行重新组合，以去除 相关性，从而创建影子特征.
2. 然后使用所有输入特征建立一个随机森林模型，并计算每个特征(包 括影子特征)的正确率损失均值的Z分数
3. 如果某个特征的Z分数显著高于影子特征的Z分数，那么这个特征就被认为是重要的;反之，这个特征就被认为是不重要的
4. 然后，去除掉影子特征和那些已经确认了重要性的特征，重复上面的过程，直到所有特征都被赋予一个表示重要性的值
5. 算法结束之后，每个初始特征都会被标记为确认、待定或 拒绝
6. 对于待定的特征，必须自己确定是否要包括在下一次建模中。根据具体情况，可以有以下几种选择:
    * 改变随机数种子，重复运行算法多次(k次)，然后只选择那些在k次运行中都标记为“确认”的属性
    * 将你的训练数据分为k折，在每折数据上分别进行算法迭代，然后选择那些在所有k折数据上都标记为“确认”的属性
    
    
    </code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="tree-models.html#cb60-1" tabindex="-1"></a><span class="do">## prepare datasets</span></span>
<span id="cb60-2"><a href="tree-models.html#cb60-2" tabindex="-1"></a><span class="do">## 数据集中有208个观测，60个输入特征，以及1个用于分类的标号向量。标号是个因子，如果sonar对象是岩石，标号就是R;如果sonar对象是矿藏，标号则是M</span></span>
<span id="cb60-3"><a href="tree-models.html#cb60-3" tabindex="-1"></a><span class="fu">data</span>(Sonar, <span class="at">package=</span><span class="st">&quot;mlbench&quot;</span>)</span>
<span id="cb60-4"><a href="tree-models.html#cb60-4" tabindex="-1"></a><span class="fu">dim</span>(Sonar)</span></code></pre></div>
<pre><code>## [1] 208  61</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="tree-models.html#cb62-1" tabindex="-1"></a><span class="fu">table</span>(Sonar<span class="sc">$</span>Class)</span></code></pre></div>
<pre><code>## 
##   M   R 
## 111  97</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="tree-models.html#cb64-1" tabindex="-1"></a><span class="do">## 在boruta()函数中创建一条模型公式。标号必须是因子类型，否则算法不会正常执行。如果想跟踪算法的进程，可以设定doTrace = 1。不要忘了设定随机数种子</span></span>
<span id="cb64-2"><a href="tree-models.html#cb64-2" tabindex="-1"></a><span class="fu">class</span>(Sonar<span class="sc">$</span>Class)</span></code></pre></div>
<pre><code>## [1] &quot;factor&quot;</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="tree-models.html#cb66-1" tabindex="-1"></a><span class="fu">library</span>(Boruta)</span>
<span id="cb66-2"><a href="tree-models.html#cb66-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb66-3"><a href="tree-models.html#cb66-3" tabindex="-1"></a>feature.selection <span class="ot">&lt;-</span> <span class="fu">Boruta</span>(Class <span class="sc">~</span> ., <span class="at">data =</span> Sonar, <span class="at">doTrace =</span> <span class="dv">1</span>)</span>
<span id="cb66-4"><a href="tree-models.html#cb66-4" tabindex="-1"></a><span class="do">## 需要大量的计算能力</span></span>
<span id="cb66-5"><a href="tree-models.html#cb66-5" tabindex="-1"></a>feature.selection<span class="sc">$</span>timeTaken</span></code></pre></div>
<pre><code>## Time difference of 11.67391 secs</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="tree-models.html#cb68-1" tabindex="-1"></a><span class="do">## 得出最终重要决策的计数</span></span>
<span id="cb68-2"><a href="tree-models.html#cb68-2" tabindex="-1"></a><span class="fu">table</span>(feature.selection<span class="sc">$</span>finalDecision)</span></code></pre></div>
<pre><code>## 
## Tentative Confirmed  Rejected 
##        11        31        18</code></pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="tree-models.html#cb70-1" tabindex="-1"></a><span class="do">## 以找出特征名称: 以找出特征名称</span></span>
<span id="cb70-2"><a href="tree-models.html#cb70-2" tabindex="-1"></a>fNames <span class="ot">&lt;-</span> <span class="fu">getSelectedAttributes</span>(feature.selection) </span>
<span id="cb70-3"><a href="tree-models.html#cb70-3" tabindex="-1"></a><span class="do">## 包括“确认”和“待定”的特征</span></span>
<span id="cb70-4"><a href="tree-models.html#cb70-4" tabindex="-1"></a>fNames <span class="ot">&lt;-</span> <span class="fu">getSelectedAttributes</span>(feature.selection, <span class="at">withTentative =</span> <span class="cn">TRUE</span>)</span>
<span id="cb70-5"><a href="tree-models.html#cb70-5" tabindex="-1"></a>fNames</span></code></pre></div>
<pre><code>##  [1] &quot;V1&quot;  &quot;V2&quot;  &quot;V4&quot;  &quot;V5&quot;  &quot;V8&quot;  &quot;V9&quot;  &quot;V10&quot; &quot;V11&quot; &quot;V12&quot; &quot;V13&quot; &quot;V14&quot; &quot;V15&quot;
## [13] &quot;V16&quot; &quot;V17&quot; &quot;V18&quot; &quot;V19&quot; &quot;V20&quot; &quot;V21&quot; &quot;V22&quot; &quot;V23&quot; &quot;V26&quot; &quot;V27&quot; &quot;V28&quot; &quot;V29&quot;
## [25] &quot;V30&quot; &quot;V31&quot; &quot;V32&quot; &quot;V35&quot; &quot;V36&quot; &quot;V37&quot; &quot;V39&quot; &quot;V43&quot; &quot;V44&quot; &quot;V45&quot; &quot;V46&quot; &quot;V47&quot;
## [37] &quot;V48&quot; &quot;V49&quot; &quot;V51&quot; &quot;V52&quot; &quot;V54&quot; &quot;V59&quot;</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="tree-models.html#cb72-1" tabindex="-1"></a><span class="do">## 使用这些特征名称，可以创建一个Sonar数据集的子集</span></span>
<span id="cb72-2"><a href="tree-models.html#cb72-2" tabindex="-1"></a>Sonar.features <span class="ot">&lt;-</span> Sonar[, fNames]</span>
<span id="cb72-3"><a href="tree-models.html#cb72-3" tabindex="-1"></a><span class="fu">dim</span>(Sonar.features)</span></code></pre></div>
<pre><code>## [1] 208  42</code></pre>
</div>
</div>
<div id="gradient-boosting" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Gradient Boosting<a href="tree-models.html#gradient-boosting" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="gradient-descent" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Gradient Descent<a href="tree-models.html#gradient-descent" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法。</p>
<div id="gradient" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Gradient<a href="tree-models.html#gradient" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>在微积分里面，对多元函数的参数求∂偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。比如函数f(x,y), 分别对x,y求偏导数，求得的梯度向量就是(∂f/∂x, ∂f/∂y)T,简称grad f(x,y)或者▽f(x,y)。对于在点(x0,y0)的具体梯度向量就是(∂f/∂x0, ∂f/∂y0)T.或者▽f(x0,y0)，如果是3个参数的向量梯度，就是(∂f/∂x, ∂f/∂y，∂f/∂z)T,以此类推</p>
<p>梯度向量的几何意义，就是函数变化增加最快的地方。具体来说，对于函数 <span class="math inline">\(f(x ， y)\)</span> ，在点 <span class="math inline">\(\left(x_{0} ， y_{0}\right)\)</span> ，沿着梯度 向量的方向就是 <span class="math inline">\(\left(\partial f / \partial x_{0} ， \partial f / \partial y_{0}\right)^{\top}\)</span> 的方向是 <span class="math inline">\(f(x, y)\)</span> 增加最快的地方。或者说，沿着梯度向量的方向，更加容易找到函数的最大值。反过来说，沿着梯度向量相反 的方向，也就是 <span class="math inline">\(-\left(\partial f / \partial x_{0} ， \partial f / \partial y_{0}\right)^{\top}\)</span> 的方向，梯度减少最快，也就是更加容易找到函数的最小值。</p>
<p>在机器学习算法中，在最小化损失函数时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。反过来，如果我们需要求解损失函数的最大值，这时就需要用梯度上升法来迭代. 梯度下降法和梯度上升法是可以互相转化的。比如我们需要求解损失函数f(θ)的最小值，这时我们需要用梯度下降法来迭代求解。但是实际上，我们可以反过来求解损失函数 -f(θ)的最大值，这时梯度上升法就派上用场了</p>
</div>
<div id="gradient-descent-1" class="section level3 hasAnchor" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Gradient Descent<a href="tree-models.html#gradient-descent-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>梯度下降的一个直观的解释。比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处。</p>
<p>从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。</p>
<p><strong>相关概念</strong></p>
<ul>
<li><strong>步长（Learning rate）</strong>：步长决定了在梯度下降迭代的过程中，每一步沿梯度负方向前进的长度。用上面下山的例子，步长就是在当前这一步所在位置沿着最陡峭最易下山的位置走的那一步的长度。</li>
<li><strong>特征 (feature)</strong> ：指的是样本中输入部分，比如2个单特征的样本 <span class="math inline">\(\left(x^{(0)}, y^{(0)}\right),\left(x^{(1)}, y^{(1)}\right)\)</span>,则第一个样本特征为 <span class="math inline">\(x^{(0)}\)</span> ，第一个样本输出为 <span class="math inline">\(y^{(0)}\)</span></li>
<li><strong>假设函数 (hypothesis function)</strong> : 在监督学习中，为了拟合输入样本，而使用的假设函数，记为 <span class="math inline">\(h_{\theta}(x)\)</span> 。比如对于单个特征的 <span class="math inline">\(\mathrm{m}\)</span> 个样本 <span class="math inline">\(\left(x^{(i)}, y^{(i)}\right)(i=1,2, \ldots m)\)</span> ，可以采用拟合函数如下: <span class="math inline">\(h_{\theta}(x)=\theta_{0}+\theta_{1} x\)</span></li>
<li><strong>损失函数 (loss function) </strong>: 为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小化，意味着拟合程度最好，对应的模型参 数即为最优参数。在线性回归中，损失函数通常为样本输出和假设函数的差取平方。比如对于 <span class="math inline">\(\mathrm{m}\)</span> 个样本 <span class="math inline">\(\left(x_{i}, y_{i}\right)(i=1,2, \ldots m)\)</span>, 采用线性回归，损失函数 为:
<span class="math display">\[
J\left(\theta_{0}, \theta_{1}\right)=\sum_{i=1}^{m}\left(h_{\theta}\left(x_{i}\right)-y_{i}\right)^{2}
\]</span>
其中 <span class="math inline">\(x_{i}\)</span> 表示第 <span class="math inline">\(\mathrm{i}\)</span> 个样本特征, <span class="math inline">\(y_{i}\)</span> 表示第 <span class="math inline">\(\mathrm{i}\)</span> 个样本对应的输出， <span class="math inline">\(h_{\theta}\left(x_{i}\right)\)</span> 为假设函数</li>
</ul>
</div>
<div id="gradient-descent-algorithm" class="section level3 hasAnchor" number="5.5.3">
<h3><span class="header-section-number">5.5.3</span> Gradient Descent Algorithm<a href="tree-models.html#gradient-descent-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>确认优化模型的假设函数 (hypothesis function)和损失函数(loss function)。比如对于线性回归，假设函数表示为 <span class="math inline">\(h_{\theta}\left(x_{1}, x_{2}, \ldots x_{n}\right)=\theta_{0}+\theta_{1} x_{1}+\ldots+\theta_{n} x_{n}\)</span> 同样是线性回归，对应于上面的假设函数，损失函数为:
<span class="math display">\[
J\left(\theta_{0}, \theta_{1} \ldots, \theta_{n}\right)=\frac{1}{2 m} \sum_{j=1}^{m}\left(h_{\theta}\left(x_{0}^{(j)}, x_{1}^{(j)}, \ldots x_{n}^{(j)}\right)-y_{j}\right)^{2}
\]</span></li>
<li>算法相关参数初始化: 主要是初始化 <span class="math inline">\(\theta_{0}, \theta_{1} \ldots, \theta_{n}\)</span> ，算法终止距离 <span class="math inline">\(\varepsilon\)</span> 以及步长 <span class="math inline">\(\alpha\)</span> 。在没有任何先验知识的时候，一般将所有的 <span class="math inline">\(\theta\)</span> 初始化为 0 ， 将步长初始化为 1 。在调优的时候再优化</li>
<li>确定当前位置的损失函数的梯度，对于 <span class="math inline">\(\theta_{i}\)</span>, 其梯度表达式如下:
<span class="math display">\[
\frac{\partial}{\partial \theta_{i}} J\left(\theta_{0}, \theta_{1} \ldots, \theta_{n}\right)
\]</span></li>
<li>用步长乘以损失函数的梯度，得到当前位置下降的距离，即 <span class="math inline">\(\alpha \frac{\partial}{\partial \theta_{i}} J\left(\theta_{0}, \theta_{1} \ldots, \theta_{n}\right)\)</span> 对应于前面登山例子中的某一步</li>
<li>确定是否所有的 <span class="math inline">\(\theta_{i}\)</span>,梯度下降的距离都小于 <span class="math inline">\(\varepsilon\)</span> ，如果小于 <span class="math inline">\(\varepsilon\)</span> 则算法终止，当前所有的 <span class="math inline">\(\theta_{i}(i=0,1, \ldots n)\)</span> 即为最终结果。否则进入下一步</li>
<li>更新所有的 <span class="math inline">\(\theta\)</span> ，对于 <span class="math inline">\(\theta_{i}\)</span> ，其更新表达式如下。更新完毕后继续转入步骤3.
<span class="math display">\[
\theta_{i}=\theta_{i}-\alpha \frac{\partial}{\partial \theta_{i}} J\left(\theta_{0}, \theta_{1} \ldots, \theta_{n}\right)
\]</span></li>
</ol>
<p><strong>Algorithm Optimization</strong></p>
<ol style="list-style-type: decimal">
<li>算法的步长选择。在前面的算法描述中步长为 1 ，但是实际上取值取决于数据样本，可以多取一些值，从大到小，分别运行算法，看看迭代效果，如果损失函数在变小，说明取值有效，否则要增大步长。前面说了。步长太大，会导致迭代过快，甚至有可能错过最优解。步长太小，迭代速度太慢，很长时间算法都不能结束。所以算法的步长需要多次运行后才能得到一个较为优的值。</li>
<li>算法参数的初始值选择。初始值不同，获得的最小值也有可能不同，因此梯度下降求得的只是局部最小值；当然如果损失函数是凸函数则一定是最优 解。由于有局部最优解的风险，需要多次用不同初始值运行算法，关键损失函数的最小值，选择损失函数最小化的初值。
3.归一化。由于样本不同特征的取值范围不一样，可能导致迭代很慢，为了减少特征取值的影响，可以对特征数据归一化，也就是对于每个特征x，求出 它的期望 <span class="math inline">\(\bar{x}\)</span> 和标准差std <span class="math inline">\((\mathrm{x})\)</span> ，然后转化为:
<span class="math display">\[
\frac{x-\bar{x}}{\operatorname{std}(x)}
\]</span>
这样特征的新期望为 0 ，新方差为 1 ，迭代速度可以大大加快。</li>
</ol>
</div>
<div id="gradient-descent-familiy" class="section level3 hasAnchor" number="5.5.4">
<h3><span class="header-section-number">5.5.4</span> Gradient Descent Familiy<a href="tree-models.html#gradient-descent-familiy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="批量梯度下降法bgd-batch-gradient-descent" class="section level4 hasAnchor" number="5.5.4.1">
<h4><span class="header-section-number">5.5.4.1</span> 批量梯度下降法（BGD, Batch Gradient Descent)<a href="tree-models.html#批量梯度下降法bgd-batch-gradient-descent" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>批量梯度下降法，是梯度下降法最常用的形式，具体做法也就是在更新参数时使用所有的样本来进行更新，如前所示,由于有m个样本，这里求梯度的时候就用了所有m个样本的梯度数据。
<span class="math display">\[
\theta_i = \theta_i - \alpha\sum\limits_{j=1}^{m}(h_\theta(x_0^{(j)}, x_1^{(j)}, ...x_n^{(j)}) - y_j)x_i^{(j)}
\]</span></p>
</div>
<div id="随机梯度下降法sgd-stochastic-gradient-descent" class="section level4 hasAnchor" number="5.5.4.2">
<h4><span class="header-section-number">5.5.4.2</span> 随机梯度下降法（SGD, Stochastic Gradient Descent）<a href="tree-models.html#随机梯度下降法sgd-stochastic-gradient-descent" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>随机梯度下降法，其实和批量梯度下降法原理类似，区别在与求梯度时没有用所有的m个样本的数据，而是仅仅选取一个样本j来求梯度。对应的更新公式是：
<span class="math display">\[
\theta_i = \theta_i - \alpha (h_\theta(x_0^{(j)}, x_1^{(j)}, ...x_n^{(j)}) - y_j)x_i^{(j)}
\]</span>
对于训练速度来说，随机梯度下降法由于每次仅仅采用一个样本来迭代，训练速度很快，而批量梯度下降法在样本量很大的时候，训练速度不能让人满意。对于准确度来说，随机梯度下降法用于仅仅用一个样本决定梯度方向，导致解很有可能不是最优。对于收敛速度来说，由于随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。小批量梯度下降法是中庸的办法</p>
</div>
<div id="小批量梯度下降法mbgd-mini-batch-gradient-descent" class="section level4 hasAnchor" number="5.5.4.3">
<h4><span class="header-section-number">5.5.4.3</span> 小批量梯度下降法（MBGD, Mini-batch Gradient Descent）<a href="tree-models.html#小批量梯度下降法mbgd-mini-batch-gradient-descent" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>小批量梯度下降法是批量梯度下降法和随机梯度下降法的折衰，也就是对于 <span class="math inline">\(\mathrm{m}\)</span> 个样本，我们采用 <span class="math inline">\(x\)</span> 个样子来迭代，1&lt;x&lt;m。般可以取 <span class="math inline">\(x=10\)</span> ，当然根据样 本的数据，可以调整这个x的值。对应的更新公式是:
<span class="math display">\[
\theta_{i}=\theta_{i}-\alpha \sum_{j=t}^{t+x-1}\left(h_{\theta}\left(x_{0}^{(j)}, x_{1}^{(j)}, \ldots x_{n}^{(j)}\right)-y_{j}\right) x_{i}^{(j)}
\]</span></p>
</div>
</div>
<div id="gbdt分类算法" class="section level3 hasAnchor" number="5.5.5">
<h3><span class="header-section-number">5.5.5</span> GBDT分类算法<a href="tree-models.html#gbdt分类算法" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="package-gbm" class="section level3 hasAnchor" number="5.5.6">
<h3><span class="header-section-number">5.5.6</span> Package ‘gbm’<a href="tree-models.html#package-gbm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>对Freund和Schapire的AdaBoost算法以及Friedman的梯度增强机的扩展的实现。 包括最小二乘，绝对损失，t分布损失，分位数回归，逻辑，多项式逻辑，泊松，Cox比例风险部分可能性，AdaBoost指数损失，Huberized铰链损失和学习排名度量（LambdaMart）的回归方法。</p>
<p>Source: <a href="https://cran.r-project.org/web/packages/gbm/gbm.pdf">https://cran.r-project.org/web/packages/gbm/gbm.pdf</a></p>
</div>
<div id="极限梯度提升分类" class="section level3 hasAnchor" number="5.5.7">
<h3><span class="header-section-number">5.5.7</span> 极限梯度提升——分类<a href="tree-models.html#极限梯度提升分类" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>xgboost package</p>
<pre><code> nrounds:最大迭代次数(最终模型中树的数量)。
 colsample_bytree:建立树时随机抽取的特征数量，用一个比率表示，默认值为1(使用100%的特征)。 
 min_child_weight:对树进行提升时使用的最小权重，默认为1。
 eta:学习率，每棵树在最终解中的贡献，默认为0.3。
 gamma:在树中新增一个叶子分区时所需的最小减损。
 subsample:子样本数据占整个观测的比例，默认值为1(100%)。  max_depth:单个树的最大深度。</code></pre>
<p>使用expand.grid()函数可以建立实验网格，以运行caret包的训练过程。 对于前面列出的参数，如果没有设定具体值，那么即使有默认值，运行函数时也 会收到出错信息。下面的参数取值是基于以前的一些训练迭代而设定的。可以根据实验参数调整过程。</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="tree-models.html#cb75-1" tabindex="-1"></a><span class="do">## 建立一个具有24个模型的网格，caret包会运行这些模型，以确定最好的调优参数。</span></span>
<span id="cb75-2"><a href="tree-models.html#cb75-2" tabindex="-1"></a>grid <span class="ot">=</span> <span class="fu">expand.grid</span>(</span>
<span id="cb75-3"><a href="tree-models.html#cb75-3" tabindex="-1"></a>  <span class="at">nrounds =</span> <span class="fu">c</span>(<span class="dv">75</span>, <span class="dv">100</span>),</span>
<span id="cb75-4"><a href="tree-models.html#cb75-4" tabindex="-1"></a>  <span class="at">colsample_bytree =</span> <span class="dv">1</span>,</span>
<span id="cb75-5"><a href="tree-models.html#cb75-5" tabindex="-1"></a>  <span class="at">min_child_weight =</span> <span class="dv">1</span>,</span>
<span id="cb75-6"><a href="tree-models.html#cb75-6" tabindex="-1"></a>  <span class="at">eta =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.3</span>), <span class="co">#0.3 is default,</span></span>
<span id="cb75-7"><a href="tree-models.html#cb75-7" tabindex="-1"></a>  <span class="at">gamma =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.25</span>),</span>
<span id="cb75-8"><a href="tree-models.html#cb75-8" tabindex="-1"></a>  <span class="at">subsample =</span> <span class="fl">0.5</span>,</span>
<span id="cb75-9"><a href="tree-models.html#cb75-9" tabindex="-1"></a>  <span class="at">max_depth =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb75-10"><a href="tree-models.html#cb75-10" tabindex="-1"></a>)</span>
<span id="cb75-11"><a href="tree-models.html#cb75-11" tabindex="-1"></a><span class="fu">head</span>(grid)</span></code></pre></div>
<pre><code>##   nrounds colsample_bytree min_child_weight  eta gamma subsample max_depth
## 1      75                1                1 0.01   0.5       0.5         2
## 2     100                1                1 0.01   0.5       0.5         2
## 3      75                1                1 0.10   0.5       0.5         2
## 4     100                1                1 0.10   0.5       0.5         2
## 5      75                1                1 0.30   0.5       0.5         2
## 6     100                1                1 0.30   0.5       0.5         2</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="tree-models.html#cb77-1" tabindex="-1"></a><span class="do">## 使用car包的train()函数之前，创建一个名为cntrl的对象，来设定trainControl的参数。这个对象会保存要使用的方法，以训练调优参数。我们使用5折交叉验证</span></span>
<span id="cb77-2"><a href="tree-models.html#cb77-2" tabindex="-1"></a><span class="do">## 在trControl中设定了verboseIter为TURE，所以可以看到每折交叉验证中的每次训练迭代。</span></span>
<span id="cb77-3"><a href="tree-models.html#cb77-3" tabindex="-1"></a>cntrl <span class="ot">=</span> <span class="fu">trainControl</span>(</span>
<span id="cb77-4"><a href="tree-models.html#cb77-4" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb77-5"><a href="tree-models.html#cb77-5" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">5</span>,</span>
<span id="cb77-6"><a href="tree-models.html#cb77-6" tabindex="-1"></a>  <span class="at">verboseIter =</span> <span class="cn">TRUE</span>,</span>
<span id="cb77-7"><a href="tree-models.html#cb77-7" tabindex="-1"></a>  <span class="at">returnData =</span> <span class="cn">FALSE</span>,</span>
<span id="cb77-8"><a href="tree-models.html#cb77-8" tabindex="-1"></a>  <span class="at">returnResamp =</span> <span class="st">&quot;final&quot;</span>                                                        </span>
<span id="cb77-9"><a href="tree-models.html#cb77-9" tabindex="-1"></a>)</span>
<span id="cb77-10"><a href="tree-models.html#cb77-10" tabindex="-1"></a></span>
<span id="cb77-11"><a href="tree-models.html#cb77-11" tabindex="-1"></a><span class="do">## 设定好所需参数即可:训练数据集、 标号、训练控制对象和实验网格。设定随机数种子</span></span>
<span id="cb77-12"><a href="tree-models.html#cb77-12" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb77-13"><a href="tree-models.html#cb77-13" tabindex="-1"></a>train.xgb <span class="ot">=</span> <span class="fu">train</span>(</span>
<span id="cb77-14"><a href="tree-models.html#cb77-14" tabindex="-1"></a>  <span class="at">x =</span> pima.train[, <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>],</span>
<span id="cb77-15"><a href="tree-models.html#cb77-15" tabindex="-1"></a>  <span class="at">y =</span> ,pima.train[, <span class="dv">8</span>],</span>
<span id="cb77-16"><a href="tree-models.html#cb77-16" tabindex="-1"></a>  <span class="at">trControl =</span> cntrl,</span>
<span id="cb77-17"><a href="tree-models.html#cb77-17" tabindex="-1"></a>  <span class="at">tuneGrid =</span> grid,</span>
<span id="cb77-18"><a href="tree-models.html#cb77-18" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;xgbTree&quot;</span></span>
<span id="cb77-19"><a href="tree-models.html#cb77-19" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## + Fold1: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:44] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:44] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:46] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:46] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold1: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:46] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold1: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:46] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:46] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:46] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:48] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold2: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:48] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold2: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:48] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:48] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:48] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:48] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold3: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold3: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:51] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:51] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:51] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:51] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:51] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold4: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:51] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold4: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.01, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.01, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.01, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.01, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.10, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.10, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.10, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:53] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.10, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:53] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.30, max_depth=2, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:53] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.30, max_depth=2, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:53] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.30, max_depth=3, gamma=0.25, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## + Fold5: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## [11:24:53] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.
## - Fold5: eta=0.30, max_depth=3, gamma=0.50, colsample_bytree=1, min_child_weight=1, subsample=0.5, nrounds=100 
## Aggregating results
## Selecting tuning parameters
## Fitting nrounds = 100, max_depth = 2, eta = 0.01, gamma = 0.5, colsample_bytree = 1, min_child_weight = 1, subsample = 0.5 on full training set</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="tree-models.html#cb79-1" tabindex="-1"></a><span class="do">## 得到最优的参数，以及每种参数设置的结果</span></span>
<span id="cb79-2"><a href="tree-models.html#cb79-2" tabindex="-1"></a>train.xgb</span></code></pre></div>
<pre><code>## eXtreme Gradient Boosting 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 308, 309, 308, 307, 308 
## Resampling results across tuning parameters:
## 
##   eta   max_depth  gamma  nrounds  Accuracy   Kappa    
##   0.01  2          0.25    75      0.7865932  0.4700801
##   0.01  2          0.25   100      0.7971195  0.5003081
##   0.01  2          0.50    75      0.7971528  0.4945394
##   0.01  2          0.50   100      0.8101407  0.5317302
##   0.01  3          0.25    75      0.7971537  0.5018986
##   0.01  3          0.25   100      0.7893948  0.4854910
##   0.01  3          0.50    75      0.8050476  0.5221906
##   0.01  3          0.50   100      0.7997853  0.5136332
##   0.10  2          0.25    75      0.7896980  0.5002401
##   0.10  2          0.25   100      0.7921605  0.5073063
##   0.10  2          0.50    75      0.7947579  0.5167947
##   0.10  2          0.50   100      0.7791717  0.4828563
##   0.10  3          0.25    75      0.7922612  0.5044835
##   0.10  3          0.25   100      0.7896297  0.5011073
##   0.10  3          0.50    75      0.7845023  0.4923603
##   0.10  3          0.50   100      0.7766418  0.4779629
##   0.30  2          0.25    75      0.7557592  0.4362591
##   0.30  2          0.25   100      0.7609198  0.4504284
##   0.30  2          0.50    75      0.7635864  0.4475264
##   0.30  2          0.50   100      0.7740093  0.4729577
##   0.30  3          0.25    75      0.7636881  0.4478178
##   0.30  3          0.25   100      0.7637547  0.4534616
##   0.30  3          0.50    75      0.7583574  0.4403953
##   0.30  3          0.50   100      0.7427721  0.3975159
## 
## Tuning parameter &#39;colsample_bytree&#39; was held constant at a value of 1
## 
## Tuning parameter &#39;min_child_weight&#39; was held constant at a value of 1
## 
## Tuning parameter &#39;subsample&#39; was held constant at a value of 0.5
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were nrounds = 100, max_depth = 2, eta
##  = 0.01, gamma = 0.5, colsample_bytree = 1, min_child_weight = 1 and
##  subsample = 0.5.</code></pre>
<p>接下来创建一个参数列表，供Xgboost包的训练函数xgb.train()使用。然后将数据框转换为一个输入特征矩阵，以及一个带标号的 数值型结果列表(其中的值是0和1)。接着，将特征矩阵和标号列表组合成符合要求的输入，即一个xgb.Dmatrix对象</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="tree-models.html#cb81-1" tabindex="-1"></a>param <span class="ot">&lt;-</span> <span class="fu">list</span>(  <span class="at">objective           =</span> <span class="st">&quot;binary:logistic&quot;</span>, </span>
<span id="cb81-2"><a href="tree-models.html#cb81-2" tabindex="-1"></a>                <span class="at">booster             =</span> <span class="st">&quot;gbtree&quot;</span>,</span>
<span id="cb81-3"><a href="tree-models.html#cb81-3" tabindex="-1"></a>                <span class="at">eval_metric         =</span> <span class="st">&quot;error&quot;</span>,</span>
<span id="cb81-4"><a href="tree-models.html#cb81-4" tabindex="-1"></a>                <span class="at">eta                 =</span> <span class="fl">0.1</span>, </span>
<span id="cb81-5"><a href="tree-models.html#cb81-5" tabindex="-1"></a>                <span class="at">max_depth           =</span> <span class="dv">2</span>, </span>
<span id="cb81-6"><a href="tree-models.html#cb81-6" tabindex="-1"></a>                <span class="at">subsample           =</span> <span class="fl">0.5</span>,</span>
<span id="cb81-7"><a href="tree-models.html#cb81-7" tabindex="-1"></a>                <span class="at">colsample_bytree    =</span> <span class="dv">1</span>,</span>
<span id="cb81-8"><a href="tree-models.html#cb81-8" tabindex="-1"></a>                <span class="at">gamma               =</span> <span class="fl">0.5</span></span>
<span id="cb81-9"><a href="tree-models.html#cb81-9" tabindex="-1"></a>)</span>
<span id="cb81-10"><a href="tree-models.html#cb81-10" tabindex="-1"></a></span>
<span id="cb81-11"><a href="tree-models.html#cb81-11" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(pima.train[, <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>])</span>
<span id="cb81-12"><a href="tree-models.html#cb81-12" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pima.train<span class="sc">$</span>type <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb81-13"><a href="tree-models.html#cb81-13" tabindex="-1"></a>train.mat <span class="ot">&lt;-</span> <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> x, </span>
<span id="cb81-14"><a href="tree-models.html#cb81-14" tabindex="-1"></a>                         <span class="at">label =</span> y)</span>
<span id="cb81-15"><a href="tree-models.html#cb81-15" tabindex="-1"></a></span>
<span id="cb81-16"><a href="tree-models.html#cb81-16" tabindex="-1"></a><span class="do">## 创建模型</span></span>
<span id="cb81-17"><a href="tree-models.html#cb81-17" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb81-18"><a href="tree-models.html#cb81-18" tabindex="-1"></a>xgb.fit <span class="ot">&lt;-</span> <span class="fu">xgb.train</span>(<span class="at">params =</span> param, <span class="at">data =</span> train.mat, <span class="at">nrounds =</span> <span class="dv">75</span>)</span>
<span id="cb81-19"><a href="tree-models.html#cb81-19" tabindex="-1"></a>xgb.fit</span></code></pre></div>
<pre><code>## ##### xgb.Booster
## raw: 68.2 Kb 
## call:
##   xgb.train(params = param, data = train.mat, nrounds = 75)
## params (as set within xgb.train):
##   objective = &quot;binary:logistic&quot;, booster = &quot;gbtree&quot;, eval_metric = &quot;error&quot;, eta = &quot;0.1&quot;, max_depth = &quot;2&quot;, subsample = &quot;0.5&quot;, colsample_bytree = &quot;1&quot;, gamma = &quot;0.5&quot;, validate_parameters = &quot;TRUE&quot;
## xgb.attributes:
##   niter
## callbacks:
##   cb.print.evaluation(period = print_every_n)
## # of features: 7 
## niter: 75
## nfeatures : 7</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="tree-models.html#cb83-1" tabindex="-1"></a><span class="do">## 查看模型效果之前，先检查变量重要性，并绘制统计图。你可以检查3个项目:gain、cover和frequecy。gain是这个特征对其所在分支的正确率做出的改善，cover是与这个特征相关的全体观测的相对数量，frequency是这个特征在所有树中出现的次数百分比</span></span>
<span id="cb83-2"><a href="tree-models.html#cb83-2" tabindex="-1"></a>impMatrix <span class="ot">&lt;-</span> <span class="fu">xgb.importance</span>(<span class="at">feature_names =</span> <span class="fu">dimnames</span>(x)[[<span class="dv">2</span>]], <span class="at">model =</span> xgb.fit)</span>
<span id="cb83-3"><a href="tree-models.html#cb83-3" tabindex="-1"></a>impMatrix </span></code></pre></div>
<pre><code>##    Feature       Gain      Cover  Frequency
## 1:     glu 0.40798616 0.29195097 0.23880597
## 2:     bmi 0.15376463 0.20961316 0.20895522
## 3:     age 0.14659440 0.14958221 0.14427861
## 4:     ped 0.11929561 0.14591596 0.15422886
## 5:   npreg 0.07242809 0.07594945 0.08457711
## 6:    skin 0.06111383 0.07025685 0.10447761
## 7:      bp 0.03881729 0.05673140 0.06467662</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="tree-models.html#cb85-1" tabindex="-1"></a><span class="fu">xgb.plot.importance</span>(impMatrix, <span class="at">main =</span> <span class="st">&quot;Gain by Feature&quot;</span>)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="tree-models.html#cb86-1" tabindex="-1"></a><span class="do">## 与训练集一样，测试集数据也要转换为矩阵</span></span>
<span id="cb86-2"><a href="tree-models.html#cb86-2" tabindex="-1"></a><span class="fu">library</span>(InformationValue)</span>
<span id="cb86-3"><a href="tree-models.html#cb86-3" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb.fit, x)</span>
<span id="cb86-4"><a href="tree-models.html#cb86-4" tabindex="-1"></a><span class="fu">optimalCutoff</span>(y, pred)      <span class="do">## 找出使误差最小化的最优概率阈</span></span></code></pre></div>
<pre><code>## [1] 0.4416743</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="tree-models.html#cb88-1" tabindex="-1"></a>pima.testMat <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(pima.test[, <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>])</span>
<span id="cb88-2"><a href="tree-models.html#cb88-2" tabindex="-1"></a>xgb.pima.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb.fit, pima.testMat)</span>
<span id="cb88-3"><a href="tree-models.html#cb88-3" tabindex="-1"></a>y.test <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(pima.test<span class="sc">$</span>type <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb88-4"><a href="tree-models.html#cb88-4" tabindex="-1"></a><span class="fu">optimalCutoff</span>(y.test, xgb.pima.test)</span></code></pre></div>
<pre><code>## [1] 0.4837992</code></pre>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="tree-models.html#cb90-1" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y.test, xgb.pima.test, <span class="at">threshold =</span> <span class="fl">0.39</span>)</span></code></pre></div>
<pre><code>##    0  1
## 0 71 14
## 1 22 40</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="tree-models.html#cb92-1" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">misClassError</span>(y.test, xgb.pima.test, <span class="at">threshold =</span> <span class="fl">0.39</span>)    <span class="do">## 模型误差大概是25%</span></span></code></pre></div>
<pre><code>## [1] 0.7551</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="tree-models.html#cb94-1" tabindex="-1"></a><span class="do">## ROC曲线</span></span>
<span id="cb94-2"><a href="tree-models.html#cb94-2" tabindex="-1"></a><span class="fu">plotROC</span>(y.test, xgb.pima.test)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-10-2.png" width="672" /></p>
</div>
</div>
<div id="cubist-model" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Cubist Model<a href="tree-models.html#cubist-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-3" class="section level3 hasAnchor" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Introduction<a href="tree-models.html#introduction-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cubist is a rule–based model that is an extension of Quinlan’s M5 model tree. A tree is grown where the terminal leaves contain linear regression models. These models are based on the predictors used in previous splits. Also, there are intermediate linear models at each step of the tree. A prediction is made using the linear regression model at the terminal node of the tree, but is “smoothed” by taking into account the prediction from the linear model in the previous node of the tree (which also occurs recursively up the tree). The tree is reduced to a set of rules, which initially are paths from the top of the tree to the bottom. Rules are eliminated via pruning and/or combined for simplification.</p>
<blockquote>
<p>Cubist是基于规则的模型，是Quinlan M5模型树的扩展。在末端叶子包含线性回归模型的地方生长一棵树。这些模型基于先前拆分中使用的预测变量。而且，在树的每个步骤中都有中间线性模型。使用树的末端节点处的线性回归模型进行预测，但通过考虑树的前一节点中的线性模型进行的预测（也可以在树上递归地进行）来“平滑”预测。将树简化为一组规则，这些规则最初是从树的顶部到底部的路径。通过修剪消除规则和/或将其组合以简化。</p>
</blockquote>
<p><strong>Cubist package</strong></p>
<table>
<colgroup>
<col width="57%" />
<col width="42%" />
</colgroup>
<thead>
<tr class="header">
<th><a href="https://rdrr.io/rforge/Cubist/man/cubist.html">cubist</a></th>
<th>Fit a Cubist model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://rdrr.io/rforge/Cubist/man/cubistControl.html">cubistControl</a></td>
<td>Various parameters that control aspects of the Cubist fit.</td>
</tr>
<tr class="even">
<td><a href="https://rdrr.io/rforge/Cubist/man/dotplot.cubist.html">dotplot.cubist</a></td>
<td>Visualization of Cubist Rules and Equations</td>
</tr>
<tr class="odd">
<td><a href="https://rdrr.io/rforge/Cubist/man/exportCubistFiles.html">exportCubistFiles</a></td>
<td>Export Cubist Information To the File System</td>
</tr>
<tr class="even">
<td><a href="https://rdrr.io/rforge/Cubist/man/predict.cubist.html">predict.cubist</a></td>
<td>Predict method for cubist fits</td>
</tr>
<tr class="odd">
<td><a href="https://rdrr.io/rforge/Cubist/man/summary.cubist.html">summary.cubist</a></td>
<td>Summarizing Cubist Fits</td>
</tr>
</tbody>
</table>
</div>
<div id="application-data-preparation" class="section level3 hasAnchor" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Application Data Preparation<a href="tree-models.html#application-data-preparation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="tree-models.html#cb95-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;Cubist&quot;</span>)</span>
<span id="cb95-2"><a href="tree-models.html#cb95-2" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mlbench&quot;</span>)</span>
<span id="cb95-3"><a href="tree-models.html#cb95-3" tabindex="-1"></a></span>
<span id="cb95-4"><a href="tree-models.html#cb95-4" tabindex="-1"></a><span class="do">## Data Preparation</span></span>
<span id="cb95-5"><a href="tree-models.html#cb95-5" tabindex="-1"></a></span>
<span id="cb95-6"><a href="tree-models.html#cb95-6" tabindex="-1"></a><span class="fu">data</span>(BostonHousing)</span>
<span id="cb95-7"><a href="tree-models.html#cb95-7" tabindex="-1"></a>BostonHousing<span class="sc">$</span>chas <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(BostonHousing<span class="sc">$</span>chas) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb95-8"><a href="tree-models.html#cb95-8" tabindex="-1"></a></span>
<span id="cb95-9"><a href="tree-models.html#cb95-9" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb95-10"><a href="tree-models.html#cb95-10" tabindex="-1"></a>inTrain <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(BostonHousing), <span class="fu">floor</span>(.<span class="dv">8</span><span class="sc">*</span><span class="fu">nrow</span>(BostonHousing)))</span>
<span id="cb95-11"><a href="tree-models.html#cb95-11" tabindex="-1"></a></span>
<span id="cb95-12"><a href="tree-models.html#cb95-12" tabindex="-1"></a><span class="do">## Predictors</span></span>
<span id="cb95-13"><a href="tree-models.html#cb95-13" tabindex="-1"></a>train_pred <span class="ot">&lt;-</span> BostonHousing[ inTrain, <span class="sc">-</span><span class="dv">14</span>]</span>
<span id="cb95-14"><a href="tree-models.html#cb95-14" tabindex="-1"></a>test_pred  <span class="ot">&lt;-</span> BostonHousing[<span class="sc">-</span>inTrain, <span class="sc">-</span><span class="dv">14</span>]</span>
<span id="cb95-15"><a href="tree-models.html#cb95-15" tabindex="-1"></a></span>
<span id="cb95-16"><a href="tree-models.html#cb95-16" tabindex="-1"></a><span class="do">## Responder variable</span></span>
<span id="cb95-17"><a href="tree-models.html#cb95-17" tabindex="-1"></a>train_resp <span class="ot">&lt;-</span> BostonHousing<span class="sc">$</span>medv[ inTrain]</span>
<span id="cb95-18"><a href="tree-models.html#cb95-18" tabindex="-1"></a>test_resp  <span class="ot">&lt;-</span> BostonHousing<span class="sc">$</span>medv[<span class="sc">-</span>inTrain]</span></code></pre></div>
</div>
<div id="fit-continious-outcome" class="section level3 hasAnchor" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> Fit Continious Outcome<a href="tree-models.html#fit-continious-outcome" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The modelTree method for Cubist shows the usage of each variable in either the rule conditions or the (terminal) linear model. In actuality, many more linear models are used in prediction that are shown in the output. Because of this, the variable usage statistics shown at the end of the output of the summary function will probably be inconsistent with the rules also shown in the output. At each split of the tree, Cubist saves a linear model (after feature selection) that is allowed to have terms for each variable used in the current split or any split above it. Quinlan (1992) discusses a smoothing algorithm where each model prediction is a linear combination of the parent and child model along the tree. As such, the final prediction is a function of all the linear models from the initial node to the terminal node. The percentages shown in the Cubist output reflects all the models involved in prediction (as opposed to the terminal models shown in the output).</p>
<blockquote>
<p>Cubist的modelTree方法显示了规则条件或（最终）线性模型中每个变量的用法。实际上，在预测中使用了更多的线性模型，这些模型显示在输出中。因此，摘要功能输出末尾显示的变量使用情况统计信息可能与输出中也显示的规则不一致。在树的每个分割处，Cubist都会保存一个线性模型（在特征选择之后），该线性模型允许对当前分割处或其上方任何分割处使用的每个变量都具有术语。 Quinlan（1992）讨论了一种平滑算法，其中每个模型预测都是沿着树的父模型和子模型的线性组合。这样，最终预测是从初始节点到终端节点的所有线性模型的函​​数。立体派输出中显示的百分比反映了预测中涉及的所有模型（与输出中显示的终端模型相对）。</p>
</blockquote>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="tree-models.html#cb96-1" tabindex="-1"></a><span class="do">## Continious Outcome</span></span>
<span id="cb96-2"><a href="tree-models.html#cb96-2" tabindex="-1"></a><span class="do">## Building mOdel</span></span>
<span id="cb96-3"><a href="tree-models.html#cb96-3" tabindex="-1"></a>model_tree <span class="ot">&lt;-</span> <span class="fu">cubist</span>(<span class="at">x =</span> train_pred, <span class="at">y =</span> train_resp)</span>
<span id="cb96-4"><a href="tree-models.html#cb96-4" tabindex="-1"></a><span class="fu">summary</span>(model_tree)</span></code></pre></div>
<pre><code>## 
## Call:
## cubist.default(x = train_pred, y = train_resp)
## 
## 
## Cubist [Release 2.07 GPL Edition]  Wed Dec  6 11:24:55 2023
## ---------------------------------
## 
##     Target attribute `outcome&#39;
## 
## Read 404 cases (14 attributes) from undefined.data
## 
## Model:
## 
##   Rule 1: [77 cases, mean 14.04, range 5 to 27.5, est err 2.14]
## 
##     if
##  nox &gt; 0.668
##     then
##  outcome = -2.18 + 3.47 dis + 21.6 nox - 0.32 lstat + 0.0089 b
##            - 0.12 ptratio - 0.02 crim - 0.005 age
## 
##   Rule 2: [167 cases, mean 19.30, range 7 to 31, est err 2.15]
## 
##     if
##  nox &lt;= 0.668
##  lstat &gt; 9.53
##     then
##  outcome = 43.02 - 0.94 ptratio - 0.27 lstat - 0.84 dis - 0.034 age
##            + 0.0082 b - 0.1 indus + 0.4 rm
## 
##   Rule 3: [29 cases, mean 25.08, range 18.2 to 50, est err 2.64]
## 
##     if
##  rm &lt;= 6.226
##  lstat &lt;= 9.53
##     then
##  outcome = -18.07 + 3.91 crim - 1.67 lstat + 0.0834 b + 3.3 rm
## 
##   Rule 4: [143 cases, mean 29.49, range 16.5 to 50, est err 2.39]
## 
##     if
##  dis &gt; 2.3999
##  lstat &lt;= 9.53
##     then
##  outcome = -28.26 + 11.1 rm + 0.62 crim - 0.58 lstat - 0.017 tax
##            - 0.059 age + 11.3 nox - 0.58 dis - 0.52 ptratio
## 
##   Rule 5: [14 cases, mean 40.54, range 22 to 50, est err 5.28]
## 
##     if
##  rm &gt; 6.226
##  dis &lt;= 2.3999
##  lstat &lt;= 9.53
##     then
##  outcome = -5.27 + 3.14 crim - 5.18 dis - 1.22 lstat + 9.6 rm
##            - 0.0141 tax - 0.031 age - 0.39 ptratio
## 
## 
## Evaluation on training data (404 cases):
## 
##     Average  |error|               2.13
##     Relative |error|               0.31
##     Correlation coefficient        0.96
## 
## 
##  Attribute usage:
##    Conds  Model
## 
##     82%   100%    lstat
##     57%    51%    nox
##     37%    93%    dis
##     10%    82%    rm
##            93%    age
##            93%    ptratio
##            63%    b
##            61%    crim
##            39%    indus
##            37%    tax
## 
## 
## Time: 0.0 secs</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="tree-models.html#cb98-1" tabindex="-1"></a><span class="do">## Make the prediction on the test datasets</span></span>
<span id="cb98-2"><a href="tree-models.html#cb98-2" tabindex="-1"></a>Cubist.probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_tree, test_pred)</span>
<span id="cb98-3"><a href="tree-models.html#cb98-3" tabindex="-1"></a></span>
<span id="cb98-4"><a href="tree-models.html#cb98-4" tabindex="-1"></a><span class="do">## Test set RMSE</span></span>
<span id="cb98-5"><a href="tree-models.html#cb98-5" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((Cubist.probs <span class="sc">-</span> test_resp)<span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 3.722453</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="tree-models.html#cb100-1" tabindex="-1"></a><span class="do">## Test set R^2</span></span>
<span id="cb100-2"><a href="tree-models.html#cb100-2" tabindex="-1"></a><span class="fu">cor</span>(Cubist.probs, test_resp)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 0.7733923</code></pre>
</div>
<div id="variable-importance" class="section level3 hasAnchor" number="5.6.4">
<h3><span class="header-section-number">5.6.4</span> Variable Importance<a href="tree-models.html#variable-importance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>the variable importance is a linear combination of the usage in the rule conditions and the model.</p>
</div>
<div id="summary-display" class="section level3 hasAnchor" number="5.6.5">
<h3><span class="header-section-number">5.6.5</span> Summary display<a href="tree-models.html#summary-display" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The tidyRules function in the tidyrules package returns rules in a tibble (an extension of dataframe) with one row per rule. The tibble provides these information about the rule: support, mean, min, max, error, LHS, RHS and committee.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="tree-models.html#cb102-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;tidyrules&quot;</span>)</span>
<span id="cb102-2"><a href="tree-models.html#cb102-2" tabindex="-1"></a>tr <span class="ot">&lt;-</span> <span class="fu">tidyRules</span>(model_tree)</span>
<span id="cb102-3"><a href="tree-models.html#cb102-3" tabindex="-1"></a>tr</span></code></pre></div>
<pre><code>## # A tibble: 5 × 9
##      id LHS                      RHS   support  mean   min   max error committee
##   &lt;int&gt; &lt;chr&gt;                    &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;
## 1     1 nox &gt; 0.668              (-2.…      77  14.0   5    27.5  2.14         1
## 2     2 nox &lt;= 0.668 &amp; lstat &gt; … (43.…     167  19.3   7    31    2.15         1
## 3     3 rm &lt;= 6.226 &amp; lstat &lt;= … (-18…      29  25.1  18.2  50    2.64         1
## 4     4 dis &gt; 2.3999 &amp; lstat &lt;=… (-28…     143  29.5  16.5  50    2.39         1
## 5     5 rm &gt; 6.226 &amp; dis &lt;= 2.3… (-5.…      14  40.5  22    50    5.28         1</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="tree-models.html#cb104-1" tabindex="-1"></a>tr[, <span class="fu">c</span>(<span class="st">&quot;LHS&quot;</span>, <span class="st">&quot;RHS&quot;</span>)]</span></code></pre></div>
<pre><code>## # A tibble: 5 × 2
##   LHS                                        RHS                                
##   &lt;chr&gt;                                      &lt;chr&gt;                              
## 1 nox &gt; 0.668                                (-2.18) + (3.47 * dis) + (21.6 * n…
## 2 nox &lt;= 0.668 &amp; lstat &gt; 9.53                (43.02) - (0.94 * ptratio) - (0.27…
## 3 rm &lt;= 6.226 &amp; lstat &lt;= 9.53                (-18.07) + (3.91 * crim) - (1.67 *…
## 4 dis &gt; 2.3999 &amp; lstat &lt;= 9.53               (-28.26) + (11.1 * rm) + (0.62 * c…
## 5 rm &gt; 6.226 &amp; dis &lt;= 2.3999 &amp; lstat &lt;= 9.53 (-5.27) + (3.14 * crim) - (5.18 * …</code></pre>
</div>
<div id="specific-parts" class="section level3 hasAnchor" number="5.6.6">
<h3><span class="header-section-number">5.6.6</span> specific parts<a href="tree-models.html#specific-parts" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These results can be used to look at specific parts of the data. For example, the 4th rule predictions are:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="tree-models.html#cb106-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;rlang&quot;</span>)</span>
<span id="cb106-2"><a href="tree-models.html#cb106-2" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;dplyr&quot;</span>)</span>
<span id="cb106-3"><a href="tree-models.html#cb106-3" tabindex="-1"></a>char_to_expr <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">index =</span> <span class="dv">1</span>, <span class="at">model =</span> <span class="cn">TRUE</span>) {</span>
<span id="cb106-4"><a href="tree-models.html#cb106-4" tabindex="-1"></a>  x <span class="ot">&lt;-</span> x <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">slice</span>(index) </span>
<span id="cb106-5"><a href="tree-models.html#cb106-5" tabindex="-1"></a>  <span class="cf">if</span> (model) {</span>
<span id="cb106-6"><a href="tree-models.html#cb106-6" tabindex="-1"></a>    x <span class="ot">&lt;-</span> x <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">pull</span>(RHS) <span class="sc">%&gt;%</span> rlang<span class="sc">::</span><span class="fu">parse_expr</span>()</span>
<span id="cb106-7"><a href="tree-models.html#cb106-7" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb106-8"><a href="tree-models.html#cb106-8" tabindex="-1"></a>    x <span class="ot">&lt;-</span> x <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">pull</span>(LHS) <span class="sc">%&gt;%</span> rlang<span class="sc">::</span><span class="fu">parse_expr</span>()</span>
<span id="cb106-9"><a href="tree-models.html#cb106-9" tabindex="-1"></a>  }</span>
<span id="cb106-10"><a href="tree-models.html#cb106-10" tabindex="-1"></a>  x</span>
<span id="cb106-11"><a href="tree-models.html#cb106-11" tabindex="-1"></a>}</span>
<span id="cb106-12"><a href="tree-models.html#cb106-12" tabindex="-1"></a></span>
<span id="cb106-13"><a href="tree-models.html#cb106-13" tabindex="-1"></a>rule_expr  <span class="ot">&lt;-</span> <span class="fu">char_to_expr</span>(tr, <span class="dv">4</span>, <span class="at">model =</span> <span class="cn">FALSE</span>)</span>
<span id="cb106-14"><a href="tree-models.html#cb106-14" tabindex="-1"></a>model_expr <span class="ot">&lt;-</span> <span class="fu">char_to_expr</span>(tr, <span class="dv">4</span>, <span class="at">model =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="ensembles-by-committees" class="section level3 hasAnchor" number="5.6.7">
<h3><span class="header-section-number">5.6.7</span> Ensembles By Committees<a href="tree-models.html#ensembles-by-committees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Cubist model can also use a boosting–like scheme called committees where iterative model trees are created in sequence. The first tree follows the procedure described in the last section. Subsequent trees are created using adjusted versions to the training set outcome: if the model over–predicted a value, the response is adjusted downward for the next model (and so on). Unlike traditional boosting, stage weights for each committee are not used to average the predictions from each model tree; the final prediction is a simple average of the predictions from each model tree.</p>
<blockquote>
<p>其中按顺序创建迭代模型树。 第一棵树遵循最后一部分中描述的过程。 使用对训练集结果的调整后的版本来创建后续树：如果模型预测值过高，则针对下一个模型向下调整响应（依此类推）。 与传统的提升不同，每个委员会的阶段权重不会用于平均每个模型树的预测； 最终预测是来自每个模型树的预测的简单平均值。</p>
</blockquote>
</div>
<div id="nearestneighbors-adjustmemt" class="section level3 hasAnchor" number="5.6.8">
<h3><span class="header-section-number">5.6.8</span> Nearest–neighbors Adjustmemt<a href="tree-models.html#nearestneighbors-adjustmemt" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another innovation in Cubist using nearest–neighbors to adjust the predictions from the rule–based model. First, a model tree (with or without committees) is created. Once a sample is predicted by this model, Cubist can find it’s nearest neighbors and determine the average of these training set points.</p>
<blockquote>
<p>使用最近邻来调整基于规则的模型中的预测。 首先，创建一个模型树（有或没有委员会）。 通过该模型预测样本后，Cubist可以找到其最近的邻居，并确定这些训练设定点的平均值。</p>
</blockquote>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="tree-models.html#cb107-1" tabindex="-1"></a><span class="do">## Ensembles By Committees </span></span>
<span id="cb107-2"><a href="tree-models.html#cb107-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb107-3"><a href="tree-models.html#cb107-3" tabindex="-1"></a>com_model <span class="ot">&lt;-</span> <span class="fu">cubist</span>(<span class="at">x =</span> train_pred, <span class="at">y =</span> train_resp, <span class="at">committees =</span> <span class="dv">5</span>)</span>
<span id="cb107-4"><a href="tree-models.html#cb107-4" tabindex="-1"></a><span class="fu">summary</span>(com_model)</span></code></pre></div>
<pre><code>## 
## Call:
## cubist.default(x = train_pred, y = train_resp, committees = 5)
## 
## 
## Cubist [Release 2.07 GPL Edition]  Wed Dec  6 11:24:55 2023
## ---------------------------------
## 
##     Target attribute `outcome&#39;
## 
## Read 404 cases (14 attributes) from undefined.data
## 
## Model 1:
## 
##   Rule 1/1: [77 cases, mean 14.04, range 5 to 27.5, est err 2.14]
## 
##     if
##  nox &gt; 0.668
##     then
##  outcome = -2.18 + 3.47 dis + 21.6 nox - 0.32 lstat + 0.0089 b
##            - 0.12 ptratio - 0.02 crim - 0.005 age
## 
##   Rule 1/2: [167 cases, mean 19.30, range 7 to 31, est err 2.15]
## 
##     if
##  nox &lt;= 0.668
##  lstat &gt; 9.53
##     then
##  outcome = 43.02 - 0.94 ptratio - 0.27 lstat - 0.84 dis - 0.034 age
##            + 0.0082 b - 0.1 indus + 0.4 rm
## 
##   Rule 1/3: [29 cases, mean 25.08, range 18.2 to 50, est err 2.64]
## 
##     if
##  rm &lt;= 6.226
##  lstat &lt;= 9.53
##     then
##  outcome = -18.07 + 3.91 crim - 1.67 lstat + 0.0834 b + 3.3 rm
## 
##   Rule 1/4: [143 cases, mean 29.49, range 16.5 to 50, est err 2.39]
## 
##     if
##  dis &gt; 2.3999
##  lstat &lt;= 9.53
##     then
##  outcome = -28.26 + 11.1 rm + 0.62 crim - 0.58 lstat - 0.017 tax
##            - 0.059 age + 11.3 nox - 0.58 dis - 0.52 ptratio
## 
##   Rule 1/5: [14 cases, mean 40.54, range 22 to 50, est err 5.28]
## 
##     if
##  rm &gt; 6.226
##  dis &lt;= 2.3999
##  lstat &lt;= 9.53
##     then
##  outcome = -5.27 + 3.14 crim - 5.18 dis - 1.22 lstat + 9.6 rm
##            - 0.0141 tax - 0.031 age - 0.39 ptratio
## 
## Model 2:
## 
##   Rule 2/1: [58 cases, mean 14.03, range 5 to 36, est err 4.06]
## 
##     if
##  dis &gt; 1.4254
##  dis &lt;= 1.8956
##  lstat &gt; 5.91
##     then
##  outcome = 86.06 - 20.56 dis - 0.47 lstat - 3 rm - 0.0201 b - 0.17 crim
##            - 4.1 nox
## 
##   Rule 2/2: [159 cases, mean 19.56, range 8.7 to 27.1, est err 1.84]
## 
##     if
##  rm &lt;= 6.251
##  dis &gt; 1.8956
##     then
##  outcome = -0.22 + 3.8 rm - 0.076 age + 0.021 b + 11.6 nox - 0.56 ptratio
##            - 0.04 lstat - 0.06 dis
## 
##   Rule 2/3: [116 cases, mean 22.43, range 7.2 to 50, est err 2.23]
## 
##     if
##  rm &gt; 6.251
##  lstat &gt; 5.91
##     then
##  outcome = -23.67 + 8.5 rm - 0.46 lstat - 0.3 crim - 0.0088 tax + 6.5 nox
##            - 0.2 dis - 0.19 ptratio + 0.0028 b - 0.008 age
## 
##   Rule 2/4: [10 cases, mean 25.07, range 5 to 50, est err 8.00]
## 
##     if
##  rm &lt;= 6.251
##  dis &lt;= 1.4254
##     then
##  outcome = 174.32 - 119.61 dis - 1.31 lstat + 38.6 nox
## 
##   Rule 2/5: [8 cases, mean 27.56, range 22.5 to 50, est err 3.33]
## 
##     if
##  rm &lt;= 6.461
##  lstat &lt;= 5.91
##     then
##  outcome = 22.34 + 6.98 crim
## 
##   Rule 2/6: [37 cases, mean 36.09, range 22.8 to 50, est err 3.40]
## 
##     if
##  rm &gt; 6.461
##  tax &gt; 265
##  lstat &lt;= 5.91
##     then
##  outcome = 53.88 - 0.2698 b + 0.0588 tax + 11.5 rm + 0.52 crim - 1.83 dis
##            - 0.129 age - 0.3 lstat - 0.12 ptratio
## 
##   Rule 2/7: [47 cases, mean 36.19, range 24.4 to 50, est err 3.56]
## 
##     if
##  rm &gt; 6.461
##  tax &lt;= 265
##     then
##  outcome = -23.33 - 0.0943 tax + 13.6 rm + 0.84 crim - 0.0276 b
##            - 0.21 lstat - 0.09 ptratio - 0.09 dis - 0.005 age + 0.006 zn
## 
## Model 3:
## 
##   Rule 3/1: [33 cases, mean 13.98, range 5 to 23.2, est err 2.95]
## 
##     if
##  nox &gt; 0.668
##  b &gt; 375.52
##     then
##  outcome = 197.68 - 0.3916 b - 0.5 age + 36.1 nox - 0.36 lstat
##            - 0.08 crim
## 
##   Rule 3/2: [44 cases, mean 14.09, range 7 to 27.5, est err 2.58]
## 
##     if
##  nox &gt; 0.668
##  b &lt;= 375.52
##     then
##  outcome = 14.76 - 0.3 lstat + 0.0196 b
## 
##   Rule 3/3: [241 cases, mean 17.54, range 5 to 31, est err 2.50]
## 
##     if
##  lstat &gt; 9.53
##     then
##  outcome = 49.71 - 1.16 dis - 0.32 lstat - 1.06 ptratio - 14.8 nox
##            + 0.0091 b + 0.9 rm + 0.07 rad - 0.017 age - 0.0023 tax
##            - 0.03 crim
## 
##   Rule 3/4: [29 cases, mean 25.08, range 18.2 to 50, est err 3.71]
## 
##     if
##  rm &lt;= 6.226
##  lstat &lt;= 9.53
##     then
##  outcome = -71.35 + 3.01 crim + 0.1693 b - 1.96 lstat + 5.5 rm
##            + 0.47 indus + 0.0173 tax
## 
##   Rule 3/5: [134 cases, mean 31.94, range 16.5 to 50, est err 2.79]
## 
##     if
##  rm &gt; 6.226
##  lstat &lt;= 9.53
##     then
##  outcome = -13.33 + 1.72 crim + 9.9 rm - 0.87 lstat - 0.86 dis
##            - 0.73 ptratio - 0.045 age - 0.0033 tax
## 
## Model 4:
## 
##   Rule 4/1: [17 cases, mean 11.90, range 8.4 to 17.8, est err 1.86]
## 
##     if
##  nox &gt; 0.693
##  lstat &gt; 19.52
##     then
##  outcome = 12.1 - 0.64 crim + 2 rm - 0.18 ptratio - 3.1 nox
## 
##   Rule 4/2: [38 cases, mean 12.67, range 5 to 23.7, est err 3.61]
## 
##     if
##  nox &lt;= 0.693
##  dis &gt; 1.4254
##  lstat &gt; 19.52
##     then
##  outcome = 112.54 - 116.7 nox - 4.67 dis - 0.109 age - 0.0155 b
##            - 0.008 tax
## 
##   Rule 4/3: [70 cases, mean 18.02, range 9.6 to 27.5, est err 1.96]
## 
##     if
##  crim &gt; 1.42502
##  dis &gt; 1.4254
##  lstat &gt; 5.91
##  lstat &lt;= 19.52
##     then
##  outcome = 28.61 - 0.9 lstat + 0.0105 b - 0.027 age - 0.06 crim + 3 nox
## 
##   Rule 4/4: [61 cases, mean 18.76, range 12.7 to 25, est err 1.92]
## 
##     if
##  crim &gt; 0.21977
##  crim &lt;= 1.42502
##  rm &lt;= 6.546
##  lstat &gt; 5.91
##     then
##  outcome = -8.96 + 6.4 rm - 0.108 age - 0.09 lstat + 0.0017 b
##            - 0.07 ptratio - 0.07 dis - 0.0008 tax - 0.01 crim
## 
##   Rule 4/5: [112 cases, mean 21.60, range 13.6 to 29.4, est err 1.67]
## 
##     if
##  crim &lt;= 0.21977
##  rm &lt;= 6.546
##  lstat &lt;= 19.52
##     then
##  outcome = -37.71 + 18.25 crim + 7.3 rm + 0.0451 b - 0.0149 tax
##            + 0.32 lstat - 0.068 age
## 
##   Rule 4/6: [9 cases, mean 22.30, range 5 to 50, est err 11.24]
## 
##     if
##  rm &lt;= 6.546
##  dis &lt;= 1.4254
##  lstat &gt; 5.91
##     then
##  outcome = 216.66 - 123.39 dis - 1.52 lstat + 31.4 nox - 5.1 rm
## 
##   Rule 4/7: [8 cases, mean 27.56, range 22.5 to 50, est err 5.10]
## 
##     if
##  rm &lt;= 6.461
##  lstat &lt;= 5.91
##     then
##  outcome = 93.41 - 2.79 lstat - 11.5 rm + 37.5 nox + 0.49 crim
##            - 0.0023 tax - 0.05 ptratio
## 
##   Rule 4/8: [118 cases, mean 32.26, range 7.5 to 50, est err 4.39]
## 
##     if
##  rm &gt; 6.546
##     then
##  outcome = -12.45 - 0.0364 tax + 8.1 rm - 0.05 lstat - 0.12 dis
##            - 0.007 age - 0.08 ptratio - 0.02 indus - 0.01 crim
## 
##   Rule 4/9: [37 cases, mean 36.09, range 22.8 to 50, est err 4.24]
## 
##     if
##  rm &gt; 6.461
##  tax &gt; 265
##  lstat &lt;= 5.91
##     then
##  outcome = 52.87 - 0.2742 b + 2.81 crim + 12 rm + 0.0478 tax - 0.151 age
##            - 1.73 dis - 0.06 lstat - 0.9 nox
## 
##   Rule 4/10: [33 cases, mean 37.05, range 25 to 50, est err 3.64]
## 
##     if
##  tax &lt;= 265
##  lstat &lt;= 5.91
##     then
##  outcome = -21.76 - 0.1186 tax + 1.59 crim + 13.2 rm - 0.33 lstat
##            - 4.6 nox - 0.16 ptratio
## 
## Model 5:
## 
##   Rule 5/1: [324 cases, mean 19.78, range 5 to 50, est err 2.75]
## 
##     if
##  rm &lt;= 6.781
##     then
##  outcome = 46.87 - 0.47 lstat - 1.05 dis - 14.9 nox - 0.78 ptratio
##            + 0.0104 b + 0.4 rm + 0.02 rad - 0.0006 tax
## 
##   Rule 5/2: [80 cases, mean 35.32, range 7.5 to 50, est err 4.52]
## 
##     if
##  rm &gt; 6.781
##     then
##  outcome = -49.93 + 13 rm - 0.83 crim - 0.19 lstat - 0.52 dis
##            - 0.45 ptratio - 6.3 nox + 0.0049 b + 0.04 rad - 0.0017 tax
##            + 0.007 zn
## 
##   Rule 5/3: [77 cases, mean 35.75, range 22.5 to 50, est err 3.93]
## 
##     if
##  lstat &lt;= 5.91
##     then
##  outcome = -10.9 + 4.64 crim - 2.66 lstat + 9.2 rm - 0.26 indus
##            - 0.84 dis - 0.12 ptratio + 0.02 rad - 1.5 nox - 0.0008 tax
##            + 0.0014 b
## 
## 
## Evaluation on training data (404 cases):
## 
##     Average  |error|               1.82
##     Relative |error|               0.26
##     Correlation coefficient        0.97
## 
## 
##  Attribute usage:
##    Conds  Model
## 
##     62%    97%    lstat
##     57%    88%    rm
##     22%    84%    dis
##     16%    66%    nox
##     10%    68%    crim
##      7%    71%    tax
##      3%    79%    b
##            80%    ptratio
##            69%    age
##            31%    rad
##            17%    indus
##             5%    zn
## 
## 
## Time: 0.0 secs</code></pre>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="tree-models.html#cb109-1" tabindex="-1"></a><span class="do">## Nearest–neighbors Adjustmemt</span></span>
<span id="cb109-2"><a href="tree-models.html#cb109-2" tabindex="-1"></a>inst_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(com_model, test_pred, <span class="at">neighbors =</span> <span class="dv">5</span>)</span>
<span id="cb109-3"><a href="tree-models.html#cb109-3" tabindex="-1"></a><span class="do">## RMSE</span></span>
<span id="cb109-4"><a href="tree-models.html#cb109-4" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">mean</span>((inst_pred <span class="sc">-</span> test_resp)<span class="sc">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 4.641258</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="tree-models.html#cb111-1" tabindex="-1"></a><span class="do">## R^2</span></span>
<span id="cb111-2"><a href="tree-models.html#cb111-2" tabindex="-1"></a><span class="fu">cor</span>(inst_pred, test_resp)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 0.6878503</code></pre>
</div>
<div id="optimize-parameters" class="section level3 hasAnchor" number="5.6.9">
<h3><span class="header-section-number">5.6.9</span> Optimize parameters<a href="tree-models.html#optimize-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To tune the model over different values of neighbors and committees, the train function in the `caret package can be used to optimize these parameters.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="tree-models.html#cb113-1" tabindex="-1"></a><span class="do">## Optimize parameters</span></span>
<span id="cb113-2"><a href="tree-models.html#cb113-2" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;caret&quot;</span>)</span>
<span id="cb113-3"><a href="tree-models.html#cb113-3" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">committees =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">100</span>),</span>
<span id="cb113-4"><a href="tree-models.html#cb113-4" tabindex="-1"></a>                    <span class="at">neighbors =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">9</span>))</span>
<span id="cb113-5"><a href="tree-models.html#cb113-5" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb113-6"><a href="tree-models.html#cb113-6" tabindex="-1"></a>boston_tuned <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb113-7"><a href="tree-models.html#cb113-7" tabindex="-1"></a>  <span class="at">x =</span> train_pred,</span>
<span id="cb113-8"><a href="tree-models.html#cb113-8" tabindex="-1"></a>  <span class="at">y =</span> train_resp,</span>
<span id="cb113-9"><a href="tree-models.html#cb113-9" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;cubist&quot;</span>,</span>
<span id="cb113-10"><a href="tree-models.html#cb113-10" tabindex="-1"></a>  <span class="at">tuneGrid =</span> grid,</span>
<span id="cb113-11"><a href="tree-models.html#cb113-11" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>)</span>
<span id="cb113-12"><a href="tree-models.html#cb113-12" tabindex="-1"></a>)</span>
<span id="cb113-13"><a href="tree-models.html#cb113-13" tabindex="-1"></a>boston_tuned</span></code></pre></div>
<pre><code>## Cubist 
## 
## 404 samples
##  13 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 364, 364, 364, 363, 364, 363, ... 
## Resampling results across tuning parameters:
## 
##   committees  neighbors  RMSE      Rsquared   MAE     
##     1         0          3.486995  0.8696332  2.410782
##     1         1          3.476423  0.8766470  2.353796
##     1         5          3.226631  0.8905880  2.172835
##     1         9          3.273334  0.8863545  2.200032
##    10         0          2.984583  0.9030420  2.107548
##    10         1          2.881682  0.9119488  2.071019
##    10         5          2.726023  0.9194164  1.907319
##    10         9          2.758086  0.9165772  1.910888
##    50         0          3.010918  0.9003286  2.114696
##    50         1          2.902492  0.9105268  2.061518
##    50         5          2.707697  0.9195486  1.881237
##    50         9          2.742850  0.9165186  1.900488
##   100         0          2.971313  0.9033629  2.093351
##   100         1          2.871736  0.9128822  2.043151
##   100         5          2.671169  0.9221820  1.862776
##   100         9          2.709607  0.9189411  1.879577
## 
## RMSE was used to select the optimal model using the smallest value.
## The final values used for the model were committees = 100 and neighbors = 5.</code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="tree-models.html#cb115-1" tabindex="-1"></a><span class="do">## The profiles of the tuning parameters </span></span>
<span id="cb115-2"><a href="tree-models.html#cb115-2" tabindex="-1"></a><span class="fu">ggplot</span>(boston_tuned)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
<div id="logistic-cv" class="section level3 hasAnchor" number="5.6.10">
<h3><span class="header-section-number">5.6.10</span> Logistic CV<a href="tree-models.html#logistic-cv" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="tree-models.html#cb116-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;MASS&quot;</span>)</span>
<span id="cb116-2"><a href="tree-models.html#cb116-2" tabindex="-1"></a><span class="fu">data</span>(biopsy)</span>
<span id="cb116-3"><a href="tree-models.html#cb116-3" tabindex="-1"></a>biopsy<span class="sc">$</span>ID <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb116-4"><a href="tree-models.html#cb116-4" tabindex="-1"></a><span class="fu">names</span>(biopsy) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;thick&quot;</span>, <span class="st">&quot;u.size&quot;</span>, <span class="st">&quot;u.shape&quot;</span>, <span class="st">&quot;adhsn&quot;</span>, </span>
<span id="cb116-5"><a href="tree-models.html#cb116-5" tabindex="-1"></a>                  <span class="st">&quot;s.size&quot;</span>, <span class="st">&quot;nucl&quot;</span>, <span class="st">&quot;chrom&quot;</span>, <span class="st">&quot;n.nuc&quot;</span>, <span class="st">&quot;mit&quot;</span>, <span class="st">&quot;class&quot;</span>)</span>
<span id="cb116-6"><a href="tree-models.html#cb116-6" tabindex="-1"></a>biopsy.v2 <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(biopsy)</span>
<span id="cb116-7"><a href="tree-models.html#cb116-7" tabindex="-1"></a></span>
<span id="cb116-8"><a href="tree-models.html#cb116-8" tabindex="-1"></a><span class="do">## 用0表示良性，用1表示恶性</span></span>
<span id="cb116-9"><a href="tree-models.html#cb116-9" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(biopsy.v2<span class="sc">$</span>class <span class="sc">==</span> <span class="st">&quot;malignant&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb116-10"><a href="tree-models.html#cb116-10" tabindex="-1"></a></span>
<span id="cb116-11"><a href="tree-models.html#cb116-11" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co">#random number generator</span></span>
<span id="cb116-12"><a href="tree-models.html#cb116-12" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">2</span>, <span class="fu">nrow</span>(biopsy.v2), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.7</span>, <span class="fl">0.3</span>))</span>
<span id="cb116-13"><a href="tree-models.html#cb116-13" tabindex="-1"></a>train <span class="ot">&lt;-</span> biopsy.v2[ind<span class="sc">==</span><span class="dv">1</span>, ] <span class="co">#the training data set</span></span>
<span id="cb116-14"><a href="tree-models.html#cb116-14" tabindex="-1"></a>test <span class="ot">&lt;-</span> biopsy.v2[ind<span class="sc">==</span><span class="dv">2</span>, ] <span class="co">#the test data set</span></span>
<span id="cb116-15"><a href="tree-models.html#cb116-15" tabindex="-1"></a></span>
<span id="cb116-16"><a href="tree-models.html#cb116-16" tabindex="-1"></a>trainY <span class="ot">&lt;-</span> y[ind<span class="sc">==</span><span class="dv">1</span>]</span>
<span id="cb116-17"><a href="tree-models.html#cb116-17" tabindex="-1"></a>testY <span class="ot">&lt;-</span> y[ind<span class="sc">==</span><span class="dv">2</span>]</span>
<span id="cb116-18"><a href="tree-models.html#cb116-18" tabindex="-1"></a></span>
<span id="cb116-19"><a href="tree-models.html#cb116-19" tabindex="-1"></a></span>
<span id="cb116-20"><a href="tree-models.html#cb116-20" tabindex="-1"></a></span>
<span id="cb116-21"><a href="tree-models.html#cb116-21" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb116-22"><a href="tree-models.html#cb116-22" tabindex="-1"></a>ctrl<span class="ot">=</span>(<span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&quot;repeatedcv&quot;</span>, <span class="at">repeats=</span><span class="dv">5</span>))</span>
<span id="cb116-23"><a href="tree-models.html#cb116-23" tabindex="-1"></a>c<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="dv">100</span>)</span>
<span id="cb116-24"><a href="tree-models.html#cb116-24" tabindex="-1"></a>n<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb116-25"><a href="tree-models.html#cb116-25" tabindex="-1"></a></span>
<span id="cb116-26"><a href="tree-models.html#cb116-26" tabindex="-1"></a>cubit.fit<span class="ot">&lt;-</span><span class="fu">train</span>(<span class="fu">as.matrix</span>(train[<span class="sc">-</span><span class="dv">10</span>]),</span>
<span id="cb116-27"><a href="tree-models.html#cb116-27" tabindex="-1"></a>                 trainY, </span>
<span id="cb116-28"><a href="tree-models.html#cb116-28" tabindex="-1"></a>                 <span class="at">method=</span><span class="st">&quot;cubist&quot;</span>,</span>
<span id="cb116-29"><a href="tree-models.html#cb116-29" tabindex="-1"></a>                 <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),</span>
<span id="cb116-30"><a href="tree-models.html#cb116-30" tabindex="-1"></a>                 <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">committees=</span>c,<span class="at">neighbors=</span>n),</span>
<span id="cb116-31"><a href="tree-models.html#cb116-31" tabindex="-1"></a>                 <span class="at">trControl =</span> ctrl)</span>
<span id="cb116-32"><a href="tree-models.html#cb116-32" tabindex="-1"></a>                </span>
<span id="cb116-33"><a href="tree-models.html#cb116-33" tabindex="-1"></a><span class="fu">summary</span>(cubit.fit)</span></code></pre></div>
<pre><code>## 
## Call:
## cubist.default(x = x, y = y, committees = param$committees)
## 
## 
## Cubist [Release 2.07 GPL Edition]  Wed Dec  6 11:26:54 2023
## ---------------------------------
## 
##     Target attribute `outcome&#39;
## 
## Read 474 cases (10 attributes) from undefined.data
## 
## Model 1:
## 
##   Rule 1/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 1/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 1/3: [287 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= -0.1056389
##  chrom &lt;= -0.1989626
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0
## 
##   Rule 1/4: [14 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = 0.1 + 0.825 u.shape - 0.551 u.size + 0.073 nucl
## 
##   Rule 1/5: [7 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &gt; -0.1989626
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = 0.5 - 0.247 mit + 0.199 nucl + 0.192 thick + 0.152 chrom
##            + 0.032 n.nuc + 0.015 u.size + 0.011 s.size
## 
##   Rule 1/6: [10 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##  chrom &lt;= -0.1989626
##     then
##  outcome = 0.8 + 0.101 nucl + 0.061 thick + 0.039 s.size + 0.039 chrom
##            + 0.038 n.nuc + 0.016 u.size
## 
##   Rule 1/7: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 1/8: [16 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  mit &gt; 0.1942086
##     then
##  outcome = 1
## 
##   Rule 1/9: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 1/10: [10 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1
## 
##   Rule 1/11: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 1/12: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 2:
## 
##   Rule 2/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 2/2: [277 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0
## 
##   Rule 2/3: [305 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.6322382
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0
## 
##   Rule 2/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.466 thick
## 
##   Rule 2/5: [9 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.3977132
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.4555328
##  nucl &lt;= 0.6322382
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.9 - 4.143 u.size + 0.019 thick + 0.015 n.nuc
## 
##   Rule 2/6: [4 cases, mean 0.8, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &gt; 1.178508
##  u.size &lt;= 1.808996
##  nucl &gt; 0.6322382
##  nucl &lt;= 1.176124
##     then
##  outcome = 7.8 - 4.401 u.size
## 
##   Rule 2/7: [6 cases, mean 0.8, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  u.size &lt;= 1.178508
##  nucl &gt; 0.6322382
##  nucl &lt;= 1.176124
##     then
##  outcome = 2.5 - 2.575 u.size
## 
##   Rule 2/8: [30 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; 0.6322382
##     then
##  outcome = 1
## 
##   Rule 2/9: [81 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 1
## 
##   Rule 2/10: [35 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &lt;= 0.6322382
##     then
##  outcome = 1
## 
##   Rule 2/11: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 2/12: [54 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.808996
##     then
##  outcome = 1
## 
##   Rule 2/13: [78 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
## Model 3:
## 
##   Rule 3/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 3/2: [275 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= 0.2174117
##  s.size &lt;= 0.7219615
##  nucl &lt;= -0.18359
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 3/3: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 3/4: [13 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &lt;= -0.4286895
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.3 + 0.567 thick + 0.397 chrom
## 
##   Rule 3/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.453 thick
## 
##   Rule 3/6: [5 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  nucl &gt; 0.9041809
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.3 + 4.121 thick - 1.787 u.size
## 
##   Rule 3/7: [7 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  s.size &gt; 0.7219615
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.9 + 0.053 nucl + 0.03 u.size + 0.022 thick + 0.02 n.nuc
##            + 0.01 s.size
## 
##   Rule 3/8: [9 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 0.5 + 0.146 nucl + 0.13 thick + 0.06 chrom + 0.06 n.nuc
##            + 0.043 s.size + 0.007 u.shape
## 
##   Rule 3/9: [6 cases, mean 0.8, range 0 to 1, est err 1.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 0.2174117
##  s.size &lt;= 0.7219615
##  nucl &lt;= -0.18359
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.3 + 1.666 u.shape + 0.553 n.nuc - 0.249 nucl + 0.246 s.size
##            + 0.019 thick + 0.013 chrom
## 
##   Rule 3/10: [8 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  u.shape &gt; 0.2174117
##  s.size &lt;= 0.7219615
##     then
##  outcome = 0.9 + 0.052 u.shape + 0.044 thick + 0.038 chrom + 0.022 nucl
## 
##   Rule 3/11: [27 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  nucl &gt; -0.18359
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1
## 
##   Rule 3/12: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 3/13: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 3/14: [7 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; 0.9041809
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.8 + 0.086 thick + 0.013 nucl + 0.007 u.size
## 
##   Rule 3/15: [37 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &lt;= 0.9041809
##     then
##  outcome = 1
## 
## Model 4:
## 
##   Rule 4/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 4/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 4/3: [35 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 0.1863816
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.3774847
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0 + 0.113 nucl + 0.097 thick
## 
##   Rule 4/4: [35 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.3774847
##  nucl &lt;= 1.176124
##     then
##  outcome = -0.1 + 0.682 nucl - 0.513 thick + 0.312 adhsn
## 
##   Rule 4/5: [6 cases, mean 0.2, range 0 to 1, est err 0.5]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.3 + 1.024 thick
## 
##   Rule 4/6: [48 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.9 + 0.059 nucl
## 
##   Rule 4/7: [113 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.1863816
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 4/8: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 4/9: [10 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1
## 
##   Rule 4/10: [14 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 1.2 - 0.106 thick - 0.047 mit
## 
##   Rule 4/11: [13 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &gt; 1.636011
##     then
##  outcome = 0.9 + 0.05 nucl + 0.023 thick + 0.011 n.nuc
## 
##   Rule 4/12: [11 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &gt; 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.9 + 0.107 u.size + 0.016 nucl
## 
##   Rule 4/13: [7 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.7 + 0.151 nucl + 0.073 thick + 0.054 n.nuc + 0.049 u.size
##            + 0.044 s.size
## 
##   Rule 4/14: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 4/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 5:
## 
##   Rule 5/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = -0
## 
##   Rule 5/2: [269 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= -0.4286895
##  adhsn &lt;= 1.064348
##     then
##  outcome = -0
## 
##   Rule 5/3: [277 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0
## 
##   Rule 5/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.478 thick
## 
##   Rule 5/5: [15 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.8 - 1.634 u.size + 0.008 u.shape
## 
##   Rule 5/6: [7 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 1.313705
##     then
##  outcome = 0.4 + 0.169 nucl + 0.125 thick + 0.061 n.nuc + 0.058 s.size
##            + 0.057 chrom
## 
##   Rule 5/7: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.9 + 0.052 nucl + 0.039 thick + 0.019 n.nuc + 0.018 s.size
##            + 0.017 chrom
## 
##   Rule 5/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 5/9: [93 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.4555328
##     then
##  outcome = 1
## 
##   Rule 5/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 5/11: [73 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 1.064348
##     then
##  outcome = 1
## 
## Model 6:
## 
##   Rule 6/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 6/2: [24 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  chrom &lt;= -0.6054638
##  n.nuc &lt;= -0.6201341
##     then
##  outcome = 0
## 
##   Rule 6/3: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.456 thick
## 
##   Rule 6/4: [27 cases, mean 0.4, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.5 - 1.196 adhsn + 0.885 nucl + 0.556 n.nuc + 0.358 thick
## 
##   Rule 6/5: [13 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  chrom &gt; -0.6054638
##  n.nuc &gt; 0.3467855
##     then
##  outcome = 0.4 + 0.212 u.shape + 0.193 nucl - 0.142 adhsn + 0.08 thick
## 
##   Rule 6/6: [49 cases, mean 0.7, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  n.nuc &gt; -0.6201341
##     then
##  outcome = 0.4 + 0.186 nucl + 0.124 u.shape + 0.093 thick + 0.082 mit
##            + 0.046 n.nuc + 0.037 u.size + 0.027 s.size + 0.015 chrom
##            + 0.006 adhsn
## 
##   Rule 6/7: [7 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 0.4 + 0.32 u.shape + 0.192 nucl
## 
##   Rule 6/8: [9 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.7 + 0.095 nucl + 0.07 thick + 0.038 n.nuc + 0.03 u.shape
##            + 0.028 s.size + 0.02 adhsn
## 
##   Rule 6/9: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 1 - 0.022 chrom
## 
##   Rule 6/10: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 6/11: [9 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &gt; 1.176124
##  n.nuc &lt;= 0.3467855
##     then
##  outcome = 0.7 + 0.212 u.shape + 0.184 mit + 0.156 nucl + 0.069 thick
## 
##   Rule 6/12: [73 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 1.064348
##     then
##  outcome = 1
## 
##   Rule 6/13: [15 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 1.242297
##  u.size &lt;= 0.2327753
##     then
##  outcome = 1 + 0.097 mit
## 
## Model 7:
## 
##   Rule 7/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 7/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 7/3: [6 cases, mean 0.2, range 0 to 1, est err 0.5]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.3 + 1.025 thick
## 
##   Rule 7/4: [16 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = -1.2 - 2.411 n.nuc + 0.506 chrom
## 
##   Rule 7/5: [15 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  chrom &lt;= 0.2075386
##  n.nuc &gt; -0.2978275
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0.5
## 
##   Rule 7/6: [4 cases, mean 0.8, range 0 to 1, est err 1.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.7209161
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.5 + 0.162 thick + 0.121 nucl + 0.104 n.nuc
## 
##   Rule 7/7: [9 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  s.size &gt; -0.5858465
##  chrom &gt; 0.2075386
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.8 + 0.21 nucl + 0.037 n.nuc + 0.033 thick + 0.017 u.size
##            + 0.017 chrom + 0.013 s.size
## 
##   Rule 7/8: [38 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 + 0.014 nucl + 0.008 thick + 0.005 n.nuc
## 
##   Rule 7/9: [6 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1.1
## 
##   Rule 7/10: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.1
## 
##   Rule 7/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 7/12: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 8:
## 
##   Rule 8/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 8/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 8/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.1 + 0.104 nucl + 0.059 u.size + 0.056 thick + 0.043 n.nuc
##            + 0.026 s.size
## 
##   Rule 8/4: [21 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &lt;= 0.7219615
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0
## 
##   Rule 8/5: [5 cases, mean 0.4, range 0 to 1, est err 0.8]
## 
##     if
##  u.size &lt;= -0.08246895
##  s.size &gt; -0.1499105
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 1.2 + 0.968 u.size + 0.391 nucl + 0.385 u.shape + 0.24 thick
## 
##   Rule 8/6: [15 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.7517401
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 2 + 1.905 s.size + 1.769 u.size + 0.611 n.nuc
## 
##   Rule 8/7: [6 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.242297
##  u.size &gt; -0.08246895
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 1 + 0.095 s.size
## 
##   Rule 8/8: [106 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 8/9: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  s.size &gt; 0.7219615
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 8/10: [59 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##     then
##  outcome = 0.9 + 0.02 adhsn + 0.017 nucl + 0.009 thick + 0.008 s.size
##            + 0.007 n.nuc
## 
##   Rule 8/11: [28 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##     then
##  outcome = 1 - 0.016 nucl
## 
##   Rule 8/12: [8 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1 - 0.025 thick - 0.012 n.nuc
## 
##   Rule 8/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 9:
## 
##   Rule 9/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = -0
## 
##   Rule 9/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 9/3: [43 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.2 + 0.476 nucl + 0.038 thick + 0.009 n.nuc
## 
##   Rule 9/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.477 thick
## 
##   Rule 9/5: [4 cases, mean 0.5, range 0 to 1, est err 0.7]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 + 0.299 nucl + 0.148 thick + 0.102 n.nuc
## 
##   Rule 9/6: [17 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.7 + 0.173 nucl + 0.007 thick
## 
##   Rule 9/7: [13 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 0.9913985
##     then
##  outcome = -3.2 + 1.833 n.nuc + 0.299 nucl
## 
##   Rule 9/8: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.9 + 0.049 nucl + 0.032 thick + 0.02 n.nuc + 0.016 chrom
##            + 0.012 s.size
## 
##   Rule 9/9: [26 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 + 0.014 nucl
## 
##   Rule 9/10: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
## Model 10:
## 
##   Rule 10/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 10/2: [235 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 10/3: [35 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.4 + 3.395 u.shape
## 
##   Rule 10/4: [4 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; 0.2174117
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.03405333
##  chrom &lt;= 0.2075386
##  n.nuc &gt; -0.2978275
##  mit &lt;= -0.3671017
##     then
##  outcome = 0.1 + 0.135 nucl - 0.095 u.shape + 0.077 thick + 0.044 n.nuc
##            + 0.035 s.size + 0.034 chrom
## 
##   Rule 10/5: [6 cases, mean 0.3, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.08246895
##  u.size &lt;= 0.2327753
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 0.7209161
##     then
##  outcome = -0.1 + 0.348 u.shape + 0.07 chrom + 0.066 thick + 0.058 nucl
##            + 0.039 s.size
## 
##   Rule 10/6: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.536 thick
## 
##   Rule 10/7: [22 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.08246895
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.4 + 0.826 u.shape - 0.395 adhsn + 0.144 thick + 0.02 chrom
##            + 0.016 nucl + 0.011 s.size
## 
##   Rule 10/8: [23 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 1
## 
##   Rule 10/9: [40 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 + 0.008 u.size
## 
##   Rule 10/10: [15 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  u.shape &lt;= 0.2174117
##     then
##  outcome = 1
## 
##   Rule 10/11: [5 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.594268
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 1 + 0.032 u.shape - 0.025 adhsn + 0.012 thick
## 
##   Rule 10/12: [10 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.03405333
##  chrom &lt;= 0.2075386
##  n.nuc &gt; -0.2978275
##  mit &lt;= -0.3671017
##     then
##  outcome = 0.7 + 0.129 nucl + 0.074 thick + 0.042 n.nuc + 0.033 s.size
##            + 0.032 chrom + 0.018 u.shape
## 
##   Rule 10/13: [59 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  mit &gt; -0.3671017
##     then
##  outcome = 1
## 
##   Rule 10/14: [88 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
##   Rule 10/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 11:
## 
##   Rule 11/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 11/2: [202 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.4555328
##     then
##  outcome = -0
## 
##   Rule 11/3: [32 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0.1 + 0.35 thick + 0.288 u.size + 0.128 chrom
## 
##   Rule 11/4: [8 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= -0.16559
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  nucl &gt; -0.4555328
##  nucl &lt;= 0.9041809
##     then
##  outcome = -0
## 
##   Rule 11/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.417 thick
## 
##   Rule 11/6: [10 cases, mean 0.4, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 0.2174117
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0.7 + 2.962 u.shape + 0.635 nucl
## 
##   Rule 11/7: [5 cases, mean 0.4, range 0 to 1, est err 0.6]
## 
##     if
##  u.size &lt;= 1.493752
##  u.shape &gt; 0.2174117
##  adhsn &lt;= 0.03405333
##  chrom &lt;= 0.2075386
##  mit &lt;= -0.3671017
##     then
##  outcome = -0
## 
##   Rule 11/8: [37 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; -0.16559
##  u.shape &lt;= 0.2174117
##  nucl &gt; -0.4555328
##     then
##  outcome = 1 + 0.027 thick
## 
##   Rule 11/9: [123 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  adhsn &gt; 0.03405333
##     then
##  outcome = 1
## 
##   Rule 11/10: [25 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  nucl &gt; 0.9041809
##     then
##  outcome = 3.3 - 1.348 nucl + 0.015 u.shape + 0.007 thick + 0.007 n.nuc
## 
##   Rule 11/11: [118 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
##   Rule 11/12: [59 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.493752
##     then
##  outcome = 1
## 
##   Rule 11/13: [59 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  mit &gt; -0.3671017
##     then
##  outcome = 1
## 
## Model 12:
## 
##   Rule 12/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 12/2: [270 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.7209161
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0
## 
##   Rule 12/3: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 12/4: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.2 + 1.014 thick
## 
##   Rule 12/5: [11 cases, mean 0.2, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 0.5383533
##  u.shape &lt;= 0.5404623
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -1
## 
##   Rule 12/6: [13 cases, mean 0.4, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##     then
##  outcome = -0.8 - 1.778 thick + 0.789 nucl
## 
##   Rule 12/7: [21 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; -0.16559
##  u.shape &lt;= 1.186563
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.4555328
##     then
##  outcome = 1 + 0.007 nucl
## 
##   Rule 12/8: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.5404623
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 12/9: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1
## 
##   Rule 12/10: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 12/11: [11 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  chrom &lt;= -0.1989626
##     then
##  outcome = 0.9 + 0.022 nucl + 0.012 thick + 0.009 n.nuc + 0.008 u.size
##            + 0.005 s.size
## 
##   Rule 12/12: [34 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 + 0.012 thick
## 
##   Rule 12/13: [4 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.1 - 0.183 u.shape
## 
##   Rule 12/14: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 12/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 13:
## 
##   Rule 13/1: [243 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= -0.18359
##     then
##  outcome = 0
## 
##   Rule 13/2: [265 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 13/3: [8 cases, mean 0.1, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &lt;= -0.7129574
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.18359
##     then
##  outcome = -2 - 3.465 s.size
## 
##   Rule 13/4: [12 cases, mean 0.3, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; -0.18359
##     then
##  outcome = 0.3 + 2.51 s.size
## 
##   Rule 13/5: [10 cases, mean 0.5, range 0 to 1, est err 0.6]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.6322382
##  n.nuc &gt; -0.2978275
##  n.nuc &lt;= 0.02447898
##     then
##  outcome = 1.4 + 1.852 u.size + 1.58 nucl - 1.184 chrom
## 
##   Rule 13/6: [21 cases, mean 0.6, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.4555328
##  nucl &lt;= 0.6322382
##     then
##  outcome = 0.2 + 0.565 thick - 0.377 nucl + 0.007 n.nuc + 0.005 chrom
## 
##   Rule 13/7: [11 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  s.size &lt;= 0.7219615
##  nucl &gt; 0.6322382
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.8 - 1.456 s.size
## 
##   Rule 13/8: [8 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 0.02447898
##  n.nuc &lt;= 0.669092
##     then
##  outcome = 1
## 
##   Rule 13/9: [10 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.08246895
##  nucl &gt; 1.176124
##     then
##  outcome = 0.8 + 0.091 nucl + 0.061 thick + 0.049 u.size + 0.035 n.nuc
## 
##   Rule 13/10: [95 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  n.nuc &gt; 0.669092
##     then
##  outcome = 1
## 
##   Rule 13/11: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 13/12: [35 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &lt;= 0.6322382
##     then
##  outcome = 1
## 
##   Rule 13/13: [11 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  s.size &gt; 0.7219615
##  nucl &gt; 0.6322382
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.7 + 0.072 nucl + 0.062 thick + 0.033 n.nuc + 0.028 s.size
##            + 0.022 chrom
## 
## Model 14:
## 
##   Rule 14/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 14/2: [18 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  n.nuc &gt; -0.6201341
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 14/3: [270 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.7209161
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0
## 
##   Rule 14/4: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 14/5: [300 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  chrom &lt;= 0.2075386
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0
## 
##   Rule 14/6: [6 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; 0.5404623
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.7 + 0.162 nucl
## 
##   Rule 14/7: [106 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 14/8: [52 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  adhsn &gt; 0.3774847
##     then
##  outcome = 1
## 
##   Rule 14/9: [107 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; -0.4555328
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
##   Rule 14/10: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1
## 
##   Rule 14/11: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 14/12: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 14/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 15:
## 
##   Rule 15/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 15/2: [213 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &lt;= -0.1056389
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0
## 
##   Rule 15/3: [231 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &lt;= -0.1056389
##  nucl &lt;= 1.176124
##  chrom &lt;= 0.6140398
##     then
##  outcome = 0
## 
##   Rule 15/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.466 thick
## 
##   Rule 15/5: [25 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.16559
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.1056389
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.2 + 0.276 thick + 0.259 nucl + 0.216 u.size + 0.053 n.nuc
##            - 0.035 u.shape + 0.022 mit
## 
##   Rule 15/6: [15 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.1056389
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = -0.2 + 1.716 u.shape - 1.278 u.size
## 
##   Rule 15/7: [5 cases, mean 0.8, range 0 to 1, est err 1.5]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.242297
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##  chrom &lt;= 0.6140398
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 2.2 + 1.727 u.shape - 0.1 chrom + 0.049 nucl + 0.034 n.nuc
##            + 0.032 thick + 0.011 u.size + 0.009 mit
## 
##   Rule 15/8: [6 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 0.8635129
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0.9 + 0.113 u.size + 0.038 n.nuc
## 
##   Rule 15/9: [10 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.08246895
##  nucl &gt; 1.176124
##     then
##  outcome = 0.9 + 0.061 nucl + 0.041 thick + 0.03 u.size + 0.021 chrom
##            + 0.017 n.nuc
## 
##   Rule 15/10: [17 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##  nucl &lt;= -0.4555328
##     then
##  outcome = 1
## 
##   Rule 15/11: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 15/12: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 15/13: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 15/14: [11 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.4555328
##  chrom &gt; 0.6140398
##     then
##  outcome = 1
## 
##   Rule 15/15: [5 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##  mit &gt; 0.1942086
##     then
##  outcome = 1 + 0.017 n.nuc
## 
## Model 16:
## 
##   Rule 16/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 16/2: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 16/3: [14 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##     then
##  outcome = -0
## 
##   Rule 16/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.453 thick
## 
##   Rule 16/5: [17 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##     then
##  outcome = 1.4 + 2.348 s.size
## 
##   Rule 16/6: [5 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  nucl &gt; 0.9041809
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.4 + 5.906 thick - 2.375 u.size
## 
##   Rule 16/7: [9 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= -0.3093781
##  s.size &gt; -0.1499105
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.6 + 0.196 s.size + 0.113 nucl + 0.016 thick
## 
##   Rule 16/8: [12 cases, mean 0.9, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.1 - 0.648 u.size - 0.459 nucl + 0.026 thick
## 
##   Rule 16/9: [26 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 + 0.048 u.size
## 
##   Rule 16/10: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 16/11: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 16/12: [7 cases, mean 1.0, range 1 to 1, est err 0.5]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; 0.9041809
##  nucl &lt;= 1.176124
##     then
##  outcome = 2.3 - 0.658 thick + 0.007 nucl
## 
##   Rule 16/13: [12 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 + 0.059 u.size
## 
## Model 17:
## 
##   Rule 17/1: [235 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 17/2: [118 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.8695334
##  u.shape &lt;= -0.4286895
##     then
##  outcome = -0
## 
##   Rule 17/3: [23 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 1.186563
##  s.size &lt;= 0.2860255
##  nucl &lt;= 1.176124
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = -0
## 
##   Rule 17/4: [17 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; -0.8695334
##  u.shape &lt;= -0.4286895
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = -2 - 3.587 s.size + 0.359 thick
## 
##   Rule 17/5: [41 cases, mean 0.2, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.3 + 0.36 thick + 0.174 s.size + 0.066 nucl + 0.01 u.size
##            + 0.005 n.nuc
## 
##   Rule 17/6: [26 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 1.178508
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.5 + 0.254 n.nuc + 0.189 adhsn
## 
##   Rule 17/7: [13 cases, mean 0.8, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.4286895
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.1 + 0.256 n.nuc + 0.19 adhsn
## 
##   Rule 17/8: [43 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1 - 0.008 nucl
## 
##   Rule 17/9: [9 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.4286895
##  nucl &gt; 1.176124
##     then
##  outcome = 0.7 + 0.122 nucl + 0.073 u.size + 0.064 thick + 0.039 n.nuc
##            + 0.023 s.size + 0.022 chrom
## 
##   Rule 17/10: [145 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.4286895
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1
## 
##   Rule 17/11: [104 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.4286895
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 17/12: [99 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.4286895
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 17/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 18:
## 
##   Rule 18/1: [205 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 18/2: [160 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 18/3: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 18/4: [7 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 0.5404623
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 0.02447898
##     then
##  outcome = -0.2
## 
##   Rule 18/5: [72 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0.6 + 1.522 nucl
## 
##   Rule 18/6: [15 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.3 + 0.317 nucl + 0.128 thick
## 
##   Rule 18/7: [8 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 0.5404623
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 0.02447898
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.9
## 
##   Rule 18/8: [106 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 18/9: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.3774847
##     then
##  outcome = 1
## 
##   Rule 18/10: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.5404623
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 18/11: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 18/12: [6 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &gt; 1.313705
##     then
##  outcome = 0.9 + 0.058 nucl + 0.005 thick
## 
##   Rule 18/13: [38 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 + 0.01 nucl
## 
##   Rule 18/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 19:
## 
##   Rule 19/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 19/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 19/3: [227 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  adhsn &lt;= 0.03405333
##  s.size &lt;= -0.1499105
##  chrom &lt;= 0.2075386
##     then
##  outcome = -0 + 0.18 chrom
## 
##   Rule 19/4: [16 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; -0.4555328
##     then
##  outcome = 0.1 + 0.069 nucl + 0.036 thick + 0.024 u.size + 0.022 s.size
##            + 0.021 u.shape + 0.021 chrom
## 
##   Rule 19/5: [42 cases, mean 0.2, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.03405333
##  nucl &gt; -0.7274755
##  chrom &lt;= 0.2075386
##     then
##  outcome = -0.1 + 0.373 thick
## 
##   Rule 19/6: [6 cases, mean 0.5, range 0 to 1, est err 0.7]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.03405333
##  s.size &gt; -0.1499105
##  nucl &gt; -0.7274755
##  chrom &gt; -0.6054638
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.6 + 0.251 nucl + 0.008 thick
## 
##   Rule 19/7: [4 cases, mean 0.8, range 0 to 1, est err 1.4]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.03405333
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##  chrom &gt; -0.6054638
##     then
##  outcome = 1.6
## 
##   Rule 19/8: [4 cases, mean 0.8, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##  chrom &gt; 0.2075386
##     then
##  outcome = 0.9 + 0.129 nucl + 0.07 thick + 0.057 s.size + 0.044 u.shape
##            + 0.041 chrom + 0.032 u.size
## 
##   Rule 19/9: [15 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; 0.9041809
##     then
##  outcome = 0.9 + 0.095 nucl
## 
##   Rule 19/10: [117 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.03405333
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 19/11: [106 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 19/12: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.3774847
##     then
##  outcome = 1
## 
##   Rule 19/13: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 19/14: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 19/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 20:
## 
##   Rule 20/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 20/2: [202 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  adhsn &lt;= -0.6528094
##     then
##  outcome = 0
## 
##   Rule 20/3: [14 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  adhsn &gt; -0.6528094
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 0.6322382
##  n.nuc &lt;= 0.02447898
##  mit &lt;= -0.3671017
##     then
##  outcome = 0
## 
##   Rule 20/4: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 20/5: [7 cases, mean 0.1, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &lt;= 0.2327753
##  adhsn &gt; -0.6528094
##  adhsn &lt;= 0.7209161
##  mit &gt; -0.3671017
##     then
##  outcome = -0.8 + 0.091 nucl + 0.06 thick + 0.021 n.nuc + 0.017 mit
## 
##   Rule 20/6: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.474 thick
## 
##   Rule 20/7: [6 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.6322382
##  n.nuc &gt; 0.02447898
##  mit &lt;= -0.3671017
##     then
##  outcome = 0.7 + 0.255 thick + 0.027 nucl
## 
##   Rule 20/8: [67 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 0.6322382
##  mit &lt;= -0.3671017
##     then
##  outcome = 1
## 
##   Rule 20/9: [59 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.493752
##     then
##  outcome = 1
## 
##   Rule 20/10: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 20/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 20/12: [50 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.594268
##     then
##  outcome = 1
## 
##   Rule 20/13: [11 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= -0.6528094
##  nucl &gt; -0.7274755
##     then
##  outcome = 1.2 - 0.137 thick - 0.109 nucl + 0.099 n.nuc
## 
##   Rule 20/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 21:
## 
##   Rule 21/1: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 21/2: [47 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &gt; -0.7517401
##  nucl &lt;= 0.9041809
##     then
##  outcome = 0
## 
##   Rule 21/3: [25 cases, mean 0.2, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; -0.16559
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.7 + 0.697 nucl + 0.289 s.size
## 
##   Rule 21/4: [6 cases, mean 0.2, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.2 + 0.998 thick
## 
##   Rule 21/5: [26 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &lt;= 0.9041809
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.8 + 0.117 nucl + 0.077 thick + 0.049 u.size + 0.042 n.nuc
##            + 0.03 s.size
## 
##   Rule 21/6: [11 cases, mean 0.7, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 0.9041809
##  chrom &lt;= 0.2075386
##     then
##  outcome = -3.4 + 2.765 nucl - 1.71 thick
## 
##   Rule 21/7: [105 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1
## 
##   Rule 21/8: [13 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  nucl &gt; 0.9041809
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.6 + 0.238 nucl + 0.019 thick + 0.012 u.size + 0.012 s.size
##            + 0.011 n.nuc
## 
##   Rule 21/9: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  nucl &gt; 0.9041809
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
##   Rule 21/10: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 22:
## 
##   Rule 22/1: [226 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 22/2: [34 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  u.shape &gt; -0.7517401
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0 + 0.012 s.size - 0.007 u.size + 0.006 nucl
## 
##   Rule 22/3: [54 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.16559
##  u.shape &lt;= 1.186563
##  s.size &lt;= -0.5858465
##  nucl &lt;= 1.176124
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = -0
## 
##   Rule 22/4: [39 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &gt; -0.7517401
##  nucl &lt;= 1.176124
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 22/5: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.1 + 0.932 thick
## 
##   Rule 22/6: [10 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; -0.5858465
##  nucl &lt;= 1.176124
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.2 - 1.22 u.shape + 0.786 nucl + 0.677 s.size
## 
##   Rule 22/7: [20 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.890325
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = 0.4 + 0.558 adhsn + 0.431 nucl
## 
##   Rule 22/8: [8 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; 0.890325
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = 0.8 + 0.107 nucl + 0.055 thick + 0.047 chrom + 0.044 s.size
##            + 0.029 n.nuc
## 
##   Rule 22/9: [10 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##  chrom &lt;= -0.1989626
##     then
##  outcome = 0.7 + 0.134 nucl + 0.07 thick + 0.059 chrom + 0.056 s.size
##            + 0.037 n.nuc
## 
##   Rule 22/10: [55 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; -0.2978275
##  mit &gt; 0.1942086
##     then
##  outcome = 1
## 
##   Rule 22/11: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 22/12: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##  nucl &lt;= 1.448066
##  chrom &gt; -0.1989626
##     then
##  outcome = 0.5 + 0.145 nucl + 0.107 chrom + 0.084 thick + 0.043 n.nuc
##            + 0.042 s.size + 0.02 u.size
## 
##   Rule 22/13: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 22/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 23:
## 
##   Rule 23/1: [239 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 23/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 23/3: [57 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.1 + 0.473 s.size
## 
##   Rule 23/4: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.1 + 0.078 nucl + 0.038 thick + 0.034 u.size + 0.031 n.nuc
##            + 0.021 s.size + 0.016 u.shape
## 
##   Rule 23/5: [14 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = -0.5 - 1.077 thick + 0.937 nucl
## 
##   Rule 23/6: [7 cases, mean 0.6, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.6 + 0.115 nucl
## 
##   Rule 23/7: [14 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0 + 1.166 thick
## 
##   Rule 23/8: [123 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 0.6322382
##     then
##  outcome = 1
## 
##   Rule 23/9: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 23/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 23/11: [6 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##  nucl &lt;= 0.6322382
##     then
##  outcome = 0.9 + 0.046 nucl + 0.022 thick + 0.02 u.size + 0.018 n.nuc
##            + 0.012 s.size + 0.009 u.shape
## 
##   Rule 23/12: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 23/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 24:
## 
##   Rule 24/1: [225 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 24/2: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = -0
## 
##   Rule 24/3: [252 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.4555328
##     then
##  outcome = -0
## 
##   Rule 24/4: [8 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &lt;= -0.4286895
##  s.size &gt; -0.5858465
##  nucl &lt;= -0.4555328
##     then
##  outcome = 2.7 + 3.738 nucl
## 
##   Rule 24/5: [12 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.4555328
##  chrom &lt;= -0.1989626
##     then
##  outcome = 0.1 - 0.337 u.size + 0.186 u.shape + 0.097 nucl
## 
##   Rule 24/6: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.476 thick
## 
##   Rule 24/7: [12 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.4555328
##  chrom &gt; -0.1989626
##     then
##  outcome = 0.9 - 0.174 u.size + 0.096 u.shape + 0.05 nucl
## 
##   Rule 24/8: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.8 + 0.072 nucl + 0.047 thick + 0.026 n.nuc + 0.021 u.shape
##            + 0.018 s.size + 0.017 chrom
## 
##   Rule 24/9: [162 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.4286895
##  s.size &gt; -0.5858465
##     then
##  outcome = 1
## 
##   Rule 24/10: [81 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 1
## 
##   Rule 24/11: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 24/12: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 24/13: [73 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 1.064348
##     then
##  outcome = 1
## 
##   Rule 24/14: [7 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.8 + 0.115 nucl + 0.067 n.nuc - 0.063 u.size + 0.035 u.shape
## 
## Model 25:
## 
##   Rule 25/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 25/2: [35 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.1 + 0.062 nucl + 0.034 thick + 0.023 n.nuc + 0.01 s.size
##            + 0.009 chrom
## 
##   Rule 25/3: [43 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.2 + 0.483 nucl + 0.026 thick + 0.008 n.nuc
## 
##   Rule 25/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.452 thick
## 
##   Rule 25/5: [17 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.7 + 0.18 nucl + 0.006 thick + 0.005 n.nuc
## 
##   Rule 25/6: [13 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 0.9913985
##     then
##  outcome = -3.6 + 2.014 n.nuc + 0.321 nucl
## 
##   Rule 25/7: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.9 + 0.042 nucl + 0.031 thick + 0.017 n.nuc + 0.014 s.size
##            + 0.013 chrom
## 
##   Rule 25/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 25/9: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
## Model 26:
## 
##   Rule 26/1: [200 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  adhsn &lt;= -0.6528094
##     then
##  outcome = -0
## 
##   Rule 26/2: [203 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= 0.08835271
##  chrom &lt;= -0.6054638
##     then
##  outcome = -0
## 
##   Rule 26/3: [265 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= -0.1056389
##  nucl &lt;= -0.4555328
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0 + 0.059 nucl + 0.044 chrom + 0.016 thick
## 
##   Rule 26/4: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 26/5: [32 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  adhsn &gt; -0.6528094
##     then
##  outcome = 0.4 + 1.943 nucl
## 
##   Rule 26/6: [14 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  adhsn &gt; -0.3093781
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0.1 + 0.617 adhsn
## 
##   Rule 26/7: [5 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 0.08835271
##  chrom &lt;= -0.6054638
##     then
##  outcome = 0.4 + 0.34 nucl
## 
##   Rule 26/8: [13 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##     then
##  outcome = 1.1
## 
##   Rule 26/9: [7 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &lt;= 1.176124
##  chrom &gt; 0.2075386
##     then
##  outcome = 0.8 + 0.316 nucl + 0.197 thick + 0.05 n.nuc + 0.037 adhsn
##            + 0.021 u.size + 0.012 s.size
## 
##   Rule 26/10: [150 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.1056389
##  chrom &gt; -0.6054638
##     then
##  outcome = 1
## 
##   Rule 26/11: [42 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##     then
##  outcome = 0.8 + 0.078 nucl + 0.047 thick + 0.029 u.size + 0.028 n.nuc
##            + 0.016 chrom
## 
##   Rule 26/12: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 26/13: [28 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##     then
##  outcome = 2.2 - 0.646 thick + 0.023 nucl + 0.011 u.size + 0.007 n.nuc
## 
##   Rule 26/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 27:
## 
##   Rule 27/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 27/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 27/3: [9 cases, mean 0.1, range 0 to 1, est err 0.2]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; -0.18359
##     then
##  outcome = 0.2 + 0.141 nucl + 0.076 thick + 0.063 u.shape + 0.055 n.nuc
##            + 0.037 s.size + 0.035 chrom + 0.011 adhsn
## 
##   Rule 27/4: [32 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.4 + 0.354 chrom + 0.049 nucl + 0.015 thick + 0.012 s.size
##            + 0.011 n.nuc
## 
##   Rule 27/5: [31 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1 + 0.012 nucl
## 
##   Rule 27/6: [54 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 + 0.01 nucl + 0.009 thick
## 
##   Rule 27/7: [4 cases, mean 1.0, range 1 to 1, est err 0.3]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.9 + 0.13 s.size + 0.093 nucl + 0.04 thick + 0.03 n.nuc
## 
##   Rule 27/8: [40 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##     then
##  outcome = 0.9 + 0.045 nucl
## 
##   Rule 27/9: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 28:
## 
##   Rule 28/1: [225 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 28/2: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 28/3: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 28/4: [241 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##     then
##  outcome = -0.1 + 0.145 u.shape + 0.135 nucl + 0.083 n.nuc + 0.06 thick
## 
##   Rule 28/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.481 thick
## 
##   Rule 28/6: [6 cases, mean 0.7, range 0 to 1, est err 1.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1.5
## 
##   Rule 28/7: [7 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 0.6 + 0.151 thick + 0.104 u.shape + 0.097 nucl
## 
##   Rule 28/8: [16 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##     then
##  outcome = 1.8 - 4.311 thick
## 
##   Rule 28/9: [12 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1
## 
##   Rule 28/10: [48 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; -0.16559
##  u.size &gt; -0.7129574
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##     then
##  outcome = 1 - 0.01 nucl - 0.009 thick
## 
##   Rule 28/11: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.9 + 0.048 nucl + 0.038 thick + 0.023 chrom + 0.019 s.size
##            + 0.014 n.nuc
## 
##   Rule 28/12: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 28/13: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 28/14: [5 cases, mean 1.0, range 1 to 1, est err 0.3]
## 
##     if
##  thick &lt;= -0.16559
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; 0.9041809
##     then
##  outcome = 0.9 + 0.169 u.shape + 0.158 nucl
## 
## Model 29:
## 
##   Rule 29/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 29/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 29/3: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.438 thick
## 
##   Rule 29/4: [15 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &lt;= 0.2174117
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.4 + 2.711 u.shape - 1.289 s.size
## 
##   Rule 29/5: [5 cases, mean 0.4, range 0 to 1, est err 0.6]
## 
##     if
##  u.size &lt;= 1.493752
##  u.shape &gt; 0.2174117
##  adhsn &lt;= 0.03405333
##  chrom &lt;= 0.2075386
##  mit &lt;= -0.3671017
##     then
##  outcome = -0.1 + 0.099 nucl + 0.071 thick + 0.037 u.shape + 0.036 chrom
##            + 0.035 n.nuc + 0.025 s.size
## 
##   Rule 29/6: [23 cases, mean 0.7, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.7274755
##     then
##  outcome = -0 - 0.96 adhsn + 0.267 thick + 0.222 n.nuc + 0.131 u.shape
##            + 0.039 nucl + 0.016 s.size
## 
##   Rule 29/7: [21 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 29/8: [59 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.493752
##     then
##  outcome = 1
## 
##   Rule 29/9: [96 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  adhsn &gt; 0.03405333
##     then
##  outcome = 1
## 
##   Rule 29/10: [112 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  adhsn &gt; -0.3093781
##     then
##  outcome = 1
## 
##   Rule 29/11: [59 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  mit &gt; -0.3671017
##     then
##  outcome = 1
## 
##   Rule 29/12: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 29/13: [88 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
## Model 30:
## 
##   Rule 30/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 30/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.1499105
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 30/3: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.473 thick
## 
##   Rule 30/4: [14 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; -0.1499105
##  nucl &lt;= 0.9041809
##     then
##  outcome = 0.4 + 0.165 nucl + 0.134 thick + 0.079 chrom + 0.065 u.shape
##            + 0.044 n.nuc + 0.031 s.size
## 
##   Rule 30/5: [22 cases, mean 0.6, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##     then
##  outcome = 1 + 1.291 s.size + 0.191 nucl + 0.063 thick
## 
##   Rule 30/6: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.8 + 0.055 nucl + 0.05 thick + 0.025 chrom + 0.019 n.nuc
##            + 0.015 u.shape + 0.013 s.size
## 
##   Rule 30/7: [115 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 0.9041809
##     then
##  outcome = 1
## 
##   Rule 30/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
## Model 31:
## 
##   Rule 31/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 31/2: [222 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &lt;= -0.4286895
##     then
##  outcome = -0
## 
##   Rule 31/3: [16 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.4286895
##     then
##  outcome = 0.1 + 0.598 thick + 0.392 chrom
## 
##   Rule 31/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.398 thick
## 
##   Rule 31/5: [21 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 0.669092
##     then
##  outcome = 0.9 - 1.192 u.size + 0.767 nucl - 0.76 u.shape + 0.696 n.nuc
##            + 0.34 thick
## 
##   Rule 31/6: [8 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.4286895
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 1.176124
##  n.nuc &gt; 0.669092
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.7 + 0.168 nucl + 0.109 thick - 0.077 u.size + 0.045 n.nuc
##            + 0.04 u.shape + 0.032 chrom
## 
##   Rule 31/7: [99 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.4286895
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 31/8: [89 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  nucl &gt; 1.176124
##  chrom &gt; -0.1989626
##     then
##  outcome = 1
## 
##   Rule 31/9: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 31/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 31/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 31/12: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 32:
## 
##   Rule 32/1: [277 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0
## 
##   Rule 32/2: [13 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &lt;= 0.2327753
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.4555328
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0.1 + 0.273 thick + 0.012 u.shape - 0.006 adhsn
## 
##   Rule 32/3: [41 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0.3 - 0.298 u.size + 0.272 n.nuc + 0.25 adhsn + 0.15 s.size
## 
##   Rule 32/4: [23 cases, mean 0.2, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##     then
##  outcome = 0.3 + 0.622 u.shape - 0.178 thick
## 
##   Rule 32/5: [7 cases, mean 0.6, range 0 to 1, est err 0.6]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##  n.nuc &gt; 0.669092
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.8 + 0.112 thick
## 
##   Rule 32/6: [20 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  s.size &gt; -0.5858465
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.7 + 0.121 nucl + 0.08 thick + 0.008 u.shape
## 
##   Rule 32/7: [26 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.9 + 0.082 thick
## 
##   Rule 32/8: [6 cases, mean 0.8, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 1.493752
##  nucl &gt; 0.3602955
##  nucl &lt;= 1.176124
##     then
##  outcome = -5.7 + 3.172 u.size
## 
##   Rule 32/9: [10 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; 0.2327753
##  u.size &lt;= 1.493752
##  nucl &gt; 0.3602955
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.6 + 0.119 nucl + 0.061 u.size + 0.056 thick + 0.05 n.nuc
##            + 0.028 s.size
## 
##   Rule 32/10: [33 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &lt;= 0.3602955
##     then
##  outcome = 1
## 
##   Rule 32/11: [9 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1 - 0.136 u.size
## 
##   Rule 32/12: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 32/13: [78 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
## Model 33:
## 
##   Rule 33/1: [226 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &lt;= 0.08835271
##     then
##  outcome = -0
## 
##   Rule 33/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 33/3: [270 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.7209161
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0
## 
##   Rule 33/4: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1 + 0.844 thick
## 
##   Rule 33/5: [11 cases, mean 0.2, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 0.5383533
##  u.shape &lt;= 0.5404623
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0.1
## 
##   Rule 33/6: [13 cases, mean 0.4, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##     then
##  outcome = -0.8 - 1.703 thick + 0.939 nucl
## 
##   Rule 33/7: [6 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; 0.5404623
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.7 + 0.176 nucl
## 
##   Rule 33/8: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1
## 
##   Rule 33/9: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 33/10: [4 cases, mean 1.0, range 1 to 1, est err 0.5]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.3
## 
##   Rule 33/11: [4 cases, mean 1.0, range 1 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 0.5383533
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 1.2
## 
##   Rule 33/12: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 33/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 34:
## 
##   Rule 34/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 34/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 34/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.1 + 0.116 nucl + 0.067 u.size + 0.063 thick + 0.045 n.nuc
##            + 0.027 s.size
## 
##   Rule 34/4: [15 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.8 + 0.932 n.nuc + 0.513 thick
## 
##   Rule 34/5: [11 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.1 - 1.003 thick + 0.019 n.nuc + 0.01 chrom
## 
##   Rule 34/6: [19 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.4 + 0.199 thick + 0.165 n.nuc + 0.131 chrom - 0.012 u.size
## 
##   Rule 34/7: [106 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 34/8: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 34/9: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 34/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 34/11: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 34/12: [90 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.08246895
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 34/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 35:
## 
##   Rule 35/1: [225 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 35/2: [170 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &lt;= -0.7129574
##     then
##  outcome = -0
## 
##   Rule 35/3: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 35/4: [85 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &lt;= -0.7129574
##     then
##  outcome = 0.3 + 0.717 nucl
## 
##   Rule 35/5: [5 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.3977132
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 0.3467855
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0.1 + 0.279 u.shape
## 
##   Rule 35/6: [8 cases, mean 0.4, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.3977132
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.1 + 0.308 u.shape - 0.226 adhsn + 0.125 thick
## 
##   Rule 35/7: [13 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.3977132
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 0.3467855
##     then
##  outcome = 0.6 - 1.718 u.size + 0.5 thick + 0.193 u.shape - 0.101 adhsn
## 
##   Rule 35/8: [7 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 1.313705
##     then
##  outcome = 0.9 + 0.058 u.shape + 0.053 nucl + 0.05 thick
## 
##   Rule 35/9: [13 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.594268
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.9 + 0.096 thick
## 
##   Rule 35/10: [108 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 35/11: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 35/12: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 35/13: [50 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.594268
##     then
##  outcome = 1
## 
## Model 36:
## 
##   Rule 36/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 36/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 36/3: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.428 thick
## 
##   Rule 36/4: [19 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &lt;= 0.2860255
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.6322382
##  n.nuc &lt;= 0.669092
##     then
##  outcome = 0.8 + 1.052 n.nuc + 0.857 nucl + 0.013 thick
## 
##   Rule 36/5: [6 cases, mean 0.5, range 0 to 1, est err 0.6]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; 0.2860255
##  nucl &lt;= 0.6322382
##  n.nuc &lt;= 0.669092
##     then
##  outcome = 1 + 0.268 nucl + 0.154 n.nuc + 0.151 thick + 0.083 adhsn
##            + 0.005 chrom
## 
##   Rule 36/6: [7 cases, mean 0.6, range 0 to 1, est err 0.6]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.6322382
##  n.nuc &gt; 0.669092
##     then
##  outcome = 0.9
## 
##   Rule 36/7: [22 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  nucl &gt; 0.6322382
##  nucl &lt;= 1.176124
##     then
##  outcome = 1 + 0.007 nucl
## 
##   Rule 36/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 36/9: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
## Model 37:
## 
##   Rule 37/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 37/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.1499105
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 37/3: [5 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 0.5383533
##  u.size &lt;= 1.808996
##  adhsn &lt;= 0.7209161
##  s.size &gt; -0.1499105
##  nucl &lt;= 1.448066
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -1
## 
##   Rule 37/4: [28 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &gt; -0.7129574
##  u.size &lt;= 1.808996
##  nucl &lt;= 1.448066
##     then
##  outcome = 0.4 + 0.527 nucl
## 
##   Rule 37/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.451 thick
## 
##   Rule 37/6: [16 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &gt; -0.7129574
##  u.size &lt;= 1.808996
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.448066
##  chrom &lt;= 0.6140398
##     then
##  outcome = 0.8 + 0.601 chrom + 0.366 thick + 0.293 s.size
## 
##   Rule 37/7: [8 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.242297
##  u.size &lt;= 1.808996
##  adhsn &lt;= 0.7209161
##  s.size &gt; -0.1499105
##  nucl &lt;= 1.448066
##     then
##  outcome = 0.7 + 0.13 nucl + 0.089 thick + 0.043 n.nuc + 0.04 u.shape
##            + 0.033 chrom + 0.031 s.size + 0.01 u.size
## 
##   Rule 37/8: [22 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &gt; -0.7129574
##  u.size &lt;= 1.808996
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.448066
##     then
##  outcome = 0.7 + 0.099 nucl + 0.083 thick + 0.048 u.shape + 0.042 chrom
##            + 0.029 s.size
## 
##   Rule 37/9: [92 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.448066
##     then
##  outcome = 1
## 
##   Rule 37/10: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 37/11: [17 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.size &lt;= 1.808996
##  nucl &lt;= 1.448066
##     then
##  outcome = 1 + 0.03 s.size - 0.014 u.size + 0.01 thick
## 
##   Rule 37/12: [15 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 1.808996
##  nucl &lt;= 1.448066
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1 + 0.033 thick
## 
##   Rule 37/13: [84 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  nucl &gt; 1.448066
##  chrom &gt; -0.1989626
##     then
##  outcome = 1
## 
##   Rule 37/14: [54 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.808996
##     then
##  outcome = 1
## 
## Model 38:
## 
##   Rule 38/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 38/2: [223 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= -0.3093781
##     then
##  outcome = -0.3
## 
##   Rule 38/3: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 38/4: [14 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &lt;= 0.2174117
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 1.064348
##     then
##  outcome = -0.1 + 0.545 u.shape
## 
##   Rule 38/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.469 thick
## 
##   Rule 38/6: [11 cases, mean 0.7, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= -0.3093781
##  s.size &gt; -0.1499105
##     then
##  outcome = 0.7 + 0.295 u.shape + 0.217 nucl
## 
##   Rule 38/7: [12 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  u.shape &gt; 0.2174117
##     then
##  outcome = -0.1 + 0.507 nucl + 0.455 u.shape + 0.009 thick + 0.009 n.nuc
##            + 0.008 chrom
## 
##   Rule 38/8: [9 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 1.493752
##  nucl &lt;= 1.448066
##     then
##  outcome = -5.7 + 3.172 u.size
## 
##   Rule 38/9: [11 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  u.size &lt;= 1.493752
##  nucl &lt;= 1.448066
##     then
##  outcome = 0.9 + 0.041 nucl + 0.031 thick + 0.018 n.nuc + 0.017 chrom
##            + 0.014 s.size
## 
##   Rule 38/10: [12 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.7274755
##     then
##  outcome = 1.1
## 
##   Rule 38/11: [92 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.448066
##     then
##  outcome = 1
## 
##   Rule 38/12: [73 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 1.064348
##     then
##  outcome = 1
## 
##   Rule 38/13: [76 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 38/14: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
## Model 39:
## 
##   Rule 39/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 39/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 39/3: [6 cases, mean 0.2, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.3 + 1.075 thick
## 
##   Rule 39/4: [26 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.1863816
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = -0 + 0.731 nucl - 0.347 thick
## 
##   Rule 39/5: [8 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 + 6.682 u.shape - 1.203 s.size + 0.011 nucl + 0.006 thick
## 
##   Rule 39/6: [15 cases, mean 0.7, range 0 to 1, est err 0.8]
## 
##     if
##  thick &lt;= 0.1863816
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1 + 1.246 adhsn - 0.66 s.size
## 
##   Rule 39/7: [138 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1
## 
##   Rule 39/8: [113 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.1863816
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 39/9: [59 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##     then
##  outcome = 0.8 + 0.054 nucl + 0.032 thick + 0.019 s.size + 0.019 n.nuc
##            + 0.018 chrom + 0.009 u.size
## 
##   Rule 39/10: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 40:
## 
##   Rule 40/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 40/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 40/3: [278 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &lt;= -0.3977132
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0
## 
##   Rule 40/4: [6 cases, mean 0.2, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.1 + 0.89 thick
## 
##   Rule 40/5: [6 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.3977132
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.7209161
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.1 + 0.339 chrom
## 
##   Rule 40/6: [8 cases, mean 0.4, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.3977132
##  u.shape &lt;= 0.5404623
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0.4 + 0.122 chrom
## 
##   Rule 40/7: [11 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; 0.5404623
##  u.shape &lt;= 1.186563
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.6 + 0.183 nucl + 0.074 thick + 0.057 u.size + 0.051 s.size
##            + 0.046 chrom + 0.043 n.nuc
## 
##   Rule 40/8: [31 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1 + 0.011 nucl
## 
##   Rule 40/9: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.3774847
##     then
##  outcome = 1
## 
##   Rule 40/10: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 40/11: [4 cases, mean 1.0, range 1 to 1, est err 2.4]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 - 6.695 u.shape + 1.205 s.size
## 
##   Rule 40/12: [13 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.3977132
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= -0.3093781
##  s.size &gt; -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 40/13: [20 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.1863816
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1.1 - 0.02 n.nuc
## 
##   Rule 40/14: [40 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 - 0.009 n.nuc - 0.008 thick
## 
##   Rule 40/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 41:
## 
##   Rule 41/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 41/2: [235 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 41/3: [274 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  adhsn &lt;= 0.7209161
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0
## 
##   Rule 41/4: [41 cases, mean 0.2, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.3 + 0.339 thick + 0.299 u.size + 0.282 nucl
## 
##   Rule 41/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.469 thick
## 
##   Rule 41/6: [38 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.9 + 0.08 nucl
## 
##   Rule 41/7: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 41/8: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 41/9: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 41/10: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 42:
## 
##   Rule 42/1: [191 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= -0.4555328
##  chrom &lt;= -0.6054638
##     then
##  outcome = 0
## 
##   Rule 42/2: [269 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  s.size &lt;= -0.1499105
##  nucl &lt;= -0.4555328
##     then
##  outcome = -0
## 
##   Rule 42/3: [253 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.7129574
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0
## 
##   Rule 42/4: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 42/5: [47 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  chrom &lt;= -0.6054638
##     then
##  outcome = -0.1 + 0.62 nucl
## 
##   Rule 42/6: [14 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  s.size &gt; -0.1499105
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0.8 + 0.273 nucl - 0.045 u.size - 0.036 adhsn + 0.019 thick
## 
##   Rule 42/7: [4 cases, mean 0.8, range 0 to 1, est err 0.6]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.242297
##  adhsn &lt;= 0.7209161
##  s.size &gt; -0.1499105
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 1.1
## 
##   Rule 42/8: [10 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.7 + 0.369 nucl - 0.325 adhsn + 0.247 thick - 0.202 u.size
##            + 0.041 chrom + 0.014 n.nuc
## 
##   Rule 42/9: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 42/10: [9 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1 - 0.014 adhsn + 0.007 chrom + 0.005 thick + 0.005 nucl
## 
##   Rule 42/11: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 42/12: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 42/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 43:
## 
##   Rule 43/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 43/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 43/3: [17 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= 0.669092
##     then
##  outcome = 0.8 + 1.244 n.nuc + 0.465 thick
## 
##   Rule 43/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.466 thick
## 
##   Rule 43/5: [4 cases, mean 0.5, range 0 to 1, est err 0.8]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.9
## 
##   Rule 43/6: [7 cases, mean 0.6, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##  n.nuc &gt; 0.669092
##     then
##  outcome = 0.7 + 0.136 u.shape - 0.103 adhsn + 0.052 nucl
## 
##   Rule 43/7: [6 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 1.313705
##     then
##  outcome = 0.8 + 0.133 nucl + 0.114 u.shape + 0.068 mit + 0.024 s.size
## 
##   Rule 43/8: [115 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 0.9041809
##     then
##  outcome = 1
## 
##   Rule 43/9: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 43/10: [12 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 + 0.009 u.size + 0.008 nucl - 0.006 adhsn
## 
##   Rule 43/11: [50 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.594268
##     then
##  outcome = 1
## 
## Model 44:
## 
##   Rule 44/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 44/2: [36 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  nucl &lt;= 0.08835271
##  chrom &lt;= -0.1989626
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.1 + 0.073 u.shape + 0.023 chrom + 0.019 thick + 0.015 n.nuc
##            + 0.011 nucl + 0.006 mit
## 
##   Rule 44/3: [257 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 0.2174117
##  nucl &lt;= -0.7274755
##  chrom &lt;= -0.1989626
##     then
##  outcome = 0
## 
##   Rule 44/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.453 thick
## 
##   Rule 44/5: [17 cases, mean 0.7, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 1.407779
##  nucl &gt; 0.08835271
##     then
##  outcome = -0 + 0.593 nucl
## 
##   Rule 44/6: [14 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; 0.2174117
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1.1 - 0.659 u.size + 0.05 nucl + 0.034 u.shape + 0.033 thick
##            + 0.028 chrom + 0.017 s.size
## 
##   Rule 44/7: [11 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  nucl &lt;= 0.08835271
##  chrom &gt; -0.1989626
##     then
##  outcome = 0.7 + 0.156 u.shape + 0.126 nucl + 0.097 thick + 0.097 n.nuc
##            + 0.083 u.size + 0.059 chrom
## 
##   Rule 44/8: [10 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  nucl &gt; -0.7274755
##  chrom &lt;= -0.1989626
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.1 + 0.129 s.size
## 
##   Rule 44/9: [130 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##     then
##  outcome = 1
## 
##   Rule 44/10: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 44/11: [62 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 1.407779
##     then
##  outcome = 1
## 
##   Rule 44/12: [15 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  u.shape &lt;= 0.2174117
##     then
##  outcome = 1
## 
##   Rule 44/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 45:
## 
##   Rule 45/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 45/2: [111 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.8695334
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 45/3: [239 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 45/4: [35 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.1 + 0.937 s.size
## 
##   Rule 45/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.437 thick
## 
##   Rule 45/6: [24 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.1 - 0.581 u.size + 0.409 u.shape + 0.224 thick - 0.212 adhsn
##            + 0.157 nucl
## 
##   Rule 45/7: [11 cases, mean 0.7, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &gt; 0.02447898
##     then
##  outcome = 1.2
## 
##   Rule 45/8: [9 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 0.5 + 0.16 nucl + 0.14 thick + 0.058 n.nuc + 0.057 s.size
##            + 0.043 adhsn
## 
##   Rule 45/9: [9 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.8 + 0.083 nucl + 0.071 thick + 0.03 s.size + 0.03 n.nuc
##            + 0.022 adhsn
## 
##   Rule 45/10: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 45/11: [14 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1 - 0.177 u.shape - 0.104 u.size + 0.04 thick - 0.038 adhsn
## 
##   Rule 45/12: [12 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 + 0.037 u.size
## 
## Model 46:
## 
##   Rule 46/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 46/2: [252 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.4555328
##     then
##  outcome = -0
## 
##   Rule 46/3: [43 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  chrom &lt;= -0.1989626
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = -0
## 
##   Rule 46/4: [8 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; -0.5858465
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.4555328
##     then
##  outcome = 2.7 + 3.677 nucl
## 
##   Rule 46/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.443 thick
## 
##   Rule 46/6: [5 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.4555328
##     then
##  outcome = 1.1 + 0.396 nucl + 0.092 thick + 0.062 u.shape + 0.053 chrom
##            + 0.048 n.nuc
## 
##   Rule 46/7: [10 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.4555328
##  chrom &gt; -0.1989626
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.9 + 0.181 nucl + 0.094 thick + 0.085 u.shape + 0.065 chrom
##            + 0.042 n.nuc
## 
##   Rule 46/8: [10 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.4555328
##  n.nuc &gt; 0.9913985
##     then
##  outcome = -4.1 + 2.118 n.nuc + 0.549 nucl
## 
##   Rule 46/9: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 46/10: [73 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 1.064348
##     then
##  outcome = 1
## 
##   Rule 46/11: [49 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1
## 
## Model 47:
## 
##   Rule 47/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 47/2: [35 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.1056389
##  s.size &lt;= -0.5858465
##     then
##  outcome = 0
## 
##   Rule 47/3: [10 cases, mean 0.2, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.1056389
##  s.size &gt; -0.5858465
##  nucl &lt;= -0.4555328
##     then
##  outcome = 2.8 + 3.829 nucl
## 
##   Rule 47/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.443 thick
## 
##   Rule 47/5: [12 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.1056389
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0 - 1.489 thick + 0.835 adhsn
## 
##   Rule 47/6: [11 cases, mean 0.5, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.9 + 3.535 u.shape + 0.746 thick
## 
##   Rule 47/7: [6 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 0.8635129
##  nucl &lt;= -0.4555328
##     then
##  outcome = 1 + 0.351 nucl + 0.09 s.size + 0.073 thick + 0.05 n.nuc
##            + 0.046 u.shape
## 
##   Rule 47/8: [17 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##  nucl &lt;= -0.4555328
##     then
##  outcome = 1
## 
##   Rule 47/9: [22 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; 1.176124
##     then
##  outcome = 0.5 + 0.162 nucl + 0.102 thick + 0.063 n.nuc + 0.047 u.shape
##            + 0.045 u.size + 0.04 chrom + 0.039 s.size
## 
##   Rule 47/10: [93 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.4555328
##     then
##  outcome = 0.9 + 0.051 thick
## 
##   Rule 47/11: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 47/12: [6 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##  n.nuc &gt; 1.636011
##     then
##  outcome = 0.9 + 0.161 thick + 0.01 nucl
## 
## Model 48:
## 
##   Rule 48/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 48/2: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 48/3: [6 cases, mean 0.3, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.1 + 0.046 nucl + 0.024 thick + 0.022 u.size + 0.018 n.nuc
##            + 0.012 s.size + 0.01 chrom
## 
##   Rule 48/4: [14 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0 + 0.072 nucl - 0.036 adhsn + 0.023 thick
## 
##   Rule 48/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.457 thick
## 
##   Rule 48/6: [14 cases, mean 0.4, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.3 - 1.056 n.nuc + 1.048 chrom + 1.029 u.size + 0.641 s.size
##            - 0.534 nucl + 0.525 thick
## 
##   Rule 48/7: [9 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 1.313705
##     then
##  outcome = 0.5 - 0.296 adhsn + 0.186 thick + 0.185 nucl
## 
##   Rule 48/8: [13 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.594268
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##     then
##  outcome = 1.1
## 
##   Rule 48/9: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1 + 0.005 nucl
## 
##   Rule 48/10: [12 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1.1 - 0.093 u.size - 0.045 thick - 0.028 s.size
## 
##   Rule 48/11: [10 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 1.594268
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.8 - 0.144 adhsn + 0.091 thick + 0.088 nucl
## 
## Model 49:
## 
##   Rule 49/1: [235 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 49/2: [16 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.8695334
##  u.shape &lt;= -0.4286895
##  nucl &gt; -0.7274755
##     then
##  outcome = 0 + 0.024 thick + 0.022 s.size + 0.011 nucl
## 
##   Rule 49/3: [27 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.2 + 0.346 s.size
## 
##   Rule 49/4: [42 cases, mean 0.2, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &lt;= -0.3977132
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.2 + 0.349 thick + 0.211 s.size + 0.013 nucl + 0.009 u.size
## 
##   Rule 49/5: [29 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.8695334
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = -1.9 - 3.386 s.size + 0.392 thick
## 
##   Rule 49/6: [25 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.9
## 
##   Rule 49/7: [7 cases, mean 0.9, range 0 to 1, est err 1.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.4286895
##  nucl &lt;= 1.176124
##  n.nuc &gt; 0.02447898
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 1.9
## 
##   Rule 49/8: [9 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.4286895
##  nucl &gt; 1.176124
##     then
##  outcome = 0.6 + 0.118 nucl + 0.076 u.size + 0.066 thick + 0.043 n.nuc
##            + 0.026 chrom + 0.022 s.size
## 
##   Rule 49/9: [145 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.4286895
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1
## 
##   Rule 49/10: [99 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.4286895
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 49/11: [4 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.3977132
##  u.shape &lt;= -0.4286895
##  s.size &gt; -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.8 + 0.093 thick + 0.06 s.size + 0.05 nucl + 0.025 u.size
##            + 0.012 n.nuc + 0.007 chrom
## 
##   Rule 49/12: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 50:
## 
##   Rule 50/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 50/2: [7 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 0.5404623
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 0.02447898
##     then
##  outcome = -0.1
## 
##   Rule 50/3: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 50/4: [15 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.5 + 0.513 chrom + 0.32 thick + 0.279 s.size
## 
##   Rule 50/5: [11 cases, mean 0.7, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 0.02447898
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.9 + 0.071 nucl
## 
##   Rule 50/6: [11 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; 0.5404623
##  u.shape &lt;= 1.186563
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.6 + 0.151 nucl + 0.076 thick + 0.067 u.size + 0.063 n.nuc
##            + 0.026 s.size + 0.025 chrom
## 
##   Rule 50/7: [106 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 50/8: [38 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 + 0.009 thick + 0.007 nucl
## 
##   Rule 50/9: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1
## 
##   Rule 50/10: [4 cases, mean 1.0, range 1 to 1, est err 0.5]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##  s.size &lt;= -0.5858465
##     then
##  outcome = 1 + 0.455 u.shape
## 
##   Rule 50/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 50/12: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 51:
## 
##   Rule 51/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = -0
## 
##   Rule 51/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 51/3: [36 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  adhsn &lt;= 0.7209161
##  chrom &lt;= -0.1989626
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = -0 + 0.122 nucl
## 
##   Rule 51/4: [7 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &lt;= 1.808996
##  adhsn &lt;= 0.7209161
##  s.size &gt; -0.5858465
##  chrom &lt;= 0.2075386
##  n.nuc &gt; -0.2978275
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0.9
## 
##   Rule 51/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.466 thick
## 
##   Rule 51/6: [6 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.6 + 0.166 nucl + 0.099 thick + 0.083 u.size + 0.052 n.nuc
## 
##   Rule 51/7: [7 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 1.808996
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.7 + 0.174 u.size + 0.143 nucl + 0.074 thick + 0.054 n.nuc
##            + 0.031 s.size + 0.021 chrom
## 
##   Rule 51/8: [4 cases, mean 0.8, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  adhsn &lt;= 0.7209161
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.1
## 
##   Rule 51/9: [12 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 1.808996
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  chrom &gt; 0.2075386
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.8 + 0.185 thick + 0.114 chrom + 0.074 nucl
## 
##   Rule 51/10: [46 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &lt;= 1.808996
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 + 0.015 nucl
## 
##   Rule 51/11: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1
## 
##   Rule 51/12: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.7274755
##  chrom &gt; -0.1989626
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 1.1
## 
##   Rule 51/13: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 51/14: [54 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.808996
##     then
##  outcome = 1
## 
## Model 52:
## 
##   Rule 52/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 52/2: [36 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 52/3: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.443 thick
## 
##   Rule 52/4: [7 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &lt;= -0.1056389
##  nucl &lt;= 0.9041809
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.3 + 0.147 nucl + 0.119 thick + 0.06 chrom + 0.056 u.shape
##            + 0.051 s.size + 0.049 n.nuc
## 
##   Rule 52/5: [20 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.1 - 3.4 u.size + 0.833 u.shape + 0.509 adhsn
## 
##   Rule 52/6: [5 cases, mean 0.6, range 0 to 1, est err 0.6]
## 
##     if
##  thick &gt; 0.1863816
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.7 + 0.239 thick + 0.161 n.nuc + 0.123 adhsn
## 
##   Rule 52/7: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.9 + 0.042 nucl + 0.034 thick + 0.017 chrom + 0.016 u.shape
##            + 0.014 s.size + 0.014 n.nuc
## 
##   Rule 52/8: [25 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; 0.9041809
##     then
##  outcome = 0.9 + 0.059 u.shape + 0.047 nucl + 0.025 thick + 0.024 chrom
##            + 0.016 s.size
## 
##   Rule 52/9: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 52/10: [13 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.594268
##  u.size &lt;= 0.2327753
##     then
##  outcome = 1 - 0.015 nucl
## 
## Model 53:
## 
##   Rule 53/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 53/2: [40 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.4286895
##     then
##  outcome = 0.3 + 0.201 nucl + 0.147 thick + 0.13 s.size + 0.09 u.shape
##            + 0.048 chrom
## 
##   Rule 53/3: [54 cases, mean 0.2, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.2 + 0.153 chrom + 0.121 n.nuc + 0.102 nucl
## 
##   Rule 53/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.443 thick
## 
##   Rule 53/5: [20 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &gt; -0.7129574
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 0.9041809
##     then
##  outcome = 0.6 + 0.179 nucl + 0.117 u.shape + 0.084 thick + 0.071 chrom
##            + 0.06 s.size + 0.016 u.size + 0.01 n.nuc
## 
##   Rule 53/6: [13 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  chrom &gt; 0.2075386
##     then
##  outcome = 0.7 + 0.149 nucl + 0.061 chrom + 0.057 n.nuc + 0.05 thick
##            + 0.048 u.size
## 
##   Rule 53/7: [41 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &gt; -0.7129574
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 1 + 0.015 u.size
## 
##   Rule 53/8: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 53/9: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1 + 0.006 nucl
## 
## Model 54:
## 
##   Rule 54/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 54/2: [257 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##  chrom &lt;= -0.1989626
##     then
##  outcome = -0
## 
##   Rule 54/3: [294 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##     then
##  outcome = -0
## 
##   Rule 54/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.46 thick
## 
##   Rule 54/5: [11 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##  chrom &gt; -0.1989626
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.1 + 0.091 nucl + 0.036 thick + 0.034 n.nuc
## 
##   Rule 54/6: [18 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; 0.1863816
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##     then
##  outcome = 1.1
## 
##   Rule 54/7: [9 cases, mean 0.8, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.5 - 1.428 thick + 0.498 adhsn
## 
##   Rule 54/8: [25 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; 0.9041809
##     then
##  outcome = 1
## 
##   Rule 54/9: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 54/10: [5 cases, mean 1.0, range 1 to 1, est err 0.9]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##  chrom &lt;= -0.1989626
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.6
## 
##   Rule 54/11: [6 cases, mean 1.0, range 1 to 1, est err 0.5]
## 
##     if
##  thick &gt; 1.594268
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.4 - 0.978 u.size - 0.368 nucl - 0.14 n.nuc
## 
## Model 55:
## 
##   Rule 55/1: [235 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 55/2: [179 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.shape &lt;= -0.4286895
##     then
##  outcome = 0
## 
##   Rule 55/3: [253 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0
## 
##   Rule 55/4: [283 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 55/5: [10 cases, mean 0.2, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.5175617
##  u.shape &lt;= -0.4286895
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = -2.3 - 3.753 s.size + 0.389 thick - 0.337 u.shape + 0.206 nucl
## 
##   Rule 55/6: [27 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.5 + 0.239 nucl + 0.198 n.nuc + 0.125 chrom
## 
##   Rule 55/7: [5 cases, mean 0.6, range 0 to 1, est err 1.4]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.4286895
##  nucl &lt;= 0.08835271
##  chrom &lt;= 0.2075386
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.5
## 
##   Rule 55/8: [9 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.9
## 
##   Rule 55/9: [12 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  n.nuc &gt; 0.9913985
##     then
##  outcome = -2.3 + 1.479 n.nuc - 0.981 mit + 0.02 nucl + 0.009 chrom
## 
##   Rule 55/10: [16 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  chrom &gt; 0.2075386
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.8 + 0.111 nucl + 0.055 thick + 0.054 n.nuc + 0.033 chrom
##            + 0.022 s.size + 0.019 u.size
## 
##   Rule 55/11: [144 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  s.size &gt; -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 55/12: [115 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.4286895
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
##   Rule 55/13: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 55/14: [5 cases, mean 1.0, range 1 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  nucl &gt; 0.08835271
##  chrom &lt;= 0.2075386
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1 + 0.325 n.nuc + 0.202 nucl
## 
##   Rule 55/15: [9 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 1.594268
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.9 + 0.027 nucl - 0.021 n.nuc
## 
## Model 56:
## 
##   Rule 56/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 56/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 56/3: [4 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= 0.7209161
##  s.size &gt; -0.5858465
##  n.nuc &gt; -0.2978275
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0.6
## 
##   Rule 56/4: [16 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.2 + 0.416 nucl + 0.077 chrom
## 
##   Rule 56/5: [4 cases, mean 0.8, range 0 to 1, est err 0.8]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.7209161
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1.2 + 0.061 thick + 0.038 nucl
## 
##   Rule 56/6: [19 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1
## 
##   Rule 56/7: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.5404623
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 56/8: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1
## 
##   Rule 56/9: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 56/10: [34 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##     then
##  outcome = 1 - 0.046 adhsn
## 
##   Rule 56/11: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.1
## 
##   Rule 56/12: [40 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 + 0.012 nucl
## 
##   Rule 56/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 57:
## 
##   Rule 57/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 57/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 57/3: [7 cases, mean 0.3, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.08246895
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  chrom &lt;= 0.6140398
##     then
##  outcome = 0.1 + 0.183 nucl + 0.091 thick + 0.085 s.size + 0.045 u.shape
##            + 0.044 n.nuc + 0.04 chrom + 0.026 u.size
## 
##   Rule 57/4: [19 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.03405333
##  nucl &gt; -0.7274755
##  chrom &lt;= 0.6140398
##     then
##  outcome = 0.3 - 1.116 adhsn + 1.002 u.size + 0.686 chrom + 0.414 thick
## 
##   Rule 57/5: [8 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.9 + 0.045 nucl
## 
##   Rule 57/6: [6 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  chrom &gt; 0.6140398
##  n.nuc &lt;= 0.02447898
##     then
##  outcome = 0.6 + 0.214 nucl + 0.041 thick + 0.036 s.size + 0.021 n.nuc
##            + 0.018 u.shape + 0.016 chrom + 0.014 u.size
## 
##   Rule 57/7: [6 cases, mean 0.8, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  adhsn &gt; 0.03405333
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  chrom &lt;= 0.6140398
##     then
##  outcome = 0.6 + 0.805 u.size + 0.378 nucl + 0.158 chrom + 0.075 thick
## 
##   Rule 57/8: [114 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  nucl &gt; -0.7274755
##  n.nuc &gt; 0.02447898
##     then
##  outcome = 1
## 
##   Rule 57/9: [106 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 57/10: [48 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 57/11: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 57/12: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 57/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 58:
## 
##   Rule 58/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 58/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 58/3: [43 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.1 + 0.575 nucl
## 
##   Rule 58/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.469 thick
## 
##   Rule 58/5: [13 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.8 + 0.121 nucl
## 
##   Rule 58/6: [13 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 0.9913985
##     then
##  outcome = -3.1 + 1.805 n.nuc + 0.275 nucl
## 
##   Rule 58/7: [108 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 58/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 58/9: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
## Model 59:
## 
##   Rule 59/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 59/2: [29 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.890325
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.1056389
##  s.size &lt;= -0.5858465
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 59/3: [41 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.890325
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.1056389
##  nucl &lt;= -0.18359
##     then
##  outcome = 0 + 0.25 n.nuc + 0.136 u.size
## 
##   Rule 59/4: [23 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.890325
##  u.shape &lt;= -0.1056389
##  s.size &gt; -0.5858465
##  nucl &lt;= -0.18359
##     then
##  outcome = 0.4 + 0.259 nucl + 0.24 u.shape + 0.18 n.nuc + 0.109 thick
##            + 0.046 u.size + 0.01 s.size + 0.009 chrom
## 
##   Rule 59/5: [6 cases, mean 0.3, range 0 to 1, est err 0.5]
## 
##     if
##  thick &gt; -0.5175617
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = -0.9
## 
##   Rule 59/6: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.541 thick
## 
##   Rule 59/7: [11 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  s.size &lt;= 0.2860255
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = 0.4 + 0.252 thick + 0.089 nucl + 0.054 u.shape + 0.029 chrom
##            + 0.028 n.nuc + 0.022 s.size
## 
##   Rule 59/8: [19 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.18359
##     then
##  outcome = 1
## 
##   Rule 59/9: [11 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##     then
##  outcome = 1
## 
##   Rule 59/10: [54 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.18359
##  chrom &gt; 0.2075386
##     then
##  outcome = 1 + 0.023 u.shape + 0.009 nucl + 0.007 n.nuc
## 
##   Rule 59/11: [91 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.890325
##     then
##  outcome = 1
## 
##   Rule 59/12: [61 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  mit &gt; 0.1942086
##     then
##  outcome = 1
## 
##   Rule 59/13: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 59/14: [48 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##     then
##  outcome = 0.9 + 0.024 nucl + 0.015 thick + 0.009 n.nuc + 0.008 u.shape
##            + 0.007 s.size
## 
##   Rule 59/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 60:
## 
##   Rule 60/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 60/2: [252 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0
## 
##   Rule 60/3: [37 cases, mean 0.2, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= -0.16559
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##     then
##  outcome = 0 + 0.552 nucl - 0.438 u.size + 0.199 u.shape
## 
##   Rule 60/4: [13 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; -0.5858465
##  nucl &lt;= -0.4555328
##     then
##  outcome = 1.9 + 2.575 nucl + 0.135 s.size
## 
##   Rule 60/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.408 thick
## 
##   Rule 60/6: [26 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.4555328
##     then
##  outcome = 1 - 0.034 u.size + 0.015 u.shape + 0.009 nucl
## 
##   Rule 60/7: [14 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1 + 0.026 nucl + 0.022 thick + 0.01 chrom + 0.01 n.nuc
##            + 0.008 u.shape + 0.006 s.size
## 
##   Rule 60/8: [81 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 1
## 
##   Rule 60/9: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 60/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 60/11: [11 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.4555328
##     then
##  outcome = 1.3 - 0.194 nucl - 0.14 u.size + 0.088 u.shape
## 
## Model 61:
## 
##   Rule 61/1: [198 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= -0.18359
##  chrom &lt;= -0.6054638
##     then
##  outcome = 0
## 
##   Rule 61/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 61/3: [83 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  s.size &lt;= -0.1499105
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = -0
## 
##   Rule 61/4: [49 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= -0.3977132
##  u.shape &gt; -0.7517401
##  s.size &lt;= -0.1499105
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 61/5: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.2 + 1.013 thick
## 
##   Rule 61/6: [7 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; -0.18359
##  chrom &lt;= -0.6054638
##     then
##  outcome = 0.5 + 1.178 u.shape + 0.043 nucl + 0.014 thick + 0.01 u.size
##            + 0.01 n.nuc + 0.007 s.size + 0.005 chrom
## 
##   Rule 61/7: [20 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 0.08835271
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.7 + 0.138 thick + 0.108 s.size + 0.081 chrom
## 
##   Rule 61/8: [15 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &lt;= -0.1499105
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.8 + 0.307 nucl + 0.173 s.size + 0.059 thick + 0.035 chrom
## 
##   Rule 61/9: [148 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  chrom &gt; -0.1989626
##     then
##  outcome = 1
## 
##   Rule 61/10: [135 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; -0.1499105
##  chrom &gt; -0.6054638
##     then
##  outcome = 1
## 
##   Rule 61/11: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 61/12: [11 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.shape &lt;= 1.186563
##  s.size &gt; -0.1499105
##  nucl &lt;= 1.176124
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1.1 - 0.026 s.size - 0.018 chrom
## 
##   Rule 61/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 62:
## 
##   Rule 62/1: [225 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 62/2: [22 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0 + 0.023 thick + 0.016 nucl
## 
##   Rule 62/3: [270 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.7209161
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0
## 
##   Rule 62/4: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 62/5: [44 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  adhsn &lt;= 0.7209161
##  chrom &lt;= -0.1989626
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0
## 
##   Rule 62/6: [10 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##  chrom &gt; -0.6054638
##     then
##  outcome = 0.1 + 0.099 nucl + 0.052 thick
## 
##   Rule 62/7: [5 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.08246895
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.1 - 0.688 u.size + 0.398 u.shape + 0.079 nucl + 0.041 thick
##            + 0.03 n.nuc + 0.016 chrom
## 
##   Rule 62/8: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.465 thick
## 
##   Rule 62/9: [4 cases, mean 0.8, range 0 to 1, est err 0.8]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.4286895
##  nucl &gt; -0.4555328
##  chrom &lt;= -0.1989626
##     then
##  outcome = 1.3 - 0.352 adhsn + 0.342 u.shape + 0.274 thick
## 
##   Rule 62/10: [9 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 0.6 + 0.204 nucl + 0.108 thick
## 
##   Rule 62/11: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.9 + 0.051 nucl + 0.031 thick + 0.018 u.size + 0.018 n.nuc
## 
##   Rule 62/12: [20 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; 0.5383533
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.6 + 0.242 thick - 0.195 adhsn + 0.189 u.shape
## 
##   Rule 62/13: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 62/14: [7 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.08246895
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##  chrom &gt; -0.1989626
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1.1 + 0.284 thick
## 
##   Rule 62/15: [12 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 + 0.076 u.size + 0.063 nucl - 0.05 adhsn
## 
## Model 63:
## 
##   Rule 63/1: [203 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= 0.08835271
##  chrom &lt;= -0.6054638
##     then
##  outcome = 0
## 
##   Rule 63/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.1499105
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 63/3: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 63/4: [15 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##     then
##  outcome = 1.3 + 1.913 u.shape + 0.876 s.size
## 
##   Rule 63/5: [5 cases, mean 0.4, range 0 to 1, est err 0.6]
## 
##     if
##  u.shape &lt;= 0.2174117
##  s.size &gt; -0.1499105
##  nucl &gt; 0.08835271
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0.1 + 0.103 nucl + 0.036 n.nuc + 0.031 thick + 0.029 s.size
##            + 0.027 u.size
## 
##   Rule 63/6: [9 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &gt; 0.2174117
##  u.shape &lt;= 1.186563
##  s.size &gt; -0.1499105
##  nucl &gt; 0.08835271
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.7 + 0.126 s.size + 0.123 thick + 0.075 n.nuc
## 
##   Rule 63/7: [5 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 0.08835271
##  chrom &lt;= -0.6054638
##     then
##  outcome = 0.6 + 0.214 nucl + 0.026 n.nuc + 0.023 thick + 0.022 s.size
##            + 0.02 u.size
## 
##   Rule 63/8: [7 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.16559
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##     then
##  outcome = 1.3 + 0.8 u.shape + 0.408 s.size + 0.268 nucl + 0.082 thick
## 
##   Rule 63/9: [8 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##  chrom &gt; -0.6054638
##  chrom &lt;= -0.1989626
##     then
##  outcome = 0.6 + 0.18 nucl + 0.097 thick + 0.071 u.size + 0.07 n.nuc
##            + 0.04 s.size
## 
##   Rule 63/10: [26 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; -0.1499105
##  nucl &lt;= 0.08835271
##  chrom &gt; -0.6054638
##     then
##  outcome = 1
## 
##   Rule 63/11: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 63/12: [28 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.1056389
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##  chrom &gt; -0.6054638
##     then
##  outcome = 1
## 
##   Rule 63/13: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 63/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 64:
## 
##   Rule 64/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 64/2: [235 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 64/3: [268 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.4286895
##  adhsn &lt;= 0.7209161
##  mit &lt;= 0.1942086
##     then
##  outcome = 0
## 
##   Rule 64/4: [35 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.3 + 3.095 u.shape
## 
##   Rule 64/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.466 thick
## 
##   Rule 64/6: [6 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= -0.8695334
##  u.size &gt; -0.7129574
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 64/7: [14 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; 0.2174117
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1.2 - 0.747 u.size + 0.019 nucl + 0.01 thick + 0.006 n.nuc
## 
##   Rule 64/8: [18 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.8695334
##  u.size &gt; -0.7129574
##  u.size &lt;= 1.178508
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  mit &lt;= 0.1942086
##     then
##  outcome = -0.2 - 1.742 mit - 1.663 u.shape + 0.441 thick - 0.238 adhsn
##            + 0.148 n.nuc + 0.146 nucl
## 
##   Rule 64/9: [55 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.8695334
##  nucl &gt; -0.7274755
##  mit &gt; 0.1942086
##     then
##  outcome = 1
## 
##   Rule 64/10: [58 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##     then
##  outcome = 1 + 0.005 chrom
## 
##   Rule 64/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 64/12: [11 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 1 - 0.015 n.nuc
## 
##   Rule 64/13: [7 cases, mean 1.0, range 1 to 1, est err 0.3]
## 
##     if
##  u.size &gt; 1.178508
##  u.shape &lt;= 0.2174117
##     then
##  outcome = 3.3 - 1.11 u.size + 0.019 nucl + 0.017 u.shape + 0.011 thick
##            + 0.009 n.nuc
## 
##   Rule 64/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 65:
## 
##   Rule 65/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 65/2: [252 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 65/3: [47 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.6322382
##     then
##  outcome = 0.1 + 0.282 nucl
## 
##   Rule 65/4: [6 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.2 - 0.438 u.size + 0.324 nucl + 0.183 thick + 0.1 n.nuc
##            + 0.038 chrom
## 
##   Rule 65/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.445 thick
## 
##   Rule 65/6: [30 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.1863816
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 65/7: [15 cases, mean 0.9, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.493752
##  chrom &lt;= 0.2075386
##     then
##  outcome = -5.7 + 3.172 u.size
## 
##   Rule 65/8: [22 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.890325
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.8 + 0.089 thick + 0.062 nucl
## 
##   Rule 65/9: [68 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  u.size &lt;= 1.493752
##     then
##  outcome = 1
## 
##   Rule 65/10: [13 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; 0.6322382
##     then
##  outcome = 0.8 - 0.122 u.size + 0.112 nucl + 0.082 thick + 0.028 n.nuc
##            + 0.011 chrom
## 
##   Rule 65/11: [95 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
## Model 66:
## 
##   Rule 66/1: [15 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0
## 
##   Rule 66/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 66/3: [262 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 66/4: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.2 + 1.022 thick
## 
##   Rule 66/5: [8 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 + 9.758 u.shape - 1.808 s.size
## 
##   Rule 66/6: [10 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##  nucl &lt;= 0.3602955
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.7 - 2.608 nucl
## 
##   Rule 66/7: [11 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= -0.5175617
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##     then
##  outcome = -2.2 - 4.473 thick + 1.243 u.shape - 0.469 n.nuc
## 
##   Rule 66/8: [26 cases, mean 0.7, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  s.size &lt;= 0.7219615
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.8 + 0.158 thick + 0.011 nucl + 0.007 n.nuc
## 
##   Rule 66/9: [126 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 0.3602955
##     then
##  outcome = 1
## 
##   Rule 66/10: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 66/11: [19 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 1 - 0.011 nucl + 0.005 thick
## 
##   Rule 66/12: [40 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 - 0.005 thick
## 
##   Rule 66/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 67:
## 
##   Rule 67/1: [226 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 67/2: [191 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= -0.4555328
##  chrom &lt;= -0.6054638
##     then
##  outcome = 0
## 
##   Rule 67/3: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.1499105
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 67/4: [124 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.8695334
##  s.size &lt;= -0.1499105
##     then
##  outcome = 0
## 
##   Rule 67/5: [83 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= 0.08835271
##  chrom &gt; -0.6054638
##     then
##  outcome = 0
## 
##   Rule 67/6: [47 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  chrom &lt;= -0.6054638
##     then
##  outcome = -0.1 + 0.62 nucl
## 
##   Rule 67/7: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.1 + 0.935 thick
## 
##   Rule 67/8: [7 cases, mean 0.4, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  s.size &gt; -0.1499105
##  nucl &gt; 0.08835271
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = 0
## 
##   Rule 67/9: [5 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; -0.1499105
##  nucl &lt;= 0.08835271
##  chrom &gt; -0.6054638
##  n.nuc &lt;= 1.636011
##  mit &lt;= 0.1942086
##     then
##  outcome = 0.8 + 0.052 thick + 0.038 chrom + 0.025 n.nuc + 0.023 s.size
## 
##   Rule 67/10: [35 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &lt;= -0.1499105
##  nucl &gt; 0.08835271
##     then
##  outcome = 1
## 
##   Rule 67/11: [76 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &gt; -0.7517401
##  s.size &gt; -0.1499105
##     then
##  outcome = 1
## 
##   Rule 67/12: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 67/13: [9 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  chrom &gt; -0.6054638
##  n.nuc &lt;= 1.636011
##  mit &gt; 0.1942086
##     then
##  outcome = 1 - 0.031 nucl
## 
##   Rule 67/14: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 67/15: [5 cases, mean 1.0, range 1 to 1, est err 0.3]
## 
##     if
##  s.size &gt; -0.5858465
##  s.size &lt;= -0.1499105
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.08835271
##  chrom &gt; -0.6054638
##     then
##  outcome = 1.1 + 0.792 nucl + 0.16 thick
## 
##   Rule 67/16: [49 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##  chrom &gt; -0.1989626
##     then
##  outcome = 1.1 - 0.053 nucl
## 
##   Rule 67/17: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 68:
## 
##   Rule 68/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 68/2: [4 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 0.1863816
##  u.shape &gt; -0.1056389
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0
## 
##   Rule 68/3: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 68/4: [194 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  adhsn &lt;= 0.3774847
##  nucl &lt;= 1.176124
##     then
##  outcome = 0
## 
##   Rule 68/5: [13 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 1.242297
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &lt;= -0.1989626
##     then
##  outcome = 1.1 + 2.353 u.shape + 0.083 nucl + 0.012 thick + 0.01 s.size
##            + 0.008 chrom
## 
##   Rule 68/6: [8 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.5 + 0.152 nucl + 0.132 thick + 0.063 chrom + 0.059 u.size
##            + 0.057 s.size
## 
##   Rule 68/7: [4 cases, mean 0.8, range 0 to 1, est err 2.1]
## 
##     if
##  thick &lt;= -0.5175617
##  u.shape &gt; -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 2
## 
##   Rule 68/8: [21 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  chrom &gt; -0.1989626
##     then
##  outcome = 1
## 
##   Rule 68/9: [53 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.1863816
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 68/10: [17 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.3774847
##  nucl &gt; 1.176124
##     then
##  outcome = 1 + 0.005 nucl
## 
##   Rule 68/11: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.1 + 0.025 s.size
## 
##   Rule 68/12: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 68/13: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 68/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 69:
## 
##   Rule 69/1: [225 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 69/2: [15 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.7274755
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0
## 
##   Rule 69/3: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 69/4: [186 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  chrom &lt;= -0.1989626
##     then
##  outcome = 0
## 
##   Rule 69/5: [85 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &lt;= -0.7129574
##     then
##  outcome = 0.3 + 0.738 nucl
## 
##   Rule 69/6: [6 cases, mean 0.3, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &lt;= -0.7129574
##  chrom &gt; -0.1989626
##     then
##  outcome = 0
## 
##   Rule 69/7: [21 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.5 - 0.841 u.size + 0.42 u.shape + 0.105 nucl + 0.077 thick
##            + 0.053 chrom
## 
##   Rule 69/8: [8 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 1.313705
##     then
##  outcome = 0.7 + 0.175 nucl + 0.169 u.shape
## 
##   Rule 69/9: [43 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1 + 0.007 nucl + 0.005 thick
## 
##   Rule 69/10: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 69/11: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 69/12: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 69/13: [73 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 1.064348
##     then
##  outcome = 1
## 
## Model 70:
## 
##   Rule 70/1: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 70/2: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= -0.7274755
##  chrom &lt;= 0.6140398
##     then
##  outcome = 0
## 
##   Rule 70/3: [11 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.5175617
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  chrom &lt;= 0.6140398
##  mit &lt;= -0.3671017
##     then
##  outcome = -0
## 
##   Rule 70/4: [18 cases, mean 0.4, range 0 to 1, est err 0.5]
## 
##     if
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  chrom &lt;= 0.6140398
##  mit &lt;= -0.3671017
##     then
##  outcome = 0
## 
##   Rule 70/5: [23 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  chrom &lt;= 0.6140398
##     then
##  outcome = 0.8 + 1.016 u.shape + 0.679 chrom + 0.303 thick
## 
##   Rule 70/6: [14 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  chrom &gt; 0.6140398
##     then
##  outcome = 0.6 + 0.162 nucl + 0.092 thick + 0.053 n.nuc + 0.044 s.size
##            + 0.043 chrom + 0.036 u.size
## 
##   Rule 70/7: [5 cases, mean 0.8, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.3 + 0.34 mit + 0.13 nucl
## 
##   Rule 70/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 70/9: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 70/10: [8 cases, mean 1.0, range 1 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  chrom &lt;= 0.6140398
##  mit &gt; -0.3671017
##     then
##  outcome = 0.9 + 0.636 mit
## 
##   Rule 70/11: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 71:
## 
##   Rule 71/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 71/2: [14 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 71/3: [55 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.7517401
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.3 + 1.836 s.size + 0.216 u.size - 0.052 u.shape
## 
##   Rule 71/4: [23 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.7517401
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.1 + 0.1 nucl + 0.047 u.shape + 0.044 u.size + 0.04 thick
##            + 0.025 n.nuc + 0.005 s.size
## 
##   Rule 71/5: [8 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.08246895
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 0.9041809
##     then
##  outcome = -0 + 0.156 nucl + 0.093 u.size + 0.059 n.nuc + 0.034 thick
##            + 0.016 s.size + 0.014 adhsn
## 
##   Rule 71/6: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.411 thick
## 
##   Rule 71/7: [22 cases, mean 0.5, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.08246895
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 0
## 
##   Rule 71/8: [15 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 1.2 + 1.134 u.shape + 0.021 thick
## 
##   Rule 71/9: [9 cases, mean 0.9, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &lt;= 0.2327753
##  u.shape &gt; 0.2174117
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.5 + 0.957 u.shape - 0.009 adhsn
## 
##   Rule 71/10: [20 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.594268
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.7517401
##  nucl &gt; 0.9041809
##     then
##  outcome = 1 - 0.015 adhsn + 0.013 u.shape
## 
##   Rule 71/11: [59 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.493752
##     then
##  outcome = 1
## 
##   Rule 71/12: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 71/13: [12 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &gt; 0.7209161
##     then
##  outcome = 0.9 + 0.054 nucl + 0.043 u.size + 0.02 n.nuc
## 
##   Rule 71/14: [10 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.594268
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 1 - 0.01 adhsn + 0.009 u.shape
## 
##   Rule 71/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 72:
## 
##   Rule 72/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 72/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 72/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.2 + 1.012 thick
## 
##   Rule 72/4: [19 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.03405333
##  nucl &gt; -0.7274755
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.3 - 0.82 adhsn + 0.699 chrom + 0.569 thick
## 
##   Rule 72/5: [8 cases, mean 0.5, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 + 1.681 u.shape - 0.303 s.size + 0.018 nucl + 0.011 thick
##            + 0.006 chrom
## 
##   Rule 72/6: [7 cases, mean 0.6, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.03405333
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.8
## 
##   Rule 72/7: [12 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  chrom &gt; 0.2075386
##     then
##  outcome = 0.8 + 0.077 nucl + 0.049 thick + 0.033 s.size + 0.027 chrom
##            + 0.021 u.size
## 
##   Rule 72/8: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 72/9: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 72/10: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 73:
## 
##   Rule 73/1: [226 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 73/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 73/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.1 + 0.934 thick
## 
##   Rule 73/4: [12 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &lt;= -0.1989626
##     then
##  outcome = 1.5 + 3.094 u.shape + 0.789 chrom
## 
##   Rule 73/5: [11 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0.7 - 1.815 thick + 0.893 nucl
## 
##   Rule 73/6: [9 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &gt; -0.1989626
##     then
##  outcome = 1 + 0.95 u.shape + 0.093 n.nuc + 0.067 thick + 0.043 chrom
##            + 0.02 nucl + 0.007 s.size + 0.005 u.size
## 
##   Rule 73/7: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 73/8: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 73/9: [9 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &gt; 1.636011
##     then
##  outcome = 0.9 + 0.04 n.nuc
## 
##   Rule 73/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 73/11: [4 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 + 0.033 nucl + 0.014 thick + 0.012 s.size + 0.01 n.nuc
##            + 0.009 u.size + 0.009 chrom
## 
##   Rule 73/12: [89 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  nucl &gt; 1.176124
##  chrom &gt; -0.1989626
##     then
##  outcome = 1
## 
##   Rule 73/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 74:
## 
##   Rule 74/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 74/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 74/3: [237 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 1.064348
##  s.size &lt;= 0.2860255
##     then
##  outcome = -0
## 
##   Rule 74/4: [278 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.3977132
##  s.size &lt;= 0.2860255
##     then
##  outcome = -0
## 
##   Rule 74/5: [11 cases, mean 0.5, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 1.064348
##  s.size &lt;= 0.2860255
##  n.nuc &gt; 0.3467855
##     then
##  outcome = -0.2 + 0.254 nucl + 0.144 thick + 0.143 chrom + 0.066 s.size
## 
##   Rule 74/6: [10 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &lt;= 1.427042
##  mit &lt;= 0.1942086
##     then
##  outcome = 1.9 - 0.916 u.shape - 0.905 s.size + 0.006 nucl
## 
##   Rule 74/7: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 74/8: [8 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 0.2174117
##  adhsn &gt; 1.064348
##  nucl &gt; -0.7274755
##  chrom &lt;= 1.427042
##     then
##  outcome = 0.9 + 0.07 nucl
## 
##   Rule 74/9: [42 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  s.size &lt;= 0.2860255
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 74/10: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.242297
##  u.size &gt; -0.3977132
##  u.shape &lt;= 0.2174117
##  adhsn &lt;= 1.064348
##  s.size &lt;= 0.2860255
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 0.3467855
##     then
##  outcome = 1.1
## 
##   Rule 74/11: [5 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  mit &gt; 0.1942086
##     then
##  outcome = 1.1
## 
##   Rule 74/12: [10 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1
## 
##   Rule 74/13: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 74/14: [42 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  chrom &gt; 1.427042
##     then
##  outcome = 1
## 
##   Rule 74/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 75:
## 
##   Rule 75/1: [235 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.4286895
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 75/2: [179 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.shape &lt;= -0.4286895
##     then
##  outcome = 0
## 
##   Rule 75/3: [260 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 75/4: [10 cases, mean 0.2, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.5175617
##  u.shape &lt;= -0.4286895
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = -2.7 - 4.327 s.size + 0.432 thick - 0.374 u.shape + 0.229 nucl
## 
##   Rule 75/5: [7 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.08246895
##  u.size &lt;= 0.2327753
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0
## 
##   Rule 75/6: [4 cases, mean 0.5, range 0 to 1, est err 0.8]
## 
##     if
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  nucl &lt;= -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1 + 0.156 nucl + 0.089 thick + 0.086 u.size + 0.053 n.nuc
##            + 0.038 chrom + 0.033 s.size
## 
##   Rule 75/7: [9 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 1 + 0.012 nucl + 0.008 thick + 0.006 chrom + 0.006 n.nuc
## 
##   Rule 75/8: [17 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.4286895
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1.1
## 
##   Rule 75/9: [17 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.4286895
##  nucl &gt; 0.9041809
##     then
##  outcome = 3 - 1.167 nucl
## 
##   Rule 75/10: [144 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  s.size &gt; -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 75/11: [81 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 1
## 
##   Rule 75/12: [115 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.4286895
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
##   Rule 75/13: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 75/14: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
## Model 76:
## 
##   Rule 76/1: [239 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 76/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 76/3: [60 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &lt;= -0.5858465
##  nucl &lt;= 0.9041809
##     then
##  outcome = 0.2 + 0.693 nucl + 0.107 n.nuc
## 
##   Rule 76/4: [11 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.7517401
##  s.size &gt; -0.5858465
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.1 + 0.261 thick + 0.111 s.size
## 
##   Rule 76/5: [7 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &lt;= 0.2327753
##  u.shape &lt;= 1.186563
##  nucl &lt;= 0.9041809
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 0.4 + 0.189 thick + 0.183 nucl + 0.099 n.nuc + 0.073 u.size
##            + 0.057 s.size
## 
##   Rule 76/6: [11 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 0.9041809
##  chrom &lt;= 0.2075386
##     then
##  outcome = -3.4 + 2.74 nucl - 1.494 thick
## 
##   Rule 76/7: [10 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; 0.1863816
##  u.size &lt;= 0.2327753
##  u.shape &gt; -0.7517401
##  s.size &gt; -0.5858465
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.8 + 0.193 nucl + 0.157 thick + 0.104 n.nuc + 0.076 u.size
##            + 0.071 s.size
## 
##   Rule 76/8: [37 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &lt;= 0.9041809
##     then
##  outcome = 1
## 
##   Rule 76/9: [13 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  nucl &gt; 0.9041809
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.6 + 0.173 nucl + 0.05 thick + 0.032 n.nuc + 0.028 s.size
##            + 0.027 chrom + 0.022 u.size
## 
##   Rule 76/10: [45 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &gt; 0.9041809
##  chrom &gt; 0.2075386
##     then
##  outcome = 0.9 + 0.063 nucl + 0.007 thick
## 
##   Rule 76/11: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 77:
## 
##   Rule 77/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 77/2: [252 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0
## 
##   Rule 77/3: [7 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; -0.5858465
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.1 + 0.155 nucl - 0.061 u.size + 0.06 s.size
## 
##   Rule 77/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.498 thick
## 
##   Rule 77/5: [10 cases, mean 0.5, range 0 to 1, est err 0.7]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##  n.nuc &lt;= 0.02447898
##     then
##  outcome = 1.9 + 2.83 u.size + 2.453 nucl - 2.084 chrom
## 
##   Rule 77/6: [29 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.2 + 0.31 nucl + 0.214 thick - 0.122 u.size + 0.12 s.size
## 
##   Rule 77/7: [9 cases, mean 0.8, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.5 + 0.392 adhsn
## 
##   Rule 77/8: [11 cases, mean 0.8, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 1.176124
##  n.nuc &gt; 0.02447898
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 2.1 - 1.618 n.nuc - 0.412 s.size + 0.257 nucl
## 
##   Rule 77/9: [13 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 0.9 + 0.019 nucl + 0.014 thick + 0.007 n.nuc + 0.006 s.size
##            + 0.005 chrom
## 
##   Rule 77/10: [22 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; 1.176124
##     then
##  outcome = 0.7 + 0.103 nucl + 0.051 thick + 0.036 n.nuc + 0.035 chrom
##            + 0.006 s.size
## 
##   Rule 77/11: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
## Model 78:
## 
##   Rule 78/1: [226 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 78/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 78/3: [270 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.7209161
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0
## 
##   Rule 78/4: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.1 + 0.931 thick
## 
##   Rule 78/5: [13 cases, mean 0.4, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##     then
##  outcome = -0.5 - 1.069 thick + 0.812 nucl
## 
##   Rule 78/6: [9 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &gt; -0.3093781
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.4555328
##     then
##  outcome = 0.1 + 0.371 chrom
## 
##   Rule 78/7: [8 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; 0.5404623
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.9 + 0.025 nucl + 0.014 thick + 0.011 n.nuc + 0.009 u.size
##            + 0.007 u.shape + 0.006 chrom
## 
##   Rule 78/8: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 78/9: [6 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 0.5383533
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= -0.3093781
##  nucl &gt; -0.4555328
##     then
##  outcome = 1.1
## 
##   Rule 78/10: [6 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1.1
## 
##   Rule 78/11: [4 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.9 + 0.101 nucl + 0.069 s.size + 0.051 thick + 0.026 chrom
##            + 0.023 n.nuc + 0.019 u.size
## 
##   Rule 78/12: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 78/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 79:
## 
##   Rule 79/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 79/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 79/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.1 + 0.099 nucl + 0.056 u.size + 0.052 thick + 0.039 n.nuc
##            + 0.026 s.size
## 
##   Rule 79/4: [15 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.8 + 0.854 n.nuc + 0.497 thick + 0.03 nucl
## 
##   Rule 79/5: [11 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0.3 - 1.417 thick + 0.506 nucl
## 
##   Rule 79/6: [4 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.08246895
##  u.shape &lt;= -0.1056389
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.6 + 0.257 n.nuc + 0.111 nucl + 0.097 thick
## 
##   Rule 79/7: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 79/8: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 79/9: [8 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1.2 - 0.069 n.nuc + 0.021 nucl
## 
##   Rule 79/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 79/11: [10 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1
## 
##   Rule 79/12: [77 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  s.size &gt; -0.1499105
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 79/13: [90 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.08246895
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 79/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 80:
## 
##   Rule 80/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 80/2: [179 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.shape &lt;= -0.4286895
##     then
##  outcome = 0
## 
##   Rule 80/3: [6 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= 0.2327753
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.8 + 0.938 u.size + 0.693 chrom + 0.213 s.size
## 
##   Rule 80/4: [19 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &lt;= 0.2327753
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = -2.3 - 3.966 s.size + 0.551 nucl
## 
##   Rule 80/5: [16 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  s.size &gt; -0.5858465
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 1 - 0.532 n.nuc
## 
##   Rule 80/6: [165 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.4286895
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 80/7: [144 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  s.size &gt; -0.5858465
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 80/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
## Model 81:
## 
##   Rule 81/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 81/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 81/3: [38 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.594268
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.4 + 0.181 n.nuc + 0.157 thick + 0.149 chrom
## 
##   Rule 81/4: [11 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 0.6 + 0.155 nucl + 0.078 thick + 0.069 n.nuc + 0.063 s.size
## 
##   Rule 81/5: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 81/6: [6 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  thick &gt; 1.594268
##  s.size &lt;= -0.1499105
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.8 - 1.441 s.size
## 
##   Rule 81/7: [50 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.594268
##     then
##  outcome = 1
## 
##   Rule 81/8: [4 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 + 0.024 nucl + 0.012 thick + 0.011 n.nuc + 0.01 s.size
## 
##   Rule 81/9: [73 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 1.064348
##     then
##  outcome = 1
## 
##   Rule 81/10: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 82:
## 
##   Rule 82/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 82/2: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= -0.6201341
##     then
##  outcome = 0
## 
##   Rule 82/3: [53 cases, mean 0.2, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &lt;= 1.448066
##     then
##  outcome = -0.1
## 
##   Rule 82/4: [15 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.4555328
##  n.nuc &gt; -0.6201341
##     then
##  outcome = 0.3 + 0.418 n.nuc + 0.263 adhsn + 0.248 thick
## 
##   Rule 82/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.454 thick
## 
##   Rule 82/6: [13 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.3977132
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.448066
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1 - 2.674 u.size + 0.288 nucl
## 
##   Rule 82/7: [8 cases, mean 0.8, range 0 to 1, est err 0.9]
## 
##     if
##  thick &lt;= 0.5383533
##  nucl &gt; 0.9041809
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.6 + 6.552 thick - 2.854 u.size
## 
##   Rule 82/8: [81 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 0.9913985
##     then
##  outcome = 1
## 
##   Rule 82/9: [92 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.448066
##     then
##  outcome = 1
## 
##   Rule 82/10: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 82/11: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 82/12: [37 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##  nucl &lt;= 0.9041809
##     then
##  outcome = 1
## 
##   Rule 82/13: [6 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  adhsn &gt; 1.064348
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1 + 0.013 nucl + 0.009 thick + 0.005 n.nuc
## 
##   Rule 82/14: [7 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; 0.9041809
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.3 - 0.17 thick + 0.008 nucl
## 
##   Rule 82/15: [6 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &gt; -0.4555328
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1.1
## 
## Model 83:
## 
##   Rule 83/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 83/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 83/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.1 + 0.107 nucl + 0.071 u.size + 0.06 thick + 0.041 n.nuc
##            + 0.023 chrom
## 
##   Rule 83/4: [45 cases, mean 0.2, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= -0.1056389
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.9 + 1.486 u.shape + 0.244 nucl + 0.162 thick
## 
##   Rule 83/5: [8 cases, mean 0.4, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.1863816
##  u.shape &gt; -0.1056389
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = -0.7 - 1.868 thick + 1.01 nucl
## 
##   Rule 83/6: [8 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.5 + 0.174 nucl + 0.093 thick + 0.065 n.nuc + 0.047 chrom
##            + 0.042 u.size + 0.042 s.size
## 
##   Rule 83/7: [113 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.1863816
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 83/8: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 83/9: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.1 + 0.01 nucl + 0.005 thick
## 
##   Rule 83/10: [19 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.8 + 0.099 thick + 0.038 mit + 0.008 adhsn
## 
##   Rule 83/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 83/12: [6 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##  s.size &gt; 2.465705
##     then
##  outcome = 0.8 + 0.052 nucl + 0.033 thick + 0.025 u.size + 0.023 n.nuc
## 
##   Rule 83/13: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 84:
## 
##   Rule 84/1: [225 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 84/2: [170 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &lt;= -0.7129574
##     then
##  outcome = -0
## 
##   Rule 84/3: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 84/4: [85 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &lt;= -0.7129574
##     then
##  outcome = 0.3 + 0.722 nucl
## 
##   Rule 84/5: [4 cases, mean 0.5, range 0 to 1, est err 0.5]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.7 + 0.204 nucl - 0.144 u.size + 0.143 u.shape + 0.128 thick
##            + 0.108 chrom + 0.088 mit
## 
##   Rule 84/6: [10 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  mit &gt; -0.3671017
##     then
##  outcome = 0.3 - 0.612 u.size + 0.393 u.shape + 0.202 nucl
## 
##   Rule 84/7: [13 cases, mean 0.5, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  mit &lt;= -0.3671017
##     then
##  outcome = 1 + 1.607 u.size + 0.766 thick + 0.457 nucl
## 
##   Rule 84/8: [29 cases, mean 0.6, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.1 + 0.514 nucl - 0.051 u.size + 0.033 u.shape
## 
##   Rule 84/9: [32 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; 0.2327753
##  chrom &lt;= 0.2075386
##     then
##  outcome = 0.9 + 0.032 nucl + 0.028 thick + 0.019 chrom + 0.017 u.shape
## 
##   Rule 84/10: [113 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.1863816
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 84/11: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 84/12: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
## Model 85:
## 
##   Rule 85/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 85/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 85/3: [9 cases, mean 0.1, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.4286895
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.1 + 0.137 thick + 0.109 nucl
## 
##   Rule 85/4: [46 cases, mean 0.2, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  chrom &lt;= 0.2075386
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.1 + 0.243 u.shape + 0.117 chrom
## 
##   Rule 85/5: [5 cases, mean 0.6, range 0 to 1, est err 1.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.4286895
##  u.shape &lt;= 0.5404623
##  s.size &lt;= -0.5858465
##  nucl &gt; -0.7274755
##  chrom &lt;= 0.2075386
##     then
##  outcome = 1.3
## 
##   Rule 85/6: [38 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.9 + 0.046 thick + 0.036 nucl
## 
##   Rule 85/7: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.5404623
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 85/8: [115 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.4286895
##  chrom &gt; 0.2075386
##     then
##  outcome = 1
## 
##   Rule 85/9: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1
## 
##   Rule 85/10: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.1
## 
##   Rule 85/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 85/12: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 86:
## 
##   Rule 86/1: [225 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 86/2: [170 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &lt;= -0.7129574
##     then
##  outcome = -0
## 
##   Rule 86/3: [14 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 86/4: [269 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= -0.1056389
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0 + 0.014 u.shape + 0.009 nucl
## 
##   Rule 86/5: [85 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &lt;= -0.7129574
##     then
##  outcome = 0.3 + 0.718 nucl
## 
##   Rule 86/6: [60 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  chrom &lt;= -0.1989626
##     then
##  outcome = -0
## 
##   Rule 86/7: [14 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0.6 + 0.168 nucl + 0.109 u.size + 0.095 thick + 0.067 n.nuc
##            + 0.041 chrom
## 
##   Rule 86/8: [4 cases, mean 0.8, range 0 to 1, est err 1.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.3 + 0.144 thick + 0.129 nucl + 0.114 n.nuc + 0.086 adhsn
## 
##   Rule 86/9: [10 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &lt;= 1.176124
##  chrom &gt; -0.1989626
##     then
##  outcome = 0.9 + 0.152 thick + 0.152 nucl + 0.086 n.nuc + 0.046 adhsn
##            + 0.029 chrom + 0.009 u.shape
## 
##   Rule 86/10: [105 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &gt; -0.7517401
##     then
##  outcome = 1
## 
##   Rule 86/11: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 86/12: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 86/13: [11 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.1 - 0.044 thick - 0.023 nucl
## 
##   Rule 86/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
##   Rule 86/15: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 86/16: [90 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.08246895
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
## Model 87:
## 
##   Rule 87/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 87/2: [24 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.1 + 0.075 nucl + 0.042 thick + 0.026 u.shape + 0.024 n.nuc
##            + 0.007 s.size + 0.006 adhsn
## 
##   Rule 87/3: [35 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.1 + 0.737 s.size
## 
##   Rule 87/4: [19 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.6322382
##  n.nuc &lt;= 1.313705
##     then
##  outcome = 0.2 + 0.426 thick + 0.034 nucl + 0.021 u.shape + 0.007 n.nuc
## 
##   Rule 87/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.41 thick
## 
##   Rule 87/6: [7 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 1.313705
##     then
##  outcome = 0.6 + 0.203 u.shape + 0.185 nucl
## 
##   Rule 87/7: [122 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 0.6322382
##     then
##  outcome = 1
## 
##   Rule 87/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1 + 0.006 nucl + 0.005 thick
## 
##   Rule 87/9: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
## Model 88:
## 
##   Rule 88/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 88/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 88/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.2 + 1.011 thick
## 
##   Rule 88/4: [14 cases, mean 0.3, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = -0.2 + 0.742 nucl - 0.658 thick
## 
##   Rule 88/5: [8 cases, mean 0.5, range 0 to 1, est err 0.2]
## 
##     if
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 + 4.513 u.shape - 0.836 s.size
## 
##   Rule 88/6: [14 cases, mean 0.6, range 0 to 1, est err 0.4]
## 
##     if
##  thick &gt; -0.16559
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.2 + 0.885 thick - 0.059 adhsn + 0.04 chrom + 0.026 n.nuc
## 
##   Rule 88/7: [10 cases, mean 0.7, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.8 + 0.104 nucl + 0.007 thick + 0.005 s.size
## 
##   Rule 88/8: [28 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; 1.176124
##     then
##  outcome = 1 - 0.005 adhsn
## 
##   Rule 88/9: [8 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &gt; 1.636011
##     then
##  outcome = 0.7 - 0.238 adhsn + 0.161 chrom + 0.105 n.nuc
## 
##   Rule 88/10: [19 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 1 + 0.007 thick
## 
##   Rule 88/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 88/12: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 89:
## 
##   Rule 89/1: [226 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 89/2: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 89/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.1 + 0.934 thick
## 
##   Rule 89/4: [7 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.08246895
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0 + 0.343 nucl + 0.152 adhsn + 0.078 u.size
## 
##   Rule 89/5: [20 cases, mean 0.5, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.8 + 1.101 u.size + 0.487 nucl + 0.32 thick + 0.178 n.nuc
## 
##   Rule 89/6: [8 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.8 + 0.06 nucl + 0.03 n.nuc + 0.02 thick + 0.016 u.size
##            + 0.01 s.size + 0.006 chrom
## 
##   Rule 89/7: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.3774847
##     then
##  outcome = 1
## 
##   Rule 89/8: [101 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 89/9: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.8 + 0.091 s.size + 0.078 nucl + 0.037 thick + 0.028 u.size
##            + 0.028 n.nuc + 0.013 chrom
## 
##   Rule 89/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 89/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 89/12: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 90:
## 
##   Rule 90/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 90/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 90/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.1 + 0.072 nucl + 0.042 thick + 0.031 n.nuc + 0.028 u.shape
##            + 0.022 s.size + 0.016 chrom + 0.012 adhsn
## 
##   Rule 90/4: [12 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.1056389
##  adhsn &lt;= 0.3774847
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -0.2
## 
##   Rule 90/5: [16 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.6 + 0.549 chrom + 0.545 n.nuc + 0.34 thick
## 
##   Rule 90/6: [7 cases, mean 0.6, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  adhsn &lt;= 0.7209161
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0.5 + 0.162 nucl + 0.08 thick + 0.057 n.nuc + 0.042 s.size
##            + 0.039 u.shape + 0.032 chrom + 0.017 adhsn
## 
##   Rule 90/7: [4 cases, mean 0.8, range 0 to 1, est err 1.0]
## 
##     if
##  thick &lt;= -0.5175617
##  u.shape &gt; -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 1.3 - 0.212 adhsn + 0.111 chrom + 0.096 nucl + 0.058 n.nuc
## 
##   Rule 90/8: [106 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  s.size &gt; 0.2860255
##     then
##  outcome = 1
## 
##   Rule 90/9: [32 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.3774847
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 90/10: [5 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  thick &gt; 0.5383533
##  thick &lt;= 1.242297
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 1.1
## 
##   Rule 90/11: [8 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1 - 0.012 adhsn + 0.006 chrom + 0.005 nucl
## 
##   Rule 90/12: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 90/13: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 90/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 91:
## 
##   Rule 91/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 91/2: [253 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.1056389
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 91/3: [37 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &gt; -0.7129574
##  adhsn &lt;= 0.3774847
##  nucl &lt;= 1.176124
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.1 + 0.261 nucl + 0.022 u.size + 0.006 thick
## 
##   Rule 91/4: [7 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.08246895
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0 + 0.204 nucl + 0.147 thick + 0.055 n.nuc + 0.048 chrom
## 
##   Rule 91/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.474 thick
## 
##   Rule 91/6: [8 cases, mean 0.6, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 0.6 + 0.144 nucl + 0.069 u.size + 0.06 thick + 0.048 n.nuc
##            + 0.026 chrom
## 
##   Rule 91/7: [8 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.08246895
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1 + 0.53 u.shape + 0.006 thick + 0.005 nucl
## 
##   Rule 91/8: [5 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.3 - 1.215 u.shape + 0.045 u.size
## 
##   Rule 91/9: [15 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.1863816
##  u.size &lt;= -0.08246895
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 91/10: [97 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 91/11: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 91/12: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 91/13: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 91/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 92:
## 
##   Rule 92/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 92/2: [252 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0
## 
##   Rule 92/3: [13 cases, mean 0.2, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &lt;= 0.2327753
##  mit &gt; -0.3671017
##     then
##  outcome = 0 + 0.076 nucl + 0.058 thick + 0.022 u.shape + 0.012 n.nuc
##            + 0.011 s.size + 0.009 chrom
## 
##   Rule 92/4: [47 cases, mean 0.2, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= 1.448066
##  n.nuc &lt;= 0.9913985
##  mit &lt;= -0.3671017
##     then
##  outcome = 0.3 + 0.665 nucl + 0.019 thick
## 
##   Rule 92/5: [6 cases, mean 0.3, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.2 + 0.212 nucl - 0.158 u.size + 0.115 u.shape + 0.089 mit
##            + 0.079 thick + 0.06 n.nuc + 0.058 chrom
## 
##   Rule 92/6: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.467 thick
## 
##   Rule 92/7: [13 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 0.9913985
##     then
##  outcome = -3.8 + 2.097 n.nuc + 0.34 nucl
## 
##   Rule 92/8: [59 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.493752
##     then
##  outcome = 1
## 
##   Rule 92/9: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 92/10: [92 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.448066
##     then
##  outcome = 1
## 
##   Rule 92/11: [50 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  nucl &gt; -0.7274755
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 1
## 
## Model 93:
## 
##   Rule 93/1: [203 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  nucl &lt;= 0.08835271
##  chrom &lt;= -0.6054638
##     then
##  outcome = -0
## 
##   Rule 93/2: [53 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  s.size &lt;= -0.5858465
##  nucl &lt;= 1.176124
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.1 + 0.209 n.nuc
## 
##   Rule 93/3: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 93/4: [11 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= -0.7129574
##  u.shape &gt; -0.7517401
##  chrom &gt; -0.6054638
##     then
##  outcome = 1.2 + 1.971 nucl - 1.318 chrom
## 
##   Rule 93/5: [30 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.1863816
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.7517401
##  adhsn &lt;= 0.03405333
##  nucl &lt;= 1.176124
##  mit &lt;= 0.1942086
##     then
##  outcome = 0.1 + 0.184 thick + 0.143 adhsn + 0.131 n.nuc
## 
##   Rule 93/6: [6 cases, mean 0.2, range 0 to 1, est err 0.5]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.3 + 1.029 thick
## 
##   Rule 93/7: [9 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 1.178508
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.03405333
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##  mit &lt;= 0.1942086
##     then
##  outcome = 0.9
## 
##   Rule 93/8: [5 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 0.08835271
##  chrom &lt;= -0.6054638
##     then
##  outcome = 0.7 + 0.176 nucl + 0.024 thick + 0.018 s.size + 0.017 n.nuc
## 
##   Rule 93/9: [13 cases, mean 0.8, range 0 to 1, est err 0.2]
## 
##     if
##  thick &gt; 0.1863816
##  u.size &lt;= 1.178508
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##  mit &lt;= 0.1942086
##     then
##  outcome = 1 + 0.03 nucl + 0.015 thick + 0.011 s.size + 0.011 n.nuc
## 
##   Rule 93/10: [30 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  s.size &gt; -0.5858465
##  chrom &gt; -0.6054638
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 1
## 
##   Rule 93/11: [59 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  chrom &gt; -0.6054638
##  mit &gt; 0.1942086
##     then
##  outcome = 1
## 
##   Rule 93/12: [59 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##     then
##  outcome = 0.9 + 0.036 nucl + 0.024 thick + 0.017 s.size + 0.011 n.nuc
## 
##   Rule 93/13: [77 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.178508
##     then
##  outcome = 1
## 
##   Rule 93/14: [11 cases, mean 1.0, range 1 to 1, est err 0.1]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##  nucl &lt;= 1.176124
##     then
##  outcome = 1 - 0.098 u.shape + 0.097 u.size + 0.066 nucl
## 
##   Rule 93/15: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 94:
## 
##   Rule 94/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = -0
## 
##   Rule 94/2: [35 cases, mean 0.1, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0.1 + 0.08 nucl + 0.067 u.shape + 0.039 mit + 0.024 thick
## 
##   Rule 94/3: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.462 thick
## 
##   Rule 94/4: [8 cases, mean 0.4, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= -0.3977132
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##     then
##  outcome = 0
## 
##   Rule 94/5: [12 cases, mean 0.4, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.3977132
##  u.size &lt;= 0.2327753
##  nucl &gt; -0.7274755
##  nucl &lt;= 0.9041809
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.7 - 3.69 u.size + 0.755 thick + 0.524 n.nuc
## 
##   Rule 94/6: [9 cases, mean 0.8, range 0 to 1, est err 0.4]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 0.2327753
##  n.nuc &gt; 0.9913985
##     then
##  outcome = -2.8 + 1.94 n.nuc
## 
##   Rule 94/7: [10 cases, mean 0.9, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  adhsn &lt;= 1.064348
##  nucl &gt; 0.9041809
##  n.nuc &lt;= 0.9913985
##     then
##  outcome = 0.5 - 1.074 u.size + 0.856 u.shape
## 
##   Rule 94/8: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1 + 0.007 nucl
## 
##   Rule 94/9: [15 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.size &lt;= 0.2327753
##     then
##  outcome = 1 - 0.09 u.size - 0.022 n.nuc
## 
##   Rule 94/10: [10 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= 0.2327753
##  adhsn &gt; 1.064348
##     then
##  outcome = 1 + 0.019 u.shape + 0.013 nucl
## 
## Model 95:
## 
##   Rule 95/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 95/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 95/3: [25 cases, mean 0.2, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= -0.5175617
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##     then
##  outcome = 0.6 + 1.104 u.shape + 0.235 adhsn + 0.09 n.nuc
## 
##   Rule 95/4: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.408 thick
## 
##   Rule 95/5: [64 cases, mean 0.6, range 0 to 1, est err 0.3]
## 
##     if
##  thick &gt; -0.5175617
##  u.size &gt; -0.7129574
##  u.shape &lt;= 0.2174117
##     then
##  outcome = 0.2 + 0.326 thick + 0.131 chrom + 0.07 nucl + 0.058 u.shape
##            + 0.042 u.size + 0.022 n.nuc
## 
##   Rule 95/6: [26 cases, mean 0.7, range 0 to 1, est err 0.5]
## 
##     if
##  thick &gt; -0.5175617
##  thick &lt;= 1.594268
##  u.size &gt; -0.7129574
##  u.size &lt;= 0.2327753
##  u.shape &lt;= 0.2174117
##  chrom &gt; -0.6054638
##     then
##  outcome = 0.7 - 1.282 u.size + 1.122 u.shape + 0.068 thick + 0.039 chrom
## 
##   Rule 95/7: [12 cases, mean 0.8, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 1.178508
##  u.shape &gt; 0.2174117
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.1 + 0.579 chrom + 0.019 thick
## 
##   Rule 95/8: [23 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.2174117
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 1
## 
##   Rule 95/9: [127 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 0.2327753
##     then
##  outcome = 1
## 
##   Rule 95/10: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 95/11: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 95/12: [31 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.178508
##  nucl &lt;= 1.176124
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 1 - 0.007 nucl
## 
##   Rule 95/13: [50 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.594268
##     then
##  outcome = 1
## 
## Model 96:
## 
##   Rule 96/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0
## 
##   Rule 96/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = -0
## 
##   Rule 96/3: [6 cases, mean 0.2, range 0 to 1, est err 0.6]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.5 + 1.217 thick
## 
##   Rule 96/4: [18 cases, mean 0.4, range 0 to 1, est err 0.1]
## 
##     if
##  thick &lt;= 0.1863816
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0 + 0.609 nucl
## 
##   Rule 96/5: [4 cases, mean 0.8, range 0 to 1, est err 0.6]
## 
##     if
##  thick &gt; 0.1863816
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 1.1
## 
##   Rule 96/6: [85 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; -0.7274755
##  n.nuc &gt; -0.2978275
##     then
##  outcome = 0.9 + 0.049 thick + 0.033 n.nuc + 0.028 chrom
## 
##   Rule 96/7: [50 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##     then
##  outcome = 0.9 + 0.027 s.size - 0.017 u.size
## 
##   Rule 96/8: [59 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  nucl &gt; 1.176124
##     then
##  outcome = 1 + 0.016 nucl + 0.007 thick + 0.007 n.nuc
## 
##   Rule 96/9: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 97:
## 
##   Rule 97/1: [254 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 97/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 97/3: [299 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 0.6322382
##  n.nuc &lt;= 1.313705
##     then
##  outcome = -0.9
## 
##   Rule 97/4: [14 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 0.5383533
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 0.5404623
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  n.nuc &lt;= -0.2978275
##     then
##  outcome = 0.5 + 0.477 u.shape + 0.419 chrom + 0.333 thick + 0.017 nucl
##            + 0.008 s.size + 0.005 n.nuc
## 
##   Rule 97/5: [123 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; -0.7517401
##  nucl &gt; 0.6322382
##     then
##  outcome = 1
## 
##   Rule 97/6: [38 cases, mean 1.0, range 0 to 1, est err 0.1]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##     then
##  outcome = 0.9 + 0.024 thick + 0.022 nucl
## 
##   Rule 97/7: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 0.5404623
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 97/8: [71 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.313705
##     then
##  outcome = 1
## 
##   Rule 97/9: [4 cases, mean 1.0, range 1 to 1, est err 0.2]
## 
##     if
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  s.size &gt; 0.2860255
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1.1 - 0.141 u.shape
## 
##   Rule 97/10: [40 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1 - 0.015 thick + 0.015 adhsn + 0.014 u.shape - 0.014 nucl
## 
##   Rule 97/11: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 98:
## 
##   Rule 98/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 98/2: [274 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  adhsn &lt;= 0.7209161
##  nucl &lt;= -0.4555328
##  n.nuc &lt;= 1.636011
##     then
##  outcome = 0
## 
##   Rule 98/3: [222 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &lt;= -0.16559
##  u.shape &lt;= -0.4286895
##     then
##  outcome = 0
## 
##   Rule 98/4: [54 cases, mean 0.1, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; -0.16559
##  u.shape &lt;= -0.4286895
##     then
##  outcome = 0.2 + 0.377 nucl + 0.369 u.size + 0.368 thick
## 
##   Rule 98/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.6 + 0.466 thick
## 
##   Rule 98/6: [156 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.4286895
##  nucl &gt; -0.4555328
##     then
##  outcome = 1
## 
##   Rule 98/7: [14 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1 + 0.005 nucl
## 
##   Rule 98/8: [19 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##     then
##  outcome = 1.2 - 0.117 thick - 0.014 adhsn
## 
##   Rule 98/9: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 98/10: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## Model 99:
## 
##   Rule 99/1: [247 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &lt;= 0.08835271
##     then
##  outcome = 0
## 
##   Rule 99/2: [268 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &lt;= 1.808996
##  u.shape &lt;= -0.1056389
##  nucl &lt;= -0.4555328
##     then
##  outcome = 0 + 0.014 nucl
## 
##   Rule 99/3: [6 cases, mean 0.2, range 0 to 1, est err 0.5]
## 
##     if
##  thick &lt;= 1.242297
##  u.size &gt; -0.7129574
##  u.shape &lt;= -0.4286895
##  nucl &gt; -0.4555328
##  nucl &lt;= 1.176124
##     then
##  outcome = 0.6 + 1.081 thick
## 
##   Rule 99/4: [14 cases, mean 0.3, range 0 to 1, est err 0.3]
## 
##     if
##  thick &lt;= 0.5383533
##  u.size &lt;= 1.808996
##  u.shape &gt; -0.1056389
##  adhsn &lt;= 0.7209161
##  nucl &lt;= 1.176124
##  n.nuc &lt;= 1.636011
##     then
##  outcome = -1
## 
##   Rule 99/5: [8 cases, mean 0.4, range 0 to 1, est err 0.3]
## 
##     if
##  u.size &lt;= -0.7129574
##  nucl &gt; 0.08835271
##     then
##  outcome = 0.5 + 0.436 thick
## 
##   Rule 99/6: [9 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  u.size &gt; -0.7129574
##  u.size &lt;= 1.808996
##  u.shape &lt;= -0.1056389
##  nucl &gt; 1.176124
##     then
##  outcome = 0.8 + 0.077 nucl + 0.043 thick + 0.036 u.size + 0.022 n.nuc
## 
##   Rule 99/7: [18 cases, mean 0.9, range 0 to 1, est err 0.1]
## 
##     if
##  u.size &gt; -0.7129574
##  u.shape &gt; -0.4286895
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.4555328
##     then
##  outcome = 1
## 
##   Rule 99/8: [92 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.5383533
##  u.shape &gt; -0.1056389
##     then
##  outcome = 1
## 
##   Rule 99/9: [100 cases, mean 1.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &gt; -0.7129574
##  nucl &gt; 1.176124
##     then
##  outcome = 1
## 
##   Rule 99/10: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 99/11: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 99/12: [55 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  n.nuc &gt; 1.636011
##     then
##  outcome = 1
## 
##   Rule 99/13: [54 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.size &gt; 1.808996
##     then
##  outcome = 1
## 
## Model 100:
## 
##   Rule 100/1: [239 cases, mean 0.0, range 0 to 0, est err 0.0]
## 
##     if
##  s.size &lt;= -0.5858465
##  nucl &lt;= -0.7274755
##     then
##  outcome = 0
## 
##   Rule 100/2: [232 cases, mean 0.0, range 0 to 1, est err 0.0]
## 
##     if
##  u.shape &lt;= -0.7517401
##     then
##  outcome = 0
## 
##   Rule 100/3: [6 cases, mean 0.2, range 0 to 1, est err 0.3]
## 
##     if
##  u.shape &lt;= -0.7517401
##  nucl &gt; 0.08835271
##     then
##  outcome = 1.2 + 1.019 thick
## 
##   Rule 100/4: [6 cases, mean 0.2, range 0 to 1, est err 0.0]
## 
##     if
##  u.size &lt;= -0.08246895
##  u.shape &gt; -0.7517401
##  s.size &gt; -0.5858465
##  nucl &lt;= -0.7274755
##     then
##  outcome = -0.3 - 3.172 u.size
## 
##   Rule 100/5: [12 cases, mean 0.3, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &lt;= -0.1989626
##     then
##  outcome = 1.4 + 2.491 u.shape + 1.102 chrom
## 
##   Rule 100/6: [9 cases, mean 0.4, range 0 to 1, est err 0.6]
## 
##     if
##  thick &lt;= 0.1863816
##  u.shape &gt; -0.1056389
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##     then
##  outcome = 0
## 
##   Rule 100/7: [8 cases, mean 0.6, range 0 to 1, est err 0.7]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &lt;= 1.186563
##  adhsn &gt; 0.3774847
##  adhsn &lt;= 0.7209161
##     then
##  outcome = -0.4 + 7.023 u.shape - 4.45 u.size
## 
##   Rule 100/8: [4 cases, mean 0.8, range 0 to 1, est err 0.6]
## 
##     if
##  u.size &gt; -0.08246895
##  u.shape &lt;= 1.186563
##  nucl &lt;= -0.7274755
##     then
##  outcome = 1 + 0.102 nucl + 0.073 thick + 0.057 chrom + 0.049 s.size
##            + 0.049 n.nuc
## 
##   Rule 100/9: [7 cases, mean 0.9, range 0 to 1, est err 0.2]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= -0.1056389
##  adhsn &lt;= 0.7209161
##  nucl &gt; -0.7274755
##  nucl &lt;= 1.176124
##  chrom &gt; -0.1989626
##     then
##  outcome = 0.9 + 0.444 u.shape + 0.181 nucl + 0.091 thick + 0.06 n.nuc
##            + 0.046 chrom + 0.04 s.size + 0.023 u.size
## 
##   Rule 100/10: [17 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &lt;= 1.242297
##  u.shape &gt; -0.7517401
##  u.shape &lt;= 1.186563
##  adhsn &lt;= 0.3774847
##  nucl &gt; 1.176124
##     then
##  outcome = 1 + 0.007 nucl
## 
##   Rule 100/11: [53 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 0.1863816
##  adhsn &lt;= 0.3774847
##  nucl &gt; -0.7274755
##     then
##  outcome = 1
## 
##   Rule 100/12: [61 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  thick &gt; 1.242297
##     then
##  outcome = 1
## 
##   Rule 100/13: [85 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  adhsn &gt; 0.7209161
##     then
##  outcome = 1
## 
##   Rule 100/14: [71 cases, mean 1.0, range 1 to 1, est err 0.0]
## 
##     if
##  u.shape &gt; 1.186563
##     then
##  outcome = 1
## 
## 
## Evaluation on training data (474 cases):
## 
##     Average  |error|                0.0
##     Relative |error|               0.07
##     Correlation coefficient        0.97
## 
## 
##  Attribute usage:
##    Conds  Model
## 
##     61%     8%    nucl
##     37%     3%    u.shape
##     36%     2%    u.size
##     22%     7%    thick
##     19%     3%    s.size
##     12%     1%    adhsn
##     12%     4%    n.nuc
##      8%     3%    chrom
##      1%           mit
## 
## 
## Time: 0.3 secs</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="tree-models.html#cb118-1" tabindex="-1"></a><span class="fu">dotPlot</span>(<span class="fu">varImp</span>(cubit.fit), <span class="at">main=</span><span class="st">&quot;Cubist Predictor importance&quot;</span>)</span></code></pre></div>
<p><img src="bookdown_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="svm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pca.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yihui/bookdown-crc/edit/master/07-Tree-models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.pdf", "bookdown.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
