<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title> Analysis of Variance</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Zehui Bai</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="02-Clinical_Experience.html">
    <span class="fa fa-user"></span>
     
    Clinical Experience
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-sliders"></span>
     
    Sample Size
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="03-SSC-Everything-to-Know-About-Sample-Size-Determination.html">Everything to Know About Sample Size Determination</a>
    </li>
    <li>
      <a href="03-SSC-Choosing-the-Effect-Size-for-Sample-Size-Calculations.html">Choosing the Effect Size</a>
    </li>
    <li>
      <a href="03-SSC-Biosimilar-Trials.html">Statistical Considerations for the Design and Analysis of Biosimilar Trials</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-and-Power-for-Non-Parametric-Analysis.html">Sample Size and Power for Non-Parametric Analysis</a>
    </li>
    <li>
      <a href="03-SSC-Power-for-Complex-Hypotheses.html">Power for Complex Hypotheses</a>
    </li>
    <li>
      <a href="03-SSC-Alternatives-to-Power.html">Bayesian methods - Alternatives to Power</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-for-Pilot-Studies.html">Sample Size for Pilot Studies</a>
    </li>
    <li>
      <a href="03-SSC-Case-Continuous-Endpoint.html">Sample Size Determination for Continuous Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Categorical-Endpoint.html">Sample Size Determination for Categorical Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Sample-Size-Determination-for-Counts-and-Rates.html">Sample Size Determination for Counts and Rates</a>
    </li>
    <li>
      <a href="03-SSC-Case-Survival-Endpoint.html">Sample Size Determination for Survival Endpoint</a>
    </li>
    <li>
      <a href="03-SSC-Case-Repeated-Measures.html">Sample Size Determination for Repeated Measures</a>
    </li>
    <li>
      <a href="03-SSC-IA-Sequential-Design.html">Statistical Considerations for Group Sequential Design</a>
    </li>
    <li>
      <a href="03-SSC-IA-Adaptive-Design.html">Statistical Considerations for Adaptive Design</a>
    </li>
    <li>
      <a href="03-SSC-Multiple-Test.html">Sample Size for Multiple Test</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-pencil-square-o"></span>
     
    Study Design
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="04-Design-Estimands-Framework.html">Estimands Framework</a>
    </li>
    <li>
      <a href="04-Design-Estimands-Practice.html">Estimands and Sensitivity Analyses</a>
    </li>
    <li>
      <a href="04-Design-Phase-I-Trials---Design-Considerations.html">Phase I Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-II-Trials---Design-Considerations.html">Phase II Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-III-Trials---Design-Considerations.html">Phase III Trials - Design Considerations</a>
    </li>
    <li>
      <a href="04-Design-Phase-IV-Trials---Design-Considerations.html">Phase IV Trials - Design Considerations for Post Marketing Surveillance</a>
    </li>
    <li>
      <a href="04-Design-Complex-Sequential-Trials.html">Complex Sequential Analysis Trials</a>
    </li>
    <li>
      <a href="04-Design-Adaptive-Clinical-Trials.html">Adaptive Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Bayesian-Clinical-Trials.html">Bayesian Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Dose-Escalation-and-Stratification-Designs.html">Dose Escalation and Stratification Designs in Early Oncology Development</a>
    </li>
    <li>
      <a href="04-Design-Single-Arm-Clinical-Trials.html">Single Arm Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Diagnostic-Study-Design-and-Evaluation.html">Diagnostic Study-Design and Evaluation</a>
    </li>
    <li>
      <a href="04-Design-Diagnostic-Study-MRMC.html">Diagnostic Study-Multireader Multicase (MRMC)</a>
    </li>
    <li>
      <a href="04-Design-Hierarchical-composite-endpoints.html">Hierarchical Composite Endpoints</a>
    </li>
    <li>
      <a href="04-Design-Externally-Controlled-Trials.html">Considerations for the Design and Conduct of Externally Controlled Trials</a>
    </li>
    <li>
      <a href="04-Design-Noninferiority-Trials.html">Noninferiority Trials</a>
    </li>
    <li>
      <a href="04-Design-Bioequivalence-and-Biosimilar-Trials.html">Bioequivalence and Biosimilar Trials</a>
    </li>
    <li>
      <a href="04-Design-Exploring-Survival-Analysis-Designs-for-Clinical-Trials.html">Exploring Survival Analysis Designs for Clinical Trials</a>
    </li>
    <li>
      <a href="04-Design-Projecting-How-Long-Your-Trial-Will-Take.html">Projecting How Long Your Trial Will Take</a>
    </li>
    <li>
      <a href="04-Design-Regulatory-Submission.html">Regulatory Submission from Stats Perspective</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-line-chart"></span>
     
    Data Visualization
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="05-Plot-Adverse-Event.html">Adverse Event Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Laboratory-Data.html">Laboratory Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Time-To-Event.html">Time to Event Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-PRO-Data.html">Patient Reported Outcome Data Visualization</a>
    </li>
    <li>
      <a href="05-Plot-SSC-and-Power-Calculation.html">Sample Size and Power Calculations Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Correlation.html">Correlation Visualization</a>
    </li>
    <li>
      <a href="05-Plot-Model-Table.html">Clinical Data and Model visualization</a>
    </li>
    <li>
      <a href="05-Plot-ScatterPlot.html">Scatter and Line Plot</a>
    </li>
    <li>
      <a href="05-Plot-BarPlot.html">Bar Chart</a>
    </li>
    <li>
      <a href="05-Plot-PieChart.html">Pie Chart</a>
    </li>
    <li>
      <a href="05-Plot-BoxPlot.html">Box Plot</a>
    </li>
    <li>
      <a href="05-Plot-Histogram.html">Histogram</a>
    </li>
    <li>
      <a href="05-Plot-Forest-Plot.html">Forest Plot</a>
    </li>
    <li>
      <a href="05-Plot-Flow-Chart.html">Flow Chart</a>
    </li>
    <li>
      <a href="05-Plot-Some-Interesting.html">Some Interesting Plots</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-calculator"></span>
     
    Statistical Analysis
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="06-Analysis-Linear-Regression.html">Linear Regression</a>
    </li>
    <li>
      <a href="06-Analysis-Logistic-Regression.html">Logistic Regression</a>
    </li>
    <li>
      <a href="06-Analysis-Mixed-Model.html">Mixed Model</a>
    </li>
    <li>
      <a href="06-Analysis-MMRM.html">Mixed Model Repeated Measures</a>
    </li>
    <li>
      <a href="06-Analysis-GEE.html">Generalized Estimating Equation</a>
    </li>
    <li>
      <a href="06-Analysis-ANOVA.html">Analysis of Variance</a>
    </li>
    <li>
      <a href="06-Analysis-Survival-Analysis.html">Survival Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Survival-Competing-Risk.html">Survival Analysis - Competing Risk</a>
    </li>
    <li>
      <a href="06-Analysis-Missing-Data.html">Missing Data Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-MI-Implementation.html">Multiple Imputation Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-SSD.html">Safety Signal Detection and Evaluation</a>
    </li>
    <li>
      <a href="06-Analysis-Meta-Analysis.html">Meta Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-PK-and-PD.html">PK and PD Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-Time-Series-Analysis.html">Time Series Analysis</a>
    </li>
    <li>
      <a href="06-Analysis-SEM.html">Structural Equation Modeling</a>
    </li>
    <li>
      <a href="06-Analysis-Factor-Analysis.html">Factor Analysis</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-bar-chart"></span>
     
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="07-ML-Bayesian-Theory.html">Bayesian Theory</a>
    </li>
    <li>
      <a href="07-ML-Bayesian-Analysis.html">Bayesian Analysis</a>
    </li>
    <li>
      <a href="07-ML-Regularization-Penalized-Regression.html">Regularization Penalized Regression</a>
    </li>
    <li>
      <a href="07-ML-Loss-Regression.html">Loss Functions in Machine Learning</a>
    </li>
    <li>
      <a href="07-ML-PCA.html">Principal Component Analysis</a>
    </li>
    <li>
      <a href="07-ML-KNN.html">K-Nearest Neighbors</a>
    </li>
    <li>
      <a href="07-ML-SVM.html">Support Vector Machine</a>
    </li>
    <li>
      <a href="07-ML-Tree-Models.html">Tree Models</a>
    </li>
    <li>
      <a href="07-ML-LDA.html">Linear Discriminant Analysis</a>
    </li>
    <li>
      <a href="07-ML-Cluster-Analysis.html">Cluster Analysis</a>
    </li>
    <li>
      <a href="07-ML-Neural-Networks.html">Neural Network</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="08-CV.html">
    <span class="fa fa-file-pdf-o"></span>
     
    CV
  </a>
</li>
<li>
  <a href="mailto:zehuibai@outlook.com">
    <span class="fa fa-envelope-o"></span>
     
    Contact me
  </a>
</li>
<li>
  <a href="https://github.com/Zehuibai">
    <span class="fa fa-github"></span>
     
    GitHub
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore"><p><img src="logo.png"
style="width:3in" /><br />
Analysis of Variance</p></h1>

</div>


<div id="anova" class="section level1">
<h1>ANOVA</h1>
<div id="regression-analysis" class="section level2">
<h2>Regression analysis</h2>
<p>Regression analysis attempts to explain data (the dependent variable
scores) in terms of a set of independent variables or predictors (the
model) and a residual component (error). Typically, a researcher who
applies regression is interested in predicting a quantitative dependent
variable from one or more quantitative independent variables, and in
determining the relative contribution of each independent variable to
the prediction: there is interest in what proportion of the variation in
the dependent variable can be attributed to variation in the independent
variable(s).</p>
<p>Regression also may employ categorical (also known as nominal or
qualitative) predictors: the use of independent variables such as sex,
marital status and type of teaching method is common.</p>
<p>Moreover, as regression is the elementary form of GLM, it is possible
to construct regression GLMs equivalent to any ANOVA and ANCOVA GLMs by
selecting and organizing quantitative variables to act as categorical
variables. Nevertheless, the convention of referring to these particular
quantitative variables as categorical variables will be maintained.</p>
</div>
<div id="analysis-of-variance" class="section level2">
<h2>Analysis of variance</h2>
<p>ANOVA also can be thought of in terms of a model plus error. Here,
the dependent variable scores constitute the data, the experimental
conditions constitute the model and the component of the data not
accommodated by the model, again, is represented by the error term.
Typically, the researcher applying ANOVA is interested in whether the
mean dependent variable scores obtained in the experimental conditions
differ significantly. This is achieved by determining how much variation
in the dependent variable scores is attributable to differences between
the scores obtained in the experimental conditions, and comparing this
with the error term, which is attributable to variation in the dependent
variable scores within each of the experimental conditions: there is
interest in what proportion of variation in the dependent variable can
be attributed to the manipulation of the experimental variable(s).</p>
<p>Although the dependent variable in ANOVA is most likely to be
measured on a quantitative scale, the statistical comparison is drawn
between the groups of subjects receiving different experimental
conditions and is categorical in nature, even when the experimental
conditions differ along a quantitative scale. Therefore, ANOVA is a
particular type of regression analysis that employs quantitative
predictors to act as categorical predictors.</p>
</div>
<div id="analysis-of-covariance" class="section level2">
<h2>Analysis of covariance</h2>
<p>As ANCOVA is the statistical technique that combines regression and
ANOVA, it too can be described in terms of a model plus error. As in
regression and ANOVA, the dependent variable scores constitute the data,
but the model includes not only experimental conditions, but also one or
more quantitative predictor variables. These quantitative predictors,
known as covariates (also concomitant or control variables), represent
sources of variance that are thought to influence the dependent
variable, but have not been controlled by the experimental procedures.
ANCOVA determines the covariation (correlation) between the covariate(s)
and the dependent variable and then removes that variance associated
with the covariate(s) from the dependent variable scores, prior to
determining whether the differences between the experimental condition
(dependent variable score) means are significant.</p>
<p>As mentioned, this technique, in which the influence of the
experimental conditions remains the major concern, but one or more
quantitative variables that predict the dependent variable also are
included in the GLM, is labelled ANCOVA most frequently, and in
psychology is labelled ANCOVA exclusively (e.g. Cohen &amp; Cohen, 1983;
Pedhazur, 1997, cf. Cox &amp; McCullagh, 1982). A very important, but
seldom emphasized, aspect of the ANCOVA method is that the relationship
between the covariate(s) and the dependent variable, upon which the
adjustments depend, is determined empirically from the data.</p>
</div>
<div id="glm-approach" class="section level2">
<h2>GLM approach</h2>
<pre><code>1. Conceptually, a major advantage is the continuity the GLM reveals between regression, ANOVA and ANCOVA. Rather than having to learn about three apparently discrete techniques, it is possible to develop an understanding of a consistent modelling approach that can be applied to the different circumstances covered by regression, ANOVA and ANCOVA. A number of practical advantages also stem from the utility of the simply conceived and easily calculated error terms. The GLM conception divides data into model and error, and it follows that the better the model explains the data, the less the error. Therefore, the set of predictors constituting a GLM can be selected by their ability to reduce the error term. Comparing a GLM of the data that contains the predictor(s) under consideration with a GLM that does not, in terms of error reduction, provides a way of estimating effects that is both intuitively appreciable and consistent across regression, ANOVA and ANCOVA applications. 
2. Moreover, as most GLM assumptions concern the error terms, residuals, the error term estimates, provide a common means by which the assumptions underlying regression, ANOVA and ANCOVA can be assessed. This also opens the door for sophisticated statistical techniques, developed primarily to assist regression error analysis, to be applied to both ANOVA and ANCOVA. 
3. Finally, recognizing ANOVA and ANCOVA as instances of the GLM also provides connection to an extensive and useful literature on methods, analysis strategies and related techniques, such as structural equation modelling, which are pertinent to experimental and non-experimental analyses alike</code></pre>
</div>
<div id="ancova" class="section level2">
<h2>ANCOVA</h2>
<p><strong>ANCOVA (Analysis of Covariance) Overview</strong></p>
<p>ANCOVA is a blend of ANOVA and regression, allowing researchers to
adjust for the effects of one or more continuous covariates that might
influence the dependent variable. This method is useful for enhancing
the precision of the analysis by controlling for variables that are not
the main focus of the study but could affect the outcome.</p>
<ul>
<li><p><strong>Covariates</strong>: These are variables that are
expected to influence the dependent variable. They are included in the
ANCOVA model to control for their effects, thus isolating the effect of
the independent variable(s) more effectively. Covariates are continuous
predictor variables, unlike the categorical factors in ANOVA.</p></li>
<li><p><strong>Confounding Variables</strong>: Unlike covariates, which
are related only to the dependent variable, confounding variables affect
both the independent and dependent variables. They introduce spurious
associations, making it hard to discern the true effect of the
independent variable.</p></li>
</ul>
<p><img src="02_Plots/ANOVA/ACNOVA_Overview.png" /></p>
<p><strong>Reducing Within-Group Error Variance</strong></p>
<p>By incorporating covariates into the analysis, ANCOVA can minimize
the error variance within groups. This is crucial for:</p>
<ul>
<li><p>Maximizing the between-groups variance, which helps in detecting
true effects of the treatments or conditions being studied.</p></li>
<li><p>Enhancing the statistical power of the test, leading to a larger
F-statistic and more robust conclusions.</p></li>
<li><p><strong>Importance of Independence</strong>: The covariate should
not be affected by the treatment or condition. If there is a significant
relationship between the covariate and the treatment, then the covariate
may actually be a confounder rather than just a covariate. This
complicates the analysis because it suggests that adjustments for this
variable might need more sophisticated methods like mediation analysis,
rather than just control through ANCOVA.</p></li>
<li><p><strong>Testing Independence</strong>: This can be assessed by
using a one-way ANOVA to check if the covariate significantly varies
across the treatment groups. If it does, this violates the assumption of
independence, indicating that the covariate might interact with the
independent variable(s) in influencing the dependent variable.</p></li>
</ul>
<p><strong>ANCOVA Model</strong></p>
<p>The general linear model (GLM) for ANCOVA is expressed as: <span
class="math display">\[ Y_{ij} = \mu + \alpha_j + \beta Z_{ij} +
\epsilon_{ij} \]</span></p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the overall mean.</li>
<li><span class="math inline">\(\alpha_j\)</span> is the effect of the
jth treatment.</li>
<li><span class="math inline">\(\beta\)</span> is the regression
coefficient for the covariate.</li>
<li><span class="math inline">\(Z_{ij}\)</span> is the score of the
covariate for the ith subject in the jth group.</li>
<li><span class="math inline">\(\epsilon_{ij}\)</span> represents the
random error.</li>
</ul>
<p>This model combines the categorical treatment effects (as in ANOVA)
with the continuous influence of the covariates (as in regression). The
regression coefficient <span class="math inline">\(\beta\)</span> shows
how changes in the covariate are associated with changes in the
dependent variable, independent of the treatment effect.</p>
</div>
</div>
<div id="one-way-anova" class="section level1">
<h1>One-way ANOVA</h1>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>These are models for data from experiments where several groups are
compared, and where the sample sizes are equal for all groups.
Independence of data values is a crucial assumption for these models. If
they are not independent, then you might be able to use one of the
alternatives. Other assumptions strictly needed for these models are
homogeneity of error variance and normality of the observations within
each group. But these are not as important as the independence
assumption (unless severely violated).</p>
<p>The one-way analysis of variance (ANOVA) is used to test the
difference in our dependent variable between three or more different
groups of observations. Our grouping variable is our independent
variable. In other words, we use the one-way ANOVA when we have a
research question with a continuous dependent variable and a categorical
independent variable with three or more categories in which different
participants are in each category.</p>
<p>The one-way ANOVA is also known as an independent factor ANOVA (note
that it is NOT the same as a factorial ANOVA, which means there are two
or more IVs!).</p>
<p>The mathematical formula for one-way ANOVA can be expressed as: Total
Sum of Squares (SST) = Sum of Squares Between Groups (SSB) + Sum of
Squares Within Groups (SSW)</p>
<p><strong>Model Representation:</strong></p>
<p><span class="math inline">\(Y_{ij} = \mu + \alpha_j +
\epsilon_{ij}\)</span></p>
<ul>
<li><span class="math inline">\(Y_{ij}\)</span>: The response
variable.</li>
<li><span class="math inline">\(\mu\)</span>: The overall mean of the
response.</li>
<li><span class="math inline">\(\alpha_j\)</span>: The effect of the
<span class="math inline">\(j\)</span>th group.</li>
<li><span class="math inline">\(\epsilon_{ij}\)</span>: The random error
component.</li>
</ul>
<p><strong>Components of Variance:</strong> - <strong>Total Sum of
Squares (SST)</strong>: Represents the total variation in the data. -
<strong>Sum of Squares Between Groups (SSB)</strong>: Represents the
variation between the means of the groups. - <strong>Sum of Squares
Within Groups (SSW)</strong>: Represents the variation within each
group.</p>
<p><strong>Purpose and Hypotheses of One-way ANOVA:</strong> -
<strong>Omnibus Test</strong>: One-way ANOVA is an omnibus statistic
used to test if there is any difference among the group means. -
<strong>Null Hypothesis (H0)</strong>: There is no difference in means
between the groups; all group means are the same. - <strong>Alternative
Hypothesis (H1)</strong>: There is a difference in means between the
groups; at least one group has a significantly different mean compared
to the other groups.</p>
<p><strong>Additional Notes:</strong> - One-way ANOVA does not specify
where the differences lie between the means. For identifying specific
differences, one needs to perform planned contrasts or post-hoc
procedures, which are discussed in subsequent chapters.</p>
<p>This summary captures the essence of the concepts related to one-way
ANOVA as presented in the image. If you need further explanation on any
of these points or additional statistical concepts, feel free to
ask!</p>
</div>
<div id="modeling-assumptions-and-basic-analysis"
class="section level2">
<h2>Modeling Assumptions and Basic Analysis</h2>
<p>The model for the data throughout this chapter is assumed to be <span
class="math display">\[
y_{i j}=\mu_{i}+\varepsilon_{i j}
\]</span> where the <span class="math inline">\(y_{i j}\)</span> are the
observed data, with <span class="math inline">\(i=1, \ldots, g\)</span>
indicating group and <span class="math inline">\(j=1, \ldots, n\)</span>
indicating measurement observed within a group. This is a full-rank
parameterization, unlike the default PROC GLM parameterization, which is
not of full rank since it includes the “intercept” term <span
class="math inline">\(\gamma\)</span>.</p>
<p>The <span class="math inline">\(\mu_{i}\)</span> are assumed to be
fixed, unknown population mean values, and the errors <span
class="math inline">\(\varepsilon_{i j}\)</span> are assumed to be
random variables that</p>
<ul>
<li>have mean zero,</li>
<li>have constant variance <span
class="math inline">\(\sigma^{2}\)</span>,</li>
<li>are independent, and</li>
<li>are normally distributed.</li>
</ul>
<p><strong>Constant Variance</strong></p>
<p>The assumption of constant variance is also called homoscedasticity,
and its violation is called heteroscedasticity. As it turns out, at
least in the balanced one-way model, heteroscedasticity is not
necessarily much of a problem, and inferences can still be approximately
valid with mild violations of this assumption.</p>
<p><strong>Levene’s Test for Homogeneity</strong></p>
<p>There are also formal statistical tests for homoscedasticity,
available with the HOVTEST option in the GLM MEANS statement; you can
use this in conjunction with the informal descriptive and graphical
assessments.</p>
<pre><code>proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 means Diet / hovtest;
run; </code></pre>
<p><strong>Independence</strong></p>
<p>The assumption that the measurements are independent is crucial. In
the extreme, its violation can lead to estimates and inferences that are
effectively based on much less information than it might appear that you
have, based on the sample size of your data set. Common ways for this
assumption to be violated include</p>
<ol style="list-style-type: decimal">
<li>there are repeated measurements on the subjects (measurements on the
same subject are usually correlated),</li>
<li>subjects are “paired” in some fashion, such as the husband/wife</li>
<li>the data involve time series or spatial autocorrelation.</li>
</ol>
<p>As with heteroscedasticity, autocorrelation can be diagnosed with
informal graphical and formal inferential measures, but the other two
violations (which are probably more common in ANOVA) require knowledge
of the design for the data—how it was collected. You can check for the
various types of dependence structure using hypothesis tests, but,
again, testing methods should not be used exclusively to diagnose
seriousness of the problem.</p>
<p><strong>Normality</strong></p>
<p>It is usually not critical that the distribution of the response be
precisely normal: the Central Limit Theorem states that estimated group
means are approximately normally distributed even if the observations
have non-normal distributions. This happy fact provides approximate
largesample justification for the methods described in this chapter, as
long as the other assumptions are valid. However, if the sample sizes
are small and the distributions are not even close to normal, then the
Central Limit Theorem may not apply.</p>
<p><strong>Testing the Normality Assumption in ANOVA</strong></p>
<pre><code>proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 output out=wlossResid r=wlossResid;
run;
proc univariate data=wlossResid normal;
 var wlossResid;
 ods select TestsForNormality;
run; </code></pre>
<p><strong>Check Assumptions for One-Way ANOVA</strong></p>
<p><strong>Assumptions for One-Way ANOVA:</strong> 1. <strong>Normal
Distribution of the Dependent Variable</strong>: - Methods to check: -
Shapiro-Wilk test - Q-Q plot - Analysis of skewness and kurtosis -
Visual inspection of data distribution</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Homogeneity of Variances</strong>:
<ul>
<li>Tested using Levene’s test.</li>
</ul></li>
<li><strong>Dependent Variable is Interval or Ratio</strong>:
<ul>
<li>This indicates that the dependent variable should be
continuous.</li>
</ul></li>
<li><strong>Independence of Scores</strong>:
<ul>
<li>Scores must be independent between groups.</li>
</ul></li>
</ol>
<p><strong>Assumptions Cannot be Directly Tested:</strong> - Assumptions
3 and 4 are based on knowledge of the data rather than empirical
testing.</p>
<p><strong>Response to Assumption Violations</strong></p>
<ul>
<li><strong>Normality Satisfied and Homogeneity of Variance
Satisfied</strong>:
<ul>
<li>Use one-way ANOVA (standard ANOVA function).</li>
</ul></li>
<li><strong>Normality Satisfied but Homogeneity of Variance Not
Satisfied</strong>:
<ul>
<li>Use Welch’s F-test (modified ANOVA function that does not assume
equal variances).</li>
</ul></li>
<li><strong>Normality Not Satisfied (Regardless of Homogeneity of
Variance)</strong>:
<ul>
<li>Use Kruskal-Wallis test, which is a non-parametric alternative to
the one-way ANOVA.</li>
</ul></li>
</ul>
<p><strong>Robustness of ANOVA</strong></p>
<ul>
<li>One-way ANOVA is somewhat robust to violations of normality and
homogeneity of variance, but this robustness applies primarily when:
<ul>
<li>Group sizes and variances are equal or nearly equal.</li>
<li>Variances should not differ drastically (e.g., no more than a 2:1
ratio).</li>
<li>Group sizes should not be extremely unbalanced (e.g., no fewer than
10 cases in the smallest group).</li>
</ul></li>
</ul>
<p><strong>Implications of Violation:</strong></p>
<ul>
<li>If the group with the larger variance also has more cases, it can
lead to an F-statistic that is non-significant or smaller than it should
be.</li>
<li>Conversely, if the group with the larger variance has fewer cases,
the F-statistic can be misleadingly high (significant or larger than it
should be).</li>
</ul>
</div>
<div id="parameter-estimates" class="section level2">
<h2>Parameter Estimates</h2>
<p><strong>Means and SD</strong></p>
<p>The estimated population means are the individual sample means for
each group, <span class="math display">\[
\hat{\mu}_{i}=\bar{y}_{i}=\frac{\sum_{j=1}^{n} y_{i j}}{n},
\]</span> and the estimated common variance of the errors is the pooled
mean squared error (MSE), <span class="math display">\[
\hat{\sigma}^{2}=\mathrm{MSE}=\frac{\sum_{i=1}^{g}
\sum_{j=1}^{n}\left(y_{i j}-\bar{y}_{i}\right)^{2}}{g(n-1)}
\]</span> These formulas are special cases of the general formulas <span
class="math inline">\(\hat{\boldsymbol{\beta}}=\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Y}\)</span> and <span
class="math inline">\(\hat{\sigma}^{2}=(\mathbf{Y}-\mathbf{X}
\hat{\boldsymbol{\beta}})^{\prime}(\mathbf{Y}-\mathbf{X}
\hat{\boldsymbol{\beta}}) / d f\)</span>; here the <span
class="math inline">\(\mathbf{X}\)</span> matrix is full rank.</p>
<p><strong>Simultaneous Confidence Intervals</strong></p>
<p>The general form of the simultaneous confidence interval <span
class="math display">\[
\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}} \pm c_{\alpha} s . e
.\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)
\]</span> produces intervals for the difference of means <span
class="math inline">\(\mu_{i}-\mu_{i^{\prime}}\)</span> having the form
<span class="math display">\[
\bar{y}_{i}-\bar{y}_{i^{\prime}} \pm c_{\alpha} \hat{\sigma} \sqrt{2 /
n}
\]</span> where <span class="math inline">\(c_{\alpha}\)</span> is a
critical value that is selected to make the <span
class="math inline">\(\mathrm{FWE}=\alpha .\)</span> The term <span
class="math inline">\(\hat{\sigma} \sqrt{2 / n}\)</span> is the square
root of the estimated variance of the difference, also called the
standard error of the estimated difference.</p>
<p>In the case of non-multiplicity-adjusted confidence intervals, you
set <span class="math inline">\(c_{\alpha}\)</span> equal to the <span
class="math inline">\(1-\alpha / 2\)</span> quantile of the <span
class="math inline">\(t\)</span> distribution, <span
class="math inline">\(t_{1-\alpha / 2, g(n-1)} .\)</span> Each
confidence interval thus constructed will contain the true difference
<span class="math inline">\(\mu_{i}-\mu_{i^{\prime}}\)</span> with
confidence <span class="math inline">\(100(1-\alpha) \%\)</span>.</p>
<p>However, when you look at many intervals (say, <span
class="math inline">\(k\)</span> of them) then all <span
class="math inline">\(k\)</span> intervals will contain their respective
true differences simultaneously with much lower confidence. The
Bonferroni inequality gives a pessimistic estimate of the simultaneous
confidence of these <span class="math inline">\(k\)</span> non
multiplicity-adjusted intervals as <span class="math inline">\(100
\times(1-k \alpha) \%\)</span>. This implies that you can construct
Bonferroni-adjusted confidence intervals by setting <span
class="math inline">\(c_{\alpha}=t_{1-\alpha^{\prime} / 2,
g(n-1)}\)</span>, where <span
class="math inline">\(\alpha^{\prime}=\alpha / k\)</span>. However, the
Bonferroni method is conservative: the value <span
class="math inline">\(c_{\alpha}=t_{1-\alpha^{\prime} / 2,
g(n-1)}\)</span> is larger than it needs to be, in the sense that the
actual simultaneous confidence level will be somewhat larger than the
nominal level <span class="math inline">\(100(1-\alpha) \%\)</span>.</p>
</div>
<div id="relationship-between-f-test-and-t-test" class="section level2">
<h2>Relationship Between F-test and T-test</h2>
<p><strong>Relationship Between F-test and T-test</strong></p>
<ul>
<li><p><strong>ANOVA (Analysis of Variance)</strong> simultaneously
examines for differences between any number of conditions while
maintaining the Type I error rate at a specified significance level,
typically 0.05. ANOVA can be thought of as an extension of the t-test
for more than two conditions, maintaining Type I error constancy. This
is evident when ANOVA is applied to just two conditions, in which case
it effectively becomes identical to performing a t-test. The F and t
statistics derived in such cases will directly correspond, resulting in
identical p-values.</p></li>
<li><p><strong>Transformation Between F and T Statistics</strong>: If
you are working with two groups and conduct an F-test, you can directly
convert the F-value to a t-statistic (and vice versa) using the
following formulas: <span class="math display">\[
F = t^2
\]</span> <span class="math display">\[
t = \sqrt{F}
\]</span> This conversion is useful if you initially conduct one test
and then realize you need the other for comparison or consistency in
reporting.</p></li>
<li><p><strong>One-Tailed T-Test vs. ANOVA</strong>: Despite the direct
relationship between t and F values, confusion may arise, especially
under specific testing conditions like directional hypotheses. For
instance, a one-tailed t-test assessing a directional hypothesis may
yield significant results (e.g., <span class="math inline">\(t(20) =
1.725, p = 0.05\)</span>), but an ANOVA performed on the same data could
yield an F-value (e.g., <span class="math inline">\(F(1,20) = 2.976, p =
0.100\)</span>) that is not significant at a 0.05 level. This
discrepancy arises because the F-test inherently addresses a two-tailed
question even when used in a one-tailed format, as it does not
inherently support directional hypotheses due to its reliance on squared
differences (removing directionality).</p></li>
<li><p><strong>Implications of F-test Characteristics</strong>: The
F-test is fundamentally a one-tailed test, but it does not inherently
support testing directional hypotheses. It’s designed to compare
variances and, as such, examines whether one variance is significantly
greater than another without implying a direction (positive or negative
difference). This is critical to understand when choosing between a
one-tailed or two-tailed F-test:</p>
<ul>
<li><strong>One-Tailed F-Test</strong>: Appropriate if your research
hypothesis predicts a specific directional effect (positive or
negative).</li>
<li><strong>Two-Tailed F-Test</strong>: More suitable for
non-directional hypotheses or when the direction of the effect is not
specified.</li>
</ul></li>
<li><p><strong>Understanding Test Distributions</strong>: The choice
between a one-tailed and a two-tailed test also reflects the underlying
distribution of the test statistic. Symmetrical distributions like the t
and z distributions inherently support two-tailed testing. In contrast,
asymmetrical distributions like those used in F-tests and chi-square
tests inherently do not have a “one-tailed vs. two-tailed” option as
they are based on distributions with only one tail. This structural
aspect of the test statistic dictates how hypothesis testing is
approached, influencing the interpretation and application of test
results.</p></li>
<li><p><strong>Statistical Power</strong>: A one-tailed test provides
greater statistical power than a two-tailed test at the same alpha
level, assuming the direction of the effect is correctly specified. This
is because a one-tailed test focuses the statistical analysis on one
direction, increasing the ability to detect an effect if one exists in
that specified direction.</p></li>
</ul>
</div>
<div id="r-implementation" class="section level2">
<h2>R Implementation</h2>
<ul>
<li><code>df.residual</code> returns the degrees of freedom of the
residual</li>
<li><code>coef</code> returns the estimated coefficients (and sometimes
their standard deviations)</li>
<li><code>residuals</code> returns residuals</li>
<li><code>deviance</code> returns the variance</li>
<li><code>fitted</code> returns the fitted value</li>
<li><code>logLik</code> calculates the log-likelihood and returns the
number of arguments</li>
<li><code>AIC</code> computes the Akaike information criterion (AIC)
(depending on logLik())</li>
</ul>
<pre class="r"><code>## Date exploration

Intelligenz &lt;- data.frame(IQ.Werte=c(99, 131, 118, 112, 128, 136, 120, 107,
                                     134, 122,134, 103, 127, 121, 139, 114, 
                                     121, 132,120, 133, 110, 141, 118, 124, 
                                     111, 138, 120,117, 125, 140, 109, 128, 
                                     137, 110, 138, 127, 141, 119, 148),
                             Fach=c(rep(1,10),rep(2,8),rep(3,9),rep(4,12)))
Intelligenz$Fach &lt;- factor(Intelligenz$Fach,labels=c(&quot;I&quot;, &quot;II&quot;, &quot;III&quot;,&quot;IV&quot;))

## Compute summary statistics
group_by(Intelligenz, Fach) %&gt;%
  dplyr::summarise(
    count = n(),
    mean = mean(IQ.Werte, na.rm = TRUE),
    sd = sd(IQ.Werte, na.rm = TRUE)
  )</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Fach"],"name":[1],"type":["fct"],"align":["left"]},{"label":["count"],"name":[2],"type":["int"],"align":["right"]},{"label":["mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["sd"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"I","2":"10","3":"120.7000","4":"12.08351"},{"1":"II","2":"8","3":"123.8750","4":"11.69172"},{"1":"III","2":"9","3":"123.8889","4":"11.17413"},{"1":"IV","2":"12","3":"128.2500","4":"12.75735"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>## Visualize your data with ggpubr
# library(&quot;ggpubr&quot;)
ggboxplot(Intelligenz, x = &quot;Fach&quot;, y = &quot;IQ.Werte&quot;, 
          color = &quot;Fach&quot;, 
          palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;,&quot;#E7298A&quot;),
          order = c(&quot;I&quot;,&quot;II&quot;,&quot;III&quot;,&quot;IV&quot;),
          ylab = &quot;IQ.Werte&quot;, xlab = &quot;Fach&quot;)</code></pre>
<p><img src="06-Analysis-ANOVA_files/figure-html/One-Way%20ANOVA%20Test-1.png" width="672" /></p>
<pre class="r"><code>## Model Fitting
Intelligenz.aov &lt;- aov(IQ.Werte~Fach, data=Intelligenz)
summary(Intelligenz.aov)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)
## Fach         3    319   106.4   0.736  0.538
## Residuals   35   5060   144.6</code></pre>
</div>
<div id="sas-implementation" class="section level2">
<h2>SAS Implementation</h2>
<p>Comparing Weight Loss for Five Different Regimens Ott (1988) reports
an experiment undertaken to evaluate the effectiveness of five
weightreducing agents. There are 10 male subjects in each group who have
been randomly assigned to one of the regimens A, B, C, D, or E. This is
a classic example of the balanced one-way ANOVA setup. After a fixed
length of time, the weight loss of each of the 50 subjects is measured.
The goal of the study is to rank the treatments, to the extent possible,
using the observed weight loss data for the 50 subjects. These box plots
are convenient for depicting and comparing the distributions of the data
in each treatment group.</p>
<pre><code>data Wloss;
 do Diet = &#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;,&#39;E&#39;;
 do i = 1 to 10;
 input Wloss @@;
 output;
 end;
 end;
datalines;
12.4 10.7 11.9 11.0 12.4 12.3 13.0 12.5 11.2 13.1
 9.1 11.5 11.3 9.7 13.2 10.7 10.6 11.3 11.1 11.7
 8.5 11.6 10.2 10.9 9.0 9.6 9.9 11.3 10.5 11.2
 8.7 9.3 8.2 8.3 9.0 9.4 9.2 12.2 8.5 9.9
12.7 13.2 11.8 11.9 12.2 11.2 13.7 11.8 11.5 11.7
;
proc sgplot data=Wloss;
 vbox Wloss/category=Diet;
run;</code></pre>
</div>
<div id="model-diagnosis" class="section level2">
<h2>Model Diagnosis</h2>
<ol style="list-style-type: decimal">
<li>Homogeneity Test
<ul>
<li>Homogeneity of variance assumption using Plot</li>
<li>Homogeneity of variance assumption using Levene’s test, which is
less sensitive to departures from normal distribution. (insensitive to
deviation from normal distribution)</li>
<li>Homogeneity of variance assumption with no assumption of equal
variances (relaxes the homogeneity of variance assumptions)</li>
</ul></li>
<li>Normality assumption</li>
<li>Multiple Test</li>
</ol>
<div id="homogeneity-test" class="section level3 unnumbered">
<h3 class="unnumbered">Homogeneity Test</h3>
<pre class="r"><code>## Check the homogeneity of variance assumption
plot(Intelligenz.aov, 1)</code></pre>
<p><img src="06-Analysis-ANOVA_files/figure-html/Homogeneity%20Test-1.png" width="672" /></p>
<pre class="r"><code>## Levene’s test,  Homogeneity of variance assumption
# library(car)
leveneTest(IQ.Werte ~ Fach, data = Intelligenz)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["F value"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"3","2":"0.1339771","3":"0.9391501","_rn_":"group"},{"1":"35","2":"NA","3":"NA","_rn_":""}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>## With no assumption of equal variances
oneway.test(IQ.Werte~Fach, data=Intelligenz)</code></pre>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  IQ.Werte and Fach
## F = 0.64123, num df = 3.000, denom df = 18.758, p-value = 0.598</code></pre>
</div>
<div id="normality-assumption" class="section level3 unnumbered">
<h3 class="unnumbered">Normality assumption</h3>
<p>Using QQ Plot or Shapiro–Wilk test to test residuals</p>
<pre class="r"><code>## Check the normality assumption
plot(Intelligenz.aov, 2)</code></pre>
<p><img src="06-Analysis-ANOVA_files/figure-html/Normality%20assumption-1.png" width="672" /></p>
<pre class="r"><code>## Shapiro–Wilk test to test residuals
## Extract the residuals and run Shapiro-Wilk test
aov_residuals &lt;- residuals(object = Intelligenz.aov )
shapiro.test(x = aov_residuals )</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  aov_residuals
## W = 0.96021, p-value = 0.1813</code></pre>
</div>
<div id="violation-of-assumptions" class="section level3 unnumbered">
<h3 class="unnumbered">Violation of assumptions</h3>
<p><strong>Random Effects Models</strong></p>
<p><span class="math display">\[Y_{ij} = \mu + \alpha_i +
\epsilon_{ij},\]</span> We assume <span class="math inline">\(\alpha_i
\; \textrm{i.i.d.} \sim N(0, \sigma_{\alpha}^2).\)</span> and <span
class="math display">\[E[Y_{ij}] = \mu\]</span> <span
class="math display">\[\text{Var}(Y_{ij}) = \sigma_{\alpha}^2 +
\sigma^2\]</span> <span class="math display">\[\text{Cor}(Y_{ij},
Y_{kl}) =    \left\{   \begin{array}{cc}     0 &amp; i \neq k
\\     \sigma_{\alpha}^2 / (\sigma_{\alpha}^2 + \sigma^2) &amp; i = k, j
\neq l (\text{intraclass correlation (ICC)})\\     1 &amp; i = k, j =
l   \end{array}   \right.\]</span></p>
<p>MLE is not usable for parameter estimation for the variance
components <span class="math inline">\(\sigma_a^2\)</span> and <span
class="math inline">\(\sigma^2\)</span>, <strong>Restricted maximum
likelihood (REML)</strong> is applied here. REML is less biased. The
parameter <span class="math inline">\(\mu\)</span> is estimated with
maximum-likelihood assuming that the variances are known.</p>
<p><strong>Non-Parametric Test</strong></p>
<p>Non-parametric alternative to one-way ANOVA test,
<strong>Kruskal-Wallis rank sum test</strong>, which can be used when
ANOVA assumptions are not met.</p>
<pre><code>kruskal.test(IQ.Werte~Fach, data=Intelligenz)</code></pre>
</div>
</div>
<div id="unbalanced-one-way-anova-and-analysis-of-covariance-ancova"
class="section level2">
<h2>Unbalanced One-Way ANOVA and Analysis-of-Covariance (ANCOVA)</h2>
<p>These data are similar to the balanced ANOVA except that sample sizes
may be unbalanced, or the comparisons between means might be done while
controlling one or more covariates (e.g., confounding variables,
pre-experimental measurements). The distributional assumptions are
identical to those of the ANOVA, with the exception that for ANCOVA, the
<strong>normality assumption must be evaluated by using
residuals</strong> and not actual data values. When discussing
statistical analysis involving <strong>Unbalanced One-Way ANOVA</strong>
and <strong>Analysis-of-Covariance (ANCOVA)</strong>, it’s crucial to
consider how these methods differ from a balanced ANOVA and what
specific challenges and adjustments they require.</p>
<div id="unbalanced-one-way-anova" class="section level3">
<h3>Unbalanced One-Way ANOVA</h3>
<p>Unbalanced ANOVA refers to situations where the sample sizes across
the groups being compared are not equal. This imbalance can affect the
analysis in several ways:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Power and Error Rates</strong>: Unequal group sizes can
lead to reductions in statistical power and can impact the error rates.
In general, when group sizes are equal, the power of the ANOVA test is
maximized, and the estimation of variance is more reliable.</p></li>
<li><p><strong>Variance Estimation</strong>: In a balanced ANOVA, the
estimation of within-group and between-group variances are
straightforward and less susceptible to sample size differences. In an
unbalanced design, the variances might be estimated with bias if the
larger sample sizes overly influence the mean estimates.</p></li>
<li><p><strong>Statistical Techniques</strong>: Certain adjustments may
be necessary when dealing with unbalanced data. For instance, using Type
III sum of squares in the ANOVA calculations helps handle the imbalance
by making the sums of squares independent of the order in which
variables are entered into the model. This is particularly important in
software like SAS or SPSS, where the type of sums of squares can be
specified.</p></li>
</ol>
</div>
<div id="analysis-of-covariance-ancova" class="section level3">
<h3>Analysis-of-Covariance (ANCOVA)</h3>
<p>ANCOVA is an extension of ANOVA that introduces covariates into the
analysis. These covariates are continuous variables that potentially
influence the dependent variable but are not the main focus of the
research. For instance, if you are studying the effect of a diet on
weight loss, age might be a covariate if it’s believed to affect weight
loss but is not the main variable of interest.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Control for Confounding</strong>: ANCOVA allows
researchers to statistically control for the effects of covariates,
which might confound the relationship between the dependent variable and
the independent variable(s). This enhances the accuracy of the
conclusions about the main effects.</p></li>
<li><p><strong>Assumption of Homogeneity of Regression Slopes</strong>:
One critical assumption in ANCOVA is that the relationship (slope)
between the covariate(s) and the dependent variable must be the same
across all groups (levels of the independent variable). This assumption
is known as the homogeneity of regression slopes and is crucial for the
proper application of ANCOVA.</p></li>
<li><p><strong>Evaluating Normality Using Residuals</strong>: Unlike
ANOVA, where normality is typically assessed using the actual data
values or transformed values, ANCOVA requires the evaluation of
normality through the residuals. Residuals are the differences between
the observed values and the values predicted by the covariate(s).
Analyzing residuals helps ensure that the adjustments made for the
covariates are appropriately accounting for their effects, and that the
error terms (residuals) of the model distribute normally.</p></li>
</ol>
</div>
<div id="practical-implications" class="section level3">
<h3>Practical Implications</h3>
<ul>
<li><strong>Statistical Software</strong>: When performing either
unbalanced ANOVA or ANCOVA, statistical software like R, SPSS, or SAS
can be utilized to handle complex calculations, and they offer options
to adjust for imbalances and include covariates effectively.</li>
<li><strong>Diagnostic Checks</strong>: It is essential to perform
diagnostic checks to validate the assumptions of homogeneity of
variances, normality of residuals, and homogeneity of regression slopes.
Plots like residual plots, Q-Q plots, or leverage plots can be
particularly helpful.</li>
</ul>
<p>In summary, while unbalanced ANOVA and ANCOVA introduce more
complexity into the analysis, they provide powerful tools for dealing
with real-world data where conditions are rarely perfectly balanced or
free from confounding variables. Understanding how to adjust for these
complexities can significantly enhance the validity and reliability of
the study’s findings.</p>
</div>
</div>
</div>
<div id="factorial-anova" class="section level1">
<h1>Factorial ANOVA</h1>
<div id="independent-factorial-anova" class="section level2">
<h2>Independent Factorial ANOVA</h2>
<p>Factorial ANOVA is a statistical method that extends the basic
principles of a one-way ANOVA to analyze the effects of two or more
independent variables simultaneously on a continuous dependent variable.
This methodology is highly versatile, supporting designs that assess
both the main effects of each factor and the interactions between them,
which can reveal more complex patterns of influence on the dependent
variable. Here’s a breakdown of the different types of factorial
designs, along with explanations of factorial ANOVA and its implications
for interpreting experimental results:</p>
<p><strong>Types of Factorial Designs:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Independent Factorial Design</strong>: This design
involves multiple between-group independent variables (IVs). Each factor
is manipulated across different groups of subjects without any
repetition within the same subject.</p></li>
<li><p><strong>Repeated Measures Factorial Design</strong>: Known as
within-group designs, these involve one or more factors being repeated
within the same subjects. This can also be referred to as a two-way (or
three-way, etc., depending on the number of IVs) repeated measures
ANOVA, where each subject is exposed to each condition.</p></li>
<li><p><strong>Mixed Factorial Design</strong>: This design incorporates
elements of both independent and repeated measures designs, where some
factors are manipulated between groups and others within the same
subjects.</p></li>
</ol>
<p><strong>Understanding Factorial ANOVA:</strong></p>
<ul>
<li><p><strong>One-way ANOVA</strong>: Primarily tests for differences
among two or more independent groups based on a single independent
variable. It’s used to determine whether the means of the groups are
significantly different, such as comparing the performance of students
from different schools.</p></li>
<li><p><strong>Factorial ANOVA</strong>: Unlike one-way ANOVA, factorial
ANOVA can test the effects of two or more independent variables on a
dependent variable. This approach not only examines the main effects of
each independent variable but also explores the interaction effects
between them. For instance, it could assess how different teaching
methods (one factor) affect various age groups (another factor)
concerning student performance.</p></li>
</ul>
</div>
<div id="repeated-factorial-anova" class="section level2">
<h2>Repeated Factorial ANOVA</h2>
<p>Repeated measures factorial designs are specialized instances of
randomized block designs, designed to handle data where measurements are
taken on the same subjects under different conditions. Unlike designs
where each measure is taken on independent subjects, these designs
consider the correlation between measures on the same subjects.</p>
<p><strong>Randomized Block and Repeated Measures Designs</strong></p>
<p>In randomized block designs, subjects are grouped into blocks based
on one or more characteristics that are expected to affect the outcome.
For example, subjects in one block might have high IQ scores, while
those in another have low IQ scores. Each block of subjects then
experiences the same experimental conditions, allowing the experiment to
control for the blocking variable.</p>
<p>When each block consists of only one subject who undergoes all
conditions, this setup becomes a repeated measures design. This design
is powerful for reducing variability caused by differences between
subjects because each subject acts as their own control.</p>
<p><strong>Counterbalancing in Crossover Designs</strong></p>
<p>Counterbalancing is used to control for order effects in studies
where subjects undergo multiple conditions. This is crucial because the
order in which conditions are presented can influence the results. For
instance, fatigue or learning might skew results in later conditions if
not properly managed.</p>
<p>To manage this, researchers can use several strategies:</p>
<ul>
<li><p><strong>Full Crossover Design:</strong> All possible orders of
conditions are used. For example, with three conditions (A, B, C), six
permutations (ABC, ACB, BAC, BCA, CAB, CBA) ensure that each condition’s
effect is not confounded by its position in the sequence. Subjects are
assigned to each order, balancing out any order effects.</p></li>
<li><p><strong>Factorial Model Construction:</strong> By including all
orders and crossing them with other experimental factors, a factorial
model can be constructed. This model will account for variances due to
order effects and their potential interactions with other variables in
the study.</p></li>
</ul>
<p><strong>Latin Square Designs</strong></p>
<p>Latin square designs offer a structured way to arrange treatments so
that each treatment appears only once in each row or column. This design
is particularly effective for controlling order effects when there are
more conditions:</p>
<ul>
<li><p><strong>Basic Setup:</strong> Each condition appears exactly once
in each row and each column, an approach that efficiently manages the
number of required subjects and conditions.</p></li>
<li><p><strong>Balanced Latin Squares:</strong> Sometimes referred to as
“digram-balanced,” these are designed such that each condition precedes
and follows every other condition. This balance only works when the
number of conditions is even.</p></li>
<li><p><strong>Adaptation for Odd Numbers of Conditions:</strong> When
the number of conditions is odd, balanced Latin squares are not
feasible. Instead, researchers might use randomly permuted Latin squares
to achieve a similar balance.</p></li>
</ul>
</div>
<div id="mixed-factorial-design" class="section level2">
<h2>Mixed factorial design</h2>
<p><strong>Mixed Factorial Design Overview</strong></p>
<p>Mixed factorial designs blend characteristics of both repeated
measures and independent groups factorial designs. In this type of
design, at least one factor is a “within-subjects” factor (meaning the
same subjects are measured under different conditions), and at least one
factor is a “between-subjects” factor (meaning different groups of
subjects are measured under each condition).</p>
<p><strong>General Linear Model (GLM) for Mixed Factorial
ANOVA</strong></p>
<p>The GLM for mixed factorial ANOVA accommodates the interaction
between independent and repeated measures within the same experimental
framework. This model allows researchers to assess not only the main
effects of each type of factor but also their interaction effects, which
can reveal how different levels of one factor affect responses at
different levels of another factor across different groups of
subjects.</p>
<p><strong>Equation:</strong></p>
<p><span class="math display">\[ Y_{ijk} = \mu + \tau_i + \alpha_j +
(\tau\alpha)_{ij} + \beta_k + (\tau\beta)_{ik} + (\alpha\beta)_{jk} +
(\tau\alpha\beta)_{ijk} + \epsilon_{ijk} \]</span></p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the overall mean or
grand mean of all observations.</li>
<li><span class="math inline">\(\tau_i\)</span> is the effect of the ith
level of the within-subjects factor.</li>
<li><span class="math inline">\(\alpha_j\)</span> is the effect of the
jth level of the between-subjects factor.</li>
<li><span class="math inline">\(\beta_k\)</span> represents the random
effects of subjects within the between-subjects factor.</li>
<li><span class="math inline">\((\tau\alpha)_{ij}\)</span> is the
interaction effect between the within-subjects factor and the
between-subjects factor.</li>
<li><span class="math inline">\((\tau\beta)_{ik}\)</span>, <span
class="math inline">\((\alpha\beta)_{jk}\)</span>, and <span
class="math inline">\((\tau\alpha\beta)_{ijk}\)</span> are the
higher-level interactions involving subjects.</li>
<li><span class="math inline">\(\epsilon_{ijk}\)</span> is the random
error associated with each observation.</li>
</ul>
<p><strong>Key Features of Mixed Factorial Designs:</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Complex Interactions</strong>: This design allows for the
examination of interactions between subject-based (within-subject)
factors and group-based (between-subject) factors, providing a deeper
understanding of how different variables influence each other.</p></li>
<li><p><strong>Efficient Use of Data</strong>: By combining both
within-subjects and between-subjects factors, mixed designs can make
more efficient use of data than pure between-subjects designs,
particularly in terms of controlling for potential confounding variables
that vary between individuals.</p></li>
<li><p><strong>Flexibility</strong>: Mixed designs offer great
flexibility in experimental setup, allowing researchers to tailor their
studies to specific research questions that involve both repeated
measures and independent group comparisons.</p></li>
</ol>
<p><strong>Statistical Analysis Considerations:</strong></p>
<ul>
<li><strong>Error Terms</strong>: The error structure in mixed factorial
designs can be complex. The model must account for variability between
subjects within groups and variability due to repeated measures on the
same subjects.</li>
<li><strong>Sphericity</strong>: The assumption of sphericity, which is
required in repeated measures ANOVA, must be checked and corrected if
violated. This assumption tests whether the variances of the differences
between all combinations of related group (level) means are equal.</li>
<li><strong>Multiple Comparisons</strong>: When significant interactions
are found, post-hoc tests are often necessary to explore these
interactions further. These tests can help clarify which specific levels
of the factors differ from each other.</li>
</ul>
</div>
<div id="introduction-1" class="section level2">
<h2>Introduction</h2>
<p><span class="math display">\[
Y_{i j k}=\mu+\alpha_{i}+\beta_{j}+(\alpha \beta)_{i j}+\epsilon_{i j k}
\]</span> - ai is the main effect of factor <span
class="math inline">\(A\)</span> at leveli - <span
class="math inline">\(\beta \mathrm{j}\)</span> is the main effect of
factor <span class="math inline">\(\mathrm{B}\)</span> at level <span
class="math inline">\(\mathrm{j}\)</span> - <span
class="math inline">\((aß)ij\)</span> is the interaction effect between
<span class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> for the level combination i,j (it is
not the product ai)</p>
<p>Test: the total sum of squares <span class="math display">\[
S S_{T}=S S_{A}+S S_{B}+S S_{A B}+S S_{E}
\]</span></p>
<ul>
<li><span class="math inline">\(SS_A = \sum_{i=1}^a b n
(\widehat{\alpha}_i)^2\)</span> “between rows”</li>
<li><span class="math inline">\(SS_B = \sum_{j=1}^b a n
(\widehat{\beta}_j)^2\)</span> “between columns”</li>
<li><span class="math inline">\(SS_{AB} = \sum_{i=1}^a \sum_{j=1}^b n
(\widehat{\alpha\beta})_{ij}^2\)</span> “correction”</li>
<li><span class="math inline">\(SS_E = \sum_{i=1}^a \sum_{j=1}^b
\sum_{k=1}^n (y_{ijk} - \overline{y}_{ij\cdot})^2\)</span> Error “within
cells”</li>
<li><span class="math inline">\(SS_T = \sum_{i=1}^a \sum_{j=1}^b
\sum_{k=1}^n (y_{ijk} - \overline{y}_{\cdot\cdot\cdot})^2\)</span>
“total”</li>
</ul>
<div id="marginal-means-in-factorial-designs" class="section level3">
<h3>Marginal Means in Factorial Designs</h3>
<p>Marginal means are computed by averaging the means across the levels
of other factors in the design, thus isolating the effect of one
particular factor. These means are essential for: - Understanding how
each factor influences the dependent variable while controlling for the
influence of other factors. - Comparing the effects of each level of a
factor on the outcome, averaged over the levels of other factors
involved in the study.</p>
<p>In factorial ANOVA, marginal means are particularly informative
because they reflect the composite effect of interactions between
factors on the dependent variable. For example:</p>
<ul>
<li>If Factor A (e.g., teaching method) and Factor B (e.g., study time)
are being tested, the marginal mean for each level of Factor A would be
the average outcome across all levels of Factor B, and vice versa.</li>
<li>This averaging helps identify if the performance differences are
primarily due to one factor regardless of the levels of another, or if
the differences are specifically due to interactions between these
factors.</li>
</ul>
<p><strong>Interpretation of Marginal Means</strong>:</p>
<ul>
<li>In the context of a factorial design, marginal means allow for the
comparison of factor effects across different conditions or
settings.</li>
<li>They help in discerning whether the observed differences in outcomes
are due to systematic effects of the factors under study or if they stem
from the particular combinations of these factors (i.e.,
interactions).</li>
</ul>
</div>
</div>
<div id="r-implementation-1" class="section level2">
<h2>R implementation</h2>
<pre class="r"><code>## Date exploration
my_data &lt;- ToothGrowth

# Show a random sample
set.seed(1234)
dplyr::sample_n(my_data, 10)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["len"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["supp"],"name":[2],"type":["fct"],"align":["left"]},{"label":["dose"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"21.5","2":"VC","3":"2.0"},{"1":"17.3","2":"VC","3":"1.0"},{"1":"27.3","2":"OJ","3":"2.0"},{"1":"18.5","2":"VC","3":"2.0"},{"1":"8.2","2":"OJ","3":"0.5"},{"1":"26.4","2":"OJ","3":"1.0"},{"1":"25.8","2":"OJ","3":"1.0"},{"1":"5.2","2":"VC","3":"0.5"},{"1":"6.4","2":"VC","3":"0.5"},{"1":"9.4","2":"OJ","3":"0.5"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code># Convert dose as a factor and recode the levels
my_data$dose &lt;- factor(my_data$dose, 
                  levels = c(0.5, 1, 2),
                  labels = c(&quot;D0.5&quot;, &quot;D1&quot;, &quot;D2&quot;))
                  
## Compute mean and SD by groups using dplyr R package:
require(&quot;dplyr&quot;)
group_by(my_data, supp, dose) %&gt;%
  summarise(
    count = n(),
    mean = mean(len, na.rm = TRUE),
    sd = sd(len, na.rm = TRUE)
  )</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["supp"],"name":[1],"type":["fct"],"align":["left"]},{"label":["dose"],"name":[2],"type":["fct"],"align":["left"]},{"label":["count"],"name":[3],"type":["int"],"align":["right"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["sd"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"OJ","2":"D0.5","3":"10","4":"13.23","5":"4.459709"},{"1":"OJ","2":"D1","3":"10","4":"22.70","5":"3.910953"},{"1":"OJ","2":"D2","3":"10","4":"26.06","5":"2.655058"},{"1":"VC","2":"D0.5","3":"10","4":"7.98","5":"2.746634"},{"1":"VC","2":"D1","3":"10","4":"16.77","5":"2.515309"},{"1":"VC","2":"D2","3":"10","4":"26.14","5":"4.797731"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code># Visualize data
# library(&quot;ggpubr&quot;)
ggboxplot(my_data, x = &quot;dose&quot;, y = &quot;len&quot;, color = &quot;supp&quot;,
          palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;))</code></pre>
<p><img src="06-Analysis-ANOVA_files/figure-html/Two-Ways%20ANOVA%20Test-1.png" width="672" /></p>
<pre class="r"><code>## Two-way interaction plot
# library(&quot;ggpubr&quot;)
ggline(my_data, x = &quot;dose&quot;, y = &quot;len&quot;, color = &quot;supp&quot;,
       add = c(&quot;mean_se&quot;, &quot;dotplot&quot;),
       palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;))</code></pre>
<p><img src="06-Analysis-ANOVA_files/figure-html/Two-Ways%20ANOVA%20Test-2.png" width="672" /></p>
<pre class="r"><code>## Model Fitting
## Compute two-way ANOVA test
res.aov2 &lt;- aov(len ~ supp + dose, data = my_data)
summary(res.aov2)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## supp         1  205.4   205.4   14.02 0.000429 ***
## dose         2 2426.4  1213.2   82.81  &lt; 2e-16 ***
## Residuals   56  820.4    14.7                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>## Two-way ANOVA with interaction effect
res.aov3 &lt;- aov(len ~ supp * dose, data = my_data)
res.aov3 &lt;- aov(len ~ supp + dose + supp:dose, data = my_data)
summary(res.aov3)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## supp         1  205.4   205.4  15.572 0.000231 ***
## dose         2 2426.4  1213.2  92.000  &lt; 2e-16 ***
## supp:dose    2  108.3    54.2   4.107 0.021860 *  
## Residuals   54  712.1    13.2                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>  ## dose的p值&lt;2e-16（显着），表明剂量水平与显着不同的牙齿长度len 有关。
  ## supp * dose之间相互作用的p值为0.02（显着），表明dose与牙齿长度len之间的关系取决于supp方法
  ## 在交互作用不明显的情况下，应使用加性模型。

## Diagnosis
## 1. Compute mean and SD by groups using dplyr R package:
require(&quot;dplyr&quot;)
group_by(my_data, supp, dose) %&gt;%
  summarise(
    count = n(),
    mean = mean(len, na.rm = TRUE),
    sd = sd(len, na.rm = TRUE)
  )</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["supp"],"name":[1],"type":["fct"],"align":["left"]},{"label":["dose"],"name":[2],"type":["fct"],"align":["left"]},{"label":["count"],"name":[3],"type":["int"],"align":["right"]},{"label":["mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["sd"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"OJ","2":"D0.5","3":"10","4":"13.23","5":"4.459709"},{"1":"OJ","2":"D1","3":"10","4":"22.70","5":"3.910953"},{"1":"OJ","2":"D2","3":"10","4":"26.06","5":"2.655058"},{"1":"VC","2":"D0.5","3":"10","4":"7.98","5":"2.746634"},{"1":"VC","2":"D1","3":"10","4":"16.77","5":"2.515309"},{"1":"VC","2":"D2","3":"10","4":"26.14","5":"4.797731"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>model.tables(res.aov3, type=&quot;means&quot;, se = TRUE)</code></pre>
<pre><code>## Tables of means
## Grand mean
##          
## 18.81333 
## 
##  supp 
## supp
##     OJ     VC 
## 20.663 16.963 
## 
##  dose 
## dose
##   D0.5     D1     D2 
## 10.605 19.735 26.100 
## 
##  supp:dose 
##     dose
## supp D0.5  D1    D2   
##   OJ 13.23 22.70 26.06
##   VC  7.98 16.77 26.14
## 
## Standard errors for differences of means
##           supp   dose supp:dose
##         0.9376 1.1484    1.6240
## replic.     30     20        10</code></pre>
<pre class="r"><code>## 2. Multiple Test
pairwise.t.test(my_data$len, my_data$dose,
                p.adjust.method = &quot;BH&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  my_data$len and my_data$dose 
## 
##    D0.5    D1     
## D1 1.0e-08 -      
## D2 4.4e-16 1.4e-05
## 
## P value adjustment method: BH</code></pre>
<pre class="r"><code>## Multiple pairwise-comparison between the means of groups
TukeyHSD(res.aov3, which = &quot;dose&quot;)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = len ~ supp + dose + supp:dose, data = my_data)
## 
## $dose
##           diff       lwr       upr   p adj
## D1-D0.5  9.130  6.362488 11.897512 0.0e+00
## D2-D0.5 15.495 12.727488 18.262512 0.0e+00
## D2-D1    6.365  3.597488  9.132512 2.7e-06</code></pre>
<pre class="r"><code># library(multcomp)
summary(glht(res.aov2, linfct = mcp(dose = &quot;Tukey&quot;)))</code></pre>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = len ~ supp + dose, data = my_data)
## 
## Linear Hypotheses:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## D1 - D0.5 == 0    9.130      1.210   7.543   &lt;1e-05 ***
## D2 - D0.5 == 0   15.495      1.210  12.802   &lt;1e-05 ***
## D2 - D1 == 0      6.365      1.210   5.259   &lt;1e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<pre class="r"><code>## 3. Homogeneity and normality
## Check the homogeneity of variance assumption (outliers)
plot(res.aov3, 1)</code></pre>
<p><img src="06-Analysis-ANOVA_files/figure-html/Two-Ways%20ANOVA%20Test-3.png" width="672" /></p>
<pre class="r"><code>## Levene’s test to check the homogeneity of variances.
# library(car)
leveneTest(len ~ supp*dose, data = my_data)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["F value"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"5","2":"1.708578","3":"0.1483606","_rn_":"group"},{"1":"54","2":"NA","3":"NA","_rn_":""}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>## Check the normality assumpttion
plot(res.aov3, 2)</code></pre>
<p><img src="06-Analysis-ANOVA_files/figure-html/Two-Ways%20ANOVA%20Test-4.png" width="672" /></p>
<pre class="r"><code># Extract the residuals, Shapiro-Wilk test
aov_residuals &lt;- residuals(object = res.aov3)
shapiro.test(x = aov_residuals )</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  aov_residuals
## W = 0.98499, p-value = 0.6694</code></pre>
</div>
<div id="sas-implementation-1" class="section level2">
<h2>SAS Implementation</h2>
<pre><code>data Waste;
 do Temp = 1 to 3;
 do Envir = 1 to 5;
 do rep=1 to 2;
 input Waste @@;
 output;
 end;
 end;
 end;
datalines;
7.09 5.90 7.94 9.15 9.23 9.85 5.43 7.73 9.43 6.90
7.01 5.82 6.18 7.19 7.86 6.33 8.49 8.67 9.62 9.07
7.78 7.73 10.39 8.78 9.27 8.90 12.17 10.95 13.07 9.76
;
run;
ods graphics on;
proc glm data=Waste;
 class Temp Envir;
 model Waste = Temp Envir Temp*Envir;
run;
quit;
ods graphics off;
</code></pre>
</div>
<div id="unbalanced-design" class="section level2">
<h2>Unbalanced design</h2>
<p>With unbalanced designs, LS-means typically are more relevant than
arithmetic means for quantifying general population characteristics,
since the LS-means estimate the marginal means over a balanced
population, whether or not the design itself is balanced; the arithmetic
means only estimate the marginal means for a population whose margins
match those of the design. In particular, the arithmetic means estimate
balanced population margins only when the design itself is balanced.
Moreover, the LS-means match the arithmetic means when the design is
balanced.</p>
<pre><code>## unequal numbers of subjects in each group.
library(car)
my_anova &lt;- aov(len ~ supp * dose, data = my_data)
Anova(my_anova, type = &quot;III&quot;)</code></pre>
<pre><code>*** Comparisons of LS-Means with Unbalanced Data;
data Drug;
 input Drug Disease @;
 do i=1 to 6;
 input Response @;
 output;
 end;
cards;
1 1 42 44 36 13 19 22
1 2 33 . 26 . 33 21
1 3 31 -3 . 25 25 24
2 1 28 . 23 34 42 13
2 2 . 34 33 31 . 36
2 3 3 26 28 32 4 16
3 1 . . 1 29 . 19
3 2 . 11 9 7 1 -6
3 3 21 1 . 9 3 .
4 1 24 . 9 22 -2 15
4 2 27 12 12 -5 16 15
4 3 22 7 25 5 12 .
;
ods graphics on;
proc glm;
 class Drug Disease;
 model Response = Drug Disease Drug*Disease/ss3;
 lsmeans Drug/ pdiff cl adjust=simulate(seed=121211 acc=.0002
report);
run; quit;
ods graphics off; </code></pre>
<pre><code>*** Computing LS-Means by Hand;
data Balanced;
 do Drug = 1 to 4;
 do Disease = 1 to 3;
 output;
 end;
 end;
data DrugPlus; set Drug(where=(Response ^= .)) Balanced;
proc glm data=DrugPlus;
 class Drug Disease;
 model Response = Drug Disease Drug*Disease;
 output out=PredBal(where=(Response = .)) p=pResponse;
proc means data=PredBal;
 class Drug;
 ways 1;
 var pResponse;
run; </code></pre>
</div>
</div>
<div id="manova---multivariate-analysis-of-variance"
class="section level1">
<h1>MANOVA - Multivariate Analysis of Variance</h1>
<p>A repeated measures ANOVA is used to determine whether or not there
is a statistically significant difference between the means of three or
more groups in which the same subjects show up in each group. A repeated
measures ANOVA is typically used in two specific situations:</p>
<ol style="list-style-type: decimal">
<li>Measuring the mean scores of subjects during three or more time
points.</li>
<li>Measuring the mean scores of subjects under three different
conditions.</li>
</ol>
<p><img src="02_Plots/ANOVA/ANOVA_Repeat1.png" /></p>
<p><img src="02_Plots/ANOVA/ANOVA_Repeat2.png" /></p>
<div id="general-linear-model-glm-for-repeated-measures-anova"
class="section level2">
<h2>General Linear Model (GLM) for Repeated Measures ANOVA</h2>
<p>The equation for repeated measures ANOVA is: <span
class="math display">\[ Y_{ij} = \mu + \pi_i + \alpha_j +
(\pi\alpha)_{ij} + \epsilon_{ij} \]</span></p>
<ul>
<li><strong><span class="math inline">\(\mu\)</span></strong> is the
overall mean or grand mean of the data.</li>
<li><strong><span class="math inline">\(\pi_i\)</span></strong>
represents the effect due to the <span
class="math inline">\(i\)</span>-th subject.</li>
<li><strong><span class="math inline">\(\alpha_j\)</span></strong> is
the effect of the <span class="math inline">\(j\)</span>-th condition or
treatment.</li>
<li><strong><span
class="math inline">\((\pi\alpha)_{ij}\)</span></strong> is the
interaction between subject <span class="math inline">\(i\)</span> and
condition <span class="math inline">\(j\)</span>, which usually is not
included (set to zero) in simple models for ease and clarity.</li>
<li><strong><span class="math inline">\(\epsilon_{ij}\)</span></strong>
is the error term, capturing random effects not explained by the
model.</li>
</ul>
<p>This model accounts for the repeated measures on the same subjects by
including a term for each subject, allowing it to analyze within-subject
variations effectively.</p>
<p>To ensure valid results from a repeated measures ANOVA, certain
assumptions must be met:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Independence</strong>: Each observation should be
independent of others. This assumption is crucial for any statistical
test involving inference. In the context of repeated measures, the
design inherently involves related observations (repeated on the same
subjects); hence the independence primarily concerns the error terms
<span class="math inline">\(\epsilon_{ij}\)</span>, which should be
independent.</p></li>
<li><p><strong>Normality</strong>: The distribution of residuals (not
the raw data) should be approximately normally distributed. This can be
checked through:</p>
<ul>
<li>Histograms or Q-Q plots of the residuals.</li>
<li>Formal tests of normality such as the Shapiro-Wilk test.</li>
</ul>
<p>Repeated measures ANOVA is robust against mild violations of
normality, especially with larger sample sizes. For severe violations,
data transformation or non-parametric alternatives like the Friedman
test might be necessary.</p></li>
<li><p><strong>Sphericity</strong>: The variances of the differences
among all combinations of related groups (conditions) must be equal.
This assumption, unique to repeated measures and multivariate designs,
can be tested using Mauchly’s Test of Sphericity. If sphericity is
violated, adjustments such as Huynh-Feldt, Greenhouse-Geisser, or
lower-bound corrections are used to correct the degrees of freedom used
in F-tests, affecting the p-values.</p></li>
</ol>
<p>If assumptions are violated, several strategies can be employed:</p>
<ul>
<li>Transforming the data to improve normality or stabilize
variances.</li>
<li>Using corrections for violations of sphericity to ensure valid
F-tests.</li>
<li>Resorting to non-parametric methods when the data significantly
deviate from these assumptions.</li>
</ul>
</div>
</div>
<div id="other" class="section level1">
<h1>Other</h1>
<div id="heteroscedastic-responses" class="section level2">
<h2>Heteroscedastic Responses</h2>
<p>If the error variances are not constant, then the ordinary methods
might be biased (in the sense of providing higher error rates than
advertised) or inefficient (in the sense that the method lacks power to
detect real differences).</p>
</div>
<div id="repeated-measures-anova-data" class="section level2">
<h2>Repeated Measures ANOVA Data</h2>
<p>When there are repeated measures on the same experimental unit, the
crucial independence assumption that is used for the previous models no
longer applies. For example, the data may contain repeated measures on
blood pressure for an individual. In such cases, you can <strong>model
the dependence</strong> of blood pressure measurements by using a
variety of possible dependence structure models, and perform
multiplicity-adjusted analyses within the context of such models.
<strong>Normality (or at least approximate normality) remains an
important assumption</strong> for these models.</p>
</div>
<div id="multivariate-responses-with-normally-distributed-data"
class="section level2">
<h2>Multivariate Responses with Normally Distributed Data</h2>
<p>In these models, there are multiple measurements on the same
individual. While repeated measures models usually assume that the
measurements are taken on the same characteristic (like blood pressure),
the multivariate response models allow completely different scales of
measurement. For example, blood pressure and self-rated anxiety level
form a multivariate response vector. Multiple inferences from such data
are improved by incorporating the correlations among such measurements.
In addition to the normality assumption, the multivariate observation
vectors also are assumed independent, with constant covariance matrices.
Our suggested method of analysis will allow covariates as well, so you
can perform multiple comparisons with <strong>multivariate analysis of
covariance (MANCOVA)</strong> data.</p>
</div>
<div
id="independent-observations-from-parametric-nonnormal-distributions"
class="section level2">
<h2>Independent Observations from Parametric Nonnormal
Distributions</h2>
<p>As an example, suppose you know that the observations are counts of
defects on a manufactured item, and you wish to compare shifts A, B, and
C. The model used may be Poisson, and you still wish to perform multiple
comparisons. In this case, you can use any of several SAS procedures to
fit the Poisson model, and can perform adjustments for multiple
comparisons easily using the fitted results from such models.</p>
</div>
<div id="dependent-observations-from-parametric-nonnormal-distributions"
class="section level2">
<h2>Dependent Observations from Parametric Nonnormal Distributions</h2>
<p>Following the previous example, suppose you know that the counts of
defects on manufactured items are associated with different machines.
You still wish to compare shifts A, B, and C, but you want to account
for the machine effect. In this case, you may model the observations on
a common machine as dependent, using a random effects model, where the
machine effect is considered random. Again the model may be Poisson, but
with a repeated measures component. In this case, you can use PROC
GLIMMIX both to perform the repeated measures modeling and to perform
the multiple comparisons.</p>
</div>
</div>
<div id="multiple-comparison" class="section level1">
<h1>Multiple Comparison</h1>
<div id="post-hoc-comparisons" class="section level2">
<h2>Post-hoc Comparisons</h2>
<p>Significance of F Statistic: If the overall F statistic from an ANOVA
is not statistically significant (i.e., p-value exceeds the alpha level,
typically 0.05), it indicates that there is no statistical evidence to
suggest that there are any differences among the group means. In such
cases, it is standard practice not to perform any further contrasts or
post hoc tests because the initial analysis did not reject the null
hypothesis of no group differences.</p>
<p>If the F statistic is significant, suggesting differences among the
group means, post hoc tests can be used to find out which specific
groups differ from each other. Here are some commonly used post hoc
tests:</p>
<ol style="list-style-type: decimal">
<li><strong>Tukey’s Honestly Significant Difference (HSD) Test</strong>:
<ul>
<li><strong>Pros</strong>: Well-balanced in terms of Type I error
control; not as conservative as Bonferroni, leading to slightly more
powerful results where moderate control is sufficient.</li>
<li><strong>Cons</strong>: Can still be too conservative compared to
tests without any corrections.</li>
</ul></li>
<li><strong>Bonferroni Correction</strong>:
<ul>
<li><strong>Method</strong>: This test adjusts the p-values by
multiplying them by the number of comparisons. For instance, if three
t-tests are conducted, each p-value is multiplied by three.</li>
<li><strong>Pros</strong>: Highly conservative, minimizing the risk of
Type I errors (false positives).</li>
<li><strong>Cons</strong>: Can drastically reduce statistical power,
particularly when many comparisons are made, possibly leading to Type II
errors (false negatives).</li>
</ul></li>
<li><strong>Holm-Bonferroni Method</strong>:
<ul>
<li><strong>Method</strong>: A sequential adjustment where the smallest
p-value is multiplied by the total number of tests, the next smallest by
one fewer, and so on. This provides a step-down method that is less
conservative than Bonferroni.</li>
<li><strong>Pros</strong>: Offers a good balance between controlling
Type I error and maintaining statistical power.</li>
</ul></li>
<li><strong>Scheffe’s Test</strong>:
<ul>
<li><strong>Method</strong>: A complex formula for calculating
adjustments, rarely used due to its complexity and
conservativeness.</li>
<li><strong>Pros</strong>: Very robust, as it allows for all possible
comparisons post-hoc.</li>
<li><strong>Cons</strong>: May be too conservative and complex for
practical use.</li>
</ul></li>
<li><strong>Welch’s F-test</strong>:
<ul>
<li><strong>Method</strong>: Adjusts the degrees of freedom used in the
F-test to account for group variances that are unequal. This test is
especially useful when the assumption of homogeneity of variances is
violated.</li>
<li><strong>Pros</strong>: Provides a more accurate assessment of the
significance of the group differences when variances are unequal.</li>
</ul></li>
<li><strong>Kruskal-Wallis Test</strong>:
<ul>
<li><strong>Method</strong>: A non-parametric alternative to ANOVA, used
when the data does not meet the assumptions necessary for ANOVA. It
compares medians from two or more groups.</li>
<li><strong>Pros</strong>: Does not assume a normal distribution and is
useful for ordinal data or skewed distributions.</li>
<li><strong>Cons</strong>: Generally less powerful than ANOVA in
detecting differences when the normality assumption is met.</li>
</ul></li>
</ol>
</div>
<div id="introduction-2" class="section level2">
<h2>Introduction</h2>
<div id="multiplicity-problem" class="section level3">
<h3>Multiplicity Problem</h3>
<p>There are real effects from multiplicity.</p>
<ul>
<li>confounding effects</li>
<li>nonresponse effects</li>
<li>placebo effects</li>
<li>learning effects</li>
<li>carryover effects</li>
</ul>
<p>The problem with all statistical tests is the fact that the (overall)
error rate increases with increasing number of tests. <span
class="math display">\[1 - (1 - \alpha)^m.\]</span></p>
</div>
<div id="error-rates" class="section level3">
<h3>Error Rates</h3>
<div id="comparisonwise-error-rate-cer" class="section level4">
<h4>Comparisonwise Error Rate (CER)</h4>
<p>Typical inferences are performed using the <span
class="math inline">\(95 \%\)</span> confidence level or <span
class="math inline">\(5 \%\)</span> significance level. In either case,
the comparisonwise error rate (CER) is <span class="math inline">\(5
\%\)</span>. For confidence intervals, CER is defined as <span
class="math display">\[\mathrm{CER}=P(\text{Interval does not contain
the parameter}).\]</span> A typical two-sided confidence interval has
the form</p>
<p>(parameter estimate) <span class="math inline">\(\pm\)</span>
(critical value) <span class="math inline">\(\times\)</span> (standard
error of the estimate).</p>
<p>For example, if the parameter of interest is a population mean <span
class="math inline">\(\mu\)</span>, and the data are normally
distributed, then the usual two-sided <span class="math inline">\(95
\%\)</span> confidence interval for <span
class="math inline">\(\mu\)</span> is <span class="math display">\[
\bar{y} \pm t_{975, n-1} \times s_{y} / \sqrt{n}
\]</span> where - <span class="math inline">\(\bar{y}\)</span> is the
estimate of the population mean - <span
class="math inline">\(s_{y}\)</span> is the sample standard deviation -
<span class="math inline">\(n\)</span> is the sample size - <span
class="math inline">\(s_{y} / \sqrt{n}\)</span> is the standard error of
the estimated mean.</p>
<p>The critical value is <span class="math inline">\(t_{975,
n-1}\)</span>, which is the <span class="math inline">\(1-0.05 /
2\)</span> quantile of the <span class="math inline">\(t\)</span>
distribution with <span class="math inline">\(n-1\)</span> degrees of
freedom. A one-sided upper confidence interval for <span
class="math inline">\(\mu\)</span> might be all values below <span
class="math display">\[
\bar{y}+t_{.95, n-1} \times s_{y} / \sqrt{n}
\]</span> For tests of hypotheses, CER is defined as <span
class="math display">\[
\mathrm{CER}=P\left(\text { Reject } H_{0} \mid H_{0}\right. \text { is
true). }
\]</span></p>
</div>
<div id="familywise-error-rate-fwe" class="section level4">
<h4>Familywise Error Rate (FWE)</h4>
<p><strong>FWE for Simultaneous Confidence Intervals</strong></p>
<p>The FWE is the probability of at least one erroneous inference,
defined for simultaneous confidence intervals as <span
class="math display">\[\text{FWE (at least one interval is incorrect) 1
(all intervals are correct).}\]</span></p>
<p><strong>FWE for Multiple Tests of Hypotheses</strong></p>
<p>The family-wise error rate is defined as the probability of rejecting
at least one of the true <span class="math inline">\(H_0\)</span></p>
<p>In the case of multiple tests of hypotheses, some of the hypotheses
<span class="math inline">\(H_{0 j}\)</span> could be true, and others
could be false. Suppose the true state of nature is that the particular
null hypotheses corresponding to <span class="math inline">\(j_{1},
\ldots, j_{m}\)</span> are true, and all other null hypotheses are
false. In other words, <span class="math inline">\(H_{0 j_{1}}, H_{0
j_{2}}, \ldots, H_{0 j_{m}}\)</span> are true, and the remaining <span
class="math inline">\((k-m)\)</span> hypotheses are false. The FWE is
then defined as</p>
<p><span class="math display">\[FWE =P( \text{reject at least one of}
H_{0 j_{1}}, H_{0 j_{2}}, \ldots, H_{0 j_{m}} \mid H_{0 j_{1}}, H_{0
j_{2}}, \ldots, H_{0 j_{m}} \text{all are true})\]</span>.</p>
</div>
<div id="control-of-the-fwe-weak-and-strong" class="section level4">
<h4>Control of the FWE: Weak and Strong</h4>
<p>An MCP is said to control the FWE in the weak sense if it controls
the FWE under the complete null configuration, but not under all other
configurations. Despite the fact that the terms “weak control” and
“strong control” are used in conjunction with FWE, you should note that
they really refer to different error rates. <strong>Weak control refers
only to controlling the probability that the complete null hypothesis is
rejected</strong>, and allows Type I errors in excess of the usual 5%
value (for example, for the component hypotheses).</p>
<p>A method that controls the FWE in the strong sense will result in a
<strong>Type I error for any component hypothesis no more than 5% of the
time</strong>.</p>
</div>
<div id="directional-decisions-and-type-iii-error-rates"
class="section level4">
<h4>Directional Decisions and Type III Error Rates</h4>
<p>A directional error (sometimes called a Type III error) is defined as
the probability of misclassifying the sign of an effect. If you reject
the hypothesis H0 : μ = 0 in favor of the (twosided) alternative HA : μ
≠ 0 using a CER= 0.05 level test, can you then claim that the sign of
the true mean μ is the same as the sign of the estimated mean y ?</p>
<p>A type III error is where you correctly reject the null hypothesis,
but it’s rejected for the wrong reason. This compares to a Type I error
(incorrectly rejecting the null hypothesis) and a Type II error (not
rejecting the null when you should). Type III errors are not considered
serious, as they do mean you arrive at the correct decision. They
usually happen because of random chance and are a rare occurrence.</p>
<p>You can also think of a Type III error as giving the right answer
(i.e. correctly rejecting the null) to the wrong question. In other
words, both your null and alternate hypotheses may be poorly worded or
completely incorrect.</p>
<p>For MCPs, the Type III FWE is the probability that the sign of any
tested effect is misclassified.</p>
</div>
<div id="false-discovery-rate-fdr" class="section level4">
<h4>False Discovery Rate (FDR)</h4>
<p>Benjamini and Hochberg (1995) referred to the expected proportion of
erroneously rejected null hypotheses among the rejected ones as the
False Discovery Rate, or FDR. Formally, for a given family of k
hypotheses and a given MCP, let R= number of hypotheses rejected, and
let V = the (unknown) number of erroneously rejected ones. Define V/R =
0 in case R=0. Then FDR is the expected value of V/R</p>
<p><span class="math display">\[
\begin{array}{cccc}
\hline &amp; H_{0} \text { accepted } &amp; H_{0} \text { rejected }
&amp; \text { Total } \\
\hline H_{0} \text { true } &amp; m-V &amp; V &amp; m \\
H_{0} \text { false } &amp; k-m-R+V &amp; R-V &amp; k-m \\
\text { Total } &amp; k-R &amp; R &amp; k \\
\hline
\end{array}
\]</span></p>
<p><span class="math display">\[
\mathrm{FDR}=E(V / R)
\]</span> (assuming <span class="math inline">\(0 / 0\)</span> is
defined as 0 ), whereas <span class="math display">\[
\mathrm{FWE}=P(V&gt;0)
\]</span> Under the overall null hypothesis, FDR and FWE are equal,
since in this case <span class="math inline">\(V / R=1\)</span> when
there is at least one rejection, and <span class="math inline">\(V /
R=0\)</span> when there are no rejections.</p>
</div>
</div>
<div id="the-adjusted-p" class="section level3">
<h3>The adjusted P</h3>
<p>Marginal p-value is based on the marginal p-values, which do not
account for a multiplicity adjustment.</p>
<p>The adjusted P value is the smallest familywise significance level at
which a particular comparison will be declared statistically significant
as part of the multiple comparison testing. A separate adjusted P value
is computed for each comparison in a family of comparisons.</p>
<p>The following show the R code about teh comparsion of adjusted and
un-adjusted p-values</p>
<pre><code>library(multcomp)
data(thuesen,package = &quot;ISwR&quot;)
thuesen &lt;- read.sas7bdat(&quot;~/Desktop/SASUniversityEdition/myfolders/Daten/thuesen.sas7bdat&quot;)

thuesen.lm &lt;- lm(short.velocity ~ blood.glucose,data = thuesen)
thuesen.mc &lt;- glht(thuesen.lm, linfct = diag(2))

## With adjustment.
summary(thuesen.mc, 
        test = adjusted(type = &quot;bonferroni&quot;))
## without adjustment.
summary(thuesen.mc, test = univariate())</code></pre>
<p>Furthermore, there are different methods for p value adjust.</p>
<pre><code>Input = (&quot;
Food               Raw.p
 Blue_fish         .34
 Bread             .594
 Butter            .212
 Carbohydrates     .384
 Cereals_and_pasta .074
 Dairy_products    .94
 Eggs              .275
 Fats              .696
 Fruit             .269
 Legumes           .341
 Nuts              .06
&quot;)
Data = read.table(textConnection(Input),header=TRUE)
## Order data by p-value
Data = Data[order(Data$Raw.p),]

## Perform p-value adjustments and add to data frame
Data$Bonferroni = 
      p.adjust(Data$Raw.p, 
               method = &quot;bonferroni&quot;)
Data$BH = 
      p.adjust(Data$Raw.p, 
               method = &quot;BH&quot;)
Data$Holm = 
      p.adjust(Data$ Raw.p, 
               method = &quot;holm&quot;)
Data$Hochberg = 
      p.adjust(Data$ Raw.p, 
               method = &quot;hochberg&quot;)
Data$Hommel = 
      p.adjust(Data$ Raw.p, 
               method = &quot;hommel&quot;)
Data$BY = 
      p.adjust(Data$ Raw.p, 
               method = &quot;BY&quot;)

                Food Raw.p Bonferroni     BH Holm Hochberg    Hommel BY
11              Nuts 0.060      0.660 0.4070 0.66     0.66 0.5485714  1
5  Cereals_and_pasta 0.074      0.814 0.4070 0.74     0.74 0.5920000  1
3             Butter 0.212      1.000 0.5280 1.00     0.94 0.8700000  1
9              Fruit 0.269      1.000 0.5280 1.00     0.94 0.9280000  1
7               Eggs 0.275      1.000 0.5280 1.00     0.94 0.9280000  1
1          Blue_fish 0.340      1.000 0.5280 1.00     0.94 0.9400000  1
10           Legumes 0.341      1.000 0.5280 1.00     0.94 0.9400000  1
4      Carbohydrates 0.384      1.000 0.5280 1.00     0.94 0.9400000  1
2              Bread 0.594      1.000 0.7260 1.00     0.94 0.9400000  1
8               Fats 0.696      1.000 0.7656 1.00     0.94 0.9400000  1
6     Dairy_products 0.940      1.000 0.9400 1.00     0.94 0.9400000  1</code></pre>
</div>
<div id="basic-statistical-concepts" class="section level3">
<h3>Basic Statistical Concepts</h3>
<p>The hypotheses described here are for the two-sample t-test, a common
test for comparing two groups. The assumptions of the two-sample t-test
are important: random, independent samples from the two groups, common
variances, and normally distributed data.</p>
<ul>
<li>The null hypothesis is <span class="math inline">\(H_{0}:
\mu_{1}=\mu_{2} ;\)</span> that is, the hypotheses that the population
means are equal.</li>
<li>The alternative hypothesis is <span class="math inline">\(H_{A}:
\mu_{1} \neq \mu_{2} ;\)</span> that is, the hypotheses that the
population means are not equal.</li>
<li>The test statistic is <span
class="math inline">\(T=\frac{\bar{X}_{1}-\bar{X}_{2}}{s_{p}
\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}\)</span>, where <span
class="math inline">\(s_{p}^{2}=\frac{\left(n_{1}-1\right)
s_{1}^{2}+\left(n_{2}-1\right) s_{2}^{2}}{n_{1}+n_{2}-2}\)</span>.</li>
<li>The decision rule is to reject <span
class="math inline">\(H_{0}\)</span> if <span class="math inline">\(|T|
\geq t_{1-\alpha / 2, n-2}\)</span>, where <span
class="math inline">\(t_{1-\alpha / 2, n-2}\)</span> is the critical
value.</li>
<li>The <span class="math inline">\(p\)</span> -value is the probability
of observing a test statistic as large as or larger than the <span
class="math inline">\(|T|\)</span> that was observed in the study,
assuming the null hypothesis is true.</li>
</ul>
<p>By construction, the <span class="math inline">\(p\)</span> -value is
found <span class="math inline">\(\leq \alpha\)</span> wherever <span
class="math inline">\(|T| \geq t_{1-\alpha / 2, n-2} .\)</span> Thus,
when all of the assumptions are satisfied, <span class="math display">\[
P\left(p \leq \alpha \mid H_{0} \text { is true }\right)=\alpha
\]</span> This leads to an important point:</p>
<p><strong>When the null hypothesis is true and when all assumptions are
satisfied, the <span class="math inline">\(p\)</span> -value has a
uniform distribution.</strong></p>
<p>From the parameter, the adjusted and unadjusted p value can be
calculated</p>
<pre><code>## Calculation without adjustment.
## regression coefficients β and their covariance matrix

betahat &lt;- coef(thuesen.lm)
Vbetahat &lt;- vcov(thuesen.lm)
##  compute two individual t test statistics and correlation matrix
C &lt;- diag(2)
Sigma &lt;- diag(1 / sqrt(diag(C %*% Vbetahat %*% t(C))))
t &lt;- Sigma %*% C %*% betahat
Cor &lt;- Sigma %*% (C %*% Vbetahat %*% t(C)) %*% t(Sigma)


## Use the pmvt function of the mvtnorm package to calculate the adjusted p value from the basic bivariate t distribution
library(&quot;mvtnorm&quot;)
thuesen.df &lt;- nrow(thuesen) - length(betahat)
q &lt;- sapply(abs(t), function(x) 1 - pmvt(-rep(x, 2), 
                                         rep(x, 2), 
                                         corr = Cor,
                                         df = thuesen.df))
##  获得了多重调整的p值 q1 &lt;0.001且q2 = 0.064

##  compute the critical value u1−α 计算临界值
delta &lt;- rep(0, 2)
myfct &lt;- function(x, conf) {
  lower &lt;- rep(-x, 2)
  upper &lt;- rep(x, 2)
  pmvt(lower, upper, df = thuesen.df, corr = Cor,
           delta, abseps = 0.0001)[1] - conf
}
u &lt;- uniroot(myfct, lower = 1, upper = 5, conf = 0.95)$root
round(u, 3)</code></pre>
</div>
<div id="functions-in-glht-package-in-r" class="section level3">
<h3>Functions in glht package in R</h3>
<table>
<colgroup>
<col width="58%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th>Functions</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>glht.mc$model</code></td>
<td>The fitted model</td>
</tr>
<tr class="even">
<td><code>glht.mc$linfct</code></td>
<td>linear conflict functions</td>
</tr>
<tr class="odd">
<td><code>glht.mc$vcov</code></td>
<td>Covariance matrix</td>
</tr>
<tr class="even">
<td><code>glht.res &lt;- summary(glht.mc)  glht.res$test$pvalues</code></td>
<td>P-values</td>
</tr>
<tr class="odd">
<td><code>summary(warpbreaks.mc, test = Ftest())</code></td>
<td>Global F-Test</td>
</tr>
<tr class="even">
<td><code>summary(warpbreaks.mc, test = Chisqtest())</code></td>
<td>Wald测试</td>
</tr>
<tr class="odd">
<td><code>summary(warpbreaks.mc, test = univariate())</code></td>
<td>未调整的p值, 不考虑多重性执行了m个单独t检验</td>
</tr>
<tr class="even">
<td><code>summary(warpbreaks.mc, test = adjusted(type = "bonferroni"))</code></td>
<td>Bonferroni校正</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="bonferroni-and-šidák-methods" class="section level2">
<h2>Bonferroni and Šidák Methods</h2>
<div id="lsd-least-significance-difference" class="section level3">
<h3>LSD (least significance difference)</h3>
<p>least significant difference method. First proposed by Fisher, it is
essentially a t-test.</p>
<p>For Two independent sample t test:</p>
<p><span
class="math display">\[t=\frac{\bar{X}_{1}-\bar{X}_{2}}{\sqrt{S_{c}^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)}}\]</span>
<span class="math display">\[S_{c}^{2}=\frac{\left(n_{1}-1\right)
S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}}{n_{1}+n_{2}-2}\]</span> is the
variance of the joint estimate of the two samples, under the premise
that the sample variance is uniform</p>
<p>The LSD method also performs a t-test of pairwise comparison. The
difference is that under the premise of meeting the homogeneity of
variance, the LSD method uses the joint variance of <strong>all
samples</strong> to estimate the standard error of the mean difference,
rather than the <strong>joint variance of the two samples</strong> to be
compared. Take the comparison of the mean difference between the three
samples as an example, the formula is</p>
<!-- LSD法采用所有样本的联合方差来估计均数差的标准误，而不是要比较的两个样本的联合方差。 -->
<p><span class="math display">\[\begin{aligned}
&amp;S_{c}^{2}=\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right)
S_{2}^{2}+\left(n_{3}-1\right) S_{3}^{2}}{n_{1}+n_{2}+n_{3}-3}
\end{aligned}\]</span></p>
<p>The LSD method calculates the smallest significant difference, namely
<span class="math display">\[\begin{aligned}
&amp;L S D=t_{\alpha / 2}
\sqrt{S_{c}^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)}
\end{aligned}\]</span></p>
<blockquote>
<p>The test level of LSD method for single comparison is still α. The
LSD test has the highest sensitivity, but increases the probability of
Type 1 error as the frequency of comparisons increases. To solve this
problem, the Sidak method and the Bonferroni method appeared.</p>
</blockquote>
</div>
<div id="šidák" class="section level3">
<h3>Šidák</h3>
<p>The Sidak method is also a t test, and the calculation formula is the
same as that of the LSD method. But the Sidak method adjusts for a. If
there are k groups, the number of pairwise comparisons for the k groups
is <span class="math inline">\(c=\frac{k(k-1)}{2}\)</span> Then after c
comparisons, the cumulative probability of making a class of errors is:
<span class="math inline">\(1-\left(1-\alpha_{a}\right)^{c}\)</span>
makes the above formula equal to 0.05, which can be reversed to deduce
the adjusted <span class="math inline">\(\alpha_{a} \quad\)</span> . For
example, after 6 post-hoc comparisons, the Sidak method = 0.0085, and
<span class="math inline">\(\alpha_{a}\)</span> is used as the
significance level of a single comparison. Obviously, <span
class="math inline">\(\alpha_{a}\)</span> becomes smaller. Since <span
class="math inline">\(\alpha_{a}\)</span> subtracts You, the conclusion
tends to accept the null hypothesis, so this method is much more
conservative than the LSD method.</p>
<p>The rationale for this method is the Boole inequality: <span
class="math display">\[
P\left(A_{1} \text { or } A_{2} \text { or } \ldots \text { or }
A_{k}\right) \leq
P\left(A_{1}\right)+P\left(A_{2}\right)+\cdots+P\left(A_{k}\right)
\]</span></p>
<p><span class="math display">\[
P\left(\left\{\text { Reject } H_{01}\right\} \text { or }\left\{\text {
Reject } H_{02}\right\}\right) \leq P\left(\text { Reject }
H_{01}\right)+P\left(\text { Reject } H_{02}\right)
\]</span></p>
<p>For the Šidák method, recall that you can reject an individual
hypothesis <span class="math inline">\(H_{0 j}\)</span> if <span
class="math inline">\(p_{j} \leq 1-(1-\alpha)^{1 / k}\)</span>; or
equivalently, when <span
class="math inline">\(1-\left(1-p_{j}\right)^{k} \leq \alpha\)</span>,
where <span class="math inline">\(\alpha\)</span> is the desired FWE
level. This gives you the Šidák adjusted <span
class="math inline">\(p\)</span> -values. Šidák Adjusted <span
class="math inline">\(p\)</span> -value for Hypothesis <span
class="math inline">\(H_{0 j}\)</span>; <span class="math display">\[
\tilde{p}_{j}=1-\left(1-p_{j}\right)^{k} .
\]</span></p>
</div>
<div id="bonferroni" class="section level3">
<h3>Bonferroni</h3>
<p>The Bonferroni method is similar to the Sidak method, and α is also
adjusted on the basis of the LSD method. The adjustment method is based
on Bonferroni’s inequality. If there are k groups, the calculation
formula is <span class="math display">\[\alpha^* = \alpha /
k\]</span></p>
<p>The Bonferroni method is generally considered to be the most
conservative. When the number of comparisons is small, the effect of
this method is better. When the number of comparisons is large (such as
k&gt;10), the adjustment of <span class="math inline">\(\alpha\)</span>
is somewhat overcorrected and the effect is not as good as Sidak</p>
<pre><code>library(multcomp)
## Create a matrix where each *row* is a contrast
K &lt;- rbind(c(1, -1/2, -1/2), ## ctrl vs. average of trt1 and trt2
           c(1, -1, 0))      ## ctrl vs. trt1
fit.gh &lt;- glht(fit, linfct = mcp(group = K))

## Individual p-values
summary(fit.gh, test = adjusted(&quot;none&quot;))

## Bonferroni corrected p-values
summary(fit.gh, test = adjusted(&quot;bonferroni&quot;))</code></pre>
<p>While the Boole inequality is directly applicable to multiple
hypothesis testing, the Bonferroni inequality is directly applicable to
<strong>simultaneous confidence intervals</strong>. As an example,
suppose that you have constructed k=10 simultaneous confidence
intervals, all at the CER level 0.05/k=0.05/10=0.005, corresponding to
99.5% confidence intervals. Then the simultaneous confidence level
is</p>
<p><span class="math display">\[
\begin{array}{l}
P(\{\text { Interval } 1 \text { correct }\} \text { and } \ldots \text
{ and }\{\text { Interval } 10 \text { correct }\}) \\
\geq 1-\{P(\text { Interval } 1 \text { incorrect })+\cdots+P(\text {
Interval } 10 \text { incorrect })\} \\
=1-10(0.005) \\
=0.95 .
\end{array}
\]</span></p>
<p>Bonferroni Adjusted <span class="math inline">\(p\)</span> -value for
Hypothesis <span class="math inline">\(H_{0 j}\)</span>; <span
class="math display">\[
\tilde{p}_{j}=\left\{\begin{array}{ccc}
k p_{j} &amp; \text { if } &amp; k p_{j} \leq 1 \\
1 &amp; \text { if } &amp; k p_{j}&gt;1
\end{array}\right.
\]</span></p>
<p><strong>Bonferroni and Šidák Adjusted p-Values Using the DATA
Step</strong></p>
<pre><code>data pvals1;
 input test pval @@;
 bon_adjp = min(1,10*pval);
 sid_adjp = 1 - (1-pval)**10;
datalines;
1 0.0911 2 0.8912
3 0.0001 4 0.5718
5 0.0132 6 0.9011
7 0.2012 8 0.0289
9 0.0498 10 0.0058
;
proc sort data=pvals1 out=pvals1;
 by pval;
proc print data=pvals1;
run; </code></pre>
<p><strong>Bonferroni and Šidák Adjusted p-Values Using PROC
MULTTEST</strong></p>
<pre><code>proc multtest inpvalues(pval)=pvals1 bon sid out=outp;
proc sort data=outp out=outp;
 by pval;
proc print data=outp label;
run;</code></pre>
<p>Bonferroni and Šidák methods are easy to implement, and they
correspond naturally to confidence intervals. Šidák’s method provides
slightly more power, but occasionally does not control the FWE. However,
when confidence intervals are not required, adaptive procedures are more
powerful, although they might not control the FWE in some cases.
Simulation studies should be used to understand this issue.</p>
<ul>
<li>For inferences with dependent data: ⇒ Use Bonferroni tests or
intervals.</li>
<li>For inferences with independent data: ⇒ Use Šidák tests or
intervals.</li>
</ul>
</div>
<div id="schweder-spjøtvoll-p-value-plot" class="section level3">
<h3>Schweder-Spjøtvoll p-Value Plot</h3>
<p>This plot, which is very useful for assessing multiplicity, depicts
the relationship between values <span
class="math inline">\(q=1-p\)</span> and their rank order. Specifically,
if <span class="math inline">\(q_{(1)} \leq \ldots \leq q_{(k)}\)</span>
are the ordered values of the <span class="math inline">\(q\)</span> ’s,
then <span class="math inline">\(q_{(1)}=1-p_{(k)},
q_{(2)}=1-p_{(k-1)}\)</span>, etc. The method is to plot the <span
class="math inline">\(\left(j, q_{(j)}\right)\)</span> pairs. If the
hypotheses all are truly null, then the <span
class="math inline">\(p\)</span> -values will behave like a sample from
the uniform distribution, and the graph should lie approximately on a
straight diagonal line. Deviations from linearity, particularly points
in the upper-right corner of the graph that are below the extended trend
line from the points in the lower-left corner, suggest hypotheses that
are false, since their <span class="math inline">\(p\)</span> -values
are too small to be consistent with the uniform distribution.</p>
<pre><code>*** Schweder-Spjøtvoll p-Value Plot Using PROC MULTTEST ;
data pvals1;
 input test pval @@;
 bon_adjp = min(1,10*pval);
 sid_adjp = 1 - (1-pval)**10;
datalines;
1 0.0911 2 0.8912
3 0.0001 4 0.5718
5 0.0132 6 0.9011
7 0.2012 8 0.0289
9 0.0498 10 0.0058
;

ods graphics on;
proc multtest inpvalues(pval)=pvals1 plots= RawUniformPlot;
run;
ods graphics off;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Schweder-Spj%C3%B8tvoll%201.PNG" alt="Figure: Schweder-Spjøtvoll (Uniform Probability) Plot" width="100%" />
<p class="caption">
Figure: Schweder-Spjøtvoll (Uniform Probability) Plot
</p>
</div>
<p>How does the plot look when there are no true effects</p>
<pre><code>ods graphics on;
proc multtest inpvalues(probt)=ttests plots= RawUniformPlot;
run;
ods graphics off;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Schweder-Spj%C3%B8tvoll%202.PNG" alt="Figure: Plot of p-Values for the Cold Study" width="100%" />
<p class="caption">
Figure: Plot of p-Values for the Cold Study
</p>
</div>
<p><strong>Adaptive Methods</strong></p>
<p>FWE of an MCP depends upon the number of true null hypotheses, m. In
order to protect the FWE in all possible circumstances, you had to
protect it for the complete null hypothesis where all nulls are true
(i.e., where m=k). Thus, in the Bonferroni method, you use k as a
divisor for the critical value (and as a multiplier for the adjusted
p-value). If you know m, the number of true nulls, then you may use m as
a divisor (or multiplier for adjusted p-values) instead of k, and still
control the FWE. From the examination of the Schweder-Spjøtvoll plot,
you can estimate the total number of true null hypotheses <span
class="math inline">\(\hat m\)</span>, and modify the critical value of
the Bonferroni procedure by rejecting any hypothesis<span
class="math inline">\(H_{0 j}\)</span> for which <span
class="math inline">\(p_{j} \leq \alpha / \hat{m} .\)</span></p>
<p><strong>Adaptive Holm (AHOLM) method specified in the following
program.</strong></p>
<pre><code>*** Estimating the Number of Null Hypotheses;
ods graphics on;
proc multtest inpvalues(pval)=pvals1
 plots= RawUniformPlot aholm;
run;
ods graphics off;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Schweder-Spj%C3%B8tvoll%203.PNG" alt="Figure: Estimating the Number of True Nulls Using Hochberg and Benjamini’s Method" width="100%" />
<p class="caption">
Figure: Estimating the Number of True Nulls Using Hochberg and
Benjamini’s Method
</p>
</div>
</div>
</div>
<div id="mcp-among-treatment-means-in-the-one-way-balanced-anova"
class="section level2">
<h2>MCP among Treatment Means in the One-Way Balanced ANOVA</h2>
<div id="ls-means" class="section level3">
<h3>LS-Means</h3>
<p>Least square means are means for groups that are adjusted for means
of other factors in the model.</p>
<p>A least square mean, or LS-mean, is the predicted average within a
certain category for a “balanced” population; for this reason, the
LS-means are also called the “estimated population marginal means”
(Searle, Speed, and Milliken, 1980).</p>
<p>LS-means correspond to Type III tests in the same way that arithmetic
means correspond to Type I tests; as with Type III tests, they are
intended to be used with complicated, possibly unbalanced models as
simple means can be used with simple models. Also, as Type III tests are
identical to Type I tests for simple models, so LS-means are the same as
arithmetic means when the latter are appropriate.</p>
<pre><code>*** Selling Prices of Homes;
data House;
 input Location$ Price Sqfeet Age @@;
datalines;
A 213.5 2374 4 A 219.9 2271 8 A 227.9 2088 5
A 192.5 1645 8 A 203.0 1814 6 A 242.1 2553 7
A 220.5 1921 9 A 205.5 1854 2 A 201.2 1536 9
A 194.7 1677 3 A 229.0 2342 5 A 208.7 1862 4
A 199.7 1894 7 A 212.0 1774 9 A 204.8 1476 8
A 186.1 1466 7 A 203.5 1800 8 A 193.0 1491 5
A 199.5 1749 8 A 198.1 1690 7 A 244.8 2741 5
A 196.3 1460 5 A 195.1 1614 6 A 225.8 2244 6
A 226.9 2165 6 A 204.7 1828 4 B 174.2 1503 6
B 169.9 1689 6 B 177.0 1638 2 B 167.0 1276 6
B 198.9 2101 9 B 181.2 1668 5 B 185.7 2123 4
B 199.8 2208 5 B 155.7 1273 8 B 220.1 2519 4
B 209.1 2303 6 B 182.4 1800 3 B 202.7 2336 8
B 192.0 2100 6 B 184.1 1697 4 C 190.8 1674 4
C 198.2 2307 7 C 194.6 2152 5 C 187.9 1948 9
D 202.5 2258 2 D 181.3 1965 6 D 186.1 1772 3
D 194.7 2385 1 D 164.7 1345 4 D 193.5 2220 8
D 180.1 1883 8 D 192.3 2012 6 D 180.6 1898 5
E 205.3 2362 7 E 206.3 2362 7 E 184.3 1963 9
E 176.6 1941 7 E 182.4 1975 5 E 198.8 2529 6
E 186.8 2079 5 E 188.5 2190 4 E 177.5 1897 5
E 186.9 1946 4
; </code></pre>
<p><strong>Calculate the least squares mean in R</strong></p>
<p>Remark:</p>
<ul>
<li>Least squares mean according to reference grid
<ul>
<li>The combination of reference levels forms the reference table</li>
<li>If it is a factor, then each level of the factor is used as a
reference level;</li>
<li>If it is a covariate, use the population mean of the covariate as
the reference level; *Once the reference table is established, the least
squares mean is a simple forecast based on the table, or the marginal
means of a list of forecast values.</li>
</ul></li>
</ul>
<pre class="r"><code># library(lsmeans)
head(oranges)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["store"],"name":[1],"type":["fct"],"align":["left"]},{"label":["day"],"name":[2],"type":["fct"],"align":["left"]},{"label":["price1"],"name":[3],"type":["int"],"align":["right"]},{"label":["price2"],"name":[4],"type":["int"],"align":["right"]},{"label":["sales1"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["sales2"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"1","3":"37","4":"61","5":"11.3208","6":"0.0047","_rn_":"1"},{"1":"1","2":"2","3":"37","4":"37","5":"12.9151","6":"0.0037","_rn_":"2"},{"1":"1","2":"3","3":"45","4":"53","5":"18.8947","6":"7.5429","_rn_":"3"},{"1":"1","2":"4","3":"41","4":"41","5":"14.6739","6":"7.0652","_rn_":"4"},{"1":"1","2":"5","3":"57","4":"41","5":"8.6493","6":"21.2085","_rn_":"5"},{"1":"1","2":"6","3":"49","4":"33","5":"9.5238","6":"16.6667","_rn_":"6"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>str(oranges)</code></pre>
<pre><code>## &#39;data.frame&#39;:    36 obs. of  6 variables:
##  $ store : Factor w/ 6 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 1 1 1 2 2 2 2 ...
##  $ day   : Factor w/ 6 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 2 3 4 5 6 1 2 3 4 ...
##  $ price1: int  37 37 45 41 57 49 49 53 53 53 ...
##  $ price2: int  61 37 53 41 41 33 49 53 45 53 ...
##  $ sales1: num  11.32 12.92 18.89 14.67 8.65 ...
##  $ sales2: num  0.0047 0.0037 7.5429 7.0652 21.2085 ...</code></pre>
<pre class="r"><code>### Build a model
### store and day are factor variables, so they are used as fixed effects
### price1 and price2 are used as covariates;

oranges.lm1 &lt;- lm(sales1 ~ price1 + price2 + store + day , data = oranges)
anova(oranges.lm1)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["int"],"align":["right"]},{"label":["Sum Sq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Mean Sq"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["F value"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>F)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"516.59214","3":"516.59214","4":"29.099631","5":"1.762987e-05","_rn_":"price1"},{"1":"1","2":"62.72614","3":"62.72614","4":"3.533363","5":"7.287312e-02","_rn_":"price2"},{"1":"5","2":"212.95239","3":"42.59048","4":"2.399121","5":"6.854756e-02","_rn_":"store"},{"1":"5","2":"433.09687","3":"86.61937","4":"4.879269","5":"3.456478e-03","_rn_":"day"},{"1":"23","2":"408.30824","3":"17.75253","4":"NA","5":"NA","_rn_":"Residuals"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>### Create a reference Grid
oranges.rg1 &lt;- ref.grid(oranges.lm1)
oranges.rg1</code></pre>
<pre><code>## &#39;emmGrid&#39; object with variables:
##     price1 = 51.222
##     price2 = 48.556
##     store = 1, 2, 3, 4, 5, 6
##     day = 1, 2, 3, 4, 5, 6</code></pre>
<pre class="r"><code>### Obtain the predicted value of different reference level combinations
### Using summary() or predict()
oranges.rg1.prediction &lt;- summary(oranges.rg1)
oranges.rg1.prediction</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["price1"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["price2"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["store"],"name":[3],"type":["fct"],"align":["left"]},{"label":["day"],"name":[4],"type":["fct"],"align":["left"]},{"label":["prediction"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["SE"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"51.22222","2":"48.55556","3":"1","4":"1","5":"2.918413","6":"2.717559","7":"23","_rn_":"1"},{"1":"51.22222","2":"48.55556","3":"2","4":"1","5":"4.961475","6":"2.377742","7":"23","_rn_":"2"},{"1":"51.22222","2":"48.55556","3":"3","4":"1","5":"3.200891","6":"2.377742","7":"23","_rn_":"3"},{"1":"51.22222","2":"48.55556","3":"4","4":"1","5":"6.198757","6":"2.363673","7":"23","_rn_":"4"},{"1":"51.22222","2":"48.55556","3":"5","4":"1","5":"5.543218","6":"2.363116","7":"23","_rn_":"5"},{"1":"51.22222","2":"48.55556","3":"6","4":"1","5":"10.563739","6":"2.366683","7":"23","_rn_":"6"},{"1":"51.22222","2":"48.55556","3":"1","4":"2","5":"3.848804","6":"2.701335","7":"23","_rn_":"7"},{"1":"51.22222","2":"48.55556","3":"2","4":"2","5":"5.891866","6":"2.335579","7":"23","_rn_":"8"},{"1":"51.22222","2":"48.55556","3":"3","4":"2","5":"4.131282","6":"2.335579","7":"23","_rn_":"9"},{"1":"51.22222","2":"48.55556","3":"4","4":"2","5":"7.129148","6":"2.352186","7":"23","_rn_":"10"},{"1":"51.22222","2":"48.55556","3":"5","4":"2","5":"6.473609","6":"2.330670","7":"23","_rn_":"11"},{"1":"51.22222","2":"48.55556","3":"6","4":"2","5":"11.494130","6":"2.339254","7":"23","_rn_":"12"},{"1":"51.22222","2":"48.55556","3":"1","4":"3","5":"11.018569","6":"2.534556","7":"23","_rn_":"13"},{"1":"51.22222","2":"48.55556","3":"2","4":"3","5":"13.061630","6":"2.416451","7":"23","_rn_":"14"},{"1":"51.22222","2":"48.55556","3":"3","4":"3","5":"11.301047","6":"2.416451","7":"23","_rn_":"15"},{"1":"51.22222","2":"48.55556","3":"4","4":"3","5":"14.298913","6":"2.431679","7":"23","_rn_":"16"},{"1":"51.22222","2":"48.55556","3":"5","4":"3","5":"13.643374","6":"2.363673","7":"23","_rn_":"17"},{"1":"51.22222","2":"48.55556","3":"6","4":"3","5":"18.663895","6":"2.347839","7":"23","_rn_":"18"},{"1":"51.22222","2":"48.55556","3":"1","4":"4","5":"6.096286","6":"2.651370","7":"23","_rn_":"19"},{"1":"51.22222","2":"48.55556","3":"2","4":"4","5":"8.139348","6":"2.352186","7":"23","_rn_":"20"},{"1":"51.22222","2":"48.55556","3":"3","4":"4","5":"6.378765","6":"2.352186","7":"23","_rn_":"21"},{"1":"51.22222","2":"48.55556","3":"4","4":"4","5":"9.376630","6":"2.388653","7":"23","_rn_":"22"},{"1":"51.22222","2":"48.55556","3":"5","4":"4","5":"8.721091","6":"2.337599","7":"23","_rn_":"23"},{"1":"51.22222","2":"48.55556","3":"6","4":"4","5":"13.741613","6":"2.341304","7":"23","_rn_":"24"},{"1":"51.22222","2":"48.55556","3":"1","4":"5","5":"12.795800","6":"2.444597","7":"23","_rn_":"25"},{"1":"51.22222","2":"48.55556","3":"2","4":"5","5":"14.838862","6":"2.466155","7":"23","_rn_":"26"},{"1":"51.22222","2":"48.55556","3":"3","4":"5","5":"13.078278","6":"2.466155","7":"23","_rn_":"27"},{"1":"51.22222","2":"48.55556","3":"4","4":"5","5":"16.076144","6":"2.519089","7":"23","_rn_":"28"},{"1":"51.22222","2":"48.55556","3":"5","4":"5","5":"15.420605","6":"2.395544","7":"23","_rn_":"29"},{"1":"51.22222","2":"48.55556","3":"6","4":"5","5":"20.441126","6":"2.370343","7":"23","_rn_":"30"},{"1":"51.22222","2":"48.55556","3":"1","4":"6","5":"8.748779","6":"2.786176","7":"23","_rn_":"31"},{"1":"51.22222","2":"48.55556","3":"2","4":"6","5":"10.791841","6":"2.337599","7":"23","_rn_":"32"},{"1":"51.22222","2":"48.55556","3":"3","4":"6","5":"9.031258","6":"2.337599","7":"23","_rn_":"33"},{"1":"51.22222","2":"48.55556","3":"4","4":"6","5":"12.029123","6":"2.364688","7":"23","_rn_":"34"},{"1":"51.22222","2":"48.55556","3":"5","4":"6","5":"11.373584","6":"2.352318","7":"23","_rn_":"35"},{"1":"51.22222","2":"48.55556","3":"6","4":"6","5":"16.394106","6":"2.370539","7":"23","_rn_":"36"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="r"><code>### Get LS Mean for day
lsmeans(oranges.rg1,&quot;day&quot;)</code></pre>
<pre><code>##  day lsmean   SE df lower.CL upper.CL
##  1     5.56 1.77 23     1.91     9.22
##  2     6.49 1.73 23     2.92    10.07
##  3    13.66 1.75 23    10.04    17.29
##  4     8.74 1.73 23     5.16    12.33
##  5    15.44 1.79 23    11.75    19.14
##  6    11.39 1.77 23     7.74    15.05
## 
## Results are averaged over the levels of: store 
## Confidence level used: 0.95</code></pre>
<p><strong>coefficients</strong></p>
<p>Construct confidence intervals for and perform hypothesis tests on
linear combinations using the ESTIMATE statement; The ESTIMATE statement
specifies the coefficients in the vector <span
class="math inline">\(\mathbf{c}\)</span> that define the linear
combination <span class="math inline">\(\mathbf{c}^{\prime}
\boldsymbol{\beta}\)</span> that you want to estimate.</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet Age;
 estimate &#39;gamma&#39; Intercept 1 Location 0 0 0 0 0 Sqfeet 0 Age 0 ;
 estimate &#39;m1-m2&#39; Intercept 0 Location 1 -1 0 0 0 Sqfeet 0 Age 0 ;
run; quit; </code></pre>
<p><strong>Inference for Estimable Linear Combinations</strong></p>
<p><span class="math display">\[
\frac{\mathbf{c}^{\prime} \hat{\beta}-\mathbf{c}^{\prime}
\boldsymbol{\beta}}{\text { s.e. }\left(\mathbf{c}^{\prime}
\boldsymbol{\beta}\right)} \sim t_{d / \varepsilon}
\]</span> where the standard error of <span
class="math inline">\(\mathbf{c}^{\prime}
\hat{\boldsymbol{\beta}}\)</span> is <span class="math display">\[
\text { s.e. }\left(\mathbf{c}^{\prime}
\hat{\boldsymbol{\beta}}\right)=\hat{\sigma}
\sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-}
\mathbf{c}} \text { . }
\]</span> The <span class="math inline">\(t\)</span> -statistic for
testing <span class="math inline">\(H_{0}: \mathbf{c}^{\prime}
\boldsymbol{\beta}=0\)</span> is then <span class="math display">\[
t=\frac{\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}}{\text { s.e.
}\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)}
\]</span> and the two-sided <span class="math inline">\(p\)</span>
-value is <span class="math display">\[
p=P\left(\left|T_{d j e}\right| \geq|t|\right)=2 P\left(T_{d f e}
\geq|t|\right) .
\]</span></p>
<p>In order to compute the confidence interval for the ‘m1-m2’ linear
combination, use the CLPARM option on the MODEL statement, as in the
following program.</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet Age / clparm;
 estimate &#39;m1-m2&#39; Intercept 0 Location 1 -1 0 0 0 Sqfeet 0 Age 0 ;
run; quit;</code></pre>
</div>
<div id="the-multivariate-t-distribution" class="section level3">
<h3>The Multivariate t Distribution</h3>
<p>Most of the classical MCPs fall under the general umbrella of “MaxT
methods”; that is, they are based on the distribution of the
<strong>maximum of multiple t-statistics.</strong></p>
<p>Confidence intervals for the estimable functions <span
class="math inline">\(\mathbf{c}_{i}^{\prime}
\boldsymbol{\beta}\)</span> have the form <span class="math display">\[
\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}} \pm c_{\alpha} s . e
.\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)
\]</span> where <span class="math inline">\(c_{\alpha}\)</span> is a
critical value that is selected to make the <span
class="math inline">\(\mathrm{FWE}=\alpha\)</span> for the set of
confidence intervals for the family <span
class="math inline">\(\mathbf{c}_{1}^{\prime} \boldsymbol{\beta},
\mathbf{c}_{2}^{\prime} \boldsymbol{\beta}, \ldots,
\mathbf{c}_{k}^{\prime} \boldsymbol{\beta}\)</span>.</p>
<p>To find the right <span class="math inline">\(c_{\alpha}\)</span>,
you can use the joint distribution of the statistics <span
class="math display">\[
T_{i}=\frac{\mathbf{c}_{i}^{\prime}
\hat{\boldsymbol{\beta}}-\mathbf{c}_{i}^{\prime}
\boldsymbol{\beta}}{\operatorname{s.e.}\left(\mathbf{c}_{i}^{\prime}
\hat{\boldsymbol{\beta}}\right)}, \quad i=1, \ldots, k
\]</span> The collection of random variables <span
class="math inline">\(\left\{T_{1}, T_{2}, \ldots,
T_{k}\right\}\)</span> has the multivariate <span
class="math inline">\(t\)</span> distribution when the classical linear
model assumptions are valid.</p>
<p>If <span class="math inline">\(\mathbf{Z}=\left(Z_{1}, \ldots,
Z_{k}\right)\)</span> is distributed as multivariate normal with zero
mean with known covariance matrix <span
class="math inline">\(\mathbf{R}\)</span>, and if <span
class="math inline">\(V\)</span> is distributed as Chi-Square with <span
class="math inline">\(d f\)</span> degrees of freedom, independent of
<span class="math inline">\(\mathbf{Z}\)</span>, then <span
class="math display">\[
\mathbf{T}=\frac{\mathbf{Z}}{\sqrt{V / d f}}
\]</span> has the multivariate <span class="math inline">\(t\)</span>
distribution with dispersion matrix <span
class="math inline">\(\mathbf{R}\)</span> and degrees of freedom <span
class="math inline">\(d f\)</span>.</p>
<p>First, define the contrast matrix <span class="math display">\[
\mathbf{C}=\left(\mathbf{c}_{1}, \ldots, \mathbf{c}_{k}\right)
\]</span> Then you can write the estimates of the set of <span
class="math inline">\(k\)</span> estimable linear combinations as the
<span class="math inline">\(k \times 1\)</span> vector <span
class="math inline">\(\mathbf{C}^{\prime}
\hat{\boldsymbol{\beta}}\)</span>, which is distributed as multivariate
normal when the assumptions are true: <span class="math display">\[
\mathbf{C}^{\prime} \hat{\boldsymbol{\beta}} \sim
\boldsymbol{N}_{k}\left(\mathbf{C}^{\prime} \boldsymbol{\beta},
\sigma^{2} \mathbf{C}^{\prime}\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-} \mathbf{C}\right)
\]</span> (If the X matrix contains random variables, then this is the
conditional distribution, given the observed <span
class="math inline">\(\mathbf{X}\)</span>.) From this expression you can
derive <span class="math inline">\(Z\)</span> -statistics: <span
class="math display">\[
Z_{i}=\frac{\mathbf{c}_{i}^{\prime}
\hat{\boldsymbol{\beta}}-\mathbf{c}_{i}^{\prime}
\boldsymbol{\beta}}{\sigma
\sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-}
\mathbf{c}}} \sim N(0,1)
\]</span> You can write the entire set of <span
class="math inline">\(Z\)</span> -statistics in matrix/vector notation
as <span class="math display">\[
\mathbf{Z}=\left(\sigma^{2} \mathbf{D}\right)^{-1 /
2}\left(\mathbf{C}^{\prime} \hat{\boldsymbol{\beta}}-\mathbf{C}^{\prime}
\boldsymbol{\beta}\right),
\]</span> where <span class="math inline">\(\mathbf{D}\)</span> is the
diagonal matrix having diagonal elements <span
class="math inline">\(\mathbf{c}_{i}^{\prime}\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-} \mathbf{c}_{i}\)</span>, thus <span
class="math display">\[
\mathbf{Z} \sim N_{k}\left(0, \mathbf{D}^{-1 / 2}
\mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-}
\mathbf{C D}^{-1 / 2}\right)
\]</span> The <span class="math inline">\(\mathbf{R}\)</span> matrix is
the <strong>covariance matrix</strong> of the <span
class="math inline">\(\mathbf{Z}\)</span> vector: <span
class="math display">\[
\mathbf{R}=\mathbf{D}^{-1 / 2}
\mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-}
\mathbf{C} \mathbf{D}^{-1 / 2}
\]</span></p>
<p>Notice that - <span class="math inline">\(\mathbf{R}\)</span> is the
correlation matrix of the <span class="math inline">\(Z
\mathrm{~s}\)</span> as there are <span class="math inline">\(1
\mathrm{~s}\)</span> on the diagonal. - <span
class="math inline">\(\mathbf{R}\)</span> is a known matrix, depending
on no unknown parameters. - The correlations between the <span
class="math inline">\(Z\)</span> ’s depend on + the set of linear
combinations to be estimated (determined by C), and + the design of the
study and the model used for the analysis (determined by <span
class="math inline">\(\mathbf{X}\)</span> ).</p>
<p>Now, to get the vector of <span class="math inline">\(t\)</span>
statistics, you can write <span class="math display">\[
\mathbf{T}=\frac{\mathbf{Z}}{s / \sigma}
\]</span> To remove the <span class="math inline">\(\sigma\)</span> in
the <span class="math inline">\(Z\)</span> statistic and replace it with
<span class="math inline">\(s\)</span>. Under the model assumptions,
<span class="math display">\[
\frac{d f \times s^{2}}{\sigma^{2}} \sim \chi_{d f}^{2}
\]</span> and is independent of <span
class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>, thus
establishing the representation of <span
class="math inline">\(\mathbf{T}\)</span> as <span
class="math display">\[
\mathbf{T}=\frac{\mathbf{Z}}{\sqrt{V / d f}}
\]</span> and hence that it has the multivariate <span
class="math inline">\(t\)</span> distribution with dispersion matrix
<span class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2}
\mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-}
\mathbf{C} \mathbf{D}^{-1 / 2}\)</span></p>
<p><strong>Obtaining the R Matrix for Multiple Comparisons</strong></p>
<pre><code>proc orthoreg data=House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmestimate Location
 &#39;m1-m2&#39; 1 -1 0 0 0,
 &#39;m2-m3&#39; 0 1 -1 0 0,
 &#39;m3-m4&#39; 0 0 1 -1 0,
 &#39;m4-m5&#39; 0 0 0 1 -1 / corr;
run;</code></pre>
</div>
<div id="calculating-the-critical-value-c_alpha" class="section level3">
<h3>Calculating the Critical Value <span
class="math inline">\(c_{\alpha}\)</span></h3>
<p>Suppose for simplicity that the critical value <span
class="math inline">\(c_{\alpha}\)</span> is for two-sided intervals and
tests. There are many ways that you can find it, or at least approximate
it. First, you might try to integrate the multivariate <span
class="math inline">\(t\)</span> distribution and solve for <span
class="math inline">\(c_{\alpha}\)</span> : <span
class="math display">\[
\int_{-c_{\alpha}}^{c_{c}} \ldots \int_{-c_{\alpha}}^{c_{c}}
f\left(t_{1}, \ldots, t_{k} ; d f, \mathbf{R}\right) d t_{1} \ldots d
t_{k}=1-\alpha
\]</span> This approach is often impractical because the complicated
form of the multivariate <span class="math inline">\(t\)</span>
distribution function <span class="math inline">\(f\left(t_{1}, \ldots,
t_{k} ; d f, \mathbf{R}\right)\)</span> precludes analytical
integration; numerical integration methods also can founder if there are
too many dimensions <span class="math inline">\(k\)</span>.</p>
<p>The value <span class="math inline">\(c_{\alpha}\)</span> is found
the following ways:</p>
<ul>
<li><strong>Exact Analytic Solution</strong>: When the data are balanced
and the comparisons are simple, the multivariate <span
class="math inline">\(t\)</span> integral simplifies and is solvable in
terms of known and special mathematical distribution functions like
“Tukey’s studentized range distribution” and “Dunnett’s range
distribution”<br />
</li>
<li><strong>Conservative Analytic Solution</strong>: In some cases with
unbalanced data and/or more complex comparisons, the exact analytic
solution provides a conservative solution in that the <span
class="math inline">\(c_{\alpha}\)</span> is larger than it needs to
be.</li>
<li><strong>Approximate Analytic Solution</strong>: In some cases, with
unbalanced data and/or more complex comparisons, the exact analytic
solution provides an approximate solution in that the <span
class="math inline">\(c_{\alpha}\)</span> is perhaps larger than it
needs to be, or perhaps smaller.</li>
<li><strong>Simple Monte Carlo Solution</strong>: By simulating many
multivariate <span class="math inline">\(t\)</span> vectors, you can
estimate the <span class="math inline">\(1-\alpha\)</span> quantile of
<span class="math inline">\(\max T\)</span>.</li>
<li><strong>Control Variate Monte Carlo Solution</strong>: This method
also proceeds by simulating multivariate <span
class="math inline">\(t\)</span> vectors, but then using control
variates to reduce the variance of the estimate of the <span
class="math inline">\(1-\alpha\)</span> quantile of <span
class="math inline">\(\max \mathrm{T}\)</span>.</li>
<li><strong>Quasi-Monte Carlo Solution</strong>: This method proceeds by
approximating the multiple integral shown above by using a systematic
grid of <span class="math inline">\(t\)</span> vectors. The method can
often provide much better accuracy with far fewer <span
class="math inline">\(t\)</span> vectors (Genz and Bretz, 2009).</li>
</ul>
</div>
<div id="all-pairwise-comparisons-and-studentized-range-distribution"
class="section level3">
<h3>All Pairwise Comparisons and Studentized Range Distribution</h3>
<p>In general, there are such comparisons.</p>
<p><span class="math display">\[
\left(\begin{array}{l}
g \\
2
\end{array}\right)=\frac{g !}{2 !(g-2) !}=\frac{g(g-1)}{2}
\]</span> For all simultaneous pairwise comparisons <span
class="math inline">\(\mu_{i}-\mu_{i^{\prime}}, 1 \leq i, i^{\prime}
\leq g\)</span>, the critical value <span
class="math inline">\(c_{\alpha}\)</span> must satisfy <span
class="math display">\[
P\left(\bar{y}_{i}-\bar{y}_{i^{\prime}}-c_{\alpha} \hat{\sigma} \sqrt{2
/ n} \leq \mu_{i}-\mu_{i^{\prime}} \leq
\bar{y}_{i}-\bar{y}_{i^{\prime}}+c_{\alpha} \hat{\sigma} \sqrt{2 / n},
\text { for all } i, i^{\prime}\right)=1-\alpha
\]</span> or equivalently <span class="math display">\[
P\left(\max _{i, i^{\prime}}
\frac{\left|\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{i^{\prime}}-\mu_{i^{\prime}}\right)\right|}{\hat{\sigma}
\sqrt{2 / n}} \leq c_{\alpha}\right)=1-\alpha
\]</span></p>
<p>This formula shows the “MaxT”. In the balanced ANOVA, the MaxT
statistic has a particularly simple form because the denominator
standard error <span class="math inline">\(\hat{\sigma} \sqrt{2 /
n}\)</span> is the same for all <span class="math inline">\(t\)</span>
-statistics. This simplification, along with the special structure of
the set of all pairwise comparisons, allows for <span
class="math inline">\(c_{\alpha}\)</span> to be calculated analytically
from the studentized range distribution. When the standard errors differ
for the various <span class="math inline">\(t\)</span> -statistics, more
complex approximations such as simulation-based methods are needed.</p>
<p><strong>Studentized Range Distribution</strong></p>
<p>If <span class="math inline">\(Z_{1}, \ldots, Z_{g}\)</span> are
independent standard normal random variables, and <span
class="math inline">\(V\)</span> is a random variable distributed as
chi-square with <span class="math inline">\(v\)</span> degrees of
freedom, independent of the <span class="math inline">\(Z
\mathrm{~s}\)</span>, then <span class="math display">\[
Q_{g, v}^{R}=\max _{i, i^{\prime}}
\frac{\left|Z_{i}-Z_{i^{\prime}}\right|}{\sqrt{V / v}}
\]</span> has the studentized range distribution with parameters <span
class="math inline">\(g\)</span> and <span
class="math inline">\(r\)</span>. With this definition and some
algebraic manipulation, along with well-known results concerning
distributions involving normally distributed variables, you can show
that <span class="math inline">\(c_{\alpha}\)</span> satisfies <span
class="math display">\[
P\left(\frac{Q_{g, g(n-1)}^{R}}{\sqrt{2}} \leq
c_{\alpha}\right)=1-\alpha
\]</span> or equivalently that <span class="math display">\[
c_{\alpha}=\frac{q_{1-\alpha, g, g(n-1)}^{R}}{\sqrt{2}}
\]</span> where <span
class="math inline">\(q_{1-\alpha_{m}}^{R}\)</span> is the <span
class="math inline">\(1-\alpha\)</span> quantile of the studentized
range distribution.</p>
<p><strong>“Hand Calculation” of Studentized Range Critical
Value</strong></p>
<p>The quantiles <span
class="math inline">\(q_{1-\alpha_{\alpha}}^{R}\)</span> of the
studentized range distribution can be calculated using the PROBMC
function in SAS, which evaluates the cumulative probability distribution
function of the random variable <span class="math inline">\(Q_{g, v}^{R}
.\)</span></p>
<pre><code>data;
 qval = probmc(&quot;RANGE&quot;,.,.95,45,5);
 c_alpha = qval/sqrt(2);
run; </code></pre>
<p><strong>Implementation</strong></p>
<p>Obtaining Pairwise Comparisons Using the LSMEANS Statement</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmeans Location / tdiff;
run; quit;</code></pre>
<p>Pairwise Comparisons with a Control, For example, perhaps region B is
considered the premium region, and you wish to know how other regions
compare with it.</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmeans Location / tdiff=control(&#39;B&#39;);
run; quit;</code></pre>
</div>
<div id="tukeys-method-for-all-pairwise-comparisons"
class="section level3">
<h3>Tukey’s Method for All Pairwise Comparisons</h3>
<p>Confidence intervals for all pairwise comparisons in the balanced
ANOVA that use the critical value <span
class="math inline">\(c_{\alpha}=q_{1-\alpha, g, g(n-1)}^{R} /
\sqrt{2}\)</span> from the studentized range distribution are commonly
said to be constructed by “Tukey’s Method,” after Tukey (1953). The
intervals may also be called “Tukey intervals” in this case. When
testing hypotheses <span class="math inline">\(H_{0}:
\mu_{i}-\mu_{i^{\prime}}=0\)</span>, either by checking to see if 0 is
inside the Tukey interval or by comparing <span
class="math inline">\(\left|t_{i, i^{\prime}}\right|\)</span> to <span
class="math inline">\(c_{\alpha}=q_{1-\alpha, g, g(n-1)}^{R} /
\sqrt{2}\)</span>, the tests are called “Tukey tests.”</p>
<p><strong>Compare the Tukey intervals with the Bonferroni
intervals</strong></p>
<p>Since there are <span class="math inline">\(5 \times 4 /
2=10\)</span> pairwise comparisons among the five groups, the Bonferroni
critical value uses <span class="math inline">\(\alpha^{\prime}=0.05 /
10=0.005\)</span>, and the critical value nnis <span
class="math inline">\(t_{0.9975,45}=2.9521\)</span>. The reason for the
difference between the Bonferroni critical value and the Tukey critical
value, <span class="math inline">\(2.9521\)</span> vs. <span
class="math inline">\(2.84145\)</span>, is that the Tukey critical value
is <strong>based on the precise distribution of the 10 pairwise
statistics</strong> <span
class="math inline">\(\left\{\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{i^{\prime}}-\mu_{i^{\prime}}\right)\right\}
/(\hat{\sigma} \sqrt{2 / n}) .\)</span> There are correlations among
these statistics because there are many common random elements. For
example, the statistics <span
class="math inline">\(\left\{\left(\bar{y}_{1}-\mu_{1}\right)-\left(\bar{y}_{2}-\mu_{2}\right)\right\}
/(\hat{\sigma} \sqrt{2 / n})\)</span> and <span
class="math inline">\(\left\{\left(\bar{y}_{1}-\mu_{1}\right)-\left(\bar{y}_{3}-\mu_{3}\right)\right\}
/(\hat{\sigma} \sqrt{2 / n})\)</span> are <strong>correlated</strong>
because both contain the common random elements <span
class="math inline">\(\bar{y}_{1}\)</span> and <span
class="math inline">\(\hat{\sigma}\)</span>.</p>
<p>In summary, Tukey’s intervals control the FWE precisely (under the
assumptions of the model), while the Bonferroni intervals over-control
and the unadjusted intervals under-control.</p>
<p><strong>SAS Implementation</strong></p>
<pre><code>***  PROC GLM Calculation of Tukey Adjusted p-Values;
proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 lsmeans Diet/pdiff adjust=tukey;
run; quit;</code></pre>
<p><strong>Simultaneous Intervals for Mean Differences</strong></p>
<ul>
<li>Unadjusted Intervals</li>
<li>Bonferroni Intervals</li>
<li>Tukey Intervals</li>
</ul>
<pre><code>proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 means Diet/cldiff t bon tukey;
run; </code></pre>
<p><strong>R Implementation</strong></p>
<pre><code>## contrMat specify other contrast matrices in advance, such as &quot;Dunnett&quot;, &quot;Williams&quot;
## Tukey 1
data(warpbreaks)
warpbreaks.aov &lt;- aov(breaks ~ tension, data = warpbreaks)
warpbreaks.mc &lt;- glht(warpbreaks.aov, 
                      linfct = mcp(tension = &quot;Tukey&quot;))
                      
## alternative 1
glht(warpbreaks.aov,linfct = mcp(tension = c(&quot;M - L = 0&quot;,
                                             &quot;H - L = 0&quot;,
                                             &quot;H - M = 0&quot;)))

## alternative 2                  
contr &lt;- rbind(&quot;M - L&quot; = c(-1,  1, 0),
               &quot;H - L&quot; = c(-1,  0, 1),
               &quot;H - M&quot; = c( 0, -1, 1));
glht(warpbreaks.aov, linfct = mcp(tension = contr))

## alternative 3
glht(warpbreaks.aov,
     linfct = cbind(0, contr %*% contr.treatment(3)))
     
     
## Multiple Comparisons of Means: Tukey Contrasts
## Linear Hypotheses:
##           Estimate
## M - L == 0  -10.000
## H - L == 0  -14.722
## H - M == 0   -4.722


## Calculate and plot simultaneous confidence intervals
warpbreaks.ci &lt;- confint(warpbreaks.mc, level = 0.95)
warpbreaks.ci
 
## Unadjusted (marginal) confidence interval
confint(warpbreaks.mc, calpha = univariate_calpha())</code></pre>
<p><strong>The Tukey Adjusted p-Value</strong></p>
<p><span class="math display">\[
\tilde{p}_{i, i^{\prime}}=P\left(Q_{g, g(n-1)}^{R} \geq
\sqrt{2}\left|t_{i, i}\right|\right)
\]</span> By comparison, the ordinary (unadjusted) <span
class="math inline">\(p\)</span> -value is given by <span
class="math inline">\(p_{i, i^{\prime}}=2 P\left(T_{g(n-1)} \geq t_{i,
i} \mid\right)\)</span>, where <span
class="math inline">\(T_{V}\)</span> denotes a Student’s <span
class="math inline">\(t\)</span> -distributed random variable with <span
class="math inline">\(v\)</span> degrees of freedom (here, <span
class="math inline">\(v=g(n-1))\)</span>.</p>
<pre><code>**** “By Hand” Calculation of Raw and Tukey Adjusted p-Values;
data;
 n=10; g=5; df=g*(n-1);
 Mean_A=12.05; Mean_B=11.02; MSE=0.993422;
 tstat_AB = (Mean_A-Mean_B)/(sqrt(MSE)*sqrt(2/n));
 raw_p = 2*(1-probt(abs(tstat_AB),df));
 adj_p = 1-probmc(&#39;RANGE&#39;,sqrt(2)*abs(tstat_AB),.,df,g);
run; 
</code></pre>
</div>
<div id="displaying-pairwise-comparisons-graphically"
class="section level3">
<h3>Displaying Pairwise Comparisons Graphically</h3>
<p><strong>Graphical Presentation for Comparing Means: LINES Option
SAS</strong></p>
<p>LINES option, which provides a listing of the means in descending
order and a text graph that displays the results of the tests.</p>
<pre><code>proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 means Diet/tukey lines;
run; </code></pre>
<p><strong>Graphical Presentation for Comparing Means: The
Diffogram</strong></p>
<p>An alternative presentation of the simultaneous confidence intervals
is known as the mean-mean scatterplot (Hsu, 1996); in SAS, it is called
a diffogram. First, all non-redundant pairs <span
class="math inline">\(\left(\bar{y}_{i},
\bar{y}_{i^{\prime}}\right)\)</span> are plotted on a two-dimensional
plot. Then the confidence intervals are represented as <span
class="math inline">\(-45^{\circ}\)</span> lines emanating symmetrically
from the centers <span class="math inline">\(\left(\bar{y}_{i},
\bar{y}_{i}\right)\)</span>, scaled in such a way that the line covers
the <span class="math inline">\(45^{\circ}\)</span> line when the
interval covers 0 ; see Figure <span class="math inline">\(4.2\)</span>
below.</p>
<pre><code>ods graphics on;
proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 lsmeans Diet/cl adjust=tukey;
run;
quit;
ods graphics off; </code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Turkey_Diffgram.PNG" alt="Figure: Diffogram indicating Comparisons of Diets" width="100%" />
<p class="caption">
Figure: Diffogram indicating Comparisons of Diets
</p>
</div>
<p><strong>R Implementation</strong></p>
<pre><code>## CI Plot
plot(warpbreaks.ci, main = &quot;&quot;, 
     ylim = c(0.5, 3.5),xlab = &quot;Breaks&quot;)</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Turkey_Plots.png" alt="Figure: Turkey CI Plots" width="100%" />
<p class="caption">
Figure: Turkey CI Plots
</p>
</div>
<pre><code>## CI Boxplots
warpbreaks.cld &lt;- cld(warpbreaks.mc)
plot(warpbreaks.cld)</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Turkey_Boxplots.png" alt="Figure: CI Boxplots" width="100%" />
<p class="caption">
Figure: CI Boxplots
</p>
</div>
</div>
<div
id="dunnetts-two-sided-comparisons-with-a-control-and-dunnetts-two-sided-range-distribution"
class="section level3">
<h3>Dunnett’s Two-Sided Comparisons with a Control and Dunnett’s
Two-Sided Range Distribution</h3>
<p>If you want to make a claim about whether the treated groups’ means
are either larger or smaller than the control group mean, then you
should use two-sided intervals.</p>
<p><span class="math inline">\(\bar{y}_{0}\)</span> denote the mean of
the control group, you need a <span
class="math inline">\(c_{\alpha}\)</span> for which <span
class="math display">\[
P\left(\bar{y}_{i}-\bar{y}_{0}-c_{\alpha} \hat{\sigma} \sqrt{2 / n} \leq
\mu_{i}-\mu_{0} \leq \bar{y}_{i}-\bar{y}_{0}+c_{\alpha} \hat{\sigma}
\sqrt{2 / n}, \text { for all } i\right)=1-\alpha
\]</span> Algebraically rearranging terms, you see that <span
class="math inline">\(c_{\alpha}\)</span> must satisfy <span
class="math display">\[
P\left(\max _{i}
\frac{\left|\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{0}-\mu_{0}\right)\right|}{\hat{\sigma}
\sqrt{2 / n}} \leq c_{\alpha}\right)=1-\alpha
\]</span> the critical value <span
class="math inline">\(c_{\alpha}\)</span> can be calculated analytically
from Dunnett’s two-sided range distribution.</p>
<p><strong>Dunnett’s two-sided range distribution</strong></p>
<p>If <span class="math inline">\(Z_{0}, Z_{1}, \ldots, Z_{g}\)</span>
are independent standard normal random variables, and <span
class="math inline">\(V\)</span> is a random variable distributed as
chi-square with <span class="math inline">\(v\)</span> degrees of
freedom, independent of the <span class="math inline">\(Z
\mathrm{~s}\)</span>, then <span class="math display">\[
Q_{g, v}^{D 2}=\frac{\max _{i}\left|Z_{i}-Z_{0}\right|}{\sqrt{2 V / v}}
\]</span> has Dunnett’s two-sided range distribution with parameters
<span class="math inline">\(g\)</span> and <span
class="math inline">\(v\)</span>.</p>
<pre><code>*** “By Hand Calculation” of Dunnett&#39;s Two-Sided Critical Value;
data;
 c_alpha = probmc(&quot;DUNNETT2&quot;,.,.95,21,6);
run;
proc print;
run;
 
### Calculate critical values for Dunnett procedure given alpha, df1 and df2 in R;

qDunnett &lt;- function (p, df, k, rho,
                      type = c(&quot;two-sided&quot;, &quot;one-sided&quot;))
{
  type &lt;- match.arg(type)
  alpha &lt;- 1 - p
  if (type == &quot;two-sided&quot;) {
    alpha &lt;- alpha/2
  }
  S &lt;- matrix(rho, nrow=k, ncol=k) + (1-rho)*diag(k)
  if (type == &quot;two-sided&quot;) {
    f &lt;- function(d, df, k, S, p) {
      mnormt::sadmvt(df=df, lower=rep(-d,k), upper=rep(d,k),
                      mean=rep(0,k), S=S, maxpts=2000*k) - p
    }
  }
  else {
    f &lt;- function(d, df, k, S, p) {
      mnormt::pmt(d, S=S, df=df) - p
    }
  }
  d &lt;- uniroot(f,
               df = df, k = k, S = S, p=p,
               lower=qt(1 - alpha, df),
               upper=qt(1 - alpha/k, df),
               tol=.Machine$double.eps, maxiter=5000)$root
  return(d)
}


p &lt;- 0.95; df &lt;- 24; rho &lt;- 0.5; k &lt;- 3
nCDunnett::qNCDun(p=p, nu=df, rho=rho,
                  delta=rep(0,times=k), two.sided=T)
qDunnett(p, df, k, rho)</code></pre>
<p><strong>SAS Implementation</strong></p>
<pre><code>data Tox;
 input Trt @;
 do j = 1 to 4;
 input Gain @; output;
 end;
datalines;
0 97.76 102.56 96.08 125.12
1 91.28 129.20 90.80 72.32
2 67.28 85.76 95.60 73.28
3 80.24 64.88 64.88 78.56
4 96.08 98.24 77.84 95.36 
5 57.68 89.84 98.48 92.72
6 68.72 85.28 68.72 74.24
;

*** Boxplots;
ods graphics on;
proc glm data=Tox;
 class Trt;
 model Gain=Trt;
 means Trt/dunnett;
run; quit;
ods graphics off;</code></pre>
<p><strong>Displaying Two-Sided Dunnett Comparisons
Graphically</strong></p>
<pre><code>means Trt/dunnett;

*** Or;
lsmeans Trt/adjust=dunnett;</code></pre>
<p><strong>R Implementation</strong></p>
<pre><code>data(&quot;recovery&quot;, package = &quot;multcomp&quot;)
recovery.aov &lt;- aov(minutes ~ blanket, data = recovery)
recovery.mc &lt;- glht(recovery.aov,
                    linfct = mcp(blanket = &quot;Dunnett&quot;),
                    alternative = &quot;less&quot;)   ## one-sided test
                    
## Alternative
contr &lt;- rbind(&quot;b1 -b0&quot; = c(-1, 1, 0, 0), 
               &quot;b2 -b0&quot; = c(-1, 0, 1, 0),
               &quot;b3 -b0&quot; = c(-1, 0, 0, 1))
summary(glht(recovery.aov, linfct = mcp(blanket = contr),
             alternative = &quot;less&quot;))
             
## KI und Plot
recovery.ci &lt;- confint(recovery.mc, level = 0.95)</code></pre>
<p><strong>Specify linear combination variante from Dunnett</strong></p>
<pre><code>## Variante from Dunnett
contr2 &lt;- rbind(&quot;b2 -b0&quot; = c(-1,  0, 1, 0),
                &quot;b2 -b1&quot; = c( 0, -1, 1, 0),
                &quot;b3 -b0&quot; = c(-1,  0, 0, 1),
                &quot;b3 -b1&quot; = c( 0, -1, 0, 1))
summary(glht(recovery.aov, linfct = mcp(blanket = contr2),
             alternative = &quot;less&quot;))
             
             
Linear Hypotheses:
            Estimate Std. Error t value Pr(&lt;t)    
b2 -b0 &gt;= 0  -7.4667     1.6038  -4.656 &lt;0.001 ***
b2 -b1 &gt;= 0  -5.3333     2.1150  -2.522 0.0278 *  
b3 -b0 &gt;= 0  -1.6667     0.8848  -1.884 0.1054    
b3 -b1 &gt;= 0   0.4667     1.6383   0.285 0.9150    </code></pre>
</div>
<div id="dunnetts-one-sided-comparisons-with-a-control"
class="section level3">
<h3>Dunnett’s One-Sided Comparisons with a Control</h3>
<p>If you want to reject the null hypothesis only when the treated
groups’ means are on one side of (e.g., lower than) the control group
mean, and if you are willing to <em>ignore any difference in the
opposite direction</em>, then you can <em>get more power</em> by using
one-sided tests or one-sided confidence intervals.</p>
<p>Thus, to obtain the critical points for lower-tailed inferences, you
need a <span class="math inline">\(c_{\alpha}\)</span> for which <span
class="math display">\[
P\left(\mu_{i}-\mu_{0} \leq \bar{y}_{i}-\bar{y}_{0}+c_{\alpha}
\hat{\sigma} \sqrt{2 / n}, \text { for all } i\right)=1-\alpha
\]</span> For upper-tailed inferences, you need a <span
class="math inline">\(c_{\alpha}\)</span> for which <span
class="math display">\[
P\left(\mu_{i}-\mu_{0} \geq \bar{y}_{i}-\bar{y}_{0}-c_{\alpha}
\hat{\sigma} \sqrt{2 / n}, \text { for all } i\right)=1-\alpha
\]</span> Rearranging terms algebraically and, in the case of lower-tail
inference <span class="math inline">\(c_{\alpha}\)</span> must satisfy
<span class="math display">\[
P\left(\max _{i}
\frac{\left(\bar{y}_{0}-\mu_{0}\right)-\left(\bar{y}_{i}-\mu_{i}\right)}{\hat{\sigma}
\sqrt{2 / n}} \leq c_{\alpha}\right)=1-\alpha
\]</span> and in the case of upper-tail inference <span
class="math inline">\(c_{\alpha}\)</span> must satisfy <span
class="math display">\[
P\left(\max _{i}
\frac{\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{0}-\mu_{0}\right)}{\hat{\sigma}
\sqrt{2 / n}} \leq c_{\alpha}\right)=1-\alpha
\]</span></p>
<p><strong>SAS Implementation</strong></p>
<pre><code>ods graphics on;
proc glm data=Tox;
 class Trt;
 model Gain=Trt;
 means Trt/dunnettl;
run; quit;
ods graphics off; </code></pre>
<p><strong>Graphing the One-Sided Dunnett Comparisons</strong></p>
<pre><code>lsmeans Trt/pdiff=controll;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Dunnett_OneSide.PNG" alt="Figure: Displaying One-Sided Dunnett Comparisons Graphically" width="100%" />
<p class="caption">
Figure: Displaying One-Sided Dunnett Comparisons Graphically
</p>
</div>
</div>
<div
id="maximum-modulus-distribution-multiple-inferences-for-independent-estimates"
class="section level3">
<h3>Maximum Modulus Distribution, Multiple Inferences for Independent
Estimates</h3>
<p>Whereas the distributions used in Tukey’s and Dunnett’s tests concern
estimates that are dependent, the studentized maximum modulus
distribution concerns estimates that are independent. The most common
applications of this distribution are to confidence intervals for means
and to orthogonal comparisons</p>
<p><strong>Simultaneous Intervals for the Treatment Means</strong></p>
<p>Suppose that you want simultaneous confidence intervals for the group
means themselves, rather than for their differences. <span
class="math inline">\(c_{\alpha}\)</span> for which <span
class="math display">\[
P\left(\bar{y}_{i}-c_{\alpha} \hat{\sigma} / \sqrt{n} \leq \mu_{i} \leq
\bar{y}_{i}+c_{\alpha} \hat{\sigma} / \sqrt{n}, \text { for all }
i\right)=1-\alpha
\]</span> Rearranging terms algebraically, <span class="math display">\[
P\left(\max _{i}
\frac{\left|\left(\bar{y}_{i}-\mu_{i}\right)\right|}{\hat{\sigma} /
\sqrt{n}} \leq c_{\alpha}\right)=1-\alpha
\]</span> Since the <span class="math inline">\(\bar{y}_{i}\)</span> are
independent, the <span
class="math inline">\(t_{i}=\left(\bar{y}_{i}-\mu_{i}\right)
/(\hat{\sigma} / \sqrt{n})\)</span> values are nearly independent, too.
They’re not quite independent because they share a common pooled
variance estimate <span class="math inline">\(\hat{\sigma}^{2}\)</span>.
Thus, you could use Šidák’s method, to approximate <span
class="math inline">\(c_{\alpha}\)</span> as the <span
class="math inline">\(1-(1-\alpha)^{1 / g}\)</span> quantile of the
<span class="math inline">\(t\)</span> -distribution. However, an exact
value for <span class="math inline">\(c_{\alpha}\)</span> can be
calculated using Tukey’s (1953) maximum modulus distribution.</p>
<p><strong>The Maximum Modulus Distribution</strong></p>
<p>If <span class="math inline">\(Z_{0}, Z_{1}, \ldots, Z_{g}\)</span>
are independent standard normal random variables, and <span
class="math inline">\(V\)</span> is a random variable distributed as
chi-square with <span class="math inline">\(v\)</span> degrees of
freedom, independent of the <span class="math inline">\(Z
\mathrm{~s}\)</span>, then <span class="math display">\[
Q_{g, v}^{M M}=\frac{\max _{i}\left|Z_{i}\right|}{\sqrt{V / v}}
\]</span> has the maximum modulus distribution with parameters <span
class="math inline">\(g\)</span> and <span
class="math inline">\(v\)</span>. You can see that the <span
class="math inline">\(c_{\alpha}\)</span> for the simultaneous
confidence intervals satisfies <span class="math display">\[
P\left(Q_{g, g(n-1)}^{M M} \leq c_{\alpha}\right)=1-\alpha
\]</span> or in other words, <span
class="math inline">\(c_{\alpha}=q_{1-\alpha, g, g(n-1)}^{M M}\)</span>,
where <span class="math inline">\(q_{1-\alpha, r}^{M M}\)</span> is the
<span class="math inline">\(1-\alpha\)</span> quantile of the maximum
modulus distribution.</p>
<p><strong>SAS Implementation</strong></p>
<pre><code>*** Simultaneous Confidence Intervals for Means;
proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 means Diet / clm smm sidak;
run; </code></pre>
<p>Since the intervals are almost independent, Šidák’s adjustment
provides a very close approximation to the maximum modulus method. Using
the maximum modulus distribution yields very slightly (about 0.2%)
tighter intervals.</p>
</div>
</div>
<div
id="multiple-comparisons-among-treatment-means-in-the-one-way-unbalanced-anova"
class="section level2">
<h2>Multiple Comparisons among Treatment Means in the One-Way Unbalanced
ANOVA</h2>
<p>For unbalanced sample sizes, s, the simple distributions such as
Tukey’s studentized range and Dunnett’s range distributions no longer
are valid. The standard errors differ from contrast to contrast, and the
simple range distributions can no longer be used directly.</p>
<div id="the-model-and-estimates" class="section level3">
<h3>The Model and Estimates</h3>
<p><span class="math display">\[
y_{i j}=\mu_{i}+\varepsilon_{i j}
\]</span> with independent, homoscedastic, and normally distributed
<span class="math inline">\(\varepsilon_{i j}\)</span> having mean
zero.</p>
<p>In the balanced case, the within-group samples all have the same size
<span class="math inline">\(n\)</span>. In the unbalanced case, we allow
them to differ, denoting the size of the <span
class="math inline">\(i^{\text {th }}\)</span> sample by <span
class="math inline">\(n_{i}\)</span>, for <span
class="math inline">\(i=1, \ldots, g\)</span>. The estimated parameters
are <span class="math inline">\(\hat{\mu}_{i}=\bar{y}_{i}=\left(1 /
n_{i}\right) \sum_{j=1}^{n_{i}} y_{i j}\)</span>, and <span
class="math inline">\(\hat{\sigma}^{2}=\Sigma_{i=1}^{g}\left\{\left(n_{i}-1\right)
s_{i}^{2}\right\} / \Sigma_{i=1}^{g}\left(n_{i}-1\right)\)</span>, where
<span class="math inline">\(s_{i}^{2}\)</span> is the ordinary sample
variance estimate for group <span class="math inline">\(i,
s_{i}^{2}=\sum_{j=1}^{n_{i}}\left(y_{i j}-\bar{y}_{i}\right)^{2}
/\left(n_{i}-1\right)\)</span>. The degrees of freedom for the estimate
of <span class="math inline">\(\sigma^{2}\)</span> is the error degrees
of freedom <span class="math inline">\(d f
e=\sum_{i=1}^{g}\left(n_{i}-1\right)=N-g\)</span>, where <span
class="math inline">\(N=\Sigma_{i=1}^{g} n_{i}\)</span> is the total of
all within-group sample sizes.</p>
<p><strong>All Pairwise Comparisons</strong></p>
<p>The confidence intervals for the difference of means <span
class="math inline">\(\mu_{i}-\mu_{i^{\prime}}\)</span> have the form
<span class="math display">\[
\bar{y}_{i}-\bar{y}_{i^{\prime}} \pm c_{\alpha} \hat{\sigma} \sqrt{1 /
n_{i}+1 / n_{i^{\prime}}}
\]</span> where <span
class="math inline">\(\bar{y}_{i}-\bar{y}_{i^{\prime}}\)</span> is the
usual least-squares estimate of <span
class="math inline">\(\mu_{i}-\mu_{i^{\prime}}\)</span> and <span
class="math inline">\(\hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i}}\)</span>
is its standard error. In the case of non-multiplicity-adjusted
confidence intervals, you set <span
class="math inline">\(c_{\alpha}\)</span> to be the <span
class="math inline">\(1-\alpha / 2\)</span> quantile of the <span
class="math inline">\(t_{d f e}\)</span> distribution, <span
class="math inline">\(t_{1-\alpha / 2, d f e}\)</span>, with <span
class="math inline">\(d f e=N-g\)</span>. As always, you can construct
Bonferroni-adjusted confidence intervals by setting <span
class="math inline">\(c_{\alpha}=t_{1-\alpha^{\prime} / 2, d f
e}\)</span>, where <span class="math inline">\(\alpha^{\prime}=\alpha /
k, k\)</span> being the number of inferences (e.g., pairwise
comparisons) in the family. And, as always, you can improve upon the
Bonferroni value by taking into account the distribution of the
differences.</p>
<p>Mathematically, <span class="math inline">\(c_{\alpha}\)</span> must
satisfy <span
class="math inline">\(P\left(\bar{y}_{i}-\bar{y}_{i}-c_{\alpha}
\hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i}} \leq \mu_{i}-\mu_{i^{\prime}}
\leq \bar{y}_{i}-\bar{y}_{i^{\prime}}+c_{\alpha} \hat{\sigma} \sqrt{1 /
n_{i}+1 / n_{i}}\right.\)</span>, for all <span
class="math inline">\(\left.i, i^{\prime}\right)=1-\alpha\)</span> or
equivalently, <span class="math display">\[
P\left(\max _{i, i^{\prime}}
\frac{\left|\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{i^{\prime}}-\mu_{i^{\prime}}\right)\right|}{\hat{\sigma}
\sqrt{1 / n_{i}+1 / n_{i}}} \leq c_{\alpha}\right)=1-\alpha
\]</span></p>
<p>Unlike the balanced case, the denominator of this expression, <span
class="math inline">\(\hat{\sigma} \sqrt{1 / n_{i}+1 /
n_{i^{\prime}}}\)</span>, is <strong>not constant</strong> for all <span
class="math inline">\(\left(i, i^{\prime}\right)\)</span> pairs. Thus,
the MaxT statistic does <strong>not have the studentized range
distribution</strong>; its distribution is actually quite
complicated.</p>
</div>
<div id="tukey-kramer-method" class="section level3">
<h3>Tukey-Kramer Method</h3>
<p>Tukey (1953) and Kramer (1956) independently proposed a method to
approximate the critical value <span
class="math inline">\(c_{\alpha}\)</span> in unbalanced designs. Recall
that when the sample sizes are all equal (i.e., when <span
class="math inline">\(\left.n_{1}=\ldots=n_{g}=n\right)\)</span>, the
statistic <span class="math display">\[
\max _{i, i^{\prime}} \sqrt{2}\left|T_{i, i^{\prime}}\right|=\max _{i,
i}
\sqrt{2}\left|\frac{\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{i^{\prime}}-\mu_{i^{\prime}}\right)}{\hat{\sigma}
\sqrt{1 / n+1 / n}}\right|
\]</span> is distributed as <span class="math inline">\(Q_{g,
g(n-1)}^{R}\)</span>, which has the studentized range distribution</p>
<p>which gives the Tukey-Kramer simultaneous confidence intervals: <span
class="math display">\[
\bar{y}_{i}-\bar{y}_{i^{\prime}} \pm\left(q_{1-\alpha, g, d f e}^{R} /
\sqrt{2}\right) \hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i}}
\]</span> Note that, as in the balanced case, the critical value <span
class="math inline">\(c_{\alpha}\)</span> is the <span
class="math inline">\(1-\alpha\)</span> quantile of the range
distribution divided by <span class="math inline">\(\sqrt{2}\)</span>.
Thus, there are no real differences in the form of the Tukey-Kramer
intervals and the Tukey intervals.</p>
<p>If you apply the above confidence interval formula in the case where
all <span class="math inline">\(n_{i}\)</span> are equal (to <span
class="math inline">\(n\)</span> ), you get exactly the Tukey intervals
for all pairwise comparisons. However, the Tukey-Kramer intervals are
not exact in the sense of providing an exact simultaneous <span
class="math inline">\(1-\alpha\)</span> coverage rate and exact <span
class="math inline">\(\mathrm{FWE}=\alpha\)</span> when the sample sizes
are unequal. Hayter (1984) proved that the method is in fact
<strong>conservative</strong>: the true FWE is <strong>less than or
equal</strong> to <span class="math inline">\(\alpha\)</span> for all
possible sample size configurations.</p>
<p><strong>SAS Implementation</strong></p>
<p>When you specify TUKEY as an option for the MEANS statement, the
Tukey-Kramer method is used automatically when the sample sizes are
unequal. This code produces the following output.</p>
<pre><code>data Recover;
 input Blanket$ Minutes @@;
 datalines;
b0 15 b0 13 b0 12 b0 16 b0 16 b0 17 b0 13 b0 13 b0 16 b0 17
b0 17 b0 19 b0 17 b0 15 b0 13 b0 12 b0 16 b0 10 b0 17 b0 12
b1 13 b1 16 b1 9
b2 5 b2 8 b2 9
b3 14 b3 16 b3 16 b3 12 b3 7 b3 12 b3 13 b3 13 b3 9 b3 16
b3 13 b3 18 b3 13 b3 12 b3 13
;
proc sgplot data=Recover;
 vbox Minutes / category=Blanket;
run;
proc glm data=Recover;
 class Blanket;
 model Minutes=Blanket;
 means Blanket/tukey;
run; </code></pre>
</div>
<div id="alternative-simulation-based-method" class="section level3">
<h3>Alternative Simulation-Based Method</h3>
<p>The Tukey-Kramer method is conservative because the critical value
<span class="math inline">\(q_{1-\alpha, g, N-g}^{R}\)</span> is larger
than the true <span class="math inline">\(c_{\alpha}\)</span>, which is
the <span class="math inline">\(1-\alpha\)</span> quantile of the
distribution of <span class="math inline">\(\max _{i, i}\left|T_{i,
i}\right| .\)</span> To calculate the correct critical value
analytically requires multidimensional integration using the
<strong>multivariate <span class="math inline">\(t\)</span>
distribution</strong>, you can approximate this critical value very
easily <strong>by simulating from the multivariate <span
class="math inline">\(t\)</span> distribution</strong> with <span
class="math inline">\(d f e=N-g\)</span> and dispersion matrix <span
class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2}
\mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-}
\mathbf{C} \mathbf{D}^{-1 / 2}\)</span>. The following simulation
algorithm avoids the problem of having to specify the <span
class="math inline">\(\mathbf{R}\)</span> matrix, and illustrates the
concept of <strong>parametric resampling</strong>.</p>
<ol style="list-style-type: decimal">
<li>Generate a random sample <span class="math inline">\(y_{i
j}^{*}\)</span> from the standard normal distribution.</li>
<li>Analyze the data exactly as you would if it were an actual data set,
getting sample means <span
class="math inline">\(\bar{y}_{i}^{*}\)</span> and a pooled variance
estimate <span
class="math inline">\(\left(\hat{\sigma}^{*}\right)^{2}\)</span>.
Compute the test statistics for all pairwise comparisons, <span
class="math inline">\(T_{i,
i^{\prime}}^{*}=\left(\bar{y}_{i}^{*}-\bar{y}_{i^{\prime}}^{*}\right)
/\left(\hat{\sigma}^{*} \sqrt{1 / n_{i}+1 /
n_{i^{\prime}}}\right)\)</span>.</li>
<li>Calculate the value <span class="math inline">\(\operatorname{Max}
\mathrm{T}=\max _{i, i^{\prime}}\left|T_{i,
i^{\prime}}^{*}\right|\)</span> and store it.</li>
<li>Repeat steps 1-3 NSAMP times, and estimate <span
class="math inline">\(c_{\alpha}\)</span> as the <span
class="math inline">\(1-\alpha\)</span> quantile of the resulting MaxT
values. Call the resulting value <span
class="math inline">\(\hat{c}_{\alpha}\)</span>.</li>
</ol>
<p><strong>Simulating the Critical Value for Recovery Data Using
Parametric Resampling</strong></p>
<pre><code>data sim;
 array nsize{4} (20,3,3,15);
 do rep = 1 to 20000;
 do i=1 to dim(nsize);
 do j=1 to nsize{i};
 y = rannor(121211);
 output;
 end;
 end;
 end;
run;
ods listing close;
proc glm data=sim;
 by rep;
 class i;
 model y=i;
 lsmeans i/ tdiff;
 ods output Diff=GDiffs;
quit;
ods listing;
proc transpose data=GDiffs out=t(where=(_label_ &gt; RowName));
 by rep RowName;
 var _1 _2 _3 _4;
data t;
 set t;
 abst = abs(COL1);
 keep rep abst;
proc means noprint data=t;
 var abst;
 by rep;
 output out=maxt max=maxt;
run;
proc univariate;
 var maxt;
 ods select Quantiles;
run; </code></pre>
<p>Thus, the correct 95th percentile is estimated to be 2.646847, based
on NSAMP=20000 simulations. The Tukey-Kramer approximation resulted in a
slightly higher number, 2.68976, which suggests a slight level of
conservatism of the Tukey-Kramer method.</p>
<pre><code>100% Max 4.844511
99% 3.288458
95% 2.646847
90% 2.332767
75% Q3 1.851581
50% Median 1.381995
25% Q1 0.981263
10% 0.681271
5% 0.528405
1% 0.293808
0% Min 0.036276</code></pre>
<p>However, remember that the percentile estimated by simulation is
subject to <strong>sampling error</strong>, so the precise degree of
conservatism is unclear. Edwards and Berry (1987) suggest generating
sufficient samples NSAMP so that <span
class="math inline">\(P\left(\operatorname{Max} T \geq
\hat{c}_{\alpha}\right)\)</span> (where <span
class="math inline">\(\hat{c}_{\alpha}\)</span> is fixed and MaxT is
random) is within an accuracy radius <span
class="math inline">\(\gamma\)</span> of <span
class="math inline">\(\alpha\)</span> with confidence <span
class="math inline">\(100(1-\delta) \%\)</span>. You can adjust <span
class="math inline">\(\alpha\)</span> using the ALPHA= option, and <span
class="math inline">\(\gamma\)</span> and <span
class="math inline">\(\delta\)</span> with the ACC <span
class="math inline">\(=\)</span> and EPS <span
class="math inline">\(=\)</span> suboptions of the ADJUST=SIMULATE
option, respectively. By default, <span
class="math inline">\(\alpha=0.05, \gamma=0.005\)</span>, and <span
class="math inline">\(\delta=0.01 ;\)</span> the method yields <span
class="math inline">\(\mathrm{NSAMP}=12,604\)</span> in this case. That
is, using quantiles from a simulation of this size, a nominal <span
class="math inline">\(95 \%\)</span> confidence interval for a mean
difference will actually have between <span class="math inline">\(94.5
\%\)</span> and <span class="math inline">\(95.5 \%\)</span> confidence
with probability <span class="math inline">\(0.99\)</span></p>
<p>If you specify the ADJUST=SIMULATE option then PROC GLM uses the
simulationestimated quantile in forming multiplicity-adjusted confidence
intervals for the differences. Although PROC GLM doesn’t display the
actual value of the quantile by default, you can use the <strong>REPORT
option</strong> for the simulation to print the quantile and other
information,</p>
<pre><code>proc glm data=Recover;
 class Blanket;
 model Minutes=Blanket;
 lsmeans Blanket/cl adjust=simulate(seed=121211 report);
 ods select SimResults LSMeanDiffCL;
run;</code></pre>
<p><span class="math display">\[
\begin{array}{lcccc}
\hline &amp; \text { Simulation Results } &amp; &amp; \\
\text { Method } &amp; \text { 95% Quantile } &amp; \text { Estimated }
&amp; \text {99% CI } \\
\text { Simulated } &amp; 2.634412 &amp; 0.0500 &amp;  0.0450 &amp;
0.0550\\
\text { Tukey-Kramer } &amp; 2.689757 &amp; 0.0432 &amp; 0.0385 &amp;
0.0478 \\
\text { Bonferroni } &amp; 2.787602 &amp; 0.0338 &amp; 0.0297 &amp;
0.0379 \\
\text { Sidak } &amp; 2.779230 &amp; 0.0346 &amp; 0.0304 &amp; 0.0388 \\
\text { GT-2 } &amp; 2.770830 &amp; 0.0350 &amp; 0.0308 &amp; 0.0392 \\
\text { Scheffe } &amp; 2.928547 &amp; 0.0237 &amp; 0.0202 &amp; 0.0272
\\
T &amp; 2.026192 &amp; 0.1870 &amp; 0.1780 &amp; 0.1959 \\
\hline
\end{array}
\]</span></p>
</div>
<div id="pairwise-comparisons-with-control" class="section level3">
<h3>Pairwise Comparisons with Control</h3>
<p>Unlike the case of all pairwise comparisons, the critical value cα
and the adjusted p-values can be calculated analytically for Dunnett’s
method in the case of all pairwise comparisons with a control, even
though the design is unbalanced. There is no need to use approximations,
such as the Tukey-Kramer or simulation-based.</p>
<p>Suppose the means are <span class="math inline">\(\bar{y}_{0},
\bar{y}_{1}, \ldots, \bar{y}_{g}\)</span>, where <span
class="math inline">\(\bar{y}_{0}\)</span> denotes the sample mean for
the control group.</p>
<p>To get the critical values and adjusted <span
class="math inline">\(p\)</span> -values for two-sided intervals and
tests, you need the distribution of <span class="math display">\[
M_{2}=\max _{i} \frac{\left|\bar{y}_{i}-\bar{y}_{0}\right|}{\hat{\sigma}
\sqrt{1 / n_{i}+1 / n_{0}}}
\]</span> The critical value <span
class="math inline">\(c_{\alpha}\)</span> for the two-sided confidence
intervals for <span class="math inline">\(\mu_{i}-\mu_{0}\)</span> is
the <span class="math inline">\(1-\alpha\)</span> quantile of the
distribution of <span class="math inline">\(M_{2}\)</span>, and adjusted
<span class="math inline">\(p\)</span> -values for two-sided tests are
given as <span class="math inline">\(\tilde{p}_{i}=P\left(M_{2}
\geq\left|t_{i}\right|\right)\)</span>, where <span
class="math inline">\(t_{i}\)</span> is the test statistic for <span
class="math inline">\(H_{0 i}: \mu_{i}-\mu_{0}=0\)</span>, i.e., <span
class="math display">\[
t_{i}=\left(\bar{y}_{i}-\bar{y}_{0}\right) /\left(\hat{\sigma} \sqrt{1 /
n_{i}+1 / n_{0}}\right)
\]</span> To get the critical values and adjusted <span
class="math inline">\(p\)</span> -values for one-sided intervals and
tests, you need the distribution of <span class="math display">\[
M_{1}=\max _{i} \frac{\bar{y}_{i}-\bar{y}_{0}}{\hat{\sigma} \sqrt{1 /
n_{i}+1 / n_{0}}}
\]</span> The critical value <span
class="math inline">\(c_{\alpha}\)</span> for the one-sided confidence
bounds is the <span class="math inline">\(1-\alpha\)</span> quantile of
the distribution of <span class="math inline">\(M_{1}\)</span>. Adjusted
<span class="math inline">\(p\)</span> -values for one-sided, upper-tail
tests are given as <span
class="math inline">\(\tilde{p}_{i}=P\left(M_{1} \geq
t_{i}\right)\)</span>, and adjusted <span
class="math inline">\(p\)</span> -values for one-sided, lower-tail tests
are given as <span class="math inline">\(\tilde{p}_{i}=P\left(M_{1}
\geq-t_{i}\right)\)</span></p>
<p><strong>Dunnett’s Two-Sided Comparisons with Unbalanced
Data</strong></p>
<pre><code>ods graphics on;
proc glm data=Recover;
 class Blanket;
 model Minutes = Blanket;
 lsmeans Blanket/pdiff cl adjust=dunnett;
run;
ods graphics off;</code></pre>
<p><strong>Dunnett’s One-Sided Comparisons with Unbalanced
Data</strong></p>
<pre><code>** “By Hand” Calculation of Dunnett&#39;s Exact One-Sided Critical Value 
    and Adjusted p-Value for Unbalanced ANOVA.
data;
 n0=20; n1=3; n2=3; n3=15;
 lambda1 = sqrt(n1/(n0+n1));
 lambda2 = sqrt(n2/(n0+n2));
 lambda3 = sqrt(n3/(n0+n3));
 c_alpha = probmc(&#39;DUNNETT1&#39;,.,.90,37,3,lambda1,lambda2,lambda3);
 t3 = -1.66666667/0.88477275;
 adjp_3 = 1-probmc(&#39;DUNNETT1&#39;,-t3,.,37,3,lambda1,lambda2,lambda3);
run; 


ods graphics on;
proc glm data=Recover;
 class Blanket;
 model Minutes = Blanket;
 lsmeans Blanket / pdiff=controll cl alpha=0.10;
run;
ods graphics off;</code></pre>
</div>
<div id="comparisons-with-the-average-meananalysis-of-means-anom"
class="section level3">
<h3>Comparisons with the Average Mean–Analysis of Means (ANOM)</h3>
<p>whether one group’s mean is confidently different from the average of
the means for the set of groups as a whole. Using this method, a quality
control engineer can confidently identify troubled or unusually good
spots (e.g., a shift that is under- or over-performing) or a product
formulation or business process that should be abandoned or
emulated.</p>
<pre><code>ods graphics on;
proc glm data=Recover;
 class Blanket;
 model Minutes = Blanket;
 lsmeans Blanket / pdiff=anom(weighted) cl alpha=0.10;
run;
ods graphics off; </code></pre>
</div>
</div>
<div id="generalizations-for-the-analysis-of-covariance-ancova-model"
class="section level2">
<h2>Generalizations for the Analysis of Covariance (ANCOVA) model</h2>
<p>A major difference is that the comparisons of interest in ANCOVA are
differences of <strong>LS-means rather than ordinary means</strong>.
This leads to some interesting graphical comparisons using regression
functions. As in the unbalanced one-way case, the <strong>standard
errors of estimated LS-mean differences are not constant</strong>,
implying that simple range distributions (Tukey-type or Dunnett-type)
cannot be used. Also, while for Dunnett comparisons there is an exact
representation of the MaxT distribution in the case of unbalanced sample
sizes without covariates, this is not the case when there are
covariates. Hence, either simulation-based or analytic approximations
must be used.</p>
<p>。</p>
<p>ANCOVA model with interaction may be written as <span
class="math display">\[
y_{i j}=\gamma+\mu_{i}+\beta x_{i j}+\varepsilon_{i j}
\]</span> where parallelism is indicated by the common slope <span
class="math inline">\(\beta\)</span> for all groups.</p>
<p>A recommendation is generally to use the SAS defaults
(<strong>Tukey-Kramer, Dunnett-Hsu</strong>) for ANCOVA applications:
although they are not exact, their accuracy is usually completely
adequate from a practical perspective, and they avoid the troublesome
issue of simulation nondeterminacy. Nevertheless, it is prudent to
validate the default analysis using the simulation adjustments.</p>
<div id="dunnett-hsu-factor-analytic-approximation"
class="section level3">
<h3>Dunnett-Hsu Factor Analytic Approximation</h3>
<blockquote>
<p>Pairwise Comparisons in ANCOVA</p>
</blockquote>
<ul>
<li>Tukey’s range, Dunnett’s range, and the maximum modulus
distributions to account for dependencies among the estimates.</li>
<li>The Range distribution becomes inexact in the case of unbalanced
data, while the Dunnett one- and twosided distributions remain exact
(with suitable modifications).</li>
<li>When you include covariates, none of these distributions is exact in
general. The general alternative of simulation is still available,
though, and quantiles can be simulated with relative ease and adequate
accuracy using the ADJUST=SIMULATE option.</li>
</ul>
<p>There is an analytical <strong>approximation</strong> that works very
well, providing critical values that, while not analytically exact, are
exceptionally accurate. In fact, the deterministic error in this
analytical approximation is usually much smaller than the Monte Carlo
error of the simulation-based methods at reasonable sample sizes.</p>
<p>As has been discussed, evaluating the critical values and adjusted
<span class="math inline">\(p\)</span> -values for the MaxT distribution
is intractable unless the correlation matrix <span
class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2}
\mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-}
\mathbf{C} \mathbf{D}^{-1 / 2}\)</span> between the constituent
differences in the MaxT statistic has a certain symmetry, in which case
the problem reduces to a feasible 2 -fold integral.</p>
<p>The required symmetry is provided by complete balance in the case of
Tukey’s test, and by a factor analytic structure (cf. Hsu, 1992 ) in the
case of Dunnett’s test. To be precise, the <span
class="math inline">\(\mathbf{R}\)</span> matrix has the required
symmetry for exact computation of Tukey’s test if the test statistics
<span class="math inline">\(t_{i}\)</span> are studentized differences
between</p>
<ul>
<li><span class="math inline">\(k(k-1) / 2\)</span> pairs of <span
class="math inline">\(k\)</span> uncorrelated means with equal
variances, that is, equal sample sizes</li>
<li><span class="math inline">\(k(k-1) / 2\)</span> pairs of <span
class="math inline">\(k\)</span> LS-means from a variance-balanced
design (for example, a balanced incomplete block design)</li>
</ul>
<p>In the case of comparisons with a control, the <span
class="math inline">\(\mathbf{R}\)</span> matrix has the factor analytic
structure for exact computation of Dunnett’s test if the <span
class="math inline">\(t_{i}\)</span> ’s are studentized differences
between</p>
<ul>
<li><span class="math inline">\(k-1\)</span> means and a control mean,
all uncorrelated. Note that it is not required that the variances of the
estimated means (that is, the sample sizes) be equal.</li>
<li><span class="math inline">\(k-1\)</span> LS-means and a control
LS-mean from either a variance-balanced design, or a design in which the
other factors are orthogonal to the treatment factor (for example, a
randomized block design with proportional cell frequencies)</li>
</ul>
<p>However, other important situations that do not result in a
correlation matrix <span class="math inline">\(\mathbf{R}\)</span> that
has the symmetry required for exact computation include</p>
<ul>
<li>all pairwise differences with unequal sample sizes</li>
<li>differences between LS-means and a control LS-mean when there are
covariates.</li>
</ul>
<p>In these situations, exact calculation of critical values and
adjusted <span class="math inline">\(p\)</span> -values is intractable
in general. For comparisons with a control when the correlation <span
class="math inline">\(\mathbf{R}\)</span> does not have a factor
analytic structure, Hsu (1992) suggests approximating <span
class="math inline">\(\mathbf{R}\)</span> with a matrix <span
class="math inline">\(\mathbf{R}^{\mathrm{F}}\)</span> that does have
such a structure and, correspondingly, approximating the MaxT critical
values and <span class="math inline">\(p\)</span> -values by assuming
that the true correlation matrix is <span
class="math inline">\(\mathbf{R}^{\mathrm{F}}\)</span>. The resulting
critical values and adjusted <span class="math inline">\(p\)</span>
values are calculated exactly for the correlation <span
class="math inline">\(\mathbf{R}^{\mathrm{F}}\)</span>, but are
approximate for the true correlation R. (Approximating <span
class="math inline">\(\mathbf{R}\)</span> in this way can also be viewed
as computing “effective sample sizes” <span
class="math inline">\(\tilde{n}_{i}\)</span> for the means and treating
them as uncorrelated.)</p>
<p>When you request Dunnett’s test for LS-means (the PDIFF=CONTROL and
ADJUST=DUNNETT options), the GLM procedure automatically uses Hsu’s
approximation when appropriate</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet;
 lsmeans Location / tdiff=control(&#39;B&#39;) pdiff cl;
run;
quit;</code></pre>
</div>
<div id="hsu-nelson-simulation-based-approximation-cvadjust-method"
class="section level3">
<h3>Hsu-Nelson Simulation-Based Approximation: CVADJUST Method</h3>
<blockquote>
<p>Pairwise Comparisons in ANCOVA</p>
</blockquote>
<ul>
<li>simple Monte Carlo method</li>
<li>simulate MaxT values for the correct correlation <span
class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2}
\mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-}
\mathbf{C} \mathbf{D}^{-1 / 2}\)</span></li>
<li>simulate covariate of MaxT values with known distribution for the
factor-analytic approximation correlation <span
class="math inline">\(\mathbf{R}^{\mathrm{F}}\)</span></li>
</ul>
<p>A useful way to strengthen the simple Monte Carlo method of
estimating confidence limits and p-values is to use the method of
control variates. This method proceeds by simulating not only MaxT
values for the correct correlation but also a covariate of MaxT values
with known distribution for the factor-analytic approximation
correlation discussed above. The conditional estimates for the correct
distribution, conditional on the approximate but known one, can be much
tighter than what you get with simple simulation (see Hsu and Nelson,
1998). To use this method, you can request it using the CVADJUST
suboption of the ADJUST=SIMULATE option of the LSMEANS statement.</p>
<pre><code>lsmeans Location/tdiff=control(&#39;B&#39;) pdiff
 adjust=simulate(acc=0.0001 seed=121211 cvadjust report) cl;</code></pre>
</div>
<div id="comparisons-in-ancova-models-with-interaction"
class="section level3">
<h3>Comparisons in ANCOVA Models with Interaction</h3>
<p>The ANCOVA model with interaction may be written as <span
class="math display">\[
y_{i j}=\gamma+\mu_{i}+\beta x_{i j}+\beta_{i} x_{i j}+\varepsilon_{i
j},
\]</span> where <span class="math inline">\(i\)</span> denotes CLASS
level and <span class="math inline">\(j\)</span> an observation within
the CLASS level; where <span class="math inline">\(\gamma\)</span> is
the overall intercept term and the <span
class="math inline">\(\mu_{i}\)</span> parameterize deviations from the
overall intercept for CLASS level <span
class="math inline">\(i\)</span>, and where similarly <span
class="math inline">\(\beta\)</span> is the overall slope term, and the
<span class="math inline">\(\beta_{i}\)</span> correspond to deviations
from the overall slope for CLASS level <span
class="math inline">\(i\)</span>. The model is overparameterized,
meaning that not all parameters can be estimated simultaneously without
imposing additional constraints</p>
<pre><code>*** One-Way ANCOVA Analysis with Interaction;
ods graphics on;
proc glm data=House;
 class Location;
 model Price = Location Sqfeet location*sqfeet;
run;
quit;
ods graphics off;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/ACNOVA_Effect.PNG" alt="Figure: Fitted ANCOVA Model with Interaction" width="100%" />
<p class="caption">
Figure: Fitted ANCOVA Model with Interaction
</p>
</div>
<p>There is some suggestion of interaction in that the effect of SQFEET
on PRICE seems less in LOCATION C, but this may be an artifact due to
small sample size, because the interaction is not statistically
significant (for testing <span class="math inline">\(H_{0}:
\beta_{1}=\ldots=\beta_{5}=0, F(4,54)=1.54, p=0.2045\)</span> ).
Nevertheless, the graph illustrates clearly that comparisons of housing
prices between levels of the CLASS variable differ, depending on the
chosen value of the covariate.</p>
<p>In PROC GLM, the default for <strong>LSMEANS is to compare the CLASS
levels at the average value(s) of the covariate(s)</strong>. In the
housing example, the average value of SQFEET is <span
class="math inline">\(1947.28125\)</span>, thus the statements</p>
<p><code>lsmeans Location / adjust=tukey cl;</code> is equel to
<code>lsmeans Location / adjust=tukey cl at Sqfeet=1947.28125;</code></p>
</div>
</div>
<div id="multiple-inferences-for-infinite-sets-of-parameters"
class="section level2">
<h2>Multiple Inferences for Infinite Sets of Parameters</h2>
<p>It may also seem that definitive inferences are impossible with
infinite families. After all, the Bonferroni method requires that you
divide <span class="math inline">\(\alpha\)</span> by <span
class="math inline">\(k\)</span>, the number of elements in the family.
If <span class="math inline">\(k=\infty\)</span>, then this approach to
multiplicity correction would require you to use <span
class="math inline">\(\alpha / \infty\)</span>, which can only be
defined as zero, for all your inferences. Since <span
class="math inline">\(p\)</span> -values are always greater than zero,
your tests will never be significant. Similarly, critical values using
<span class="math inline">\(\alpha=0.0\)</span> can only be defined as
infinitely large; hence, confidence intervals would be infinitely wide
in this case, not to mention, infinitely useless as well.</p>
<p>Evidently, the Bonferroni approach is not appropriate for infinite
contrasts. One problem is dependence: <strong>the greater the degree of
dependence among the tests or intervals, the less appropriate is the
Bonferroni correction</strong>. What often happens with infinite
collections of tests is that, <strong>as more and more tests are
considered, the dependencies among the tests increase</strong>. After a
certain point, the dependencies become so great that essentially no more
correction is needed.</p>
<p><strong>Summary Pre</strong></p>
<p>If you want to perform inferences for an infinite set of linear
functions (contrasts or otherwise) in the linear model, you can use
either Scheffé’s method, the Working-Hotelling method, or the
discretization method.</p>
<ul>
<li>If you want to search through your data to identify the most
significant contrasts, then you should use the Scheffé critical value,
since your family is virtually infinite.</li>
<li>If you want to calculate simultaneous confidence bands for
regression functions or for differences of regression functions, you can
safely use the Working-Hotelling critical value in many cases. However,
since the Working-Hotelling critical value can be conservative, you
should use the discretization method with a reasonably large grid with
the ESTIMATE statement to assess the conservativeness of the
Working-Hotelling approach. If the Working-Hotelling approach is too
conservative, then you should use the discretization method.</li>
</ul>
<div id="scheffés-method" class="section level3">
<h3>Scheffés Method</h3>
<p>This family is the set of all contrasts <span
class="math display">\[\mathbf{c}_{\boldsymbol{i}}
\boldsymbol{\mu}=c_{1} \mu_{1}+c_{2} \mu_{2}+\cdots+c_{g}
\mu_{g}\]</span> where the sum of the elements is zero <span
class="math inline">\(\left(\sum c_{i}=0.0\right)\)</span></p>
<p>Scheffé’s (1953) method involves finding the distribution of <span
class="math inline">\(\max _{\mathbf{c}} T_{\mathrm{c}}^{2}\)</span>,
where <span class="math inline">\(T_{\mathrm{c}}\)</span> is the <span
class="math inline">\(t\)</span> statistic for the contrast <span
class="math inline">\(\mathbf{c}^{\prime} \boldsymbol{\mu}\)</span>
<span class="math display">\[
T_{\mathrm{c}}=\frac{\mathbf{c}^{\prime} \hat{\mu}-\mathbf{c}^{\prime}
\mu}{s . e .\left(\mathbf{c}^{\prime} \hat{\mu}\right)}
\]</span> In the case of the one-way ANOVA without covariates (balanced
or unbalanced), the standard error of <span
class="math inline">\(\mathbf{c}^{\prime} \hat{\mu}\)</span> is <span
class="math display">\[
\text { s.e. }\left(\mathbf{c}^{\prime}
\hat{\boldsymbol{\mu}}\right)=\hat{\sigma} \sqrt{\sum
\frac{c_{i}^{2}}{n_{i}}}
\]</span></p>
<p>Scheffé showed that the distribution of <span
class="math inline">\(\max _{\mathrm{c}} T_{\mathrm{c}}^{2}\)</span>
overall contrasts <span class="math inline">\(\mathbf{c}\)</span> (i.e,
over the infinite set of <span
class="math inline">\(\mathbf{c}=\left(c_{1}, \cdots,
c_{g}\right)^{\prime}\)</span> for which <span
class="math inline">\(c_{1}+\cdots+c_{g}=0\)</span> ) is <span
class="math inline">\((g-1) F_{g-1, d f e}\)</span>, or the distribution
of <span class="math inline">\((g-1)\)</span> times an <span
class="math inline">\(F\)</span> distributed random variable with <span
class="math inline">\((g-1)\)</span> numerator and <span
class="math inline">\(d\)</span> fe denominator degrees of freedom. The
term <span class="math inline">\(d f e\)</span> is, as usual, the error
degrees of freedom.</p>
<p>Thus, the <span class="math inline">\(1-\alpha\)</span> quantile of
the distribution of <span class="math inline">\(\max
_{\mathfrak{c}}\left|T_{\mathrm{c}}\right|\)</span> is just <span
class="math inline">\(c_{\alpha}=\sqrt{(g-1) F_{1-\alpha, g-1, d f
e}}\)</span>, and the simultaneous Scheffé intervals are <span
class="math display">\[
\mathbf{c}^{\prime} \hat{\mu} \pm \sqrt{(g-1) F_{1-\alpha, g-1, d f e}}
s . e .\left(\mathbf{c}^{\prime} \hat{\mu}\right)
\]</span></p>
<p><strong>SAS Implementation</strong></p>
<pre><code>data WLoss;
 do diet = &#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;,&#39;E&#39;;
 do i = 1 to 10;
 input wloss @@;
 output;
 end;
 end;
datalines;
12.4 10.7 11.9 11.0 12.4 12.3 13.0 12.5 11.2 13.1
 9.1 11.5 11.3 9.7 13.2 10.7 10.6 11.3 11.1 11.7
 8.5 11.6 10.2 10.9 9.0 9.6 9.9 11.3 10.5 11.2
 8.7 9.3 8.2 8.3 9.0 9.4 9.2 12.2 8.5 9.9
12.7 13.2 11.8 11.9 12.2 11.2 13.7 11.8 11.5 11.7
;
data WLossNew;
 set Wloss;
 Wloss=Wloss + 6*rannor(121211); /* Random error added */
run; 
proc glm data=Wlossnew;
 class Diet;
 model Wloss=Diet;
 means Diet / cldiff scheffe;
run; </code></pre>
<p><strong>This test controls the Type I experimentwise error rate, but
it generally has a higher Type II error rate than Tukey’s for all
pairwise comparisons.</strong> Scheffé’s method is consistent with the
ANOVA <span class="math inline">\(F\)</span> -test. <strong>If the <span
class="math inline">\(F\)</span> -test is insignificant, then Scheffé’s
method will not judge any mean difference or contrast to be significant.
And if the <span class="math inline">\(F\)</span> -test is significant,
then Scheffé’s method will judge at least one mean contrast to be
significant, though this may not be one of the pairwise
contrasts</strong>.</p>
<pre><code>***Critical Value of F;
data;
 fwe = 0.05;
 g = 5;
 dfe = 45;
 fcrit = finv(1-fwe,g-1,dfe);
 c_alpha = sqrt((g-1)*fcrit); 
run;</code></pre>
<p><strong>Scheffé adjusted p-values</strong></p>
<p>You can use Scheffé adjusted <span class="math inline">\(p\)</span>
-values and compare them to <span class="math inline">\(0.05 .\)</span>
The adjusted <span class="math inline">\(p\)</span> -values for the
Scheffé procedure are given by <span class="math display">\[
\tilde{p}=P\left(\sqrt{(g-1) F_{g-1, d f e}}
\geq\left|t_{\mathrm{c}}\right|\right)=1-P\left(F_{g-1, d
f_{e}}&lt;t_{\mathrm{c}}^{2} /(g-1)\right) .
\]</span></p>
<p><strong>Specified contrasts</strong></p>
<p>However, if some of the comparisons are selected post hoc (i.e.,
after looking at the data), then the seeming family size of k=16 used
for Bonferroni is not valid. Had the specified contrasts indeed been
preselected, then Bonferroni would be more appropriate than Scheffé, but
the simulation-consistent method would be more appropriate than either
Bonferroni or Scheffé.</p>
</div>
<div id="finding-the-maximal-contrast" class="section level3">
<h3>Finding the Maximal Contrast</h3>
<pre><code>data House;
 input Location$ Price Sqfeet age @@;
datalines;
A 213.5 2374 4 A 219.9 2271 8 A 227.9 2088 5
A 192.5 1645 8 A 203.0 1814 6 A 242.1 2553 7
A 220.5 1921 9 A 205.5 1854 2 A 201.2 1536 9
A 194.7 1677 3 A 229.0 2342 5 A 208.7 1862 4
A 199.7 1894 7 A 212.0 1774 9 A 204.8 1476 8
A 186.1 1466 7 A 203.5 1800 8 A 193.0 1491 5
A 199.5 1749 8 A 198.1 1690 7 A 244.8 2741 5
A 196.3 1460 5 A 195.1 1614 6 A 225.8 2244 6
A 226.9 2165 6 A 204.7 1828 4 B 174.2 1503 6
B 169.9 1689 6 B 177.0 1638 2 B 167.0 1276 6
B 198.9 2101 9 B 181.2 1668 5 B 185.7 2123 4
B 199.8 2208 5 B 155.7 1273 8 B 220.1 2519 4
B 209.1 2303 6 B 182.4 1800 3 B 202.7 2336 8
B 192.0 2100 6 B 184.1 1697 4 C 190.8 1674 4
C 198.2 2307 7 C 194.6 2152 5 C 187.9 1948 9
D 202.5 2258 2 D 181.3 1965 6 D 186.1 1772 3
D 194.7 2385 1 D 164.7 1345 4 D 193.5 2220 8
D 180.1 1883 8 D 192.3 2012 6 D 180.6 1898 5
E 205.3 2362 7 E 206.3 2362 7 E 184.3 1963 9
E 176.6 1941 7 E 182.4 1975 5 E 198.8 2529 6
E 186.8 2079 5 E 188.5 2190 4 E 177.5 1897 5
E 186.9 1946 4
;
%let classvar = Location;
proc glm data= House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmeans Location / out=stats cov;
data Cov; set stats; keep Cov:;
proc iml;
 use stats; read all var {&amp;classvar LSMean};
 use Cov; read all into V;
 nclass = nrow(&amp;classvar);
 CBase = j(1,nclass-1) // -i(nclass-1);
 /* 1 - j contrasts, j = 2,...,nclass */
 num = (CBase`*LSMean)*(CBase`*LSMean)`;
 den = CBase`*V*CBase;
 evec = eigvec(num*inv(den));
 C = evec[,1]`*inv(den)*CBase`;
 C = C/sum((C&gt;0)#C);
 print C [label =&quot;Most Significant &amp;classvar Contrast&quot;
 colname=&amp;classvar];
quit;

***Testing a Discovered Contrast;
proc orthoreg data=House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmestimate Location
 &#39;A-B&#39; 3 -3 ,
 &#39;A-C&#39; 3 0 -3 ,
 &#39;A-D&#39; 3 0 0 -3 ,
 &#39;A-E&#39; 3 0 0 0 -3 ,
 &#39;A-[B,D,E]&#39; 3 -1 0 -1 -1 / divisor=3 adjust=scheffe cl;
 ods output LSMEstimates=LSME;
proc print data=LSME noobs label;
 where (Label = &quot;A-[B,D,E]&quot;);
 var Label Estimate StdErr tValue probt Adjp AdjLower AdjUpper;
run; </code></pre>
<p><span class="math display">\[
\begin{array}{lrrrrr}
\hline &amp; {\text { Most Significant Location Contrast }} \\
A &amp; B &amp; C &amp; D &amp; E \\
1 &amp; -0.307122 &amp; -0.074921 &amp; -0.249097 &amp; -0.36886 \\
\hline
\end{array}
\]</span></p>
</div>
<div id="working-hotelling-method" class="section level3">
<h3>Working-Hotelling method</h3>
<blockquote>
<p>Confidence Band for a Simple Linear Regression</p>
</blockquote>
<p>For simple linear regression model <span class="math display">\[
y_{i}=\beta_{0}+\beta_{1} x_{i}+\varepsilon_{i}
\]</span> <span class="math display">\[\left(\hat{\beta}_{0},
\hat{\beta}_{1}\right)=\hat{\boldsymbol{\beta}}=\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Y}\]</span> The
simultaneous confidence intervals for <span
class="math inline">\(\beta_{0}+\beta_{1} x\)</span> for all <span
class="math inline">\(a \leq x \leq b\)</span>. The intervals have the
usual form <span class="math display">\[
\hat{\beta}_{0}+\hat{\beta}_{1} x \pm c_{\alpha} s . e
.\left(\hat{\beta}_{0}+\hat{\beta}_{1} x\right),
\]</span> <span class="math display">\[
\text { s.e. }\left(\hat{\beta}_{0}+\hat{\beta}_{1}
x\right)=\hat{\sigma} \sqrt{\mathbf{x}^{\prime}\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{x}}
\]</span> <span class="math inline">\(\hat{\sigma}=\)</span> RMSE , and
<span class="math inline">\(\mathbf{x}^{\prime}=(1 x)\)</span>. The
difficult question is, <strong>how to choose <span
class="math inline">\(c_{\alpha} ?\)</span></strong></p>
<p>Even if the bounds a and b are both finite, the set of inferences
still is infinite because there are infinitely many points in the
interval from a to b. Thus, the solution to the problem requires
something similar to the Scheffé method. The <strong>Working-Hotelling
method</strong> uses the same essential technique as the Scheffé method.
It is based on the fact that the intervals <span class="math display">\[
\ell_{0} \hat{\beta}_{0}+\ell_{1} \hat{\beta}_{1} \pm \sqrt{2
F_{1-\alpha, 2, n-2}} \hat{\sigma}
\sqrt{l^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1}
\boldsymbol{l}}
\]</span> are exact simultaneous <span
class="math inline">\(1-\alpha\)</span> confidence intervals for the
parameters <span class="math inline">\(l^{\prime} \beta=\ell_{0}
\beta_{0}+\ell_{1} \beta_{1}\)</span>, over the infinite set of all
linear combinations <span
class="math inline">\(\boldsymbol{l}=\left(\ell_{0},
\ell_{1}\right)^{\prime} .\)</span></p>
<p><strong>Problem</strong>: Too conservative. The infinite family
contains all points in the range <span
class="math inline">\(-\infty&lt;x&lt;+\infty\)</span>, which is too
big, since you are only interested in a finite interval <span
class="math inline">\(a \leq x \leq b\)</span>.</p>
</div>
<div id="discrete-approximation-method" class="section level3">
<h3>Discrete approximation method</h3>
<blockquote>
<p>Confidence Band for a Simple Linear Regression</p>
</blockquote>
<p>Rather than use the conservative Working-Hotelling approach, you can
use the exact distribution of <span class="math inline">\(\max _{a \leq
x \leq b}\left|T_{x}\right|\)</span>, where <span
class="math inline">\(T_{x}\)</span> is the usual <span
class="math inline">\(t\)</span> statistic <span class="math display">\[
T_{x}=\frac{\hat{\beta}_{0}+\hat{\beta}_{1} x-\left(\beta_{0}+\beta_{1}
x\right)}{\text { s.e. }\left(\hat{\beta}_{0}+\hat{\beta}_{1} x\right)}
\]</span> Letting <span class="math inline">\(c_{\alpha}\)</span> be the
<span class="math inline">\(1-\alpha\)</span> quantile of the
distribution of <span class="math inline">\(\max _{a \leq x \leq
b}\left|T_{x}\right|\)</span>, the simultaneous confidence intervals are
<span class="math display">\[
\hat{\beta}_{0}+\hat{\beta}_{1} x \pm c_{\alpha} \text { s.e.
}\left(\hat{\beta}_{0}+\hat{\beta}_{1} x\right) .
\]</span> These intervals will be narrower than the Working-Hotelling
intervals, and they will be exact in the sense that they will contain
the true regression line with exactly <span
class="math inline">\((1-\alpha) \times 100\)</span> percent
confidence.</p>
<pre><code>***Simultaneous Confidence Bounds for Regression Function;
data House;
 input Location$ Price Sqfeet age @@;
datalines;
A 213.5 2374 4 A 219.9 2271 8 A 227.9 2088 5
A 192.5 1645 8 A 203.0 1814 6 A 242.1 2553 7
A 220.5 1921 9 A 205.5 1854 2 A 201.2 1536 9
A 194.7 1677 3 A 229.0 2342 5 A 208.7 1862 4
A 199.7 1894 7 A 212.0 1774 9 A 204.8 1476 8
A 186.1 1466 7 A 203.5 1800 8 A 193.0 1491 5
A 199.5 1749 8 A 198.1 1690 7 A 244.8 2741 5
A 196.3 1460 5 A 195.1 1614 6 A 225.8 2244 6
A 226.9 2165 6 A 204.7 1828 4 B 174.2 1503 6
B 169.9 1689 6 B 177.0 1638 2 B 167.0 1276 6
B 198.9 2101 9 B 181.2 1668 5 B 185.7 2123 4
B 199.8 2208 5 B 155.7 1273 8 B 220.1 2519 4
B 209.1 2303 6 B 182.4 1800 3 B 202.7 2336 8
B 192.0 2100 6 B 184.1 1697 4 C 190.8 1674 4
C 198.2 2307 7 C 194.6 2152 5 C 187.9 1948 9
D 202.5 2258 2 D 181.3 1965 6 D 186.1 1772 3
D 194.7 2385 1 D 164.7 1345 4 D 193.5 2220 8
D 180.1 1883 8 D 192.3 2012 6 D 180.6 1898 5
E 205.3 2362 7 E 206.3 2362 7 E 184.3 1963 9
E 176.6 1941 7 E 182.4 1975 5 E 198.8 2529 6
E 186.8 2079 5 E 188.5 2190 4 E 177.5 1897 5
E 186.9 1946 4
; 
proc orthoreg data=House(where=(Location=&#39;A&#39;));
 model Price=Sqfeet;
 estimate
 &quot;1000&quot; Intercept 1 Sqfeet 1000 ,
 &quot;1200&quot; Intercept 1 Sqfeet 1200 ,
 &quot;1400&quot; Intercept 1 Sqfeet 1400 ,
 &quot;1600&quot; Intercept 1 Sqfeet 1600 ,
 &quot;1800&quot; Intercept 1 Sqfeet 1800 ,
 &quot;2000&quot; Intercept 1 Sqfeet 2000 ,
 &quot;2200&quot; Intercept 1 Sqfeet 2200 ,
 &quot;2400&quot; Intercept 1 Sqfeet 2400 ,
 &quot;2600&quot; Intercept 1 Sqfeet 2600 ,
 &quot;2800&quot; Intercept 1 Sqfeet 2800 ,
 &quot;3000&quot; Intercept 1 Sqfeet 3000
 / adjust=simulate(acc=.0002 seed=121211 report) cl;
 ods output Estimates=Estimates;
proc print data=Estimates noobs label;
 var Label Estimate StdErr tValue probt Adjp AdjLower AdjUpper;
proc sgplot data=Estimates(rename=(Estimate=Price label=Sqfeet));
 series x = Sqfeet Y = Price;
 series x = Sqfeet Y = AdjLower;
 series x = Sqfeet Y = Adjupper;
 title &#39;Confidence Bounds for Mean Price&#39;;
run; 

*** For Working-Hotelling confidence bounds;
*** estimate --- / adjust=scheffe cl;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/discrete_approximation.png" alt="Figure:1 Simultaneous Confidence Bounds (Discrete Approximation) for Mean Price of Houses in Location ‘A’" width="100%" />
<p class="caption">
Figure:1 Simultaneous Confidence Bounds (Discrete Approximation) for
Mean Price of Houses in Location ‘A’
</p>
</div>
</div>
</div>
<div id="multiple-comparisons-under-heteroscedasticity"
class="section level2">
<h2>Multiple Comparisons under Heteroscedasticity</h2>
<div id="introduction-of-heteroscedasticity" class="section level3">
<h3>Introduction of heteroscedasticity</h3>
<p><strong>Results from Homoscedastic</strong></p>
<p>With extreme heteroscedasticity, Tukey’s method can fail miserably.
The problem is that the estimated error variance that is used for all
comparisons is a weighted average of the within-group variance
estimates. If the true variances differ widely between groups, then this
overall weighted average will be too large for some of the pairwise
comparisons and too small for others. As a consequence, it may be more
likely that some comparisons will be erroneously flagged as
“significant;” and conversely, it may also be more likely that other
comparisons will be erroneously flagged as “insignificant.”</p>
<p><strong>Under homoscedasticity and uncorrelated errors
assumptions</strong></p>
<p>Linear model <span class="math inline">\(\mathbf{Y}=\mathbf{X}
\beta+\boldsymbol{\varepsilon}\)</span> with all assumptions satisfied,
and <span class="math inline">\(\mathbf{X}\)</span> of full column rank.
Then the covariance matrix of <span
class="math inline">\(\hat{\boldsymbol{\beta}}=\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Y}\)</span> is, by
standard statistical theory, <span class="math display">\[
\operatorname{Cov}(\hat{\boldsymbol{\beta}})=\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{X}^{\prime}
\operatorname{Cov}(\mathbf{Y})\left\{\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{X}^{\prime}\right\}^{\prime}
\]</span> When <span class="math inline">\(\mathbf{Y}\)</span> is
homoscedastic - that is, when <span
class="math inline">\(\operatorname{Cov}(\mathbf{Y})=\sigma^{2}
I-\)</span> a little matrix algebra makes life simpler: <span
class="math display">\[
\operatorname{Cov}(\hat{\boldsymbol{\beta}})=\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{X}^{\prime}\left(\sigma^{2}
I\right)\left\{\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1}
\mathbf{X}^{\prime}\right\}^{\prime}=\sigma^{2}\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1}
\]</span></p>
<p>This latter form gives the standard error of <span
class="math inline">\(\mathbf{c}^{\prime} \hat{\beta}\)</span> since
<span class="math inline">\(\operatorname{Var}\left(\mathbf{c}^{\prime}
\hat{\boldsymbol{\beta}}\right)=\mathbf{c}^{\prime}
\operatorname{Cov}(\hat{\boldsymbol{\beta}}) \mathbf{c}=\sigma^{2}
\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1}
\mathbf{c}\)</span>. Taking the square root of the variance and
supplying the estimate for <span
class="math inline">\(\sigma^{2}\)</span> gives the formula s.e. <span
class="math inline">\(\left(\mathbf{c}^{\prime}
\hat{\boldsymbol{\beta}}\right)=\hat{\sigma}
\sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{c}}\)</span>.</p>
<p><strong>Under heteroscedasticity</strong></p>
<p>In this case, <span
class="math inline">\(\operatorname{Cov}(\mathbf{Y})=\mathbf{V}\)</span>,
a diagonal matrix where the <span class="math inline">\(i^{\text {th
}}\)</span> diagonal element is <span
class="math inline">\(\sigma_{j}^{2}\)</span> if observation <span
class="math inline">\(i\)</span> is in group <span
class="math inline">\(j\)</span>.</p>
<p>The estimation of <span class="math inline">\(\beta\)</span>,
obtaining what are known as generalized least squares (GLS) estimates:
<span class="math display">\[
\hat{\boldsymbol{\beta}}_{G L S}=\left(\mathbf{X}^{\prime}
\mathbf{V}^{-1} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime}
\mathbf{V}^{-1} \mathbf{Y}
\]</span> The method that uses GLS will be referred to as “the High
Road,” because the GLS estimate is the best linear unbiased estimate
(BLUE) for <span class="math inline">\(\beta\)</span> when <span
class="math inline">\(\mathbf{V}\)</span> is known. The High Road
standard errors of the estimated contrasts are given by the reasonably
simple form <span class="math display">\[
\text { s.e. }\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}_{G L
S}\right)=\sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime}
\mathbf{V}^{-1} \mathbf{X}\right)^{-1} \mathbf{c}}
\]</span> In practice, <span class="math inline">\(\mathbf{V}\)</span>
must be estimated, leading to the “estimated generalized least squares”
(EGLS) estimate <span class="math display">\[
\hat{\boldsymbol{\beta}}_{E G L S}=\left(\mathbf{X}^{\prime}
\hat{\mathbf{V}}^{-1} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime}
\hat{\mathbf{V}}^{-1} \mathbf{Y}
\]</span></p>
<p>The EGLS estimate is no longer the BLUE of <span
class="math inline">\(\beta\)</span>, but is typically <strong>more
efficient than the ordinary least squares (OLS) estimate</strong> when
<span class="math inline">\(n\)</span> is large.</p>
<p>So much for the High Road. If you want to take the Low Road instead,
you’ll use the OLS estimate with the correct standard errors. If <span
class="math inline">\(\operatorname{Cov}(\mathbf{Y})=\mathbf{V}\)</span>,
then <span class="math display">\[
\operatorname{Cov}\left(\hat{\boldsymbol{\beta}}_{\text {OLS
}}\right)=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1}
\mathbf{X}^{\prime} \mathbf{V} \mathbf{X}\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1}
\]</span> Supplying the estimated <span
class="math inline">\(\mathbf{V}\)</span> gives you the more complicated
formula for the Low Road standard errors: <span class="math display">\[
\text { s.e. }\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}_{O L
S}\right)=\sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime}
\mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \hat{\mathbf{V}}
\mathbf{X}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{c}} .
\]</span> ### Satterthwaite Approximation</p>
<p><strong>No more <span class="math inline">\(t\)</span>
-distribution</strong></p>
<p>Whether you take the High Road or the Low Road, OLS or EGLS, the
usual <span class="math inline">\(t\)</span> -distribution no longer
applies; specifically the statistic <span class="math display">\[
t=\frac{\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}-\mathbf{c}^{\prime}
\boldsymbol{\beta}}{\text { s.e. }\left(\mathbf{c}^{\prime}
\hat{\boldsymbol{\beta}}\right)}
\]</span> is not distributed as <span class="math inline">\(t\)</span>
with <span
class="math inline">\(n-\operatorname{rank}(\mathbf{X})\)</span> degrees
of freedom when <span class="math inline">\(\mathbf{Y}\)</span> is
normal. Of course, in the unlikely case that <span
class="math inline">\(\mathbf{V}\)</span> is known, the <span
class="math inline">\(t\)</span> statistic is distributed as <span
class="math inline">\(\mathrm{N}(0,1)\)</span>. But when you have to use
<span class="math inline">\(\hat{\mathbf{V}}\)</span> in place of <span
class="math inline">\(\mathbf{V}\)</span>, there is extra variability in
the distribution that should make a <span
class="math inline">\(t\)</span> distribution approximation closer than
a normal approximation. Still, there is no exact distribution in
general, and you are stuck with an approximation of one sort or
another.</p>
<p><strong>Satterthwaite degrees</strong></p>
<p>Satterthwaite formula gives a datadependent and approximate degrees
of freedom for the distribution of the <span
class="math inline">\(t\)</span> -statistic. For comparing <span
class="math inline">\(\mu_{i}\)</span> with <span
class="math inline">\(\mu_{i^{\prime}}\)</span>, the Satterthwaite
degrees of freedom formula gives <span class="math display">\[
d f_{i, i^{\prime}}=\frac{\left(\hat{\sigma}_{i}^{2} /
n_{i}+\hat{\sigma}_{i^{\prime}}^{2} /
n_{i^{\prime}}\right)^{2}}{\left(\hat{\sigma}_{i}^{2} / n_{i}\right)^{2}
/\left(n_{i}-1\right)+\left(\hat{\sigma}_{i^{\prime}}^{2} /
n_{i^{\prime}}\right)^{2} /\left(n_{i^{\prime}}-1\right)} .
\]</span> Thus, rather than having a common <span
class="math inline">\(t\)</span> distribution for all comparisons, you
use <span class="math inline">\(t\)</span> distributions with different
degrees of freedom for every comparison.</p>
<pre><code>*** Satterthwaite-Based Multiple Comparisons with Bonferroni Adjustments Using PROC MIXED
proc mixed data=UPSIT;
 class Agegroup;
 model Smell = Agegroup / ddfm=Satterth;
 repeated / group=Agegroup;
 lsmeans Agegroup/adjust=Bonferroni cl;
 ods output Diffs=Diffs;
proc print data=Diffs noobs label;
 var Agegroup _Agegroup Estimate StdErr df probt
 Adjp AdjLower AdjUpper;
run; 

*** PROC GLIMMIX allows for non-normal distributions and has additional multiple comparisons enhancements
proc glimmix data=UPSIT;
 class Agegroup;
 model Smell = Agegroup / ddfm=Satterth;
 random _residual_ / group=Agegroup;
 lsmeans Agegroup / adjust=Bonferroni adjdfe=row cl lines;
run; </code></pre>
</div>
<div id="maxt-method-under-heteroscedasticity" class="section level3">
<h3>MaxT Method under Heteroscedasticity</h3>
<p>The Bonferroni method is conservative because it does <strong>not
account for dependence among the t statistics</strong>. The distribution
of MaxT that correctly incorporates these dependencies, either via exact
analytic solution, approximate analytic solution, or simulation-based
analytic solution.</p>
<p>No matter whether EGLS or OLS is used to estimate <span
class="math inline">\(\beta\)</span> (the “High Road” and the “Low Road”
of the previous section), the covariance matrix of <span
class="math inline">\(\hat{\beta}\)</span> will depend on <span
class="math inline">\(\mathbf{V}\)</span>. Replace <span
class="math inline">\(\mathbf{V}\)</span> by its estimate <span
class="math inline">\(\hat{\mathbf{V}}\)</span>, and call the estimated
covariance matrix <span
class="math inline">\(s^{2}(\hat{\boldsymbol{\beta}})\)</span>. Then the
estimated covariance matrix of the set of contrasts <span
class="math inline">\(\mathbf{C}^{\prime} \hat{\beta}\)</span> is <span
class="math inline">\(\mathbf{C}^{\prime}\left\{s^{2}(\hat{\boldsymbol{\beta}})\right\}
\mathbf{C}\)</span>, and the estimated covariance matrix of the set of
<span class="math inline">\(t\)</span> statistics <span
class="math display">\[
\left\{t_{i}\right\}=\left\{\frac{\mathbf{c}^{\prime}
\hat{\boldsymbol{\beta}}-\mathbf{c}_{i}
\boldsymbol{\beta}}{\operatorname{see}\left(\mathbf{c}_{i}^{\prime}
\boldsymbol{\beta}\right)}\right\}=\left\{\frac{\mathbf{c}_{i}
\hat{\boldsymbol{\beta}}-\mathbf{c}_{\boldsymbol{i}}
\boldsymbol{\beta}}{\left[\mathbf{c}_{i}^{\prime}\left\{s^{2}(\hat{\boldsymbol{\beta}})\right\}
\mathbf{c}_{i}\right]^{1 / 2}}\right\}
\]</span> also happens to be a correlation matrix <span
class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2}
\mathbf{C}^{\prime}\left\{s^{2}(\hat{\boldsymbol{\beta}})\right\}
\mathbf{C} \mathbf{D}^{-1 / 2}\)</span>, where <span
class="math inline">\(\mathbf{D}\)</span> is the diagonal matrix having
diagonal elements <span
class="math inline">\(\mathbf{c}_{i}^{\prime}\left\{s^{2}(\hat{\boldsymbol{\beta}})\right\}
\mathbf{c}_{i}\)</span>.</p>
<p>The task is to simulate the distribution of MaxT, where the
correlation matrix of the <span class="math inline">\(t\)</span>
statistics is given by <span class="math inline">\(\mathbf{R}\)</span>.
This is straightforward when the degrees of freedom are constant across
<span class="math inline">\(t\)</span> statistics, but when there are
differing degrees of freedom, it is more complex. Here is an approximate
method for generating one value of MaxT from such a distribution:</p>
<p><strong>Simulating Correlated T Values with Different Marginal
Degrees of Freedom</strong></p>
<ol style="list-style-type: decimal">
<li>Generate <span class="math inline">\(\mathbf{Z}\)</span> as
multivariate normal with mean zero and covariance matrix <span
class="math inline">\(\mathbf{R}\)</span>.</li>
<li>Generate a scalar uniform random variable, <span
class="math inline">\(U\)</span>, independent of the vector <span
class="math inline">\(\mathbf{Z}\)</span>.</li>
<li>Letting <span class="math inline">\(F_{\mathrm{v}}\)</span> denote
the cdf of a chi-square random variable with <span
class="math inline">\(\mathrm{v}\)</span> degrees of freedom, calculate
<span class="math inline">\(d_{i}=\sqrt{F_{v_{i}}^{-1}(U) /
v_{i}}\)</span>, where <span class="math inline">\(v_{i}\)</span> is the
degrees of freedom for the <span class="math inline">\(i^{\text {th
}}\)</span> test statistic.</li>
<li>Define <span class="math inline">\(\mathbf{d}\)</span> as <span
class="math inline">\(\mathbf{d}=\operatorname{diag}\left\{d_{i}\right\}\)</span>,
and let <span class="math inline">\(\mathbf{T}=\mathbf{d}^{-1}
\mathbf{Z}\)</span>.</li>
<li>Let MaxT <span class="math inline">\(=\max
(\mathbf{T})\)</span>.</li>
</ol>
</div>
<div id="minp-method-under-heteroscedasticity" class="section level3">
<h3>MinP Method under Heteroscedasticity</h3>
<p>The potential inconsistency between MaxT and Bonferroni whenever the
T-statistics have different marginal distributions, which is the case
when there are differing degrees of freedom, or when the response is
discrete. Westfall and Young presented a solution <strong>based on the
minimum p-value instead of the maximum t value</strong>. This so-called
MinP method is available in PROC MULTTEST for nonparametric and
semiparametric applications</p>
<p>Construction of simultaneous confidence intervals, consider the
problem of obtaining balanced marginal confidence intervals with a
simulation-consistent method where the marginal t distributions have
varying degrees of freedom. It will need a different critical value
<span class="math inline">\(c_{i \alpha}\)</span> for every interval
<span class="math inline">\(\hat{\theta}_{i}-c_{i \alpha}\)</span> s.e.
<span class="math inline">\(\left(\hat{\theta}_{i}\right)\)</span>, and
you want the following to hold:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\quad P\left(\left|T_{i}\right|&lt;c_{i
\alpha}\right.\)</span>, all <span
class="math inline">\(\left.i\right)=1-\alpha\)</span>, so that the FWE
is <span class="math inline">\(\alpha\)</span>, and</li>
<li><span class="math inline">\(\quad P\left(\left|T_{i}\right|&lt;c_{i
\alpha}\right)=1-\alpha^{\prime}\)</span>, so that the marginal
confidence levels are the same value <span
class="math inline">\(1-\alpha^{\prime}\)</span>.</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
&amp; P\left(\left|T_{i}\right|&lt;F_{v_{i}}^{-1}\left(1-\alpha^{\prime}
/ 2\right), \text { all } i\right) &amp;=1-\alpha \\
\Leftrightarrow &amp;
P\left(F_{v_{i}}\left(\left|T_{i}\right|\right)&lt;1-\alpha^{\prime} /
2, \text { all } i\right) &amp;=1-\alpha \\
\Leftrightarrow &amp;
P\left(2\left\{1-F_{v_{i}}\left(\left|T_{i}\right|\right)\right\}&gt;\alpha^{\prime},
\text { all } i\right) &amp;=1-\alpha \\
\Leftrightarrow &amp; P\left(P_{i} \leq \alpha^{\prime}, \text { some }
i\right) &amp;=\alpha \\
\Leftrightarrow &amp; P\left(\min P_{i} \leq \alpha^{\prime}\right)
&amp;=\alpha
\end{aligned}
\]</span></p>
<p>where <span
class="math inline">\(P_{i}=2\left\{1-F_{v_{i}}\left(\left|T_{i}\right|\right)\right\}
.\)</span> Thus <span class="math inline">\(\alpha^{\prime}\)</span> is
the <span class="math inline">\(\alpha\)</span> quantile of the
distribution of the minimum <span class="math inline">\(p\)</span>
value- the MinP distribution, which can be computed by simulating
correlated <span class="math inline">\(T_{i}\)</span> values</p>
</div>
</div>
<div id="closed-and-stepwise-testing-methods" class="section level2">
<h2>Closed and Stepwise Testing Methods</h2>
<p><span class="math display">\[
\begin{array}{l}
\hline \text { if you... } \\
\hline \begin{array}{l}
\text { want to declare any significance, and are unsure } \\
\text { about dependence structure }
\end{array} &amp; \text { Bonferroni-Holm } \\
\hline \begin{array}{l}
\text { want to declare any significance and are reasonably} \\
\text { sure that the tests are independent or positively } \\
\text { dependent }
\end{array} &amp; \text { Simes-Hommel } \\  
\hline \begin{array}{l}
\text { want to declare any significance and are sure that } \\
\text { the tests are independent and strongly reinforcing }
\end{array} &amp; \text { closed Fisher combination } \\
\hline \begin{array}{l}
\text { want to declare significance only in a pre-assigned } \\
\text { order }
\end{array} &amp; \text { fixed sequence tests } \\
\hline \begin{array}{l}
\text { want to declare any significance among a collection } \\
\text { of secondary hypotheses, but only after } \\
\text { significance of a primary hypothesis is achieved }
\end{array} &amp;  \text {gatekeeper tests } \\
\hline
\end{array}
\]</span></p>
<div id="closed-family-of-hypotheses" class="section level3">
<h3>Closed Family of Hypotheses</h3>
<p><strong>Kohärenz and Konsonanz</strong></p>
<p>Ein multipler Test <span class="math inline">\(\varphi\)</span> für
<span class="math inline">\((\Omega, \mathcal{A}, \mathcal{P},
\mathcal{H})\)</span> heißt kohärent, falls <span
class="math display">\[
\forall i, j \in I \text { mit } H_{i} \subseteq
H_{j}:\left\{\varphi_{j}=1\right\}
\Rightarrow\left\{\varphi_{i}=1\right\}
\]</span> ist. Anderenfalls heißt <span
class="math inline">\(\varphi\)</span> inkohärent. Ein multipler Test
<span class="math inline">\(\varphi=\left(\varphi_{i}: i \in I=1,
\ldots, m\right)\)</span> für <span class="math inline">\((\Omega,
\mathcal{A}, \mathcal{P}, \mathcal{H})\)</span> heißt konsonant, falls
<span class="math display">\[
\forall i \in I \text { mit } \exists j \in I: H_{i} \subset
H_{j}:\left\{\varphi_{i}=1\right\} \subseteq \bigcup_{j: H_{j} \supset
H_{i}}\left\{\varphi_{j}=1\right\}
\]</span> Wird <span class="math inline">\(H i\)</span> von einem
konsonanten multiplen Test <span class="math inline">\(\varphi\)</span>
abgelehnt und gibt es echte Obermengen <span class="math inline">\(H
j\)</span> von <span class="math inline">\(H_{i}\)</span> in <span
class="math inline">\(\mathcal{H}\)</span>, so wird auch mindestens eine
dieser Obermengen von <span class="math inline">\(\varphi\)</span>
abgelehnt. Anderenfalls heißt <span
class="math inline">\(\varphi\)</span> dissonant.</p>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Close_Begin.PNG" alt="Figure: Closure Diagram with k=4 Basic Tests of Cold Remedy Endpoints" width="100%" />
<p class="caption">
Figure: Closure Diagram with k=4 Basic Tests of Cold Remedy Endpoints
</p>
</div>
<p><strong>The Closed Testing Method</strong></p>
<p>The closed diagram defined in the previous subsection is pretty
complicated, but it essentially gives you the entire flowchart for
performing the closed testing method. The method proceeds as
follows:</p>
<ul>
<li>Test every member of the closed family by a (suitable) <span
class="math inline">\(\alpha\)</span> -level test. (Here, <span
class="math inline">\(\alpha\)</span> refers to nominal comparison-wise
error rate.)</li>
<li>Reject a basic hypothesis if
<ul>
<li>ts corresponding <span class="math inline">\(\alpha\)</span> -level
test rejects it, and</li>
<li>every intersection hypothesis that includes it is also rejected by
its <span class="math inline">\(\alpha\)</span> -level test.</li>
</ul></li>
</ul>
<p>Thus, to determine whether the closed testing method rejects <span
class="math inline">\(H_{1}: \delta_{1}=0\)</span>, you must reject
<span class="math inline">\(H_{1}\)</span> using an <span
class="math inline">\(\alpha\)</span> -level test, and you must reject
each of <span class="math inline">\(H_{\{1,2\}}, H_{\{1,3\}},
H_{\{1,4\}}\)</span>, <span class="math inline">\(H_{\{1,2,3\}},
H_{\{1,2,4\}}, H_{\{1,3,4\}}\)</span>, and <span
class="math inline">\(H_{\{1,2,3,4\}}\)</span>, all using <span
class="math inline">\(\alpha\)</span> -level tests for each of these
composite hypotheses.</p>
<p><strong>Adjusted p-Values</strong></p>
<p>The adjusted <span class="math inline">\(p\)</span> -value for
hypothesis <span class="math inline">\(H_{i}\)</span> is the maximum of
all <span class="math inline">\(p\)</span> -values for all intersection
hypotheses in the closed family that includes <span
class="math inline">\(H_{i}\)</span> as part of the intersection;
formally, letting <span class="math inline">\(p_{S}\)</span> denote the
<span class="math inline">\(p\)</span> -value for testing an
intersection hypothesis <span class="math inline">\(H_{S}\)</span>,
where <span class="math inline">\(S \subseteq\{1, \ldots, k\}\)</span>,
<span class="math display">\[
\tilde{p}_{i}=\max _{\{S \mid i \in S\}} p_{S} .
\]</span></p>
</div>
<div id="bonferroni-holm-method" class="section level3">
<h3>Bonferroni-Holm Method</h3>
<p>The Bonferroni test for each member of the closed family. Denote by
<span class="math inline">\(p_{i}\)</span> the <span
class="math inline">\(p\)</span> -value for the basic hypothesis <span
class="math inline">\(H_{i}\)</span>. Then each composite hypothesis
<span class="math inline">\(H_{S}\)</span> will be tested by comparing
<span class="math inline">\(\min _{i \in S} p_{i}\)</span> with <span
class="math inline">\(\alpha / k^{*}\)</span>, where <span
class="math inline">\(k^{*}\)</span> is the number of hypotheses in the
set, also denoted by <span class="math inline">\(k^{*}=|S| .\)</span>
Equivalently, you can calculate the Bonferroni <span
class="math inline">\(p\)</span> -value for each test of the composite
hypotheses <span class="math inline">\(H_{S}\)</span> as <span
class="math inline">\(p_{S}=k^{*} \times\)</span> <span
class="math inline">\(\min _{i \in S} p_{i}\)</span></p>
<p><strong>The Bonferroni-Holm Shortcut Closed Testing Procedure
</strong></p>
<p>Let <span class="math inline">\(p_{(1)} \leq p_{(2)} \leq \ldots \leq
p_{(k)}\)</span> be the ordered <span class="math inline">\(p\)</span>
-values and <span class="math inline">\(H_{(1)}, H_{(2)}, \ldots,
H_{(k)}\)</span> be the corresponding hypotheses.</p>
<ul>
<li>Step 1. Start by comparing <span
class="math inline">\(p_{(1)}\)</span> with <span
class="math inline">\(\alpha / k\)</span>. If larger, stop and retain
all hypotheses <span class="math inline">\(H_{(1), \ldots,}
H_{(k)}\)</span>; otherwise, reject <span
class="math inline">\(H_{(1)}\)</span> and proceed.</li>
<li>Step 2. Compare <span class="math inline">\(p_{(2)}\)</span> with
<span class="math inline">\(\alpha /(k-1)\)</span>. If larger, stop and
retain <span class="math inline">\(H_{(2), \ldots} H_{(k)}\)</span>;
otherwise, reject <span class="math inline">\(H_{(2)}\)</span> and
proceed.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}-\mathbf{1}\)</span>.
Compare <span class="math inline">\(p_{(k-1)}\)</span> with <span
class="math inline">\(\alpha / 2\)</span>. If larger, stop and retain
<span class="math inline">\(H_{(k-1)}, H_{(k)}\)</span>; otherwise,
reject <span class="math inline">\(H_{(k-1)}\)</span> and proceed.</li>
<li>Step k. Compare <span class="math inline">\(p_{(k)}\)</span> with
<span class="math inline">\(\alpha\)</span>. If larger, stop and retain
<span class="math inline">\(H_{(k)}\)</span>; otherwise, reject <span
class="math inline">\(H_{(k)}\)</span>.</li>
</ul>
<p><strong>Bonferroni-Holm Adjusted p-Values</strong></p>
<p>Adjusted p-values make it simple to use multiple comparisons
procedures⎯all you need to do is compare the adjusted p-value to your
nominal FWE level.</p>
<ul>
<li>Step 1. For testing <span class="math inline">\(H_{(1)},
\tilde{p}_{(1)}=k p_{(1)}\)</span>.</li>
<li>Step 2. For testing <span class="math inline">\(H_{(2)},
\tilde{p}_{(2)}=\max \left(\tilde{p}_{(1)},(k-1)
p_{(2)}\right)\)</span>.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}-\mathbf{1}\)</span>.
For testing <span class="math inline">\(H_{(k-1)},
\tilde{p}_{(k-1)}=\max \left(\tilde{p}_{(k-2)}, 2 p_{(k-1)}\right)
.\)</span></li>
<li>Step <span class="math inline">\(\boldsymbol{k}\)</span>. For
testing <span class="math inline">\(H_{(k)}, \tilde{p}_{(k)}=\max
\left(\tilde{p}_{(k-1)}, p_{(k)}\right)\)</span>. A simple formula that
covers all steps is <span class="math display">\[
\tilde{p}_{(i)}=\max _{j \leq i}\left\{(k-j+1) p_{(j)}\right\} .
\]</span> Since there is no need to report any p-value to be greater
than 1.0 <span class="math display">\[
\tilde{p}_{(i)}=\min \left(1, \max _{j \leq i}\left\{(k-j+1)
p_{(j)}\right\}\right) .
\]</span></li>
</ul>
<p><strong>Calculating Bonferroni-Holm Adjusted p-Values Using PROC
MULTTEST</strong></p>
<pre><code>data prog13p1;
 input p @@;
 datalines;
0.0121 0.0142 0.1986 0.0191
;
proc multtest inpvalues(p)=prog13p1 holm;
run;</code></pre>
</div>
<div id="šidák-holm-method" class="section level3">
<h3>Šidák-Holm Method</h3>
<p><strong>The Šidák-Holm Shortcut Closed Testing Procedure</strong></p>
<ul>
<li>Step 1. Start by comparing <span
class="math inline">\(p_{(1)}\)</span> with <span
class="math inline">\(1-(1-\alpha)^{1 / k}\)</span>. If larger, stop and
retain all hypotheses <span class="math inline">\(H_{(1)}, \ldots,
H_{(k)} ;\)</span> otherwise, reject <span
class="math inline">\(H_{(1)}\)</span> and proceed.</li>
<li>Step 2. Compare <span class="math inline">\(p_{(2)}\)</span> with
<span class="math inline">\(1-(1-\alpha)^{1 /(k-1)}\)</span>. If larger,
stop and retain <span class="math inline">\(H_{(2)}, \ldots,
H_{(k)}\)</span>; otherwise, reject <span
class="math inline">\(H_{(2)}\)</span> and proceed.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}-\mathbf{1}\)</span>.
Compare <span class="math inline">\(p_{(k-1)}\)</span> with <span
class="math inline">\(1-(1-\alpha)^{1 / 2}\)</span>. If larger, stop and
retain <span class="math inline">\(H_{(k-1)}, H_{(k)}\)</span>;
otherwise, reject <span class="math inline">\(H_{(k-1)}\)</span> and
proceed.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}\)</span>. Compare
<span class="math inline">\(p^{(k)}\)</span> with <span
class="math inline">\(\alpha\)</span>. If larger, stop and retain <span
class="math inline">\(H^{(k)}\)</span>; otherwise, reject <span
class="math inline">\(H^{(k)}\)</span>.</li>
</ul>
<p>Equivalently, and more simply, the results of the Šidák-Holm shortcut
closed testing procedure can be displayed using adjusted <span
class="math inline">\(p\)</span> -values: <span class="math display">\[
\tilde{p}_{(i)}=\max _{j \leq
i}\left\{1-\left(1-p_{(j)}\right)^{k-j+1}\right\}
\]</span> Unlike the Bonferroni-Holm adjusted <span
class="math inline">\(p\)</span> -values, the Šidák-Holm adjustment
automatically satisfies <span class="math inline">\(\tilde{p}_{(i)} \leq
1.0\)</span>, so there is no need to truncate.</p>
<p><strong>Calculating Šidák-Holm Adjusted p-Values Using PROC
MULTTEST</strong></p>
<pre><code>data prog13p1;
 input p @@;
 datalines;
0.0121 0.0142 0.1986 0.0191
;
proc multtest inpvalues(p)=prog13p1 stepsid;
run;</code></pre>
</div>
<div id="closed-fisher-combination-method" class="section level3">
<h3>Closed Fisher Combination Method</h3>
<blockquote>
<p>Meta-analysis</p>
</blockquote>
<p>Composite hypotheses <span class="math inline">\(H_{S}\)</span> often
occur in meta-analysis. For example, suppose companies A, B, and <span
class="math inline">\(\mathrm{C}\)</span> all test a drug and find <span
class="math inline">\(p\)</span> -values <span
class="math inline">\(0.061,0.083\)</span>, and <span
class="math inline">\(0.089\)</span> for efficacy. Even though the <span
class="math inline">\(p\)</span> values individually are insignificant,
is this still the case under the composite null hypothesis that there is
no drug effect for all companies? Meta-analysis provides ways to combine
data from disparate studies to answer questions such as this, ideally
gaining power in alternative hypothesis directions of interest.</p>
<p>The Fisher combination test is popular in meta-analysis. Like the
Šidák test, the Fisher combination test assumes that the <span
class="math inline">\(p\)</span> -values are independent and uniformly
distributed <span class="math inline">\(\left(p_{i}
\sim_{\mathrm{iid}}\right.\)</span> <span
class="math inline">\(\mathrm{U}(0,1))\)</span> when the composite null
hypothesis is true. Suppose a generic composite hypothesis has <span
class="math inline">\(p\)</span> -values <span
class="math inline">\(p_{1}, \ldots, p_{k^{*}}\)</span> for the
component hypotheses. Then the Fisher combination test rejects the
composite hypothesis when <span class="math display">\[
\sum_{i=1}^{k^{*}}-2 \ln \left(p_{i}\right) \geq \chi_{2 k^{*},
1-\alpha}^{2}
\]</span> where <span class="math inline">\(\chi_{2 k^{*},
1-\alpha}^{2}\)</span> is the <span
class="math inline">\(1-\alpha\)</span> quantile of the chi-squared
distribution with <span class="math inline">\(2 k^{*}\)</span> degrees
of freedom.</p>
<blockquote>
<p>综合假设HS经常发生在荟萃分析中。
例如，假设公司A，B和C都对一种药物进行了测试，并且发现功效的p值分别为0.061、0.083和0.089。
即使各个p值无关紧要，但在所有公司都没有药物效应的复合无效假设下，情况是否仍然如此？
荟萃分析提供了各种方法，可将来自不同研究的数据相结合，以回答诸如此类的问题，理想情况下，可以在感兴趣的替代假设方向上获得影响力。
Fisher组合检验在荟萃分析中很流行。
像Šidák检验一样，Fisher组合检验假设当复合零假设为真时，p值是独立且均匀分布的.</p>
</blockquote>
<p><strong>Closed Fisher Combination Testing Using PROC
MULTTEST</strong></p>
<pre><code>data subgroups;
 input pval @@;
 datalines;
0.0784 0.0481 0.0041 0.0794
0.0043 0.0873 0.1007 0.1550
;
proc multtest inpvals(pval)=subgroups fisher_c;
run;</code></pre>
</div>
<div id="simes-hommel-method" class="section level3">
<h3>Simes-Hommel Method</h3>
<p>The Simes test (Simes, 1986 ) is another combination test, like the
Fisher combination test. It also assumes that the <span
class="math inline">\(p\)</span> -values are independent and uniformly
distributed <span class="math inline">\(\left(p_{i} \sim_{\text {iid }}
U(0,1)\right)\)</span> when the composite null hypothesis is true,
although it has been shown to be valid (in the sense of not exceeding
the nominal Type I error level) when the <span
class="math inline">\(p\)</span> -values exhibit positive dependence
structures as well (Sarkar, 1998). Suppose a generic composite test has
ordered <span class="math inline">\(p\)</span> -values <span
class="math inline">\(p_{(1)} \leq\)</span> <span
class="math inline">\(\ldots \leq p_{\left(k^{*}\right)}\)</span> for
the component tests. Then the Simes test rejects the composite
hypothesis when <span class="math display">\[
p_{\text {Simes }}=\min \left\{\frac{k^{*}}{1} p_{(1)}, \frac{k^{*}}{2}
p_{(2)}, \ldots, \frac{k^{*}}{k^{*}} p_{\left(k^{*}\right)}\right\} \leq
\alpha
\]</span></p>
<p>Notice that the Simes p-value is never larger than the p-value for
the simple Bonferroni test since <span class="math display">\[
p_{\text {Simes }} \leq k^{*} p_{(1)}=p_{\text {Bonferroni }}
\]</span></p>
<p><strong>Calculating Simes-Hommel Adjusted p-Values Using PROC
MULTTEST</strong></p>
<pre><code>data prog13p1;
 input p @@;
 datalines;
0.0121 0.0142 0.1986 0.0191
;
proc multtest inpvalues(p)=prog13p1 holm hommel;
run; </code></pre>
</div>
<div id="hochbergs-ok-step-up" class="section level3">
<h3>Hochberg’s O(k) Step-Up</h3>
<p>Hochberg (1988) devised a shortcut to the Simes-Hommel method that
can be computed in k steps, like the Bonferroni-Holm method. It is less
conservative than the Bonferroni-Holm method, but more conservative than
the Simes-Hommel method: The adjusted p-values mathematically are as
follows:</p>
<p><span class="math display">\[
\tilde{p}_{i, \text { Simes-Hommel }} \leq \tilde{p}_{i, \text {
Hochberg }} \leq \tilde{p}_{i, \text { Bonferroni-Holm }} \leq
\tilde{p}_{i, \text { Bonferroni }}
\]</span></p>
<p>The method’s justification rests on the validity of the Simes test,
meaning that it requires independence or positive dependence. It is very
similar to the Bonferroni-Holm method, except that the <span
class="math inline">\(p\)</span> -values are evaluated from least
significant to most significant. Hence, unlike the Bonferroni-Holm
method, which is sometimes called a “step-down” procedure, the Hochberg
method is called a “step-up” procedure. Here is the algorithm:</p>
<blockquote>
<p>该方法的合理性取决于Simes检验的有效性，这意味着它需要独立性或正相关性</p>
</blockquote>
<p><strong>Hochberg’s Conservative Shortcut to the Simes-Hommel Closed
Testing Procedure</strong></p>
<ul>
<li>Step 1. Start by comparing <span
class="math inline">\(p_{(k)}\)</span> with <span
class="math inline">\(\alpha\)</span>. If smaller than or equal to <span
class="math inline">\(\alpha\)</span>, stop and reject all hypotheses
<span class="math inline">\(H_{(1), \ldots,} H_{(k)} ;\)</span>
otherwise, retain <span class="math inline">\(H_{(k)}\)</span> and
proceed.</li>
<li>Step 2. Compare <span class="math inline">\(p_{(k-1)}\)</span> with
<span class="math inline">\(\alpha / 2\)</span>. If smaller than or
equal to <span class="math inline">\(\alpha / 2\)</span>, stop and
reject all <span class="math inline">\(H_{(1), \ldots}\)</span> <span
class="math inline">\(H_{(k-1)}\)</span>; otherwise, retain <span
class="math inline">\(H_{(k-1)}\)</span> and proceed. <span
class="math inline">\(\cdots\)</span></li>
<li>Step <span class="math inline">\(\boldsymbol{k}-\mathbf{1}
.\)</span> Compare <span class="math inline">\(p_{(2)}\)</span> with
<span class="math inline">\(\alpha /(k-1)\)</span>. If smaller than or
equal to <span class="math inline">\(\alpha /(k-1)\)</span>, stop and
reject <span class="math inline">\(H_{(1)}, H_{(2)}\)</span>; otherwise,
retain <span class="math inline">\(H_{(2)}\)</span> and proceed.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}\)</span>. Compare
<span class="math inline">\(p_{(1)}\)</span> with <span
class="math inline">\(\alpha / k\)</span>. If smaller than or equal to
<span class="math inline">\(\alpha / k\)</span>, reject <span
class="math inline">\(H_{(1)}\)</span>; otherwise, retain <span
class="math inline">\(H_{(1)}\)</span>.</li>
</ul>
<p>The adjusted <span class="math inline">\(p\)</span> -values for this
procedure are written simply as <span class="math display">\[
\tilde{p}_{(i)}=\min _{i \leq j}\left\{(k-j+1) p_{(j)}\right\} \text { .
}
\]</span></p>
</div>
<div id="sequential-testing-with-fixed-sequences"
class="section level3">
<h3>Sequential Testing with Fixed Sequences</h3>
<p>Suppose your hypotheses follow a logical sequence, in the sense that
<span class="math inline">\(H_{1}\)</span> precedes (in implication or
importance) <span class="math inline">\(H_{2}, H_{2}\)</span> precedes
<span class="math inline">\(H_{3}\)</span>, and so on. Then you can test
them in order: first test <span class="math inline">\(H_{1}\)</span>,
and if rejected, then test <span class="math inline">\(H_{2}\)</span>,
and if rejected, then test <span class="math inline">\(H_{3}\)</span>,
etc. In contrast to the examples of the previous sections, the order of
the hypotheses in this application is determined a priori by the
researcher, rather than determined a posteriori by the ordering of the
<span class="math inline">\(p\)</span> -values.</p>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Sequential_testing.png" alt="Figure: Fixed Sequence as a Closed Testing Procedure" width="100%" />
<p class="caption">
Figure: Fixed Sequence as a Closed Testing Procedure
</p>
</div>
<p><strong>Adjusted p-Values for Fixed Sequence Testing</strong></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\tilde{p}_{1}=p_{1}\)</span></li>
<li><span class="math inline">\(\tilde{p}_{2}=\max \left(\tilde{p}_{1},
p_{2}\right)\)</span></li>
<li><span class="math inline">\(\tilde{p}_{3}=\max \left(\tilde{p}_{2},
p_{3}\right)\)</span></li>
<li>…</li>
</ol>
<p><strong>Adjusted p-Values from Fixed-Sequence Tests</strong></p>
<pre><code>data a;
 input p @@;
 if (_N_ = 1) then pseq = 0;
 pseq = max(pseq,p);
 retain pseq;
 datalines;
0.021 0.043 0.402 0.004
;
run;</code></pre>
</div>
<div id="sequential-testing-using-gatekeeping-methods"
class="section level3">
<h3>Sequential Testing Using Gatekeeping Methods</h3>
<p>Gatekeeping methods are a slight variation on fixed sequence methods.
They are used when there is one test of primary importance, and several
other tests (say <span class="math inline">\(h\)</span> ) of more or
less <strong>equal importance</strong>. The family of tests includes all
<span class="math inline">\(k=h+1\)</span> hypotheses.</p>
<p>The method is described simply: First, test the primary hypothesis at
level <span class="math inline">\(\alpha\)</span>. If insignificant, do
no further testing. If significant, test all <span
class="math inline">\(h\)</span> secondaries at familywise <span
class="math inline">\(\alpha\)</span> level for the <span
class="math inline">\(h\)</span> remaining hypotheses. For example if
there are <span class="math inline">\(h=3\)</span> secondaries and you
are using the single-step Bonferroni method of Chapter 2, you would use
<span class="math inline">\(\alpha / 3\)</span> rather than <span
class="math inline">\(\alpha / 4\)</span> for the secondaries, despite
the fact that the method controls the FWE for all <span
class="math inline">\(k=4\)</span> tests.</p>
<p>The benefits of the gatekeeping method are - no need to adjust the
primary test for multiplicity at all - smaller family size for the
secondaries</p>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Sequential_Gatekeeping_testing.png" alt="Figure: Gatekeeping as a Closed Testing Procedure" width="100%" />
<p class="caption">
Figure: Gatekeeping as a Closed Testing Procedure
</p>
</div>
</div>
</div>
<div id="closed-testing-of-pairwise-comparisons-and-general-contrasts"
class="section level2">
<h2>Closed Testing of Pairwise Comparisons and General Contrasts</h2>
<div id="incorporating-logical-constraints" class="section level3">
<h3>Incorporating Logical Constraints</h3>
<p><strong>Here is a graphical display of the closed family of all
pairwise comparisons.</strong></p>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/all_pairwise_comparisons.png" alt="Figure: Closed Family of All Pairwise Comparisons" width="100%" />
<p class="caption">
Figure: Closed Family of All Pairwise Comparisons
</p>
</div>
<p><strong>logical constraints</strong></p>
<p>The reduced size of the closure tree in the case of all pairwise
comparisons can be attributed to logical constraints among the
hypotheses. If <span class="math inline">\(H_{12}:
\mu_{1}=\mu_{2}\)</span> is true and <span class="math inline">\(H_{23}:
\mu_{2}=\mu_{3}\)</span> is true, then logically, <span
class="math inline">\(H_{13}: \mu_{1}=\mu_{3}\)</span> is constrained to
be true.</p>
<p><strong>truncated closed testing</strong></p>
<p>Uses a special, order-dependent form of closed testing called
truncated closed testing, in which inferences are constrained to be
performed in the order of their unadjusted p-values: if a hypothesis H
is accepted/rejected using the truncated closed testing method, then no
hypothesis with a larger/smaller unadjusted p-value will be
rejected/accepted. Equivalently, the method of performing such a
multiple comparisons procedure has the following general form.</p>
<p>Order the hypotheses <span class="math inline">\(H_{(1)}, \ldots,
H_{(k)}\)</span> by the strength of the evidence for them based on the
data, <span class="math inline">\(H_{(1)}\)</span> being the most
“significant.”</p>
<ol style="list-style-type: decimal">
<li>If the test for <span class="math inline">\(H_{(1)}\)</span> is not
significant using closed testing, then stop and reject no hypothesis;
otherwise, reject <span class="math inline">\(H_{(1)}\)</span> and
continue.</li>
<li>If the test for <span class="math inline">\(H_{(2)}\)</span> is not
significant using closed testing, then stop and reject no hypothesis
among <span class="math inline">\(\left.H_{(2)}, \ldots, H_{(k
k}\right)\)</span>; otherwise, reject <span
class="math inline">\(H_{(2)}\)</span> and continue.</li>
<li>If the test for <span class="math inline">\(H_{(3)}\)</span> is not
significant using closed testing, then stop and reject no hypothesis
among <span class="math inline">\(H_{(3)}, \ldots, H_{(k k)}\)</span>;
otherwise, reject <span class="math inline">\(H_{(3)}\)</span> and
continue.</li>
</ol>
<p><strong>Difference</strong></p>
<ul>
<li>General closure: no order restriction for hypotheses in general
closure. General closure allows you to test hypotheses in any order;
hence it always finds as many rejections as truncated closure, and
perhaps more.</li>
<li>Order constraint for truncated closed testing: benefit is that it
guarantees that the order of multiplicity-adjusted inferences (from most
to least significant) never contradicts the corresponding order of the
unadjusted inferences. Truncated closure protects the FWE and has
inherently better computational order than general closure, at the
potential cost of a small amount of power; experience shows that such
power loss is negligible.</li>
</ul>
<p>Different truncated closed testing procedures are distinguished by
how the hypotheses are ordered and by how they are tested at each step.
For example, the Bonferroni-Holm testing procedure orders hypotheses by
their raw <span class="math inline">\(p\)</span> -values and tests <span
class="math inline">\(H_{(i)}\)</span> by comparing <span
class="math inline">\(p_{(i)}\)</span> to the critical value <span
class="math inline">\(\alpha /(k-i+1)\)</span>. Shaffer’s method uses
the same initial ordering but has different critical values.</p>
</div>
<div id="shaffers-method" class="section level3">
<h3>Shaffer’s Method</h3>
<p>As with Bonferroni-Holm, hypotheses are ordered by their <strong>raw
<span class="math inline">\(p\)</span> -values</strong>; however,
instead of testing <span class="math inline">\(H_{(i)}\)</span> by
comparing <span class="math inline">\(p_{(i)}\)</span> to <span
class="math inline">\(\alpha(k-i+1)\)</span>, you <strong>compare it to
<span class="math inline">\(\alpha / k_{i}\)</span></strong>, where
<span class="math inline">\(k_{i}\)</span> is the maximum subset size of
hypotheses among <span class="math inline">\(H_{(i)}, \ldots,
H_{(k)}\)</span> that include <span
class="math inline">\(H_{(i)}\)</span> and can possibly be true, given
that <span class="math inline">\(H_{(1)}, \ldots\)</span> <span
class="math inline">\(H_{(i-1)}\)</span> are false. Of course, <span
class="math inline">\(k_{i}\)</span> can be no larger than <span
class="math inline">\(k-i+1\)</span>, but as you saw above, it can be
much smaller, making Shaffer’s method more powerful. Shaffer’s method is
implemented in many SAS procedures using the STEPDOWN option of LSMEANS,
along with the TYPE=LOGICAL suboption. The REPORT option displays the
Bonferroni divisors <span class="math inline">\(k_{2}, k_{3},
\ldots\)</span> and other information.</p>
<pre><code>data Anova1;
 input G Y @@;
 datalines;
1 9.0 1 11.0
2 9.1 2 9.2 2 9.9 2 11.9 2 11.9 2 12.4 2 8.5 2 10.4 2 11.8 2 9.6
3 10.3 3 8.2 3 10.5 3 10.5 3 10.8 3 11.5 3 8.6 3 10 3 10.4 3 9.6
4 12.6 4 11.2 4 11.7 4 11.2 4 13 4 11.9 4 14 4 11.5 4 10.5 4 10.4
;
proc orthoreg data=Anova1;
 class G;
 model Y = G;
 lsmeans G / pdiff stepdown(type=logical report);
run;</code></pre>
<p><span class="math display">\[
\begin{array}{l}
\hline
\text { Logically Consistent Step-wise Subsets } \\
\hline
\text { Subset Step Size } 1 &amp; \text { Hypotheses } \\
\hline
1 &amp; 1 &amp; 6 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
2 &amp; 2 &amp; 3 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
3 &amp; 2 &amp; 2 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
4 &amp; 3 &amp; 2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
5 &amp; 4 &amp; 3 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
6 &amp; 5 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
7 &amp; 6 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\hline
\end{array}
\]</span></p>
</div>
<div id="extended-shaffer-royen-method" class="section level3">
<h3>Extended Shaffer-Royen Method</h3>
<p>The step-down methods for all pairwise comparisons discussed thus far
have been based on the Bonferroni inequality, whose fundamental feature
is that it <strong>ignores random correlations between the hypotheses
being tested</strong>. As with single-step methods, you can use the true
distribution of the MaxT statistic to sharpen step-down comparisons by
taking correlations into account</p>
<blockquote>
<p>到目前为止讨论的所有成对比较的降压方法都是基于Bonferroni不等式的，其基本特征是它忽略了被测假设之间的随机相关性。</p>
</blockquote>
<p><strong>Using Correlations to Improve Holm’s Step-Down Method:
Sequential Testing Method</strong></p>
<p>The hypotheses are ordered by their corresponding test statistics
<span class="math inline">\(t_{(1)} \geq \ldots \geq t_{(k)}\)</span>,
and <span class="math inline">\(H_{(i)}\)</span> is tested by comparing
<span class="math inline">\(t_{(i)}\)</span> to <span
class="math inline">\(c_{i \alpha}\)</span>, the <span
class="math inline">\(1-\alpha\)</span> quantile of the distribution of
<span class="math inline">\(\max _{j \in S_{i} T_{j}}\)</span>, where
<span class="math inline">\(S_{i}\)</span> is the set of all hypotheses
not yet rejected at stage <span class="math inline">\(i\)</span>. The
results of the procedure can be re-expressed using adjusted <span
class="math inline">\(p\)</span> -values:</p>
<ul>
<li>Stage 1: <span class="math inline">\(\tilde{p}_{(1)}=P\left(\max _{i
\in\{1, \ldots, k\}} T_{i} \geq t_{(1)}\right)\)</span></li>
<li>Stage 2: <span class="math inline">\(\tilde{p}_{(2)}=\max
\left\{\tilde{p}_{(1)}, P\left(\max _{i \in S_{2}} T_{i} \geq
t_{(2)}\right)\right\}\)</span> <span
class="math inline">\(\cdots\)</span></li>
<li>Stage <span class="math inline">\(\boldsymbol{k}:
\tilde{p}_{(k)}=\max \left\{\tilde{p}_{(k-1)},
p_{(k)}\right\}\)</span></li>
</ul>
<p><strong>The Effect of Using Correlations in Step-Down
Tests</strong></p>
<pre><code>***Bonferroni-Holm method;
proc orthoreg data=Anova1;
 class G;
 model Y = G;
 lsmeans G / stepdown(type=free);
 ods select diffs;
run;

***correlation-based free step-down method:
proc orthoreg data=Anova1;
 class G;
 model Y = G;
 lsmeans G / adjust=simulate(acc=0.0005 seed=121211)
 stepdown(type=free);
 ods select diffs;
run; </code></pre>
<p><strong>Extended Shaffer-Royen (ESR)</strong></p>
<p>Because the Holm-Simulated method accounts for correlations, the
adjusted p-values are smaller than those obtained using the Bonferroni
inequality; i.e., they are smaller than the Bonferroni-Holm adjusted
p-values. But you can do even better. Instead of using the Holm method
(via either simulation or Bonferroni’s inequality), which does not
account for logical constraints, you can reduce the subset sizes for
which the critical values and adjusted p-values are obtained, and
calculate the values again by simulating MaxT for all the subsets. This
method is called the Extended Shaffer-Royen (ESR) method, after Shaffer
(1986), who pioneered the method for finding the logical restrictions,
and Royen (1989), who incorporated correlations in the balanced
ANOVA.</p>
<blockquote>
<p>Holm-Simulated方法考虑了相关性，所以调整后的p值小于使用Bonferroni不等式获得的p值。
即，它们小于Bonferroni-Holm调整后的p值。 但是您可以做得更好。
代替使用不考虑逻辑约束的Holm方法（通过仿真或Bonferroni不等式），您可以减少获得临界值和调整后的p值的子集大小，然后通过模拟MaxT再次计算值
对于所有子集。 这种方法被称为扩展Shaffer-Royen（ESR）方法</p>
</blockquote>
<pre><code>proc orthoreg data=Anova1;
 class G;
 model Y = G;
 lsmeans G / adjust=simulate(acc=0.0005 seed=121211)
 stepdown(type=logical);
 ods select diffs;
run;</code></pre>
</div>
<div id="step-down-dunnett-test" class="section level3">
<h3>Step-down Dunnett test</h3>
<p>The test was based on the calculation of a common critical point that
exploits the correlation structure among the statistics, which are just
the familiar pairwise t-tests of all group means with the control
mean.</p>
<p>There are three pairwise hypotheses of interest, namely, <span
class="math inline">\(\mu_{0}=\mu_{1}, \mu_{0}=\mu_{2}\)</span>, and
<span class="math inline">\(\mu_{0}=\mu_{3}\)</span>. To form the closed
family, you take all intersections among these pairwise hypotheses, and
you get the following family:</p>
<ul>
<li>The original two-means homogeneity hypotheses: <span
class="math inline">\(\mu_{0}=\mu_{1}, \mu_{0}=\mu_{2}\)</span>, and
<span class="math inline">\(\mu_{0}=\mu_{3}\)</span>.</li>
<li>The three-means homogeneity hypotheses: <span
class="math inline">\(\mu_{0}=\mu_{1}=\mu_{2},
\mu_{0}=\mu_{1}=\mu_{3}\)</span>, and <span
class="math inline">\(\mu_{0}=\mu_{2}=\mu_{3}\)</span>.</li>
<li>The four-means homogeneity hypothesis: <span
class="math inline">\(\mu_{0}=\mu_{1}=\mu_{2}=\mu_{3}\)</span>.</li>
</ul>
<p><strong>Key point</strong>: Dunnett comparisons are not logically
restricted; truth of any subset of <span
class="math inline">\(\mu_{0}=\mu_{1}, \mu_{0}=\mu_{2}\)</span>, and
<span class="math inline">\(\mu_{0}=\mu_{3}\)</span> does not imply
truth of a hypothesis outside the subset. So there is th full collection
of <span class="math inline">\(2^{3}-1=7\)</span> hypotheses in this
example.</p>
<div class="figure" style="text-align: center">
<img src="02_Plots/ANOVA/Dunnett_Close_Test.png" alt="Figure: Closed Family of Tests Based on Pairwise Comparisons with a Control" width="100%" />
<p class="caption">
Figure: Closed Family of Tests Based on Pairwise Comparisons with a
Control
</p>
</div>
<p><strong>SAS Implementation</strong></p>
<pre><code>*** &quot;By Hand” Calculation of Lower-Tailed Step-Down Dunnett Critical Values;
data _null_;
 dfe = 21;
 do j1=1 to 6;
 j = 6-j1+1;
 c_j = -probmc(&quot;DUNNETT1&quot;,.,.95,dfe,j);
 put j= c_j= 6.3;
 end;
run; 

*** Step-Down Dunnett Tests;
proc orthoreg data=Tox;
 class Trt;
 model Gain=Trt;
 lsmeans Trt / adjust=dunnett pdiff=controll stepdown;
run;</code></pre>
<p><strong>R Implementation</strong></p>
<pre class="r"><code># library(&quot;multcomp&quot;)
data(&quot;recovery&quot;, package = &quot;multcomp&quot;)
recovery.aov &lt;- aov(minutes ~ blanket, data = recovery)
recovery.mc &lt;- glht(recovery.aov,
                    linfct = mcp(blanket = &quot;Dunnett&quot;),
                    alternative = &quot;less&quot;) 
summary(recovery.mc, test = adjusted(type = &quot;free&quot;))</code></pre>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Dunnett Contrasts
## 
## 
## Fit: aov(formula = minutes ~ blanket, data = recovery)
## 
## Linear Hypotheses:
##              Estimate Std. Error t value   Pr(&lt;t)    
## b1 - b0 &gt;= 0  -2.1333     1.6038  -1.330   0.0958 .  
## b2 - b0 &gt;= 0  -7.4667     1.6038  -4.656 5.58e-05 ***
## b3 - b0 &gt;= 0  -1.6667     0.8848  -1.884   0.0640 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- free method)</code></pre>
</div>
</div>
<div id="multiple-comparisons-with-binary-data" class="section level2">
<h2>Multiple Comparisons with Binary Data</h2>
<div id="introduction-3" class="section level3">
<h3>Introduction</h3>
<blockquote>
<p>对于典型的连续响应数据，考虑相关性的多重性调整并不是全部这与基于Bonferroni的简单调整有很大不同。可以肯定的是，合并相关性时，调整后的p值会稍小一些，并且在多个测试中，只要有可能，就应该合并相关性结构。但在大多数情况下，如果使用连续数据，则改进不会明显好于Bonferroni。
二进制数据，合并相关性的确比Bonferroni方法带来了真正的显着改进。如果使用正确的多重调整并结合了分布的离散性质，则调整后的p值很容易是Bonferronia调整后的p值的十分之一！</p>
</blockquote>
<p>The method for calculating adjusted <span
class="math inline">\(p\)</span> -values in the binary case is identical
to that for the continuous case discussed in Chapter <span
class="math inline">\(16-\)</span> namely, adjusted <span
class="math inline">\(p\)</span> -values are based on the distribution
of the minimum <span class="math inline">\(p\)</span> -value, <span
class="math display">\[
\tilde{p}_{j}=P\left(\min _{i} P_{i} \leq p_{j}\right)
\]</span> The thing is, with discrete data, the random <span
class="math inline">\(p\)</span> -values <span
class="math inline">\(P_{i}\)</span> for some individual tests may never
be very small, so effectively they don’t really contribute to <span
class="math inline">\(\min P_{i}\)</span>. This makes <span
class="math inline">\(\min P_{i}\)</span> larger than might have been
expected, which in turn makes the adjusted <span
class="math inline">\(p\)</span> -value <span
class="math inline">\(P\left(\min _{i} P_{i} \leq p_{j}\right)\)</span>
smaller. That is, with discrete data, you don’t necessarily need to
adjust for all hypotheses <span class="math inline">\(H_{j} .\)</span>
The <strong>resampling-based methods</strong> automatically discount
hypotheses where data are sparse. They achieve this by operating on the
appropriate underlying discrete</p>
<blockquote>
<p>在二进制情况下，计算调整后的p值的方法与第16章中讨论的连续情况相同，即调整后的p值基于最小p值（min）的分布。问题在于，对于离散数据，某些单个测试的随机p值可能永远不会很小，因此实际上它们并没有真正影响最小Pi。这使min
Pi大于预期，从而使调整后的p值P（mini
Pi≤pj）较小。也就是说，对于离散数据，您不一定需要针对所有假设Hj进行调整。</p>
</blockquote>
<blockquote>
<p>PROC MULTTEST 允许使用自举或置换重采样(Bootstrap and Permutation
Resampling)来放宽正态性假设。</p>
</blockquote>
</div>
<div id="multivariate-two-sample-binary-outcomes"
class="section level3">
<h3>Multivariate Two-Sample Binary Outcomes</h3>
<p>The case of multivariate two-sample analysis is a case where
<strong>permutation analysis</strong> can provide exact tests under
global permutation resampling.</p>
<p><strong>Example: Adverse Events in Clinical Trials</strong></p>
<blockquote>
<p>件必须在人类受试者上测试新药的安全性和有效性。安全性研究得出的数据通常具有多元二进制形式，即几个不良事件（即副作用）中的每一个的0/1指标。通常可能会发生很多不良事件，并且如果在不进行多重性调整的情况下测试所有此类事件，则可能会出现假阳性结果。这就是说，尽管药物通常确实有副作用，但基于简单的p≤0.05规则的统计确定可能会错误地过多地标记副作用。与任何筛选程序一样，存在错误和成本。不良事件分析中的I型错误意味着声称该药物实际上没有这种作用时会引起某种问题（例如头痛）。此类I类错误的成本包括药品的延迟批准，甚至可能取消优质药品的开发，这给制药公司和消费者都带来了成本。如果竞争对手生产基本上等同的药物，并且（正确地）发现不存在此类不良事件，那么I型错误的代价也可能非常高昂。</p>
</blockquote>
<blockquote>
<p>另一方面，II型错误（无法检测到真正的副作用的严重性）也非常严重，因为它们可能给公众造成不必要的痛苦，并可能给制药公司提起诉讼。由于担心II型错误，一些人提倡不强调多重性问题，甚至在未经调整的=
0.10水平上单独分析所有潜在的副作用。
另一方面，同时提供经过多重调整的p值和未经调整的p值当然是合理的，以评估任何不良事件研究的多重性问题的程度。理性地控制具有多种副作用的I型错误的可能性增加，而不是仅仅忽略它们。也就是说，由于类型I错误可能并且确实发生，因此数据分析应该以某种直接的方式来确认这一事实。
PROC
MULTTEST的离散多重性调整方法为处理多重性问题提供了一种简单，有效且功能强大的方法</p>
</blockquote>
<p><strong>Resampling-Based Multiplicity Adjustment</strong></p>
<blockquote>
<p>研究了对照组和治疗组的反应，注意到27种不同不良事件的发生率。
第28个“事件”被定义为其他事件的组合，对于每组，数据表示为受试者总数，无不良事件发生的人数。
然后针对其他主题，分别列出不良事件的数量和发生的原因。</p>
</blockquote>
<pre><code>data Adverse; keep Group AE1-AE28;
 array AE{28};
 length Group $ 9;
 input Group nTotal nNone;
 do i = 1 to dim(AE); AE{i} = 0; end;
 do iobs = 1 to nNone; output; end;
 do iobs = 1 to nTotal-nNone;
 input nAE @@;
 do i = 1 to dim(AE); AE{i} = 0; end;
 do i = 1 to nAE; input iAE @@; AE{iAE} = 1; end;
 output;
 end;
 datalines;
Control 80 46
4 2 3 17 28 2 18 28 2 2 28 3 4 22 28
3 1 3 28 2 1 28 4 2 3 11 28 2 2 28
3 12 27 28 2 1 28 3 2 19 28 3 1 9 28
2 14 28 2 7 28 2 4 28 2 4 28
2 2 28 2 3 28 4 1 4 9 28 3 1 26 28
2 1 28 3 5 12 28 2 2 28 2 4 28
3 5 13 28 2 16 28 2 9 28 3 1 2 28
2 24 28 2 2 28 2 7 28 2 7 28
2 25 28 5 3 14 19 21 28
Treatment 80 44
2 23 28 2 1 28 3 1 4 28 2 2 28
2 1 28 4 1 3 6 28 4 1 5 8 28 3 1 21 28
3 1 10 28 3 3 8 28 5 1 2 3 10 28 3 2 15 28
2 1 28 3 2 6 28 4 1 5 9 28 3 1 5 28
3 1 15 28 2 7 28 2 7 28 3 1 8 28
3 1 6 28 3 1 3 28 3 1 6 28 3 2 8 28
3 1 4 28 3 1 2 28 3 1 20 28 3 1 4 28
3 1 2 28 2 1 28 4 1 5 16 28 3 2 8 28
2 1 28 4 1 4 5 28 2 3 28 2 3 28
;
proc multtest data=Adverse stepperm seed=121211 n=100000;
 class Group;
 test fisher(AE1-AE28/upper);
 contrast &quot;Treatment-Control&quot; -1 1;
 ods output Discrete=Discrete;
 ods output pValues=pValues;
run;
proc transpose data=Discrete(rename=(Group=_NAME_))
 out =Discrete(drop =_NAME_ );
 by notsorted Variable;
 var Percent;
data pValues; merge Discrete pValues;
 drop Contrast;
proc rank data=pValues out=pValues;
 var Raw;
 ranks Rank; 
proc print data=pValues noobs label;
 where (Rank &lt;= 6);
 var Variable Control Treatment Raw StepdownPermutation;
 title &quot;Fisher Exact (Raw) and Multivariate Permutation-Adjusted pValues&quot;;
run;
title;</code></pre>
</div>
</div>
</div>
<div id="reference" class="section level1">
<h1>Reference</h1>
<p>Andrew Rutherford, Introducing Anova and Ancova: A GLM Approach <a
href="https://books.google.co.uk/books/about/Introducing_Anova_and_Ancova.html?id=T6uvhsy8d_8C&amp;source=kp_book_description&amp;redir_esc=y"
class="uri">https://books.google.co.uk/books/about/Introducing_Anova_and_Ancova.html?id=T6uvhsy8d_8C&amp;source=kp_book_description&amp;redir_esc=y</a></p>
<p>One-Way ANOVA Test in R <a
href="https://www.sthda.com/english/wiki/one-way-anova-test-in-r?title=one-way-anova-test-in-r"
class="uri">https://www.sthda.com/english/wiki/one-way-anova-test-in-r?title=one-way-anova-test-in-r</a></p>
<p>Two-Way ANOVA Test in R <a
href="https://www.sthda.com/english/wiki/two-way-anova-test-in-r?title=two-way-anova-test-in-r"
class="uri">https://www.sthda.com/english/wiki/two-way-anova-test-in-r?title=two-way-anova-test-in-r</a></p>
<p>MANOVA Test in R: Multivariate Analysis of Variance <a
href="https://www.sthda.com/english/wiki/manova-test-in-r-multivariate-analysis-of-variance?title=manova-test-in-r-multivariate-analysis-of-variance"
class="uri">https://www.sthda.com/english/wiki/manova-test-in-r-multivariate-analysis-of-variance?title=manova-test-in-r-multivariate-analysis-of-variance</a></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
